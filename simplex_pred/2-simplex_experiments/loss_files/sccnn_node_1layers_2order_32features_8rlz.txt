epoch 0, loss: 0.701092
model updated at epoch 0 
epoch 0, 
 train loss: 0.701092, val loss: 0.701428 
 val auc: 0.486336,  test auc: 0.458296
epoch 1, loss: 0.695636
model updated at epoch 1 
epoch 1, 
 train loss: 0.695636, val loss: 0.695853 
 val auc: 0.491667,  test auc: 0.472945
epoch 2, loss: 0.691280
model updated at epoch 2 
epoch 2, 
 train loss: 0.691280, val loss: 0.691536 
 val auc: 0.497973,  test auc: 0.494707
epoch 3, loss: 0.687881
model updated at epoch 3 
epoch 3, 
 train loss: 0.687881, val loss: 0.688382 
 val auc: 0.507920,  test auc: 0.516423
epoch 4, loss: 0.685148
model updated at epoch 4 
epoch 4, 
 train loss: 0.685148, val loss: 0.686055 
 val auc: 0.520158,  test auc: 0.533896
epoch 5, loss: 0.682763
model updated at epoch 5 
epoch 5, 
 train loss: 0.682763, val loss: 0.684215 
 val auc: 0.528791,  test auc: 0.547476
epoch 6, loss: 0.680537
model updated at epoch 6 
epoch 6, 
 train loss: 0.680537, val loss: 0.682632 
 val auc: 0.538138,  test auc: 0.559947
epoch 7, loss: 0.678289
model updated at epoch 7 
epoch 7, 
 train loss: 0.678289, val loss: 0.681124 
 val auc: 0.549137,  test auc: 0.571884
epoch 8, loss: 0.675974
model updated at epoch 8 
epoch 8, 
 train loss: 0.675974, val loss: 0.679574 
 val auc: 0.558671,  test auc: 0.585492
epoch 9, loss: 0.673615
model updated at epoch 9 
epoch 9, 
 train loss: 0.673615, val loss: 0.677994 
 val auc: 0.568168,  test auc: 0.599043
epoch 10, loss: 0.671269
model updated at epoch 10 
epoch 10, 
 train loss: 0.671269, val loss: 0.676485 
 val auc: 0.576764,  test auc: 0.612312
epoch 11, loss: 0.668939
model updated at epoch 11 
epoch 11, 
 train loss: 0.668939, val loss: 0.675087 
 val auc: 0.583483,  test auc: 0.623827
epoch 12, loss: 0.666676
model updated at epoch 12 
epoch 12, 
 train loss: 0.666676, val loss: 0.673807 
 val auc: 0.591291,  test auc: 0.631588
epoch 13, loss: 0.664424
model updated at epoch 13 
epoch 13, 
 train loss: 0.664424, val loss: 0.672559 
 val auc: 0.597710,  test auc: 0.636402
epoch 14, loss: 0.662219
model updated at epoch 14 
epoch 14, 
 train loss: 0.662219, val loss: 0.671381 
 val auc: 0.601614,  test auc: 0.638420
epoch 15, loss: 0.659988
model updated at epoch 15 
epoch 15, 
 train loss: 0.659988, val loss: 0.670191 
 val auc: 0.604542,  test auc: 0.640175
epoch 16, loss: 0.657702
model updated at epoch 16 
epoch 16, 
 train loss: 0.657702, val loss: 0.668929 
 val auc: 0.607020,  test auc: 0.642145
epoch 17, loss: 0.655402
model updated at epoch 17 
epoch 17, 
 train loss: 0.655402, val loss: 0.667557 
 val auc: 0.610473,  test auc: 0.645036
epoch 18, loss: 0.653109
model updated at epoch 18 
epoch 18, 
 train loss: 0.653109, val loss: 0.666152 
 val auc: 0.612538,  test auc: 0.647260
epoch 19, loss: 0.650837
model updated at epoch 19 
epoch 19, 
 train loss: 0.650837, val loss: 0.664732 
 val auc: 0.614077,  test auc: 0.649371
epoch 20, loss: 0.648571
model updated at epoch 20 
epoch 20, 
 train loss: 0.648571, val loss: 0.663336 
 val auc: 0.616404,  test auc: 0.651567
epoch 21, loss: 0.646295
model updated at epoch 21 
epoch 21, 
 train loss: 0.646295, val loss: 0.661942 
 val auc: 0.618093,  test auc: 0.653604
epoch 22, loss: 0.644035
model updated at epoch 22 
epoch 22, 
 train loss: 0.644035, val loss: 0.660604 
 val auc: 0.620308,  test auc: 0.655696
epoch 23, loss: 0.641725
model updated at epoch 23 
epoch 23, 
 train loss: 0.641725, val loss: 0.659231 
 val auc: 0.623011,  test auc: 0.658756
epoch 24, loss: 0.639383
model updated at epoch 24 
epoch 24, 
 train loss: 0.639383, val loss: 0.657803 
 val auc: 0.626089,  test auc: 0.661759
epoch 25, loss: 0.637006
model updated at epoch 25 
epoch 25, 
 train loss: 0.637006, val loss: 0.656316 
 val auc: 0.629655,  test auc: 0.665653
epoch 26, loss: 0.634606
model updated at epoch 26 
epoch 26, 
 train loss: 0.634606, val loss: 0.654776 
 val auc: 0.634159,  test auc: 0.669923
epoch 27, loss: 0.632292
model updated at epoch 27 
epoch 27, 
 train loss: 0.632292, val loss: 0.653283 
 val auc: 0.637575,  test auc: 0.674202
epoch 28, loss: 0.629966
model updated at epoch 28 
epoch 28, 
 train loss: 0.629966, val loss: 0.651761 
 val auc: 0.640315,  test auc: 0.677327
epoch 29, loss: 0.627581
model updated at epoch 29 
epoch 29, 
 train loss: 0.627581, val loss: 0.650194 
 val auc: 0.642680,  test auc: 0.680574
epoch 30, loss: 0.625122
model updated at epoch 30 
epoch 30, 
 train loss: 0.625122, val loss: 0.648569 
 val auc: 0.646697,  test auc: 0.684394
epoch 31, loss: 0.622598
model updated at epoch 31 
epoch 31, 
 train loss: 0.622598, val loss: 0.646889 
 val auc: 0.649700,  test auc: 0.687566
epoch 32, loss: 0.620021
model updated at epoch 32 
epoch 32, 
 train loss: 0.620021, val loss: 0.645116 
 val auc: 0.652890,  test auc: 0.690719
epoch 33, loss: 0.617394
model updated at epoch 33 
epoch 33, 
 train loss: 0.617394, val loss: 0.643209 
 val auc: 0.656381,  test auc: 0.693985
epoch 34, loss: 0.614769
model updated at epoch 34 
epoch 34, 
 train loss: 0.614769, val loss: 0.641206 
 val auc: 0.659760,  test auc: 0.697457
epoch 35, loss: 0.612057
model updated at epoch 35 
epoch 35, 
 train loss: 0.612057, val loss: 0.639038 
 val auc: 0.664752,  test auc: 0.701577
epoch 36, loss: 0.609224
model updated at epoch 36 
epoch 36, 
 train loss: 0.609224, val loss: 0.636639 
 val auc: 0.668919,  test auc: 0.706119
epoch 37, loss: 0.606250
model updated at epoch 37 
epoch 37, 
 train loss: 0.606250, val loss: 0.633975 
 val auc: 0.673761,  test auc: 0.710773
epoch 38, loss: 0.603266
model updated at epoch 38 
epoch 38, 
 train loss: 0.603266, val loss: 0.631127 
 val auc: 0.679880,  test auc: 0.715907
epoch 39, loss: 0.600282
model updated at epoch 39 
epoch 39, 
 train loss: 0.600282, val loss: 0.628275 
 val auc: 0.685961,  test auc: 0.721171
epoch 40, loss: 0.597308
model updated at epoch 40 
epoch 40, 
 train loss: 0.597308, val loss: 0.625422 
 val auc: 0.691254,  test auc: 0.726248
epoch 41, loss: 0.594217
model updated at epoch 41 
epoch 41, 
 train loss: 0.594217, val loss: 0.622451 
 val auc: 0.697072,  test auc: 0.730724
epoch 42, loss: 0.591041
model updated at epoch 42 
epoch 42, 
 train loss: 0.591041, val loss: 0.619417 
 val auc: 0.702740,  test auc: 0.735473
epoch 43, loss: 0.587824
model updated at epoch 43 
epoch 43, 
 train loss: 0.587824, val loss: 0.616448 
 val auc: 0.707995,  test auc: 0.739959
epoch 44, loss: 0.584533
model updated at epoch 44 
epoch 44, 
 train loss: 0.584533, val loss: 0.613512 
 val auc: 0.713176,  test auc: 0.744904
epoch 45, loss: 0.581225
model updated at epoch 45 
epoch 45, 
 train loss: 0.581225, val loss: 0.610412 
 val auc: 0.719069,  test auc: 0.750507
epoch 46, loss: 0.577774
model updated at epoch 46 
epoch 46, 
 train loss: 0.577774, val loss: 0.607134 
 val auc: 0.724287,  test auc: 0.755912
epoch 47, loss: 0.574187
model updated at epoch 47 
epoch 47, 
 train loss: 0.574187, val loss: 0.603627 
 val auc: 0.729542,  test auc: 0.761318
epoch 48, loss: 0.570519
model updated at epoch 48 
epoch 48, 
 train loss: 0.570519, val loss: 0.600041 
 val auc: 0.735248,  test auc: 0.766263
epoch 49, loss: 0.566666
model updated at epoch 49 
epoch 49, 
 train loss: 0.566666, val loss: 0.596483 
 val auc: 0.740240,  test auc: 0.771171
epoch 50, loss: 0.562626
model updated at epoch 50 
epoch 50, 
 train loss: 0.562626, val loss: 0.592907 
 val auc: 0.745308,  test auc: 0.775375
epoch 51, loss: 0.558530
model updated at epoch 51 
epoch 51, 
 train loss: 0.558530, val loss: 0.589405 
 val auc: 0.750188,  test auc: 0.779073
epoch 52, loss: 0.554219
model updated at epoch 52 
epoch 52, 
 train loss: 0.554219, val loss: 0.585511 
 val auc: 0.755443,  test auc: 0.783878
epoch 53, loss: 0.549780
model updated at epoch 53 
epoch 53, 
 train loss: 0.549780, val loss: 0.581358 
 val auc: 0.761712,  test auc: 0.789968
epoch 54, loss: 0.545234
model updated at epoch 54 
epoch 54, 
 train loss: 0.545234, val loss: 0.577151 
 val auc: 0.768581,  test auc: 0.795373
epoch 55, loss: 0.540616
model updated at epoch 55 
epoch 55, 
 train loss: 0.540616, val loss: 0.572743 
 val auc: 0.775901,  test auc: 0.801164
epoch 56, loss: 0.535837
model updated at epoch 56 
epoch 56, 
 train loss: 0.535837, val loss: 0.567991 
 val auc: 0.782845,  test auc: 0.806616
epoch 57, loss: 0.530902
model updated at epoch 57 
epoch 57, 
 train loss: 0.530902, val loss: 0.562883 
 val auc: 0.789602,  test auc: 0.812134
epoch 58, loss: 0.525796
model updated at epoch 58 
epoch 58, 
 train loss: 0.525796, val loss: 0.557536 
 val auc: 0.796584,  test auc: 0.818027
epoch 59, loss: 0.520490
model updated at epoch 59 
epoch 59, 
 train loss: 0.520490, val loss: 0.551774 
 val auc: 0.802853,  test auc: 0.823611
epoch 60, loss: 0.515063
model updated at epoch 60 
epoch 60, 
 train loss: 0.515063, val loss: 0.546149 
 val auc: 0.809872,  test auc: 0.829054
epoch 61, loss: 0.509457
model updated at epoch 61 
epoch 61, 
 train loss: 0.509457, val loss: 0.540481 
 val auc: 0.816366,  test auc: 0.834741
epoch 62, loss: 0.503715
model updated at epoch 62 
epoch 62, 
 train loss: 0.503715, val loss: 0.534603 
 val auc: 0.823574,  test auc: 0.840287
epoch 63, loss: 0.497825
model updated at epoch 63 
epoch 63, 
 train loss: 0.497825, val loss: 0.528476 
 val auc: 0.828866,  test auc: 0.845073
epoch 64, loss: 0.491787
model updated at epoch 64 
epoch 64, 
 train loss: 0.491787, val loss: 0.522209 
 val auc: 0.834572,  test auc: 0.849653
epoch 65, loss: 0.485614
model updated at epoch 65 
epoch 65, 
 train loss: 0.485614, val loss: 0.516126 
 val auc: 0.840428,  test auc: 0.854176
epoch 66, loss: 0.479329
model updated at epoch 66 
epoch 66, 
 train loss: 0.479329, val loss: 0.509417 
 val auc: 0.846359,  test auc: 0.858840
epoch 67, loss: 0.473003
model updated at epoch 67 
epoch 67, 
 train loss: 0.473003, val loss: 0.502610 
 val auc: 0.853228,  test auc: 0.864227
epoch 68, loss: 0.466539
model updated at epoch 68 
epoch 68, 
 train loss: 0.466539, val loss: 0.496037 
 val auc: 0.859459,  test auc: 0.868853
epoch 69, loss: 0.459898
model updated at epoch 69 
epoch 69, 
 train loss: 0.459898, val loss: 0.489524 
 val auc: 0.863589,  test auc: 0.872607
epoch 70, loss: 0.453115
model updated at epoch 70 
epoch 70, 
 train loss: 0.453115, val loss: 0.482667 
 val auc: 0.867568,  test auc: 0.876032
epoch 71, loss: 0.446416
model updated at epoch 71 
epoch 71, 
 train loss: 0.446416, val loss: 0.475695 
 val auc: 0.872673,  test auc: 0.880161
epoch 72, loss: 0.439571
model updated at epoch 72 
epoch 72, 
 train loss: 0.439571, val loss: 0.469119 
 val auc: 0.877590,  test auc: 0.884206
epoch 73, loss: 0.432644
model updated at epoch 73 
epoch 73, 
 train loss: 0.432644, val loss: 0.462211 
 val auc: 0.882395,  test auc: 0.888476
epoch 74, loss: 0.425589
model updated at epoch 74 
epoch 74, 
 train loss: 0.425589, val loss: 0.454966 
 val auc: 0.886486,  test auc: 0.892248
epoch 75, loss: 0.418382
model updated at epoch 75 
epoch 75, 
 train loss: 0.418382, val loss: 0.447900 
 val auc: 0.890878,  test auc: 0.895993
epoch 76, loss: 0.411143
model updated at epoch 76 
epoch 76, 
 train loss: 0.411143, val loss: 0.440946 
 val auc: 0.895083,  test auc: 0.899681
epoch 77, loss: 0.403690
model updated at epoch 77 
epoch 77, 
 train loss: 0.403690, val loss: 0.432928 
 val auc: 0.900901,  test auc: 0.904570
epoch 78, loss: 0.396325
model updated at epoch 78 
epoch 78, 
 train loss: 0.396325, val loss: 0.425075 
 val auc: 0.906119,  test auc: 0.909262
epoch 79, loss: 0.389017
model updated at epoch 79 
epoch 79, 
 train loss: 0.389017, val loss: 0.418376 
 val auc: 0.909459,  test auc: 0.912021
epoch 80, loss: 0.381729
model updated at epoch 80 
epoch 80, 
 train loss: 0.381729, val loss: 0.411706 
 val auc: 0.911374,  test auc: 0.914030
epoch 81, loss: 0.374712
model updated at epoch 81 
epoch 81, 
 train loss: 0.374712, val loss: 0.404027 
 val auc: 0.915053,  test auc: 0.916836
epoch 82, loss: 0.367627
model updated at epoch 82 
epoch 82, 
 train loss: 0.367627, val loss: 0.396871 
 val auc: 0.918656,  test auc: 0.919792
epoch 83, loss: 0.360660
model updated at epoch 83 
epoch 83, 
 train loss: 0.360660, val loss: 0.388552 
 val auc: 0.922935,  test auc: 0.923226
epoch 84, loss: 0.353895
model updated at epoch 84 
epoch 84, 
 train loss: 0.353895, val loss: 0.380380 
 val auc: 0.926689,  test auc: 0.925892
epoch 85, loss: 0.347151
model updated at epoch 85 
epoch 85, 
 train loss: 0.347151, val loss: 0.374152 
 val auc: 0.928604,  test auc: 0.927684
epoch 86, loss: 0.340625
model updated at epoch 86 
epoch 86, 
 train loss: 0.340625, val loss: 0.367309 
 val auc: 0.931044,  test auc: 0.930039
epoch 87, loss: 0.334203
model updated at epoch 87 
epoch 87, 
 train loss: 0.334203, val loss: 0.360616 
 val auc: 0.933709,  test auc: 0.932273
epoch 88, loss: 0.327821
model updated at epoch 88 
epoch 88, 
 train loss: 0.327821, val loss: 0.354680 
 val auc: 0.935811,  test auc: 0.933803
epoch 89, loss: 0.321640
model updated at epoch 89 
epoch 89, 
 train loss: 0.321640, val loss: 0.347766 
 val auc: 0.938438,  test auc: 0.936102
epoch 90, loss: 0.315653
model updated at epoch 90 
epoch 90, 
 train loss: 0.315653, val loss: 0.341839 
 val auc: 0.940428,  test auc: 0.937782
epoch 91, loss: 0.309964
model updated at epoch 91 
epoch 91, 
 train loss: 0.309964, val loss: 0.336599 
 val auc: 0.942342,  test auc: 0.939405
epoch 92, loss: 0.304493
model updated at epoch 92 
epoch 92, 
 train loss: 0.304493, val loss: 0.330882 
 val auc: 0.944707,  test auc: 0.941094
epoch 93, loss: 0.299148
model updated at epoch 93 
epoch 93, 
 train loss: 0.299148, val loss: 0.325675 
 val auc: 0.946246,  test auc: 0.942455
epoch 94, loss: 0.293965
model updated at epoch 94 
epoch 94, 
 train loss: 0.293965, val loss: 0.320060 
 val auc: 0.947898,  test auc: 0.944125
epoch 95, loss: 0.288957
model updated at epoch 95 
epoch 95, 
 train loss: 0.288957, val loss: 0.314873 
 val auc: 0.949512,  test auc: 0.945355
epoch 96, loss: 0.283948
model updated at epoch 96 
epoch 96, 
 train loss: 0.283948, val loss: 0.309807 
 val auc: 0.951464,  test auc: 0.946913
epoch 97, loss: 0.279172
model updated at epoch 97 
epoch 97, 
 train loss: 0.279172, val loss: 0.304891 
 val auc: 0.953228,  test auc: 0.948386
epoch 98, loss: 0.274695
model updated at epoch 98 
epoch 98, 
 train loss: 0.274695, val loss: 0.301245 
 val auc: 0.954354,  test auc: 0.949371
epoch 99, loss: 0.270473
model updated at epoch 99 
epoch 99, 
 train loss: 0.270473, val loss: 0.295759 
 val auc: 0.955968,  test auc: 0.950441
epoch 100, loss: 0.266641
model updated at epoch 100 
epoch 100, 
 train loss: 0.266641, val loss: 0.294003 
 val auc: 0.956419,  test auc: 0.950732
epoch 101, loss: 0.263294
model updated at epoch 101 
epoch 101, 
 train loss: 0.263294, val loss: 0.287735 
 val auc: 0.957658,  test auc: 0.951380
epoch 102, loss: 0.259681
epoch 102, 
 train loss: 0.259681, val loss: 0.288521 
 val auc: 0.957395,  test auc: 0.951164
epoch 103, loss: 0.255579
model updated at epoch 103 
epoch 103, 
 train loss: 0.255579, val loss: 0.282070 
 val auc: 0.958559,  test auc: 0.952243
epoch 104, loss: 0.252029
model updated at epoch 104 
epoch 104, 
 train loss: 0.252029, val loss: 0.278509 
 val auc: 0.959722,  test auc: 0.953069
epoch 105, loss: 0.249250
model updated at epoch 105 
epoch 105, 
 train loss: 0.249250, val loss: 0.277396 
 val auc: 0.960548,  test auc: 0.952975
epoch 106, loss: 0.245874
model updated at epoch 106 
epoch 106, 
 train loss: 0.245874, val loss: 0.271781 
 val auc: 0.961149,  test auc: 0.953707
epoch 107, loss: 0.242405
model updated at epoch 107 
epoch 107, 
 train loss: 0.242405, val loss: 0.270158 
 val auc: 0.961562,  test auc: 0.954073
epoch 108, loss: 0.240041
model updated at epoch 108 
epoch 108, 
 train loss: 0.240041, val loss: 0.269647 
 val auc: 0.961899,  test auc: 0.954054
epoch 109, loss: 0.237106
model updated at epoch 109 
epoch 109, 
 train loss: 0.237106, val loss: 0.264120 
 val auc: 0.961674,  test auc: 0.954364
epoch 110, loss: 0.233954
model updated at epoch 110 
epoch 110, 
 train loss: 0.233954, val loss: 0.261924 
 val auc: 0.963176,  test auc: 0.955190
epoch 111, loss: 0.232028
model updated at epoch 111 
epoch 111, 
 train loss: 0.232028, val loss: 0.261448 
 val auc: 0.963514,  test auc: 0.955133
epoch 112, loss: 0.229362
model updated at epoch 112 
epoch 112, 
 train loss: 0.229362, val loss: 0.256894 
 val auc: 0.963326,  test auc: 0.955546
epoch 113, loss: 0.226398
model updated at epoch 113 
epoch 113, 
 train loss: 0.226398, val loss: 0.255280 
 val auc: 0.964264,  test auc: 0.955865
epoch 114, loss: 0.224998
epoch 114, 
 train loss: 0.224998, val loss: 0.255400 
 val auc: 0.964114,  test auc: 0.955509
epoch 115, loss: 0.222473
model updated at epoch 115 
epoch 115, 
 train loss: 0.222473, val loss: 0.250832 
 val auc: 0.964790,  test auc: 0.956513
epoch 116, loss: 0.220200
model updated at epoch 116 
epoch 116, 
 train loss: 0.220200, val loss: 0.249340 
 val auc: 0.965353,  test auc: 0.956682
epoch 117, loss: 0.218985
epoch 117, 
 train loss: 0.218985, val loss: 0.250238 
 val auc: 0.965128,  test auc: 0.956550
epoch 118, loss: 0.216503
model updated at epoch 118 
epoch 118, 
 train loss: 0.216503, val loss: 0.246567 
 val auc: 0.965653,  test auc: 0.956813
epoch 119, loss: 0.214782
model updated at epoch 119 
epoch 119, 
 train loss: 0.214782, val loss: 0.245163 
 val auc: 0.965841,  test auc: 0.956944
epoch 120, loss: 0.213426
epoch 120, 
 train loss: 0.213426, val loss: 0.245655 
 val auc: 0.965390,  test auc: 0.956776
epoch 121, loss: 0.211196
model updated at epoch 121 
epoch 121, 
 train loss: 0.211196, val loss: 0.242510 
 val auc: 0.966029,  test auc: 0.957020
epoch 122, loss: 0.209796
model updated at epoch 122 
epoch 122, 
 train loss: 0.209796, val loss: 0.241016 
 val auc: 0.966441,  test auc: 0.957273
epoch 123, loss: 0.208368
epoch 123, 
 train loss: 0.208368, val loss: 0.241066 
 val auc: 0.965803,  test auc: 0.956879
epoch 124, loss: 0.206532
model updated at epoch 124 
epoch 124, 
 train loss: 0.206532, val loss: 0.238633 
 val auc: 0.966291,  test auc: 0.957320
epoch 125, loss: 0.205230
model updated at epoch 125 
epoch 125, 
 train loss: 0.205230, val loss: 0.237266 
 val auc: 0.966479,  test auc: 0.957432
epoch 126, loss: 0.203969
model updated at epoch 126 
epoch 126, 
 train loss: 0.203969, val loss: 0.237097 
 val auc: 0.966029,  test auc: 0.957451
epoch 127, loss: 0.202401
model updated at epoch 127 
epoch 127, 
 train loss: 0.202401, val loss: 0.235086 
 val auc: 0.966479,  test auc: 0.957686
epoch 128, loss: 0.201027
model updated at epoch 128 
epoch 128, 
 train loss: 0.201027, val loss: 0.234067 
 val auc: 0.966404,  test auc: 0.957761
epoch 129, loss: 0.199971
model updated at epoch 129 
epoch 129, 
 train loss: 0.199971, val loss: 0.233606 
 val auc: 0.966179,  test auc: 0.957705
epoch 130, loss: 0.198821
model updated at epoch 130 
epoch 130, 
 train loss: 0.198821, val loss: 0.231842 
 val auc: 0.966854,  test auc: 0.957920
epoch 131, loss: 0.197392
model updated at epoch 131 
epoch 131, 
 train loss: 0.197392, val loss: 0.231429 
 val auc: 0.966667,  test auc: 0.958014
epoch 132, loss: 0.196194
model updated at epoch 132 
epoch 132, 
 train loss: 0.196194, val loss: 0.230605 
 val auc: 0.966967,  test auc: 0.958127
epoch 133, loss: 0.195241
model updated at epoch 133 
epoch 133, 
 train loss: 0.195241, val loss: 0.229626 
 val auc: 0.966929,  test auc: 0.958174
epoch 134, loss: 0.194275
epoch 134, 
 train loss: 0.194275, val loss: 0.229731 
 val auc: 0.966817,  test auc: 0.958014
epoch 135, loss: 0.193268
model updated at epoch 135 
epoch 135, 
 train loss: 0.193268, val loss: 0.228054 
 val auc: 0.967192,  test auc: 0.958427
epoch 136, loss: 0.191992
model updated at epoch 136 
epoch 136, 
 train loss: 0.191992, val loss: 0.227811 
 val auc: 0.967080,  test auc: 0.958408
epoch 137, loss: 0.190800
model updated at epoch 137 
epoch 137, 
 train loss: 0.190800, val loss: 0.226526 
 val auc: 0.967267,  test auc: 0.958671
epoch 138, loss: 0.189736
model updated at epoch 138 
epoch 138, 
 train loss: 0.189736, val loss: 0.226071 
 val auc: 0.967230,  test auc: 0.958737
epoch 139, loss: 0.188804
model updated at epoch 139 
epoch 139, 
 train loss: 0.188804, val loss: 0.225907 
 val auc: 0.967455,  test auc: 0.958699
epoch 140, loss: 0.187983
model updated at epoch 140 
epoch 140, 
 train loss: 0.187983, val loss: 0.224895 
 val auc: 0.967568,  test auc: 0.958849
epoch 141, loss: 0.187204
epoch 141, 
 train loss: 0.187204, val loss: 0.225353 
 val auc: 0.967305,  test auc: 0.958662
epoch 142, loss: 0.186610
model updated at epoch 142 
epoch 142, 
 train loss: 0.186610, val loss: 0.223867 
 val auc: 0.968018,  test auc: 0.959009
epoch 143, loss: 0.185459
epoch 143, 
 train loss: 0.185459, val loss: 0.224509 
 val auc: 0.967380,  test auc: 0.958868
epoch 144, loss: 0.184200
model updated at epoch 144 
epoch 144, 
 train loss: 0.184200, val loss: 0.222987 
 val auc: 0.967980,  test auc: 0.959169
epoch 145, loss: 0.183029
model updated at epoch 145 
epoch 145, 
 train loss: 0.183029, val loss: 0.222753 
 val auc: 0.967755,  test auc: 0.959234
epoch 146, loss: 0.182328
model updated at epoch 146 
epoch 146, 
 train loss: 0.182328, val loss: 0.222703 
 val auc: 0.967643,  test auc: 0.959262
epoch 147, loss: 0.181792
model updated at epoch 147 
epoch 147, 
 train loss: 0.181792, val loss: 0.221557 
 val auc: 0.967980,  test auc: 0.959563
epoch 148, loss: 0.180679
epoch 148, 
 train loss: 0.180679, val loss: 0.221876 
 val auc: 0.967530,  test auc: 0.959441
epoch 149, loss: 0.179526
model updated at epoch 149 
epoch 149, 
 train loss: 0.179526, val loss: 0.220509 
 val auc: 0.968018,  test auc: 0.960004
epoch 150, loss: 0.178569
model updated at epoch 150 
epoch 150, 
 train loss: 0.178569, val loss: 0.220185 
 val auc: 0.968093,  test auc: 0.960135
epoch 151, loss: 0.177889
epoch 151, 
 train loss: 0.177889, val loss: 0.220243 
 val auc: 0.967755,  test auc: 0.959929
epoch 152, loss: 0.177331
model updated at epoch 152 
epoch 152, 
 train loss: 0.177331, val loss: 0.219220 
 val auc: 0.968093,  test auc: 0.960454
epoch 153, loss: 0.176442
epoch 153, 
 train loss: 0.176442, val loss: 0.219833 
 val auc: 0.967680,  test auc: 0.960220
epoch 154, loss: 0.175503
model updated at epoch 154 
epoch 154, 
 train loss: 0.175503, val loss: 0.218587 
 val auc: 0.968056,  test auc: 0.960595
epoch 155, loss: 0.174480
epoch 155, 
 train loss: 0.174480, val loss: 0.218622 
 val auc: 0.967830,  test auc: 0.960539
epoch 156, loss: 0.173771
model updated at epoch 156 
epoch 156, 
 train loss: 0.173771, val loss: 0.218363 
 val auc: 0.967830,  test auc: 0.960511
epoch 157, loss: 0.173241
model updated at epoch 157 
epoch 157, 
 train loss: 0.173241, val loss: 0.217388 
 val auc: 0.968356,  test auc: 0.960820
epoch 158, loss: 0.172476
epoch 158, 
 train loss: 0.172476, val loss: 0.217716 
 val auc: 0.967718,  test auc: 0.960520
epoch 159, loss: 0.171620
model updated at epoch 159 
epoch 159, 
 train loss: 0.171620, val loss: 0.216459 
 val auc: 0.968468,  test auc: 0.960933
epoch 160, loss: 0.170834
model updated at epoch 160 
epoch 160, 
 train loss: 0.170834, val loss: 0.216162 
 val auc: 0.968619,  test auc: 0.961064
epoch 161, loss: 0.170223
model updated at epoch 161 
epoch 161, 
 train loss: 0.170223, val loss: 0.215940 
 val auc: 0.968506,  test auc: 0.960942
epoch 162, loss: 0.169679
model updated at epoch 162 
epoch 162, 
 train loss: 0.169679, val loss: 0.214904 
 val auc: 0.968881,  test auc: 0.961149
epoch 163, loss: 0.168998
epoch 163, 
 train loss: 0.168998, val loss: 0.214961 
 val auc: 0.968919,  test auc: 0.961120
epoch 164, loss: 0.168278
model updated at epoch 164 
epoch 164, 
 train loss: 0.168278, val loss: 0.213827 
 val auc: 0.969144,  test auc: 0.961393
epoch 165, loss: 0.167512
model updated at epoch 165 
epoch 165, 
 train loss: 0.167512, val loss: 0.213784 
 val auc: 0.969332,  test auc: 0.961402
epoch 166, loss: 0.166852
model updated at epoch 166 
epoch 166, 
 train loss: 0.166852, val loss: 0.213312 
 val auc: 0.969407,  test auc: 0.961562
epoch 167, loss: 0.166273
model updated at epoch 167 
epoch 167, 
 train loss: 0.166273, val loss: 0.212380 
 val auc: 0.969482,  test auc: 0.961693
epoch 168, loss: 0.165652
model updated at epoch 168 
epoch 168, 
 train loss: 0.165652, val loss: 0.212216 
 val auc: 0.969557,  test auc: 0.961787
epoch 169, loss: 0.164975
model updated at epoch 169 
epoch 169, 
 train loss: 0.164975, val loss: 0.211201 
 val auc: 0.969707,  test auc: 0.961946
epoch 170, loss: 0.164306
model updated at epoch 170 
epoch 170, 
 train loss: 0.164306, val loss: 0.210979 
 val auc: 0.969632,  test auc: 0.961984
epoch 171, loss: 0.163701
model updated at epoch 171 
epoch 171, 
 train loss: 0.163701, val loss: 0.210650 
 val auc: 0.969745,  test auc: 0.962078
epoch 172, loss: 0.163139
model updated at epoch 172 
epoch 172, 
 train loss: 0.163139, val loss: 0.209987 
 val auc: 0.969932,  test auc: 0.962059
epoch 173, loss: 0.162550
model updated at epoch 173 
epoch 173, 
 train loss: 0.162550, val loss: 0.209960 
 val auc: 0.970008,  test auc: 0.962162
epoch 174, loss: 0.161931
model updated at epoch 174 
epoch 174, 
 train loss: 0.161931, val loss: 0.208855 
 val auc: 0.970120,  test auc: 0.962312
epoch 175, loss: 0.161311
model updated at epoch 175 
epoch 175, 
 train loss: 0.161311, val loss: 0.208596 
 val auc: 0.970345,  test auc: 0.962538
epoch 176, loss: 0.160704
model updated at epoch 176 
epoch 176, 
 train loss: 0.160704, val loss: 0.207922 
 val auc: 0.970571,  test auc: 0.962631
epoch 177, loss: 0.160114
model updated at epoch 177 
epoch 177, 
 train loss: 0.160114, val loss: 0.207467 
 val auc: 0.970533,  test auc: 0.962631
epoch 178, loss: 0.159543
model updated at epoch 178 
epoch 178, 
 train loss: 0.159543, val loss: 0.207318 
 val auc: 0.970608,  test auc: 0.962763
epoch 179, loss: 0.158986
model updated at epoch 179 
epoch 179, 
 train loss: 0.158986, val loss: 0.206785 
 val auc: 0.970646,  test auc: 0.962772
epoch 180, loss: 0.158416
epoch 180, 
 train loss: 0.158416, val loss: 0.207037 
 val auc: 0.970533,  test auc: 0.962875
epoch 181, loss: 0.157863
model updated at epoch 181 
epoch 181, 
 train loss: 0.157863, val loss: 0.206255 
 val auc: 0.970983,  test auc: 0.962960
epoch 182, loss: 0.157308
epoch 182, 
 train loss: 0.157308, val loss: 0.206534 
 val auc: 0.970721,  test auc: 0.963101
epoch 183, loss: 0.156756
model updated at epoch 183 
epoch 183, 
 train loss: 0.156756, val loss: 0.205604 
 val auc: 0.971209,  test auc: 0.963307
epoch 184, loss: 0.156179
epoch 184, 
 train loss: 0.156179, val loss: 0.205908 
 val auc: 0.971021,  test auc: 0.963316
epoch 185, loss: 0.155625
model updated at epoch 185 
epoch 185, 
 train loss: 0.155625, val loss: 0.204780 
 val auc: 0.971059,  test auc: 0.963392
epoch 186, loss: 0.155048
epoch 186, 
 train loss: 0.155048, val loss: 0.205056 
 val auc: 0.971134,  test auc: 0.963514
epoch 187, loss: 0.154557
model updated at epoch 187 
epoch 187, 
 train loss: 0.154557, val loss: 0.203945 
 val auc: 0.971284,  test auc: 0.963664
epoch 188, loss: 0.154061
epoch 188, 
 train loss: 0.154061, val loss: 0.204910 
 val auc: 0.971059,  test auc: 0.963664
epoch 189, loss: 0.153707
model updated at epoch 189 
epoch 189, 
 train loss: 0.153707, val loss: 0.203656 
 val auc: 0.971434,  test auc: 0.963964
epoch 190, loss: 0.153167
epoch 190, 
 train loss: 0.153167, val loss: 0.204672 
 val auc: 0.971359,  test auc: 0.963833
epoch 191, loss: 0.152704
model updated at epoch 191 
epoch 191, 
 train loss: 0.152704, val loss: 0.202873 
 val auc: 0.971622,  test auc: 0.964217
epoch 192, loss: 0.151889
epoch 192, 
 train loss: 0.151889, val loss: 0.203457 
 val auc: 0.971697,  test auc: 0.964227
epoch 193, loss: 0.151126
model updated at epoch 193 
epoch 193, 
 train loss: 0.151126, val loss: 0.202025 
 val auc: 0.971922,  test auc: 0.964518
epoch 194, loss: 0.150448
epoch 194, 
 train loss: 0.150448, val loss: 0.202038 
 val auc: 0.971809,  test auc: 0.964480
epoch 195, loss: 0.149924
model updated at epoch 195 
epoch 195, 
 train loss: 0.149924, val loss: 0.201773 
 val auc: 0.971847,  test auc: 0.964574
epoch 196, loss: 0.149560
model updated at epoch 196 
epoch 196, 
 train loss: 0.149560, val loss: 0.200928 
 val auc: 0.971997,  test auc: 0.964809
epoch 197, loss: 0.149209
epoch 197, 
 train loss: 0.149209, val loss: 0.201748 
 val auc: 0.971697,  test auc: 0.964649
epoch 198, loss: 0.148919
model updated at epoch 198 
epoch 198, 
 train loss: 0.148919, val loss: 0.200386 
 val auc: 0.971697,  test auc: 0.964846
epoch 199, loss: 0.148414
epoch 199, 
 train loss: 0.148414, val loss: 0.201858 
 val auc: 0.971434,  test auc: 0.964583
epoch 200, loss: 0.147881
model updated at epoch 200 
epoch 200, 
 train loss: 0.147881, val loss: 0.200052 
 val auc: 0.972110,  test auc: 0.964902
epoch 201, loss: 0.147015
epoch 201, 
 train loss: 0.147015, val loss: 0.200328 
 val auc: 0.971734,  test auc: 0.965006
epoch 202, loss: 0.146361
model updated at epoch 202 
epoch 202, 
 train loss: 0.146361, val loss: 0.199096 
 val auc: 0.972072,  test auc: 0.965372
epoch 203, loss: 0.145896
model updated at epoch 203 
epoch 203, 
 train loss: 0.145896, val loss: 0.198571 
 val auc: 0.972410,  test auc: 0.965494
epoch 204, loss: 0.145561
epoch 204, 
 train loss: 0.145561, val loss: 0.199056 
 val auc: 0.972147,  test auc: 0.965175
epoch 205, loss: 0.145247
model updated at epoch 205 
epoch 205, 
 train loss: 0.145247, val loss: 0.198082 
 val auc: 0.972297,  test auc: 0.965343
epoch 206, loss: 0.144734
epoch 206, 
 train loss: 0.144734, val loss: 0.199032 
 val auc: 0.972185,  test auc: 0.965297
epoch 207, loss: 0.144185
model updated at epoch 207 
epoch 207, 
 train loss: 0.144185, val loss: 0.197554 
 val auc: 0.972372,  test auc: 0.965616
epoch 208, loss: 0.143525
epoch 208, 
 train loss: 0.143525, val loss: 0.197667 
 val auc: 0.972447,  test auc: 0.965653
epoch 209, loss: 0.142971
model updated at epoch 209 
epoch 209, 
 train loss: 0.142971, val loss: 0.196659 
 val auc: 0.972523,  test auc: 0.965738
epoch 210, loss: 0.142541
model updated at epoch 210 
epoch 210, 
 train loss: 0.142541, val loss: 0.195967 
 val auc: 0.972560,  test auc: 0.965897
epoch 211, loss: 0.142185
epoch 211, 
 train loss: 0.142185, val loss: 0.196274 
 val auc: 0.972635,  test auc: 0.965907
epoch 212, loss: 0.141872
model updated at epoch 212 
epoch 212, 
 train loss: 0.141872, val loss: 0.195236 
 val auc: 0.972823,  test auc: 0.966122
epoch 213, loss: 0.141415
epoch 213, 
 train loss: 0.141415, val loss: 0.196140 
 val auc: 0.972710,  test auc: 0.965991
epoch 214, loss: 0.140947
model updated at epoch 214 
epoch 214, 
 train loss: 0.140947, val loss: 0.194832 
 val auc: 0.972823,  test auc: 0.966160
epoch 215, loss: 0.140331
epoch 215, 
 train loss: 0.140331, val loss: 0.195538 
 val auc: 0.972748,  test auc: 0.966000
epoch 216, loss: 0.139765
model updated at epoch 216 
epoch 216, 
 train loss: 0.139765, val loss: 0.194613 
 val auc: 0.973236,  test auc: 0.966310
epoch 217, loss: 0.139265
model updated at epoch 217 
epoch 217, 
 train loss: 0.139265, val loss: 0.194533 
 val auc: 0.973161,  test auc: 0.966413
epoch 218, loss: 0.138833
model updated at epoch 218 
epoch 218, 
 train loss: 0.138833, val loss: 0.194397 
 val auc: 0.973161,  test auc: 0.966517
epoch 219, loss: 0.138463
model updated at epoch 219 
epoch 219, 
 train loss: 0.138463, val loss: 0.193460 
 val auc: 0.973386,  test auc: 0.966610
epoch 220, loss: 0.138019
epoch 220, 
 train loss: 0.138019, val loss: 0.193675 
 val auc: 0.973311,  test auc: 0.966648
epoch 221, loss: 0.137543
model updated at epoch 221 
epoch 221, 
 train loss: 0.137543, val loss: 0.192621 
 val auc: 0.973536,  test auc: 0.966901
epoch 222, loss: 0.137030
epoch 222, 
 train loss: 0.137030, val loss: 0.192779 
 val auc: 0.973423,  test auc: 0.966892
epoch 223, loss: 0.136551
model updated at epoch 223 
epoch 223, 
 train loss: 0.136551, val loss: 0.192238 
 val auc: 0.973611,  test auc: 0.967051
epoch 224, loss: 0.136110
model updated at epoch 224 
epoch 224, 
 train loss: 0.136110, val loss: 0.191766 
 val auc: 0.973686,  test auc: 0.967136
epoch 225, loss: 0.135694
model updated at epoch 225 
epoch 225, 
 train loss: 0.135694, val loss: 0.191526 
 val auc: 0.973536,  test auc: 0.967202
epoch 226, loss: 0.135308
model updated at epoch 226 
epoch 226, 
 train loss: 0.135308, val loss: 0.190639 
 val auc: 0.973874,  test auc: 0.967361
epoch 227, loss: 0.134883
epoch 227, 
 train loss: 0.134883, val loss: 0.190965 
 val auc: 0.973761,  test auc: 0.967324
epoch 228, loss: 0.134460
model updated at epoch 228 
epoch 228, 
 train loss: 0.134460, val loss: 0.190166 
 val auc: 0.974062,  test auc: 0.967464
epoch 229, loss: 0.134001
epoch 229, 
 train loss: 0.134001, val loss: 0.190728 
 val auc: 0.973911,  test auc: 0.967427
epoch 230, loss: 0.133549
model updated at epoch 230 
epoch 230, 
 train loss: 0.133549, val loss: 0.189923 
 val auc: 0.974099,  test auc: 0.967605
epoch 231, loss: 0.133093
epoch 231, 
 train loss: 0.133093, val loss: 0.189977 
 val auc: 0.974174,  test auc: 0.967699
epoch 232, loss: 0.132654
model updated at epoch 232 
epoch 232, 
 train loss: 0.132654, val loss: 0.189003 
 val auc: 0.974249,  test auc: 0.967896
epoch 233, loss: 0.132228
model updated at epoch 233 
epoch 233, 
 train loss: 0.132228, val loss: 0.188615 
 val auc: 0.974437,  test auc: 0.967999
epoch 234, loss: 0.131806
model updated at epoch 234 
epoch 234, 
 train loss: 0.131806, val loss: 0.188071 
 val auc: 0.974512,  test auc: 0.968102
epoch 235, loss: 0.131381
model updated at epoch 235 
epoch 235, 
 train loss: 0.131381, val loss: 0.188028 
 val auc: 0.974625,  test auc: 0.968196
epoch 236, loss: 0.130961
model updated at epoch 236 
epoch 236, 
 train loss: 0.130961, val loss: 0.187732 
 val auc: 0.974737,  test auc: 0.968281
epoch 237, loss: 0.130544
model updated at epoch 237 
epoch 237, 
 train loss: 0.130544, val loss: 0.187410 
 val auc: 0.975000,  test auc: 0.968356
epoch 238, loss: 0.130128
model updated at epoch 238 
epoch 238, 
 train loss: 0.130128, val loss: 0.186864 
 val auc: 0.975075,  test auc: 0.968431
epoch 239, loss: 0.129710
model updated at epoch 239 
epoch 239, 
 train loss: 0.129710, val loss: 0.186407 
 val auc: 0.975113,  test auc: 0.968497
epoch 240, loss: 0.129288
model updated at epoch 240 
epoch 240, 
 train loss: 0.129288, val loss: 0.186157 
 val auc: 0.975188,  test auc: 0.968666
epoch 241, loss: 0.128875
model updated at epoch 241 
epoch 241, 
 train loss: 0.128875, val loss: 0.185815 
 val auc: 0.975113,  test auc: 0.968731
epoch 242, loss: 0.128446
model updated at epoch 242 
epoch 242, 
 train loss: 0.128446, val loss: 0.185530 
 val auc: 0.975338,  test auc: 0.968722
epoch 243, loss: 0.128026
model updated at epoch 243 
epoch 243, 
 train loss: 0.128026, val loss: 0.184923 
 val auc: 0.975338,  test auc: 0.968750
epoch 244, loss: 0.127608
model updated at epoch 244 
epoch 244, 
 train loss: 0.127608, val loss: 0.184857 
 val auc: 0.975638,  test auc: 0.968881
epoch 245, loss: 0.127246
model updated at epoch 245 
epoch 245, 
 train loss: 0.127246, val loss: 0.184109 
 val auc: 0.975713,  test auc: 0.969032
epoch 246, loss: 0.126899
epoch 246, 
 train loss: 0.126899, val loss: 0.184562 
 val auc: 0.975901,  test auc: 0.969032
epoch 247, loss: 0.126764
model updated at epoch 247 
epoch 247, 
 train loss: 0.126764, val loss: 0.183122 
 val auc: 0.975788,  test auc: 0.969060
epoch 248, loss: 0.126820
epoch 248, 
 train loss: 0.126820, val loss: 0.184937 
 val auc: 0.975863,  test auc: 0.969107
epoch 249, loss: 0.127356
model updated at epoch 249 
epoch 249, 
 train loss: 0.127356, val loss: 0.182620 
 val auc: 0.976089,  test auc: 0.969276
epoch 250, loss: 0.126745
epoch 250, 
 train loss: 0.126745, val loss: 0.185491 
 val auc: 0.976089,  test auc: 0.969360
epoch 251, loss: 0.125943
model updated at epoch 251 
epoch 251, 
 train loss: 0.125943, val loss: 0.182131 
 val auc: 0.976201,  test auc: 0.969548
epoch 252, loss: 0.124424
epoch 252, 
 train loss: 0.124424, val loss: 0.183058 
 val auc: 0.976314,  test auc: 0.969482
epoch 253, loss: 0.123914
epoch 253, 
 train loss: 0.123914, val loss: 0.182592 
 val auc: 0.976239,  test auc: 0.969576
epoch 254, loss: 0.124247
model updated at epoch 254 
epoch 254, 
 train loss: 0.124247, val loss: 0.181427 
 val auc: 0.976351,  test auc: 0.969754
epoch 255, loss: 0.124071
epoch 255, 
 train loss: 0.124071, val loss: 0.183638 
 val auc: 0.976239,  test auc: 0.969688
epoch 256, loss: 0.123304
model updated at epoch 256 
epoch 256, 
 train loss: 0.123304, val loss: 0.180946 
 val auc: 0.976502,  test auc: 0.969942
epoch 257, loss: 0.122213
epoch 257, 
 train loss: 0.122213, val loss: 0.181191 
 val auc: 0.976502,  test auc: 0.969932
epoch 258, loss: 0.122066
epoch 258, 
 train loss: 0.122066, val loss: 0.181300 
 val auc: 0.976464,  test auc: 0.969857
epoch 259, loss: 0.122246
model updated at epoch 259 
epoch 259, 
 train loss: 0.122246, val loss: 0.179422 
 val auc: 0.976989,  test auc: 0.970176
epoch 260, loss: 0.121458
epoch 260, 
 train loss: 0.121458, val loss: 0.180912 
 val auc: 0.976727,  test auc: 0.970223
epoch 261, loss: 0.120629
model updated at epoch 261 
epoch 261, 
 train loss: 0.120629, val loss: 0.179204 
 val auc: 0.977027,  test auc: 0.970411
epoch 262, loss: 0.120369
model updated at epoch 262 
epoch 262, 
 train loss: 0.120369, val loss: 0.178559 
 val auc: 0.977102,  test auc: 0.970495
epoch 263, loss: 0.120254
epoch 263, 
 train loss: 0.120254, val loss: 0.179906 
 val auc: 0.976989,  test auc: 0.970420
epoch 264, loss: 0.119795
model updated at epoch 264 
epoch 264, 
 train loss: 0.119795, val loss: 0.177998 
 val auc: 0.977065,  test auc: 0.970533
epoch 265, loss: 0.119070
epoch 265, 
 train loss: 0.119070, val loss: 0.178528 
 val auc: 0.977215,  test auc: 0.970617
epoch 266, loss: 0.118706
epoch 266, 
 train loss: 0.118706, val loss: 0.178254 
 val auc: 0.977327,  test auc: 0.970749
epoch 267, loss: 0.118548
model updated at epoch 267 
epoch 267, 
 train loss: 0.118548, val loss: 0.176939 
 val auc: 0.977290,  test auc: 0.970739
epoch 268, loss: 0.118095
epoch 268, 
 train loss: 0.118095, val loss: 0.177994 
 val auc: 0.977402,  test auc: 0.970871
epoch 269, loss: 0.117503
model updated at epoch 269 
epoch 269, 
 train loss: 0.117503, val loss: 0.176659 
 val auc: 0.977327,  test auc: 0.970852
epoch 270, loss: 0.117080
epoch 270, 
 train loss: 0.117080, val loss: 0.176705 
 val auc: 0.977440,  test auc: 0.970927
epoch 271, loss: 0.116840
epoch 271, 
 train loss: 0.116840, val loss: 0.177603 
 val auc: 0.977590,  test auc: 0.971049
epoch 272, loss: 0.116556
model updated at epoch 272 
epoch 272, 
 train loss: 0.116556, val loss: 0.176399 
 val auc: 0.977740,  test auc: 0.971115
epoch 273, loss: 0.116056
epoch 273, 
 train loss: 0.116056, val loss: 0.177377 
 val auc: 0.977628,  test auc: 0.971096
epoch 274, loss: 0.115515
model updated at epoch 274 
epoch 274, 
 train loss: 0.115515, val loss: 0.176172 
 val auc: 0.977740,  test auc: 0.971199
epoch 275, loss: 0.115093
model updated at epoch 275 
epoch 275, 
 train loss: 0.115093, val loss: 0.175925 
 val auc: 0.977778,  test auc: 0.971265
epoch 276, loss: 0.114783
epoch 276, 
 train loss: 0.114783, val loss: 0.176256 
 val auc: 0.977853,  test auc: 0.971237
epoch 277, loss: 0.114428
model updated at epoch 277 
epoch 277, 
 train loss: 0.114428, val loss: 0.175159 
 val auc: 0.978228,  test auc: 0.971406
epoch 278, loss: 0.113953
epoch 278, 
 train loss: 0.113953, val loss: 0.175824 
 val auc: 0.977890,  test auc: 0.971434
epoch 279, loss: 0.113489
epoch 279, 
 train loss: 0.113489, val loss: 0.175222 
 val auc: 0.978041,  test auc: 0.971481
epoch 280, loss: 0.113102
model updated at epoch 280 
epoch 280, 
 train loss: 0.113102, val loss: 0.175129 
 val auc: 0.978041,  test auc: 0.971659
epoch 281, loss: 0.112745
epoch 281, 
 train loss: 0.112745, val loss: 0.175582 
 val auc: 0.978003,  test auc: 0.971687
epoch 282, loss: 0.112380
model updated at epoch 282 
epoch 282, 
 train loss: 0.112380, val loss: 0.174592 
 val auc: 0.978303,  test auc: 0.971697
epoch 283, loss: 0.111967
epoch 283, 
 train loss: 0.111967, val loss: 0.175312 
 val auc: 0.978078,  test auc: 0.971715
epoch 284, loss: 0.111532
epoch 284, 
 train loss: 0.111532, val loss: 0.174666 
 val auc: 0.978078,  test auc: 0.971744
epoch 285, loss: 0.111086
epoch 285, 
 train loss: 0.111086, val loss: 0.175087 
 val auc: 0.977890,  test auc: 0.971753
epoch 286, loss: 0.110669
epoch 286, 
 train loss: 0.110669, val loss: 0.174878 
 val auc: 0.978116,  test auc: 0.971866
epoch 287, loss: 0.110272
epoch 287, 
 train loss: 0.110272, val loss: 0.174640 
 val auc: 0.978078,  test auc: 0.971903
epoch 288, loss: 0.109894
epoch 288, 
 train loss: 0.109894, val loss: 0.175022 
 val auc: 0.977928,  test auc: 0.972044
epoch 289, loss: 0.109514
model updated at epoch 289 
epoch 289, 
 train loss: 0.109514, val loss: 0.174125 
 val auc: 0.978116,  test auc: 0.972100
epoch 290, loss: 0.109104
epoch 290, 
 train loss: 0.109104, val loss: 0.174821 
 val auc: 0.977928,  test auc: 0.972063
epoch 291, loss: 0.108675
model updated at epoch 291 
epoch 291, 
 train loss: 0.108675, val loss: 0.173912 
 val auc: 0.978116,  test auc: 0.972110
epoch 292, loss: 0.108225
epoch 292, 
 train loss: 0.108225, val loss: 0.174758 
 val auc: 0.978041,  test auc: 0.972147
epoch 293, loss: 0.107782
epoch 293, 
 train loss: 0.107782, val loss: 0.174171 
 val auc: 0.978041,  test auc: 0.972166
epoch 294, loss: 0.107337
epoch 294, 
 train loss: 0.107337, val loss: 0.174329 
 val auc: 0.978003,  test auc: 0.972166
epoch 295, loss: 0.106898
epoch 295, 
 train loss: 0.106898, val loss: 0.174234 
 val auc: 0.978003,  test auc: 0.972232
epoch 296, loss: 0.106466
epoch 296, 
 train loss: 0.106466, val loss: 0.174177 
 val auc: 0.978003,  test auc: 0.972316
epoch 297, loss: 0.106045
epoch 297, 
 train loss: 0.106045, val loss: 0.174422 
 val auc: 0.978078,  test auc: 0.972354
epoch 298, loss: 0.105630
epoch 298, 
 train loss: 0.105630, val loss: 0.173933 
 val auc: 0.978266,  test auc: 0.972429
epoch 299, loss: 0.105248
epoch 299, 
 train loss: 0.105248, val loss: 0.174229 
 val auc: 0.978153,  test auc: 0.972494
epoch 300, loss: 0.104930
model updated at epoch 300 
epoch 300, 
 train loss: 0.104930, val loss: 0.172886 
 val auc: 0.978228,  test auc: 0.972504
epoch 301, loss: 0.104635
epoch 301, 
 train loss: 0.104635, val loss: 0.174805 
 val auc: 0.978191,  test auc: 0.972598
epoch 302, loss: 0.104468
epoch 302, 
 train loss: 0.104468, val loss: 0.173183 
 val auc: 0.978491,  test auc: 0.972588
epoch 303, loss: 0.104302
epoch 303, 
 train loss: 0.104302, val loss: 0.175861 
 val auc: 0.978191,  test auc: 0.972616
epoch 304, loss: 0.104197
model updated at epoch 304 
epoch 304, 
 train loss: 0.104197, val loss: 0.172825 
 val auc: 0.978641,  test auc: 0.972682
epoch 305, loss: 0.103540
epoch 305, 
 train loss: 0.103540, val loss: 0.176071 
 val auc: 0.978078,  test auc: 0.972767
epoch 306, loss: 0.102777
epoch 306, 
 train loss: 0.102777, val loss: 0.173108 
 val auc: 0.978641,  test auc: 0.972860
epoch 307, loss: 0.101917
epoch 307, 
 train loss: 0.101917, val loss: 0.174507 
 val auc: 0.978153,  test auc: 0.972898
epoch 308, loss: 0.101387
epoch 308, 
 train loss: 0.101387, val loss: 0.173880 
 val auc: 0.978191,  test auc: 0.972870
epoch 309, loss: 0.101190
epoch 309, 
 train loss: 0.101190, val loss: 0.173183 
 val auc: 0.978453,  test auc: 0.973048
epoch 310, loss: 0.101099
epoch 310, 
 train loss: 0.101099, val loss: 0.175469 
 val auc: 0.978078,  test auc: 0.972926
epoch 311, loss: 0.100910
epoch 311, 
 train loss: 0.100910, val loss: 0.173070 
 val auc: 0.978529,  test auc: 0.973011
epoch 312, loss: 0.100316
epoch 312, 
 train loss: 0.100316, val loss: 0.175569 
 val auc: 0.978153,  test auc: 0.973029
epoch 313, loss: 0.099652
epoch 313, 
 train loss: 0.099652, val loss: 0.173746 
 val auc: 0.978378,  test auc: 0.973076
epoch 314, loss: 0.099091
epoch 314, 
 train loss: 0.099091, val loss: 0.174771 
 val auc: 0.978003,  test auc: 0.972973
epoch 315, loss: 0.098784
epoch 315, 
 train loss: 0.098784, val loss: 0.175154 
 val auc: 0.978003,  test auc: 0.973076
epoch 316, loss: 0.098616
epoch 316, 
 train loss: 0.098616, val loss: 0.173874 
 val auc: 0.978341,  test auc: 0.973161
epoch 317, loss: 0.098419
epoch 317, 
 train loss: 0.098419, val loss: 0.175773 
 val auc: 0.978153,  test auc: 0.973208
epoch 318, loss: 0.098096
epoch 318, 
 train loss: 0.098096, val loss: 0.173644 
 val auc: 0.978416,  test auc: 0.973292
epoch 319, loss: 0.097530
epoch 319, 
 train loss: 0.097530, val loss: 0.175550 
 val auc: 0.978153,  test auc: 0.973320
epoch 320, loss: 0.096991
epoch 320, 
 train loss: 0.096991, val loss: 0.173892 
 val auc: 0.978378,  test auc: 0.973395
epoch 321, loss: 0.096624
epoch 321, 
 train loss: 0.096624, val loss: 0.173726 
 val auc: 0.978453,  test auc: 0.973386
epoch 322, loss: 0.096403
epoch 322, 
 train loss: 0.096403, val loss: 0.174803 
 val auc: 0.978416,  test auc: 0.973452
epoch 323, loss: 0.096221
epoch 323, 
 train loss: 0.096221, val loss: 0.173723 
 val auc: 0.978491,  test auc: 0.973611
epoch 324, loss: 0.095922
epoch 324, 
 train loss: 0.095922, val loss: 0.175959 
 val auc: 0.978041,  test auc: 0.973470
epoch 325, loss: 0.095508
epoch 325, 
 train loss: 0.095508, val loss: 0.173907 
 val auc: 0.978378,  test auc: 0.973620
epoch 326, loss: 0.095029
epoch 326, 
 train loss: 0.095029, val loss: 0.174913 
 val auc: 0.978191,  test auc: 0.973452
epoch 327, loss: 0.094636
epoch 327, 
 train loss: 0.094636, val loss: 0.174079 
 val auc: 0.978378,  test auc: 0.973517
epoch 328, loss: 0.094361
epoch 328, 
 train loss: 0.094361, val loss: 0.173954 
 val auc: 0.978491,  test auc: 0.973658
epoch 329, loss: 0.094135
epoch 329, 
 train loss: 0.094135, val loss: 0.175039 
 val auc: 0.978153,  test auc: 0.973592
epoch 330, loss: 0.093870
epoch 330, 
 train loss: 0.093870, val loss: 0.173675 
 val auc: 0.978491,  test auc: 0.973714
epoch 331, loss: 0.093535
epoch 331, 
 train loss: 0.093535, val loss: 0.174872 
 val auc: 0.978228,  test auc: 0.973574
epoch 332, loss: 0.093162
epoch 332, 
 train loss: 0.093162, val loss: 0.173363 
 val auc: 0.978604,  test auc: 0.973808
epoch 333, loss: 0.092795
epoch 333, 
 train loss: 0.092795, val loss: 0.174105 
 val auc: 0.978453,  test auc: 0.973827
epoch 334, loss: 0.092473
epoch 334, 
 train loss: 0.092473, val loss: 0.173699 
 val auc: 0.978604,  test auc: 0.973883
epoch 335, loss: 0.092201
epoch 335, 
 train loss: 0.092201, val loss: 0.173143 
 val auc: 0.978641,  test auc: 0.973855
epoch 336, loss: 0.091935
epoch 336, 
 train loss: 0.091935, val loss: 0.173972 
 val auc: 0.978641,  test auc: 0.973874
epoch 337, loss: 0.091670
epoch 337, 
 train loss: 0.091670, val loss: 0.173252 
 val auc: 0.978641,  test auc: 0.973986
epoch 338, loss: 0.091385
epoch 338, 
 train loss: 0.091385, val loss: 0.174531 
 val auc: 0.978491,  test auc: 0.973968
epoch 339, loss: 0.091076
epoch 339, 
 train loss: 0.091076, val loss: 0.173613 
 val auc: 0.978716,  test auc: 0.974099
epoch 340, loss: 0.090753
epoch 340, 
 train loss: 0.090753, val loss: 0.174126 
 val auc: 0.978679,  test auc: 0.974099
epoch 341, loss: 0.090447
epoch 341, 
 train loss: 0.090447, val loss: 0.173381 
 val auc: 0.978754,  test auc: 0.974118
epoch 342, loss: 0.090149
epoch 342, 
 train loss: 0.090149, val loss: 0.173501 
 val auc: 0.978716,  test auc: 0.974137
epoch 343, loss: 0.089873
epoch 343, 
 train loss: 0.089873, val loss: 0.173378 
 val auc: 0.978754,  test auc: 0.974184
epoch 344, loss: 0.089601
epoch 344, 
 train loss: 0.089601, val loss: 0.172886 
 val auc: 0.978866,  test auc: 0.974277
epoch 345, loss: 0.089332
epoch 345, 
 train loss: 0.089332, val loss: 0.173369 
 val auc: 0.978941,  test auc: 0.974390
epoch 346, loss: 0.089066
epoch 346, 
 train loss: 0.089066, val loss: 0.172983 
 val auc: 0.978829,  test auc: 0.974362
epoch 347, loss: 0.088803
epoch 347, 
 train loss: 0.088803, val loss: 0.173796 
 val auc: 0.978791,  test auc: 0.974446
epoch 348, loss: 0.088540
model updated at epoch 348 
epoch 348, 
 train loss: 0.088540, val loss: 0.172755 
 val auc: 0.978979,  test auc: 0.974568
epoch 349, loss: 0.088289
epoch 349, 
 train loss: 0.088289, val loss: 0.173380 
 val auc: 0.979054,  test auc: 0.974587
epoch 350, loss: 0.088031
model updated at epoch 350 
epoch 350, 
 train loss: 0.088031, val loss: 0.172420 
 val auc: 0.979129,  test auc: 0.974681
epoch 351, loss: 0.087780
epoch 351, 
 train loss: 0.087780, val loss: 0.173820 
 val auc: 0.979017,  test auc: 0.974643
epoch 352, loss: 0.087519
epoch 352, 
 train loss: 0.087519, val loss: 0.172788 
 val auc: 0.979092,  test auc: 0.974737
epoch 353, loss: 0.087248
epoch 353, 
 train loss: 0.087248, val loss: 0.173893 
 val auc: 0.979167,  test auc: 0.974747
epoch 354, loss: 0.086987
epoch 354, 
 train loss: 0.086987, val loss: 0.172718 
 val auc: 0.979092,  test auc: 0.974747
epoch 355, loss: 0.086717
epoch 355, 
 train loss: 0.086717, val loss: 0.173985 
 val auc: 0.979129,  test auc: 0.974794
epoch 356, loss: 0.086452
epoch 356, 
 train loss: 0.086452, val loss: 0.173124 
 val auc: 0.979242,  test auc: 0.974944
epoch 357, loss: 0.086194
epoch 357, 
 train loss: 0.086194, val loss: 0.174107 
 val auc: 0.979242,  test auc: 0.974878
epoch 358, loss: 0.085960
epoch 358, 
 train loss: 0.085960, val loss: 0.172949 
 val auc: 0.979129,  test auc: 0.974953
epoch 359, loss: 0.085741
epoch 359, 
 train loss: 0.085741, val loss: 0.173913 
 val auc: 0.979242,  test auc: 0.974981
epoch 360, loss: 0.085565
epoch 360, 
 train loss: 0.085565, val loss: 0.172847 
 val auc: 0.979354,  test auc: 0.975113
epoch 361, loss: 0.085410
epoch 361, 
 train loss: 0.085410, val loss: 0.174867 
 val auc: 0.979354,  test auc: 0.975066
epoch 362, loss: 0.085262
epoch 362, 
 train loss: 0.085262, val loss: 0.172705 
 val auc: 0.979692,  test auc: 0.975188
epoch 363, loss: 0.085051
epoch 363, 
 train loss: 0.085051, val loss: 0.174982 
 val auc: 0.979542,  test auc: 0.975113
epoch 364, loss: 0.084808
epoch 364, 
 train loss: 0.084808, val loss: 0.172642 
 val auc: 0.979692,  test auc: 0.975310
epoch 365, loss: 0.084496
epoch 365, 
 train loss: 0.084496, val loss: 0.174864 
 val auc: 0.979617,  test auc: 0.975338
epoch 366, loss: 0.084164
epoch 366, 
 train loss: 0.084164, val loss: 0.172605 
 val auc: 0.979767,  test auc: 0.975357
epoch 367, loss: 0.083806
epoch 367, 
 train loss: 0.083806, val loss: 0.174310 
 val auc: 0.979617,  test auc: 0.975338
epoch 368, loss: 0.083471
epoch 368, 
 train loss: 0.083471, val loss: 0.173274 
 val auc: 0.979730,  test auc: 0.975385
epoch 369, loss: 0.083189
epoch 369, 
 train loss: 0.083189, val loss: 0.173862 
 val auc: 0.979692,  test auc: 0.975385
epoch 370, loss: 0.082958
epoch 370, 
 train loss: 0.082958, val loss: 0.173678 
 val auc: 0.979655,  test auc: 0.975385
epoch 371, loss: 0.082764
epoch 371, 
 train loss: 0.082764, val loss: 0.172762 
 val auc: 0.979805,  test auc: 0.975535
epoch 372, loss: 0.082582
epoch 372, 
 train loss: 0.082582, val loss: 0.173893 
 val auc: 0.979842,  test auc: 0.975507
epoch 373, loss: 0.082389
epoch 373, 
 train loss: 0.082389, val loss: 0.172895 
 val auc: 0.980030,  test auc: 0.975685
epoch 374, loss: 0.082187
epoch 374, 
 train loss: 0.082187, val loss: 0.174314 
 val auc: 0.979805,  test auc: 0.975497
epoch 375, loss: 0.081949
model updated at epoch 375 
epoch 375, 
 train loss: 0.081949, val loss: 0.172389 
 val auc: 0.979992,  test auc: 0.975704
epoch 376, loss: 0.081675
epoch 376, 
 train loss: 0.081675, val loss: 0.173627 
 val auc: 0.979955,  test auc: 0.975638
epoch 377, loss: 0.081405
epoch 377, 
 train loss: 0.081405, val loss: 0.172538 
 val auc: 0.980105,  test auc: 0.975770
epoch 378, loss: 0.081135
epoch 378, 
 train loss: 0.081135, val loss: 0.173578 
 val auc: 0.980030,  test auc: 0.975713
epoch 379, loss: 0.080870
epoch 379, 
 train loss: 0.080870, val loss: 0.172719 
 val auc: 0.980105,  test auc: 0.975807
epoch 380, loss: 0.080625
epoch 380, 
 train loss: 0.080625, val loss: 0.172850 
 val auc: 0.980068,  test auc: 0.975779
epoch 381, loss: 0.080399
epoch 381, 
 train loss: 0.080399, val loss: 0.172763 
 val auc: 0.980105,  test auc: 0.975873
epoch 382, loss: 0.080178
epoch 382, 
 train loss: 0.080178, val loss: 0.172556 
 val auc: 0.980180,  test auc: 0.975920
epoch 383, loss: 0.079955
epoch 383, 
 train loss: 0.079955, val loss: 0.172672 
 val auc: 0.980105,  test auc: 0.975948
epoch 384, loss: 0.079739
model updated at epoch 384 
epoch 384, 
 train loss: 0.079739, val loss: 0.172071 
 val auc: 0.980180,  test auc: 0.975967
epoch 385, loss: 0.079532
epoch 385, 
 train loss: 0.079532, val loss: 0.172454 
 val auc: 0.980180,  test auc: 0.976060
epoch 386, loss: 0.079333
model updated at epoch 386 
epoch 386, 
 train loss: 0.079333, val loss: 0.171655 
 val auc: 0.980293,  test auc: 0.976126
epoch 387, loss: 0.079134
epoch 387, 
 train loss: 0.079134, val loss: 0.172804 
 val auc: 0.980180,  test auc: 0.976145
epoch 388, loss: 0.078940
epoch 388, 
 train loss: 0.078940, val loss: 0.171851 
 val auc: 0.980293,  test auc: 0.976239
epoch 389, loss: 0.078758
epoch 389, 
 train loss: 0.078758, val loss: 0.173139 
 val auc: 0.980068,  test auc: 0.976173
epoch 390, loss: 0.078586
epoch 390, 
 train loss: 0.078586, val loss: 0.171735 
 val auc: 0.980330,  test auc: 0.976342
epoch 391, loss: 0.078415
epoch 391, 
 train loss: 0.078415, val loss: 0.173444 
 val auc: 0.980030,  test auc: 0.976286
epoch 392, loss: 0.078240
epoch 392, 
 train loss: 0.078240, val loss: 0.171855 
 val auc: 0.980330,  test auc: 0.976455
epoch 393, loss: 0.078024
epoch 393, 
 train loss: 0.078024, val loss: 0.173598 
 val auc: 0.980143,  test auc: 0.976436
epoch 394, loss: 0.077800
model updated at epoch 394 
epoch 394, 
 train loss: 0.077800, val loss: 0.171457 
 val auc: 0.980218,  test auc: 0.976483
epoch 395, loss: 0.077542
epoch 395, 
 train loss: 0.077542, val loss: 0.173238 
 val auc: 0.980180,  test auc: 0.976464
epoch 396, loss: 0.077279
epoch 396, 
 train loss: 0.077279, val loss: 0.171909 
 val auc: 0.980405,  test auc: 0.976577
epoch 397, loss: 0.077000
epoch 397, 
 train loss: 0.077000, val loss: 0.172896 
 val auc: 0.980255,  test auc: 0.976511
epoch 398, loss: 0.076741
epoch 398, 
 train loss: 0.076741, val loss: 0.171577 
 val auc: 0.980330,  test auc: 0.976642
epoch 399, loss: 0.076501
epoch 399, 
 train loss: 0.076501, val loss: 0.171965 
 val auc: 0.980180,  test auc: 0.976633
epoch 400, loss: 0.076281
epoch 400, 
 train loss: 0.076281, val loss: 0.171792 
 val auc: 0.980330,  test auc: 0.976802
epoch 401, loss: 0.076074
epoch 401, 
 train loss: 0.076074, val loss: 0.171895 
 val auc: 0.980405,  test auc: 0.976905
epoch 402, loss: 0.075871
epoch 402, 
 train loss: 0.075871, val loss: 0.171952 
 val auc: 0.980405,  test auc: 0.976867
epoch 403, loss: 0.075676
model updated at epoch 403 
epoch 403, 
 train loss: 0.075676, val loss: 0.171446 
 val auc: 0.980518,  test auc: 0.976933
epoch 404, loss: 0.075489
epoch 404, 
 train loss: 0.075489, val loss: 0.171816 
 val auc: 0.980556,  test auc: 0.976905
epoch 405, loss: 0.075302
model updated at epoch 405 
epoch 405, 
 train loss: 0.075302, val loss: 0.171033 
 val auc: 0.980706,  test auc: 0.977018
epoch 406, loss: 0.075117
epoch 406, 
 train loss: 0.075117, val loss: 0.171813 
 val auc: 0.980443,  test auc: 0.976943
epoch 407, loss: 0.074941
epoch 407, 
 train loss: 0.074941, val loss: 0.171068 
 val auc: 0.980706,  test auc: 0.977055
epoch 408, loss: 0.074765
epoch 408, 
 train loss: 0.074765, val loss: 0.172357 
 val auc: 0.980480,  test auc: 0.977083
epoch 409, loss: 0.074600
model updated at epoch 409 
epoch 409, 
 train loss: 0.074600, val loss: 0.170995 
 val auc: 0.980781,  test auc: 0.977224
epoch 410, loss: 0.074435
epoch 410, 
 train loss: 0.074435, val loss: 0.172092 
 val auc: 0.980556,  test auc: 0.977093
epoch 411, loss: 0.074287
model updated at epoch 411 
epoch 411, 
 train loss: 0.074287, val loss: 0.170438 
 val auc: 0.980856,  test auc: 0.977299
epoch 412, loss: 0.074140
epoch 412, 
 train loss: 0.074140, val loss: 0.172209 
 val auc: 0.980668,  test auc: 0.977196
epoch 413, loss: 0.073989
epoch 413, 
 train loss: 0.073989, val loss: 0.170468 
 val auc: 0.981006,  test auc: 0.977402
epoch 414, loss: 0.073810
epoch 414, 
 train loss: 0.073810, val loss: 0.172249 
 val auc: 0.980631,  test auc: 0.977233
epoch 415, loss: 0.073605
model updated at epoch 415 
epoch 415, 
 train loss: 0.073605, val loss: 0.170330 
 val auc: 0.981044,  test auc: 0.977515
epoch 416, loss: 0.073361
epoch 416, 
 train loss: 0.073361, val loss: 0.172022 
 val auc: 0.980781,  test auc: 0.977355
epoch 417, loss: 0.073106
model updated at epoch 417 
epoch 417, 
 train loss: 0.073106, val loss: 0.170154 
 val auc: 0.981081,  test auc: 0.977609
epoch 418, loss: 0.072835
epoch 418, 
 train loss: 0.072835, val loss: 0.171554 
 val auc: 0.980781,  test auc: 0.977459
epoch 419, loss: 0.072572
epoch 419, 
 train loss: 0.072572, val loss: 0.170537 
 val auc: 0.981081,  test auc: 0.977693
epoch 420, loss: 0.072333
epoch 420, 
 train loss: 0.072333, val loss: 0.171359 
 val auc: 0.980931,  test auc: 0.977656
epoch 421, loss: 0.072123
epoch 421, 
 train loss: 0.072123, val loss: 0.170934 
 val auc: 0.981119,  test auc: 0.977750
epoch 422, loss: 0.071931
epoch 422, 
 train loss: 0.071931, val loss: 0.170819 
 val auc: 0.981156,  test auc: 0.977778
epoch 423, loss: 0.071749
epoch 423, 
 train loss: 0.071749, val loss: 0.170655 
 val auc: 0.981044,  test auc: 0.977815
epoch 424, loss: 0.071577
epoch 424, 
 train loss: 0.071577, val loss: 0.170158 
 val auc: 0.981231,  test auc: 0.977956
epoch 425, loss: 0.071410
epoch 425, 
 train loss: 0.071410, val loss: 0.170864 
 val auc: 0.981081,  test auc: 0.977853
epoch 426, loss: 0.071252
epoch 426, 
 train loss: 0.071252, val loss: 0.170162 
 val auc: 0.981194,  test auc: 0.978050
epoch 427, loss: 0.071098
epoch 427, 
 train loss: 0.071098, val loss: 0.171254 
 val auc: 0.981119,  test auc: 0.977965
epoch 428, loss: 0.070947
model updated at epoch 428 
epoch 428, 
 train loss: 0.070947, val loss: 0.170107 
 val auc: 0.981231,  test auc: 0.978078
epoch 429, loss: 0.070790
epoch 429, 
 train loss: 0.070790, val loss: 0.171311 
 val auc: 0.981081,  test auc: 0.978012
epoch 430, loss: 0.070642
model updated at epoch 430 
epoch 430, 
 train loss: 0.070642, val loss: 0.169639 
 val auc: 0.981231,  test auc: 0.978116
epoch 431, loss: 0.070488
epoch 431, 
 train loss: 0.070488, val loss: 0.171204 
 val auc: 0.981194,  test auc: 0.978078
epoch 432, loss: 0.070367
epoch 432, 
 train loss: 0.070367, val loss: 0.169722 
 val auc: 0.981419,  test auc: 0.978163
epoch 433, loss: 0.070250
epoch 433, 
 train loss: 0.070250, val loss: 0.171991 
 val auc: 0.981269,  test auc: 0.978153
epoch 434, loss: 0.070111
epoch 434, 
 train loss: 0.070111, val loss: 0.170097 
 val auc: 0.981419,  test auc: 0.978303
epoch 435, loss: 0.069883
epoch 435, 
 train loss: 0.069883, val loss: 0.172062 
 val auc: 0.981269,  test auc: 0.978303
epoch 436, loss: 0.069593
model updated at epoch 436 
epoch 436, 
 train loss: 0.069593, val loss: 0.169548 
 val auc: 0.981381,  test auc: 0.978435
epoch 437, loss: 0.069274
epoch 437, 
 train loss: 0.069274, val loss: 0.170705 
 val auc: 0.981306,  test auc: 0.978435
epoch 438, loss: 0.068989
epoch 438, 
 train loss: 0.068989, val loss: 0.169962 
 val auc: 0.981306,  test auc: 0.978463
epoch 439, loss: 0.068782
epoch 439, 
 train loss: 0.068782, val loss: 0.170188 
 val auc: 0.981419,  test auc: 0.978519
epoch 440, loss: 0.068641
epoch 440, 
 train loss: 0.068641, val loss: 0.170339 
 val auc: 0.981456,  test auc: 0.978482
epoch 441, loss: 0.068536
model updated at epoch 441 
epoch 441, 
 train loss: 0.068536, val loss: 0.169175 
 val auc: 0.981419,  test auc: 0.978557
epoch 442, loss: 0.068437
epoch 442, 
 train loss: 0.068437, val loss: 0.170642 
 val auc: 0.981456,  test auc: 0.978566
epoch 443, loss: 0.068322
model updated at epoch 443 
epoch 443, 
 train loss: 0.068322, val loss: 0.169057 
 val auc: 0.981532,  test auc: 0.978660
epoch 444, loss: 0.068146
epoch 444, 
 train loss: 0.068146, val loss: 0.170663 
 val auc: 0.981532,  test auc: 0.978641
epoch 445, loss: 0.067939
model updated at epoch 445 
epoch 445, 
 train loss: 0.067939, val loss: 0.168976 
 val auc: 0.981532,  test auc: 0.978744
epoch 446, loss: 0.067691
epoch 446, 
 train loss: 0.067691, val loss: 0.170507 
 val auc: 0.981682,  test auc: 0.978754
epoch 447, loss: 0.067434
epoch 447, 
 train loss: 0.067434, val loss: 0.169461 
 val auc: 0.981682,  test auc: 0.978876
epoch 448, loss: 0.067199
epoch 448, 
 train loss: 0.067199, val loss: 0.170100 
 val auc: 0.981682,  test auc: 0.978801
epoch 449, loss: 0.067011
epoch 449, 
 train loss: 0.067011, val loss: 0.169855 
 val auc: 0.981682,  test auc: 0.978791
epoch 450, loss: 0.066863
epoch 450, 
 train loss: 0.066863, val loss: 0.169473 
 val auc: 0.981719,  test auc: 0.978876
epoch 451, loss: 0.066732
epoch 451, 
 train loss: 0.066732, val loss: 0.170174 
 val auc: 0.981869,  test auc: 0.978838
epoch 452, loss: 0.066599
epoch 452, 
 train loss: 0.066599, val loss: 0.169082 
 val auc: 0.981869,  test auc: 0.979082
epoch 453, loss: 0.066454
epoch 453, 
 train loss: 0.066454, val loss: 0.170125 
 val auc: 0.981944,  test auc: 0.978895
epoch 454, loss: 0.066278
model updated at epoch 454 
epoch 454, 
 train loss: 0.066278, val loss: 0.168751 
 val auc: 0.982020,  test auc: 0.979092
epoch 455, loss: 0.066089
epoch 455, 
 train loss: 0.066089, val loss: 0.170135 
 val auc: 0.981944,  test auc: 0.978932
epoch 456, loss: 0.065879
epoch 456, 
 train loss: 0.065879, val loss: 0.169020 
 val auc: 0.982020,  test auc: 0.979148
epoch 457, loss: 0.065673
epoch 457, 
 train loss: 0.065673, val loss: 0.169632 
 val auc: 0.982057,  test auc: 0.979026
epoch 458, loss: 0.065474
epoch 458, 
 train loss: 0.065474, val loss: 0.168909 
 val auc: 0.982207,  test auc: 0.979214
epoch 459, loss: 0.065291
epoch 459, 
 train loss: 0.065291, val loss: 0.169125 
 val auc: 0.982132,  test auc: 0.979204
epoch 460, loss: 0.065114
epoch 460, 
 train loss: 0.065114, val loss: 0.168985 
 val auc: 0.982245,  test auc: 0.979261
epoch 461, loss: 0.064952
model updated at epoch 461 
epoch 461, 
 train loss: 0.064952, val loss: 0.168514 
 val auc: 0.982170,  test auc: 0.979326
epoch 462, loss: 0.064801
epoch 462, 
 train loss: 0.064801, val loss: 0.169334 
 val auc: 0.982095,  test auc: 0.979232
epoch 463, loss: 0.064663
epoch 463, 
 train loss: 0.064663, val loss: 0.168844 
 val auc: 0.981982,  test auc: 0.979345
epoch 464, loss: 0.064521
epoch 464, 
 train loss: 0.064521, val loss: 0.169718 
 val auc: 0.981944,  test auc: 0.979242
epoch 465, loss: 0.064372
epoch 465, 
 train loss: 0.064372, val loss: 0.168521 
 val auc: 0.981982,  test auc: 0.979354
epoch 466, loss: 0.064202
epoch 466, 
 train loss: 0.064202, val loss: 0.169667 
 val auc: 0.981907,  test auc: 0.979336
epoch 467, loss: 0.064018
epoch 467, 
 train loss: 0.064018, val loss: 0.168837 
 val auc: 0.981982,  test auc: 0.979448
epoch 468, loss: 0.063828
epoch 468, 
 train loss: 0.063828, val loss: 0.169513 
 val auc: 0.981944,  test auc: 0.979420
epoch 469, loss: 0.063654
epoch 469, 
 train loss: 0.063654, val loss: 0.168833 
 val auc: 0.982020,  test auc: 0.979495
epoch 470, loss: 0.063493
epoch 470, 
 train loss: 0.063493, val loss: 0.169085 
 val auc: 0.982020,  test auc: 0.979523
epoch 471, loss: 0.063333
epoch 471, 
 train loss: 0.063333, val loss: 0.169249 
 val auc: 0.981982,  test auc: 0.979523
epoch 472, loss: 0.063192
epoch 472, 
 train loss: 0.063192, val loss: 0.169288 
 val auc: 0.981982,  test auc: 0.979570
epoch 473, loss: 0.063140
epoch 473, 
 train loss: 0.063140, val loss: 0.170026 
 val auc: 0.981944,  test auc: 0.979523
epoch 474, loss: 0.063209
epoch 474, 
 train loss: 0.063209, val loss: 0.168871 
 val auc: 0.982170,  test auc: 0.979711
epoch 475, loss: 0.063301
epoch 475, 
 train loss: 0.063301, val loss: 0.171888 
 val auc: 0.982170,  test auc: 0.979598
epoch 476, loss: 0.063383
epoch 476, 
 train loss: 0.063383, val loss: 0.169396 
 val auc: 0.982470,  test auc: 0.979805
epoch 477, loss: 0.063337
epoch 477, 
 train loss: 0.063337, val loss: 0.172707 
 val auc: 0.982395,  test auc: 0.979683
epoch 478, loss: 0.063115
epoch 478, 
 train loss: 0.063115, val loss: 0.169272 
 val auc: 0.982583,  test auc: 0.979908
epoch 479, loss: 0.062645
epoch 479, 
 train loss: 0.062645, val loss: 0.171926 
 val auc: 0.982245,  test auc: 0.979730
epoch 480, loss: 0.062147
epoch 480, 
 train loss: 0.062147, val loss: 0.169735 
 val auc: 0.982357,  test auc: 0.979974
epoch 481, loss: 0.061869
epoch 481, 
 train loss: 0.061869, val loss: 0.170381 
 val auc: 0.982207,  test auc: 0.979833
epoch 482, loss: 0.061868
epoch 482, 
 train loss: 0.061868, val loss: 0.171448 
 val auc: 0.982245,  test auc: 0.979805
epoch 483, loss: 0.061938
epoch 483, 
 train loss: 0.061938, val loss: 0.169702 
 val auc: 0.982470,  test auc: 0.980143
epoch 484, loss: 0.061868
epoch 484, 
 train loss: 0.061868, val loss: 0.171879 
 val auc: 0.982320,  test auc: 0.979870
epoch 485, loss: 0.061607
epoch 485, 
 train loss: 0.061607, val loss: 0.169370 
 val auc: 0.982508,  test auc: 0.980190
epoch 486, loss: 0.061255
epoch 486, 
 train loss: 0.061255, val loss: 0.170890 
 val auc: 0.982245,  test auc: 0.979955
epoch 487, loss: 0.060985
epoch 487, 
 train loss: 0.060985, val loss: 0.170051 
 val auc: 0.982245,  test auc: 0.980049
epoch 488, loss: 0.060878
epoch 488, 
 train loss: 0.060878, val loss: 0.169921 
 val auc: 0.982282,  test auc: 0.980086
epoch 489, loss: 0.060865
epoch 489, 
 train loss: 0.060865, val loss: 0.171235 
 val auc: 0.982282,  test auc: 0.979955
epoch 490, loss: 0.060818
epoch 490, 
 train loss: 0.060818, val loss: 0.169906 
 val auc: 0.982470,  test auc: 0.980180
epoch 491, loss: 0.060641
epoch 491, 
 train loss: 0.060641, val loss: 0.171651 
 val auc: 0.982245,  test auc: 0.979983
epoch 492, loss: 0.060390
epoch 492, 
 train loss: 0.060390, val loss: 0.170017 
 val auc: 0.982357,  test auc: 0.980152
epoch 493, loss: 0.060158
epoch 493, 
 train loss: 0.060158, val loss: 0.170698 
 val auc: 0.982357,  test auc: 0.980114
epoch 494, loss: 0.060004
epoch 494, 
 train loss: 0.060004, val loss: 0.170554 
 val auc: 0.982320,  test auc: 0.980152
epoch 495, loss: 0.059921
epoch 495, 
 train loss: 0.059921, val loss: 0.170323 
 val auc: 0.982395,  test auc: 0.980274
epoch 496, loss: 0.059860
epoch 496, 
 train loss: 0.059860, val loss: 0.171594 
 val auc: 0.982245,  test auc: 0.980039
epoch 497, loss: 0.059757
epoch 497, 
 train loss: 0.059757, val loss: 0.170360 
 val auc: 0.982432,  test auc: 0.980274
epoch 498, loss: 0.059586
epoch 498, 
 train loss: 0.059586, val loss: 0.171812 
 val auc: 0.982320,  test auc: 0.980152
epoch 499, loss: 0.059379
epoch 499, 
 train loss: 0.059379, val loss: 0.170701 
 val auc: 0.982470,  test auc: 0.980312
epoch 500, loss: 0.059195
epoch 500, 
 train loss: 0.059195, val loss: 0.171125 
 val auc: 0.982395,  test auc: 0.980236
epoch 501, loss: 0.059066
epoch 501, 
 train loss: 0.059066, val loss: 0.171289 
 val auc: 0.982395,  test auc: 0.980227
epoch 502, loss: 0.058978
epoch 502, 
 train loss: 0.058978, val loss: 0.170875 
 val auc: 0.982470,  test auc: 0.980312
epoch 503, loss: 0.058921
epoch 503, 
 train loss: 0.058921, val loss: 0.171656 
 val auc: 0.982432,  test auc: 0.980265
epoch 504, loss: 0.058815
epoch 504, 
 train loss: 0.058815, val loss: 0.170806 
 val auc: 0.982845,  test auc: 0.980574
epoch 505, loss: 0.058654
epoch 505, 
 train loss: 0.058654, val loss: 0.172464 
 val auc: 0.982545,  test auc: 0.980340
epoch 506, loss: 0.058448
epoch 506, 
 train loss: 0.058448, val loss: 0.170866 
 val auc: 0.982695,  test auc: 0.980471
epoch 507, loss: 0.058275
epoch 507, 
 train loss: 0.058275, val loss: 0.170990 
 val auc: 0.982733,  test auc: 0.980387
epoch 508, loss: 0.058138
epoch 508, 
 train loss: 0.058138, val loss: 0.171604 
 val auc: 0.982620,  test auc: 0.980405
epoch 509, loss: 0.058035
epoch 509, 
 train loss: 0.058035, val loss: 0.171499 
 val auc: 0.982770,  test auc: 0.980546
epoch 510, loss: 0.057932
epoch 510, 
 train loss: 0.057932, val loss: 0.172227 
 val auc: 0.982470,  test auc: 0.980312
epoch 511, loss: 0.057812
epoch 511, 
 train loss: 0.057812, val loss: 0.171168 
 val auc: 0.982770,  test auc: 0.980527
epoch 512, loss: 0.057653
epoch 512, 
 train loss: 0.057653, val loss: 0.172491 
 val auc: 0.982545,  test auc: 0.980312
epoch 513, loss: 0.057481
epoch 513, 
 train loss: 0.057481, val loss: 0.171842 
 val auc: 0.982658,  test auc: 0.980509
epoch 514, loss: 0.057332
epoch 514, 
 train loss: 0.057332, val loss: 0.171962 
 val auc: 0.982620,  test auc: 0.980377
epoch 515, loss: 0.057212
epoch 515, 
 train loss: 0.057212, val loss: 0.172024 
 val auc: 0.982620,  test auc: 0.980358
epoch 516, loss: 0.057108
epoch 516, 
 train loss: 0.057108, val loss: 0.171542 
 val auc: 0.982733,  test auc: 0.980509
epoch 517, loss: 0.056996
epoch 517, 
 train loss: 0.056996, val loss: 0.171964 
 val auc: 0.982545,  test auc: 0.980358
epoch 518, loss: 0.056857
epoch 518, 
 train loss: 0.056857, val loss: 0.170813 
 val auc: 0.982883,  test auc: 0.980556
epoch 519, loss: 0.056706
epoch 519, 
 train loss: 0.056706, val loss: 0.171490 
 val auc: 0.982658,  test auc: 0.980443
epoch 520, loss: 0.056567
epoch 520, 
 train loss: 0.056567, val loss: 0.171424 
 val auc: 0.982733,  test auc: 0.980556
epoch 521, loss: 0.056442
epoch 521, 
 train loss: 0.056442, val loss: 0.171530 
 val auc: 0.982733,  test auc: 0.980527
epoch 522, loss: 0.056329
epoch 522, 
 train loss: 0.056329, val loss: 0.171950 
 val auc: 0.982583,  test auc: 0.980443
epoch 523, loss: 0.056220
epoch 523, 
 train loss: 0.056220, val loss: 0.171877 
 val auc: 0.982845,  test auc: 0.980631
epoch 524, loss: 0.056114
epoch 524, 
 train loss: 0.056114, val loss: 0.172794 
 val auc: 0.982620,  test auc: 0.980452
epoch 525, loss: 0.056002
epoch 525, 
 train loss: 0.056002, val loss: 0.172064 
 val auc: 0.982958,  test auc: 0.980696
epoch 526, loss: 0.055876
epoch 526, 
 train loss: 0.055876, val loss: 0.172867 
 val auc: 0.982658,  test auc: 0.980565
epoch 527, loss: 0.055739
epoch 527, 
 train loss: 0.055739, val loss: 0.172197 
 val auc: 0.982845,  test auc: 0.980659
epoch 528, loss: 0.055602
epoch 528, 
 train loss: 0.055602, val loss: 0.172675 
 val auc: 0.982620,  test auc: 0.980565
epoch 529, loss: 0.055473
epoch 529, 
 train loss: 0.055473, val loss: 0.172668 
 val auc: 0.982733,  test auc: 0.980659
epoch 530, loss: 0.055357
epoch 530, 
 train loss: 0.055357, val loss: 0.172765 
 val auc: 0.982770,  test auc: 0.980678
epoch 531, loss: 0.055253
epoch 531, 
 train loss: 0.055253, val loss: 0.173185 
 val auc: 0.982658,  test auc: 0.980584
epoch 532, loss: 0.055154
epoch 532, 
 train loss: 0.055154, val loss: 0.172783 
 val auc: 0.982808,  test auc: 0.980724
epoch 533, loss: 0.055053
epoch 533, 
 train loss: 0.055053, val loss: 0.173626 
 val auc: 0.982658,  test auc: 0.980565
epoch 534, loss: 0.054951
epoch 534, 
 train loss: 0.054951, val loss: 0.173047 
 val auc: 0.982845,  test auc: 0.980743
epoch 535, loss: 0.054824
epoch 535, 
 train loss: 0.054824, val loss: 0.174060 
 val auc: 0.982470,  test auc: 0.980527
epoch 536, loss: 0.054690
epoch 536, 
 train loss: 0.054690, val loss: 0.173398 
 val auc: 0.982770,  test auc: 0.980753
epoch 537, loss: 0.054556
epoch 537, 
 train loss: 0.054556, val loss: 0.174178 
 val auc: 0.982583,  test auc: 0.980659
epoch 538, loss: 0.054423
epoch 538, 
 train loss: 0.054423, val loss: 0.173886 
 val auc: 0.982695,  test auc: 0.980753
epoch 539, loss: 0.054309
epoch 539, 
 train loss: 0.054309, val loss: 0.173778 
 val auc: 0.982695,  test auc: 0.980706
epoch 540, loss: 0.054202
epoch 540, 
 train loss: 0.054202, val loss: 0.173910 
 val auc: 0.982695,  test auc: 0.980706
epoch 541, loss: 0.054103
epoch 541, 
 train loss: 0.054103, val loss: 0.173586 
 val auc: 0.982883,  test auc: 0.980818
epoch 542, loss: 0.054003
epoch 542, 
 train loss: 0.054003, val loss: 0.174308 
 val auc: 0.982695,  test auc: 0.980696
epoch 543, loss: 0.053897
epoch 543, 
 train loss: 0.053897, val loss: 0.173800 
 val auc: 0.982883,  test auc: 0.980846
epoch 544, loss: 0.053791
epoch 544, 
 train loss: 0.053791, val loss: 0.174734 
 val auc: 0.982620,  test auc: 0.980696
epoch 545, loss: 0.053688
epoch 545, 
 train loss: 0.053688, val loss: 0.174056 
 val auc: 0.982845,  test auc: 0.980837
epoch 546, loss: 0.053585
epoch 546, 
 train loss: 0.053585, val loss: 0.175103 
 val auc: 0.982545,  test auc: 0.980668
epoch 547, loss: 0.053486
epoch 547, 
 train loss: 0.053486, val loss: 0.174244 
 val auc: 0.982845,  test auc: 0.980865
epoch 548, loss: 0.053446
epoch 548, 
 train loss: 0.053446, val loss: 0.175057 
 val auc: 0.982658,  test auc: 0.980743
epoch 549, loss: 0.053372
epoch 549, 
 train loss: 0.053372, val loss: 0.174326 
 val auc: 0.982995,  test auc: 0.981006
epoch 550, loss: 0.053297
epoch 550, 
 train loss: 0.053297, val loss: 0.176130 
 val auc: 0.982583,  test auc: 0.980790
epoch 551, loss: 0.053141
epoch 551, 
 train loss: 0.053141, val loss: 0.174280 
 val auc: 0.983071,  test auc: 0.981025
epoch 552, loss: 0.052983
epoch 552, 
 train loss: 0.052983, val loss: 0.175369 
 val auc: 0.982620,  test auc: 0.980837
epoch 553, loss: 0.052814
epoch 553, 
 train loss: 0.052814, val loss: 0.175014 
 val auc: 0.982845,  test auc: 0.981015
epoch 554, loss: 0.052676
epoch 554, 
 train loss: 0.052676, val loss: 0.175653 
 val auc: 0.982733,  test auc: 0.980884
epoch 555, loss: 0.052551
epoch 555, 
 train loss: 0.052551, val loss: 0.175273 
 val auc: 0.982845,  test auc: 0.980903
epoch 556, loss: 0.052457
epoch 556, 
 train loss: 0.052457, val loss: 0.175310 
 val auc: 0.982995,  test auc: 0.980903
epoch 557, loss: 0.052361
epoch 557, 
 train loss: 0.052361, val loss: 0.175941 
 val auc: 0.982583,  test auc: 0.980743
epoch 558, loss: 0.052284
epoch 558, 
 train loss: 0.052284, val loss: 0.175046 
 val auc: 0.982733,  test auc: 0.980828
epoch 559, loss: 0.052195
epoch 559, 
 train loss: 0.052195, val loss: 0.176004 
 val auc: 0.982658,  test auc: 0.980753
epoch 560, loss: 0.052112
epoch 560, 
 train loss: 0.052112, val loss: 0.175381 
 val auc: 0.982733,  test auc: 0.980884
epoch 561, loss: 0.052001
epoch 561, 
 train loss: 0.052001, val loss: 0.176738 
 val auc: 0.982320,  test auc: 0.980696
epoch 562, loss: 0.051881
epoch 562, 
 train loss: 0.051881, val loss: 0.175533 
 val auc: 0.982770,  test auc: 0.980903
epoch 563, loss: 0.051738
epoch 563, 
 train loss: 0.051738, val loss: 0.176138 
 val auc: 0.982545,  test auc: 0.980734
epoch 564, loss: 0.051608
epoch 564, 
 train loss: 0.051608, val loss: 0.175390 
 val auc: 0.982883,  test auc: 0.980950
epoch 565, loss: 0.051489
epoch 565, 
 train loss: 0.051489, val loss: 0.175891 
 val auc: 0.982770,  test auc: 0.980903
epoch 566, loss: 0.051387
epoch 566, 
 train loss: 0.051387, val loss: 0.175933 
 val auc: 0.982658,  test auc: 0.980884
epoch 567, loss: 0.051296
epoch 567, 
 train loss: 0.051296, val loss: 0.175625 
 val auc: 0.982733,  test auc: 0.980903
epoch 568, loss: 0.051212
epoch 568, 
 train loss: 0.051212, val loss: 0.176056 
 val auc: 0.982583,  test auc: 0.980856
epoch 569, loss: 0.051129
epoch 569, 
 train loss: 0.051129, val loss: 0.175496 
 val auc: 0.982845,  test auc: 0.981015
epoch 570, loss: 0.051044
epoch 570, 
 train loss: 0.051044, val loss: 0.176568 
 val auc: 0.982545,  test auc: 0.980856
epoch 571, loss: 0.050965
epoch 571, 
 train loss: 0.050965, val loss: 0.175818 
 val auc: 0.982883,  test auc: 0.981053
epoch 572, loss: 0.050881
epoch 572, 
 train loss: 0.050881, val loss: 0.177136 
 val auc: 0.982432,  test auc: 0.980809
epoch 573, loss: 0.050788
epoch 573, 
 train loss: 0.050788, val loss: 0.176329 
 val auc: 0.982845,  test auc: 0.981053
epoch 574, loss: 0.050676
epoch 574, 
 train loss: 0.050676, val loss: 0.177745 
 val auc: 0.982357,  test auc: 0.980790
epoch 575, loss: 0.050558
epoch 575, 
 train loss: 0.050558, val loss: 0.176809 
 val auc: 0.982620,  test auc: 0.980940
epoch 576, loss: 0.050435
epoch 576, 
 train loss: 0.050435, val loss: 0.177598 
 val auc: 0.982170,  test auc: 0.980781
epoch 577, loss: 0.050317
epoch 577, 
 train loss: 0.050317, val loss: 0.176958 
 val auc: 0.982545,  test auc: 0.980978
epoch 578, loss: 0.050203
epoch 578, 
 train loss: 0.050203, val loss: 0.177351 
 val auc: 0.982432,  test auc: 0.980912
epoch 579, loss: 0.050094
epoch 579, 
 train loss: 0.050094, val loss: 0.176816 
 val auc: 0.982620,  test auc: 0.981006
epoch 580, loss: 0.049993
epoch 580, 
 train loss: 0.049993, val loss: 0.177222 
 val auc: 0.982508,  test auc: 0.980997
epoch 581, loss: 0.049902
epoch 581, 
 train loss: 0.049902, val loss: 0.177631 
 val auc: 0.982432,  test auc: 0.980987
epoch 582, loss: 0.049800
epoch 582, 
 train loss: 0.049800, val loss: 0.177335 
 val auc: 0.982583,  test auc: 0.981044
epoch 583, loss: 0.049709
epoch 583, 
 train loss: 0.049709, val loss: 0.177538 
 val auc: 0.982508,  test auc: 0.981025
epoch 584, loss: 0.049615
epoch 584, 
 train loss: 0.049615, val loss: 0.177590 
 val auc: 0.982508,  test auc: 0.981044
epoch 585, loss: 0.049520
epoch 585, 
 train loss: 0.049520, val loss: 0.178083 
 val auc: 0.982357,  test auc: 0.980987
epoch 586, loss: 0.049434
epoch 586, 
 train loss: 0.049434, val loss: 0.177663 
 val auc: 0.982583,  test auc: 0.981006
epoch 587, loss: 0.049344
epoch 587, 
 train loss: 0.049344, val loss: 0.178209 
 val auc: 0.982357,  test auc: 0.980987
epoch 588, loss: 0.049262
epoch 588, 
 train loss: 0.049262, val loss: 0.178021 
 val auc: 0.982470,  test auc: 0.981044
epoch 589, loss: 0.049199
epoch 589, 
 train loss: 0.049199, val loss: 0.178610 
 val auc: 0.982320,  test auc: 0.980987
epoch 590, loss: 0.049163
epoch 590, 
 train loss: 0.049163, val loss: 0.177573 
 val auc: 0.982658,  test auc: 0.981166
epoch 591, loss: 0.049160
epoch 591, 
 train loss: 0.049160, val loss: 0.179245 
 val auc: 0.982245,  test auc: 0.980959
epoch 592, loss: 0.049199
epoch 592, 
 train loss: 0.049199, val loss: 0.178056 
 val auc: 0.982883,  test auc: 0.981250
epoch 593, loss: 0.049267
epoch 593, 
 train loss: 0.049267, val loss: 0.180579 
 val auc: 0.982320,  test auc: 0.980968
epoch 594, loss: 0.049413
epoch 594, 
 train loss: 0.049413, val loss: 0.178427 
 val auc: 0.982995,  test auc: 0.981269
epoch 595, loss: 0.050147
epoch 595, 
 train loss: 0.050147, val loss: 0.181309 
 val auc: 0.982395,  test auc: 0.980997
epoch 596, loss: 0.051017
epoch 596, 
 train loss: 0.051017, val loss: 0.179700 
 val auc: 0.983258,  test auc: 0.981485
epoch 597, loss: 0.052486
epoch 597, 
 train loss: 0.052486, val loss: 0.188057 
 val auc: 0.981907,  test auc: 0.980997
epoch 598, loss: 0.054157
epoch 598, 
 train loss: 0.054157, val loss: 0.182499 
 val auc: 0.983296,  test auc: 0.981100
epoch 599, loss: 0.054409
epoch 599, 
 train loss: 0.054409, val loss: 0.190727 
 val auc: 0.981944,  test auc: 0.980734
epoch 600, loss: 0.051433
epoch 600, 
 train loss: 0.051433, val loss: 0.183162 
 val auc: 0.982920,  test auc: 0.981391
epoch 601, loss: 0.048631
epoch 601, 
 train loss: 0.048631, val loss: 0.182937 
 val auc: 0.982320,  test auc: 0.981363
epoch 602, loss: 0.050864
epoch 602, 
 train loss: 0.050864, val loss: 0.186299 
 val auc: 0.982207,  test auc: 0.980903
epoch 603, loss: 0.050881
epoch 603, 
 train loss: 0.050881, val loss: 0.180326 
 val auc: 0.983108,  test auc: 0.981175
epoch 604, loss: 0.048330
epoch 604, 
 train loss: 0.048330, val loss: 0.181618 
 val auc: 0.982395,  test auc: 0.981363
epoch 605, loss: 0.049610
epoch 605, 
 train loss: 0.049610, val loss: 0.185376 
 val auc: 0.982320,  test auc: 0.981241
epoch 606, loss: 0.049802
epoch 606, 
 train loss: 0.049802, val loss: 0.179868 
 val auc: 0.983371,  test auc: 0.981513
epoch 607, loss: 0.047952
epoch 607, 
 train loss: 0.047952, val loss: 0.180126 
 val auc: 0.982770,  test auc: 0.981278
epoch 608, loss: 0.048952
epoch 608, 
 train loss: 0.048952, val loss: 0.183156 
 val auc: 0.982470,  test auc: 0.981119
epoch 609, loss: 0.048861
epoch 609, 
 train loss: 0.048861, val loss: 0.178860 
 val auc: 0.983333,  test auc: 0.981447
epoch 610, loss: 0.047647
epoch 610, 
 train loss: 0.047647, val loss: 0.179473 
 val auc: 0.982658,  test auc: 0.981269
epoch 611, loss: 0.048424
epoch 611, 
 train loss: 0.048424, val loss: 0.182316 
 val auc: 0.982432,  test auc: 0.981062
epoch 612, loss: 0.048096
epoch 612, 
 train loss: 0.048096, val loss: 0.178585 
 val auc: 0.983108,  test auc: 0.981372
epoch 613, loss: 0.047325
epoch 613, 
 train loss: 0.047325, val loss: 0.179099 
 val auc: 0.982658,  test auc: 0.981297
epoch 614, loss: 0.047938
epoch 614, 
 train loss: 0.047938, val loss: 0.181980 
 val auc: 0.982320,  test auc: 0.981053
epoch 615, loss: 0.047419
epoch 615, 
 train loss: 0.047419, val loss: 0.178563 
 val auc: 0.982808,  test auc: 0.981363
epoch 616, loss: 0.047130
epoch 616, 
 train loss: 0.047130, val loss: 0.178675 
 val auc: 0.982845,  test auc: 0.981334
epoch 617, loss: 0.047530
epoch 617, 
 train loss: 0.047530, val loss: 0.181304 
 val auc: 0.982470,  test auc: 0.981086
epoch 618, loss: 0.046964
epoch 618, 
 train loss: 0.046964, val loss: 0.179147 
 val auc: 0.982695,  test auc: 0.981288
epoch 619, loss: 0.046954
epoch 619, 
 train loss: 0.046954, val loss: 0.179935 
 val auc: 0.982733,  test auc: 0.981381
epoch 620, loss: 0.047093
epoch 620, 
 train loss: 0.047093, val loss: 0.182699 
 val auc: 0.982470,  test auc: 0.981166
epoch 621, loss: 0.046620
epoch 621, 
 train loss: 0.046620, val loss: 0.180341 
 val auc: 0.982658,  test auc: 0.981325
epoch 622, loss: 0.046727
epoch 622, 
 train loss: 0.046727, val loss: 0.179777 
 val auc: 0.982733,  test auc: 0.981344
epoch 623, loss: 0.046713
epoch 623, 
 train loss: 0.046713, val loss: 0.182333 
 val auc: 0.982545,  test auc: 0.981334
epoch 624, loss: 0.046348
epoch 624, 
 train loss: 0.046348, val loss: 0.181469 
 val auc: 0.982658,  test auc: 0.981410
epoch 625, loss: 0.046462
epoch 625, 
 train loss: 0.046462, val loss: 0.180852 
 val auc: 0.982695,  test auc: 0.981410
epoch 626, loss: 0.046377
epoch 626, 
 train loss: 0.046377, val loss: 0.182177 
 val auc: 0.982545,  test auc: 0.981297
epoch 627, loss: 0.046097
epoch 627, 
 train loss: 0.046097, val loss: 0.181496 
 val auc: 0.982733,  test auc: 0.981410
epoch 628, loss: 0.046201
epoch 628, 
 train loss: 0.046201, val loss: 0.181452 
 val auc: 0.982620,  test auc: 0.981410
epoch 629, loss: 0.046059
epoch 629, 
 train loss: 0.046059, val loss: 0.182980 
 val auc: 0.982583,  test auc: 0.981344
epoch 630, loss: 0.045869
epoch 630, 
 train loss: 0.045869, val loss: 0.182220 
 val auc: 0.982583,  test auc: 0.981316
epoch 631, loss: 0.045923
epoch 631, 
 train loss: 0.045923, val loss: 0.181650 
 val auc: 0.982695,  test auc: 0.981391
epoch 632, loss: 0.045771
epoch 632, 
 train loss: 0.045771, val loss: 0.182951 
 val auc: 0.982545,  test auc: 0.981428
epoch 633, loss: 0.045636
epoch 633, 
 train loss: 0.045636, val loss: 0.182454 
 val auc: 0.982583,  test auc: 0.981466
epoch 634, loss: 0.045652
epoch 634, 
 train loss: 0.045652, val loss: 0.181496 
 val auc: 0.982695,  test auc: 0.981447
epoch 635, loss: 0.045506
epoch 635, 
 train loss: 0.045506, val loss: 0.182258 
 val auc: 0.982658,  test auc: 0.981503
epoch 636, loss: 0.045400
epoch 636, 
 train loss: 0.045400, val loss: 0.182338 
 val auc: 0.982695,  test auc: 0.981503
epoch 637, loss: 0.045393
epoch 637, 
 train loss: 0.045393, val loss: 0.182005 
 val auc: 0.982658,  test auc: 0.981503
epoch 638, loss: 0.045256
epoch 638, 
 train loss: 0.045256, val loss: 0.182753 
 val auc: 0.982658,  test auc: 0.981550
epoch 639, loss: 0.045169
epoch 639, 
 train loss: 0.045169, val loss: 0.182755 
 val auc: 0.982620,  test auc: 0.981485
epoch 640, loss: 0.045136
epoch 640, 
 train loss: 0.045136, val loss: 0.182299 
 val auc: 0.982695,  test auc: 0.981532
epoch 641, loss: 0.045008
epoch 641, 
 train loss: 0.045008, val loss: 0.182809 
 val auc: 0.982620,  test auc: 0.981541
epoch 642, loss: 0.044950
epoch 642, 
 train loss: 0.044950, val loss: 0.182811 
 val auc: 0.982620,  test auc: 0.981550
epoch 643, loss: 0.044881
epoch 643, 
 train loss: 0.044881, val loss: 0.182277 
 val auc: 0.982733,  test auc: 0.981607
epoch 644, loss: 0.044776
epoch 644, 
 train loss: 0.044776, val loss: 0.182799 
 val auc: 0.982695,  test auc: 0.981578
epoch 645, loss: 0.044721
epoch 645, 
 train loss: 0.044721, val loss: 0.183324 
 val auc: 0.982620,  test auc: 0.981541
epoch 646, loss: 0.044646
epoch 646, 
 train loss: 0.044646, val loss: 0.183143 
 val auc: 0.982658,  test auc: 0.981588
epoch 647, loss: 0.044549
epoch 647, 
 train loss: 0.044549, val loss: 0.183552 
 val auc: 0.982620,  test auc: 0.981588
epoch 648, loss: 0.044492
epoch 648, 
 train loss: 0.044492, val loss: 0.183652 
 val auc: 0.982545,  test auc: 0.981550
epoch 649, loss: 0.044410
epoch 649, 
 train loss: 0.044410, val loss: 0.182942 
 val auc: 0.982695,  test auc: 0.981672
epoch 650, loss: 0.044322
epoch 650, 
 train loss: 0.044322, val loss: 0.183103 
 val auc: 0.982695,  test auc: 0.981672
epoch 651, loss: 0.044259
epoch 651, 
 train loss: 0.044259, val loss: 0.183565 
 val auc: 0.982658,  test auc: 0.981654
epoch 652, loss: 0.044176
epoch 652, 
 train loss: 0.044176, val loss: 0.183420 
 val auc: 0.982658,  test auc: 0.981700
epoch 653, loss: 0.044098
epoch 653, 
 train loss: 0.044098, val loss: 0.183621 
 val auc: 0.982620,  test auc: 0.981663
epoch 654, loss: 0.044032
epoch 654, 
 train loss: 0.044032, val loss: 0.184021 
 val auc: 0.982658,  test auc: 0.981625
epoch 655, loss: 0.043953
epoch 655, 
 train loss: 0.043953, val loss: 0.183892 
 val auc: 0.982658,  test auc: 0.981710
epoch 656, loss: 0.043872
epoch 656, 
 train loss: 0.043872, val loss: 0.184055 
 val auc: 0.982658,  test auc: 0.981710
epoch 657, loss: 0.043806
epoch 657, 
 train loss: 0.043806, val loss: 0.184225 
 val auc: 0.982620,  test auc: 0.981607
epoch 658, loss: 0.043728
epoch 658, 
 train loss: 0.043728, val loss: 0.184091 
 val auc: 0.982695,  test auc: 0.981729
epoch 659, loss: 0.043656
epoch 659, 
 train loss: 0.043656, val loss: 0.184294 
 val auc: 0.982733,  test auc: 0.981738
epoch 660, loss: 0.043586
epoch 660, 
 train loss: 0.043586, val loss: 0.184440 
 val auc: 0.982733,  test auc: 0.981700
epoch 661, loss: 0.043510
epoch 661, 
 train loss: 0.043510, val loss: 0.184244 
 val auc: 0.982658,  test auc: 0.981719
epoch 662, loss: 0.043433
epoch 662, 
 train loss: 0.043433, val loss: 0.184557 
 val auc: 0.982620,  test auc: 0.981682
epoch 663, loss: 0.043365
epoch 663, 
 train loss: 0.043365, val loss: 0.184727 
 val auc: 0.982620,  test auc: 0.981644
epoch 664, loss: 0.043295
epoch 664, 
 train loss: 0.043295, val loss: 0.184591 
 val auc: 0.982620,  test auc: 0.981738
epoch 665, loss: 0.043219
epoch 665, 
 train loss: 0.043219, val loss: 0.184780 
 val auc: 0.982620,  test auc: 0.981691
epoch 666, loss: 0.043148
epoch 666, 
 train loss: 0.043148, val loss: 0.184953 
 val auc: 0.982620,  test auc: 0.981719
epoch 667, loss: 0.043076
epoch 667, 
 train loss: 0.043076, val loss: 0.184943 
 val auc: 0.982620,  test auc: 0.981776
epoch 668, loss: 0.043008
epoch 668, 
 train loss: 0.043008, val loss: 0.185193 
 val auc: 0.982620,  test auc: 0.981757
epoch 669, loss: 0.042935
epoch 669, 
 train loss: 0.042935, val loss: 0.185160 
 val auc: 0.982620,  test auc: 0.981729
epoch 670, loss: 0.042866
epoch 670, 
 train loss: 0.042866, val loss: 0.184989 
 val auc: 0.982545,  test auc: 0.981766
epoch 671, loss: 0.042797
epoch 671, 
 train loss: 0.042797, val loss: 0.185138 
 val auc: 0.982583,  test auc: 0.981804
epoch 672, loss: 0.042727
epoch 672, 
 train loss: 0.042727, val loss: 0.185250 
 val auc: 0.982583,  test auc: 0.981794
epoch 673, loss: 0.042658
epoch 673, 
 train loss: 0.042658, val loss: 0.185315 
 val auc: 0.982508,  test auc: 0.981729
epoch 674, loss: 0.042591
epoch 674, 
 train loss: 0.042591, val loss: 0.185540 
 val auc: 0.982508,  test auc: 0.981710
epoch 675, loss: 0.042522
epoch 675, 
 train loss: 0.042522, val loss: 0.185699 
 val auc: 0.982583,  test auc: 0.981729
epoch 676, loss: 0.042452
epoch 676, 
 train loss: 0.042452, val loss: 0.185860 
 val auc: 0.982508,  test auc: 0.981766
epoch 677, loss: 0.042384
epoch 677, 
 train loss: 0.042384, val loss: 0.185919 
 val auc: 0.982470,  test auc: 0.981747
epoch 678, loss: 0.042316
epoch 678, 
 train loss: 0.042316, val loss: 0.185849 
 val auc: 0.982432,  test auc: 0.981747
epoch 679, loss: 0.042250
epoch 679, 
 train loss: 0.042250, val loss: 0.185773 
 val auc: 0.982508,  test auc: 0.981794
epoch 680, loss: 0.042184
epoch 680, 
 train loss: 0.042184, val loss: 0.186067 
 val auc: 0.982508,  test auc: 0.981785
epoch 681, loss: 0.042114
epoch 681, 
 train loss: 0.042114, val loss: 0.186089 
 val auc: 0.982470,  test auc: 0.981794
epoch 682, loss: 0.042048
epoch 682, 
 train loss: 0.042048, val loss: 0.186118 
 val auc: 0.982470,  test auc: 0.981794
epoch 683, loss: 0.041984
epoch 683, 
 train loss: 0.041984, val loss: 0.186300 
 val auc: 0.982470,  test auc: 0.981785
epoch 684, loss: 0.041917
epoch 684, 
 train loss: 0.041917, val loss: 0.186435 
 val auc: 0.982508,  test auc: 0.981794
epoch 685, loss: 0.041849
epoch 685, 
 train loss: 0.041849, val loss: 0.186577 
 val auc: 0.982470,  test auc: 0.981757
epoch 686, loss: 0.041785
epoch 686, 
 train loss: 0.041785, val loss: 0.186693 
 val auc: 0.982508,  test auc: 0.981747
epoch 687, loss: 0.041720
epoch 687, 
 train loss: 0.041720, val loss: 0.186699 
 val auc: 0.982508,  test auc: 0.981794
epoch 688, loss: 0.041654
epoch 688, 
 train loss: 0.041654, val loss: 0.186854 
 val auc: 0.982545,  test auc: 0.981757
epoch 689, loss: 0.041592
epoch 689, 
 train loss: 0.041592, val loss: 0.187028 
 val auc: 0.982470,  test auc: 0.981757
epoch 690, loss: 0.041530
epoch 690, 
 train loss: 0.041530, val loss: 0.187020 
 val auc: 0.982508,  test auc: 0.981776
epoch 691, loss: 0.041463
epoch 691, 
 train loss: 0.041463, val loss: 0.187257 
 val auc: 0.982545,  test auc: 0.981757
epoch 692, loss: 0.041401
epoch 692, 
 train loss: 0.041401, val loss: 0.187427 
 val auc: 0.982432,  test auc: 0.981729
epoch 693, loss: 0.041339
epoch 693, 
 train loss: 0.041339, val loss: 0.187574 
 val auc: 0.982470,  test auc: 0.981757
epoch 694, loss: 0.041274
epoch 694, 
 train loss: 0.041274, val loss: 0.187722 
 val auc: 0.982470,  test auc: 0.981757
epoch 695, loss: 0.041214
epoch 695, 
 train loss: 0.041214, val loss: 0.187756 
 val auc: 0.982470,  test auc: 0.981766
epoch 696, loss: 0.041153
epoch 696, 
 train loss: 0.041153, val loss: 0.187687 
 val auc: 0.982470,  test auc: 0.981785
epoch 697, loss: 0.041091
epoch 697, 
 train loss: 0.041091, val loss: 0.187987 
 val auc: 0.982545,  test auc: 0.981785
epoch 698, loss: 0.041028
epoch 698, 
 train loss: 0.041028, val loss: 0.187984 
 val auc: 0.982508,  test auc: 0.981804
epoch 699, loss: 0.040967
epoch 699, 
 train loss: 0.040967, val loss: 0.188095 
 val auc: 0.982545,  test auc: 0.981841
epoch 700, loss: 0.040907
epoch 700, 
 train loss: 0.040907, val loss: 0.188064 
 val auc: 0.982583,  test auc: 0.981851
epoch 701, loss: 0.040847
epoch 701, 
 train loss: 0.040847, val loss: 0.187861 
 val auc: 0.982583,  test auc: 0.981869
epoch 702, loss: 0.040785
epoch 702, 
 train loss: 0.040785, val loss: 0.188014 
 val auc: 0.982658,  test auc: 0.981860
epoch 703, loss: 0.040724
epoch 703, 
 train loss: 0.040724, val loss: 0.188251 
 val auc: 0.982658,  test auc: 0.981869
epoch 704, loss: 0.040667
epoch 704, 
 train loss: 0.040667, val loss: 0.188311 
 val auc: 0.982658,  test auc: 0.981879
epoch 705, loss: 0.040614
epoch 705, 
 train loss: 0.040614, val loss: 0.188321 
 val auc: 0.982583,  test auc: 0.981851
epoch 706, loss: 0.040582
epoch 706, 
 train loss: 0.040582, val loss: 0.188504 
 val auc: 0.982658,  test auc: 0.981832
epoch 707, loss: 0.040635
epoch 707, 
 train loss: 0.040635, val loss: 0.188585 
 val auc: 0.982583,  test auc: 0.981813
epoch 708, loss: 0.040878
epoch 708, 
 train loss: 0.040878, val loss: 0.189538 
 val auc: 0.982545,  test auc: 0.981719
epoch 709, loss: 0.040706
epoch 709, 
 train loss: 0.040706, val loss: 0.188221 
 val auc: 0.982770,  test auc: 0.981907
epoch 710, loss: 0.040354
epoch 710, 
 train loss: 0.040354, val loss: 0.189068 
 val auc: 0.982695,  test auc: 0.981935
epoch 711, loss: 0.040540
epoch 711, 
 train loss: 0.040540, val loss: 0.189668 
 val auc: 0.982545,  test auc: 0.981738
epoch 712, loss: 0.040488
epoch 712, 
 train loss: 0.040488, val loss: 0.188096 
 val auc: 0.982770,  test auc: 0.981907
epoch 713, loss: 0.040194
epoch 713, 
 train loss: 0.040194, val loss: 0.188804 
 val auc: 0.982620,  test auc: 0.981926
epoch 714, loss: 0.040245
epoch 714, 
 train loss: 0.040245, val loss: 0.189329 
 val auc: 0.982695,  test auc: 0.981898
epoch 715, loss: 0.040258
epoch 715, 
 train loss: 0.040258, val loss: 0.188285 
 val auc: 0.982808,  test auc: 0.981954
epoch 716, loss: 0.040009
epoch 716, 
 train loss: 0.040009, val loss: 0.189575 
 val auc: 0.982770,  test auc: 0.981944
epoch 717, loss: 0.040041
epoch 717, 
 train loss: 0.040041, val loss: 0.190509 
 val auc: 0.982695,  test auc: 0.981841
epoch 718, loss: 0.040037
epoch 718, 
 train loss: 0.040037, val loss: 0.189244 
 val auc: 0.982770,  test auc: 0.981916
epoch 719, loss: 0.039853
epoch 719, 
 train loss: 0.039853, val loss: 0.189728 
 val auc: 0.982808,  test auc: 0.981898
epoch 720, loss: 0.039831
epoch 720, 
 train loss: 0.039831, val loss: 0.190439 
 val auc: 0.982658,  test auc: 0.981860
epoch 721, loss: 0.039838
epoch 721, 
 train loss: 0.039838, val loss: 0.189843 
 val auc: 0.982770,  test auc: 0.981935
epoch 722, loss: 0.039691
epoch 722, 
 train loss: 0.039691, val loss: 0.189945 
 val auc: 0.982770,  test auc: 0.981832
epoch 723, loss: 0.039638
epoch 723, 
 train loss: 0.039638, val loss: 0.190115 
 val auc: 0.982733,  test auc: 0.981851
epoch 724, loss: 0.039643
epoch 724, 
 train loss: 0.039643, val loss: 0.189835 
 val auc: 0.982770,  test auc: 0.981963
epoch 725, loss: 0.039513
epoch 725, 
 train loss: 0.039513, val loss: 0.190083 
 val auc: 0.982733,  test auc: 0.981898
epoch 726, loss: 0.039461
epoch 726, 
 train loss: 0.039461, val loss: 0.189745 
 val auc: 0.982845,  test auc: 0.981898
epoch 727, loss: 0.039450
epoch 727, 
 train loss: 0.039450, val loss: 0.189590 
 val auc: 0.982733,  test auc: 0.981954
epoch 728, loss: 0.039356
epoch 728, 
 train loss: 0.039356, val loss: 0.190351 
 val auc: 0.982620,  test auc: 0.981963
epoch 729, loss: 0.039287
epoch 729, 
 train loss: 0.039287, val loss: 0.189981 
 val auc: 0.982770,  test auc: 0.981926
epoch 730, loss: 0.039269
epoch 730, 
 train loss: 0.039269, val loss: 0.189719 
 val auc: 0.982808,  test auc: 0.981926
epoch 731, loss: 0.039190
epoch 731, 
 train loss: 0.039190, val loss: 0.190492 
 val auc: 0.982658,  test auc: 0.981926
epoch 732, loss: 0.039119
epoch 732, 
 train loss: 0.039119, val loss: 0.190258 
 val auc: 0.982695,  test auc: 0.981935
epoch 733, loss: 0.039097
epoch 733, 
 train loss: 0.039097, val loss: 0.189890 
 val auc: 0.982808,  test auc: 0.981963
epoch 734, loss: 0.039028
epoch 734, 
 train loss: 0.039028, val loss: 0.190597 
 val auc: 0.982733,  test auc: 0.981973
epoch 735, loss: 0.038956
epoch 735, 
 train loss: 0.038956, val loss: 0.190493 
 val auc: 0.982733,  test auc: 0.981954
epoch 736, loss: 0.038922
epoch 736, 
 train loss: 0.038922, val loss: 0.190252 
 val auc: 0.982808,  test auc: 0.981973
epoch 737, loss: 0.038870
epoch 737, 
 train loss: 0.038870, val loss: 0.190686 
 val auc: 0.982733,  test auc: 0.981991
epoch 738, loss: 0.038802
epoch 738, 
 train loss: 0.038802, val loss: 0.190611 
 val auc: 0.982808,  test auc: 0.981963
epoch 739, loss: 0.038757
epoch 739, 
 train loss: 0.038757, val loss: 0.190492 
 val auc: 0.982845,  test auc: 0.981973
epoch 740, loss: 0.038713
epoch 740, 
 train loss: 0.038713, val loss: 0.190820 
 val auc: 0.982845,  test auc: 0.982029
epoch 741, loss: 0.038648
epoch 741, 
 train loss: 0.038648, val loss: 0.190695 
 val auc: 0.982845,  test auc: 0.981963
epoch 742, loss: 0.038598
epoch 742, 
 train loss: 0.038598, val loss: 0.190794 
 val auc: 0.982845,  test auc: 0.981973
epoch 743, loss: 0.038558
epoch 743, 
 train loss: 0.038558, val loss: 0.191029 
 val auc: 0.982808,  test auc: 0.981991
epoch 744, loss: 0.038501
epoch 744, 
 train loss: 0.038501, val loss: 0.190976 
 val auc: 0.982808,  test auc: 0.981944
epoch 745, loss: 0.038448
epoch 745, 
 train loss: 0.038448, val loss: 0.191124 
 val auc: 0.982845,  test auc: 0.981991
epoch 746, loss: 0.038403
epoch 746, 
 train loss: 0.038403, val loss: 0.191354 
 val auc: 0.982770,  test auc: 0.981954
epoch 747, loss: 0.038354
epoch 747, 
 train loss: 0.038354, val loss: 0.191280 
 val auc: 0.982808,  test auc: 0.981926
epoch 748, loss: 0.038300
epoch 748, 
 train loss: 0.038300, val loss: 0.191603 
 val auc: 0.982808,  test auc: 0.982010
epoch 749, loss: 0.038252
epoch 749, 
 train loss: 0.038252, val loss: 0.191488 
 val auc: 0.982770,  test auc: 0.982001
epoch 750, loss: 0.038208
epoch 750, 
 train loss: 0.038208, val loss: 0.191112 
 val auc: 0.982883,  test auc: 0.981991
epoch 751, loss: 0.038154
epoch 751, 
 train loss: 0.038154, val loss: 0.191331 
 val auc: 0.982845,  test auc: 0.982001
epoch 752, loss: 0.038106
epoch 752, 
 train loss: 0.038106, val loss: 0.191571 
 val auc: 0.982770,  test auc: 0.981991
epoch 753, loss: 0.038066
epoch 753, 
 train loss: 0.038066, val loss: 0.191491 
 val auc: 0.982845,  test auc: 0.981963
epoch 754, loss: 0.038015
epoch 754, 
 train loss: 0.038015, val loss: 0.191767 
 val auc: 0.982808,  test auc: 0.982001
epoch 755, loss: 0.037963
epoch 755, 
 train loss: 0.037963, val loss: 0.191566 
 val auc: 0.982808,  test auc: 0.981982
epoch 756, loss: 0.037919
epoch 756, 
 train loss: 0.037919, val loss: 0.191505 
 val auc: 0.982920,  test auc: 0.982048
epoch 757, loss: 0.037879
epoch 757, 
 train loss: 0.037879, val loss: 0.191826 
 val auc: 0.982808,  test auc: 0.982029
epoch 758, loss: 0.037826
epoch 758, 
 train loss: 0.037826, val loss: 0.191750 
 val auc: 0.982920,  test auc: 0.982048
epoch 759, loss: 0.037779
epoch 759, 
 train loss: 0.037779, val loss: 0.191791 
 val auc: 0.982883,  test auc: 0.982048
epoch 760, loss: 0.037735
epoch 760, 
 train loss: 0.037735, val loss: 0.191948 
 val auc: 0.982883,  test auc: 0.982048
epoch 761, loss: 0.037689
epoch 761, 
 train loss: 0.037689, val loss: 0.192028 
 val auc: 0.982920,  test auc: 0.982048
epoch 762, loss: 0.037642
epoch 762, 
 train loss: 0.037642, val loss: 0.192087 
 val auc: 0.982920,  test auc: 0.982104
epoch 763, loss: 0.037594
epoch 763, 
 train loss: 0.037594, val loss: 0.191922 
 val auc: 0.982920,  test auc: 0.982095
epoch 764, loss: 0.037550
epoch 764, 
 train loss: 0.037550, val loss: 0.192028 
 val auc: 0.982995,  test auc: 0.982095
epoch 765, loss: 0.037507
epoch 765, 
 train loss: 0.037507, val loss: 0.192422 
 val auc: 0.982995,  test auc: 0.982113
epoch 766, loss: 0.037462
epoch 766, 
 train loss: 0.037462, val loss: 0.192370 
 val auc: 0.983033,  test auc: 0.982113
epoch 767, loss: 0.037415
epoch 767, 
 train loss: 0.037415, val loss: 0.192429 
 val auc: 0.982958,  test auc: 0.982123
epoch 768, loss: 0.037370
epoch 768, 
 train loss: 0.037370, val loss: 0.192318 
 val auc: 0.982995,  test auc: 0.982104
epoch 769, loss: 0.037326
epoch 769, 
 train loss: 0.037326, val loss: 0.192442 
 val auc: 0.982958,  test auc: 0.982132
epoch 770, loss: 0.037280
epoch 770, 
 train loss: 0.037280, val loss: 0.192677 
 val auc: 0.982920,  test auc: 0.982160
epoch 771, loss: 0.037238
epoch 771, 
 train loss: 0.037238, val loss: 0.192794 
 val auc: 0.982920,  test auc: 0.982104
epoch 772, loss: 0.037194
epoch 772, 
 train loss: 0.037194, val loss: 0.192784 
 val auc: 0.982920,  test auc: 0.982123
epoch 773, loss: 0.037152
epoch 773, 
 train loss: 0.037152, val loss: 0.192529 
 val auc: 0.982958,  test auc: 0.982151
epoch 774, loss: 0.037110
epoch 774, 
 train loss: 0.037110, val loss: 0.192672 
 val auc: 0.982995,  test auc: 0.982151
epoch 775, loss: 0.037064
epoch 775, 
 train loss: 0.037064, val loss: 0.192869 
 val auc: 0.983033,  test auc: 0.982160
epoch 776, loss: 0.037023
epoch 776, 
 train loss: 0.037023, val loss: 0.193280 
 val auc: 0.982958,  test auc: 0.982160
epoch 777, loss: 0.036976
epoch 777, 
 train loss: 0.036976, val loss: 0.193158 
 val auc: 0.982995,  test auc: 0.982160
epoch 778, loss: 0.036932
epoch 778, 
 train loss: 0.036932, val loss: 0.193088 
 val auc: 0.982958,  test auc: 0.982170
epoch 779, loss: 0.036890
epoch 779, 
 train loss: 0.036890, val loss: 0.193212 
 val auc: 0.982920,  test auc: 0.982170
epoch 780, loss: 0.036844
epoch 780, 
 train loss: 0.036844, val loss: 0.193525 
 val auc: 0.982958,  test auc: 0.982151
epoch 781, loss: 0.036804
epoch 781, 
 train loss: 0.036804, val loss: 0.193820 
 val auc: 0.982958,  test auc: 0.982142
epoch 782, loss: 0.036757
epoch 782, 
 train loss: 0.036757, val loss: 0.193577 
 val auc: 0.983033,  test auc: 0.982188
epoch 783, loss: 0.036716
epoch 783, 
 train loss: 0.036716, val loss: 0.193200 
 val auc: 0.982958,  test auc: 0.982179
epoch 784, loss: 0.036674
epoch 784, 
 train loss: 0.036674, val loss: 0.193072 
 val auc: 0.982958,  test auc: 0.982160
epoch 785, loss: 0.036629
epoch 785, 
 train loss: 0.036629, val loss: 0.193395 
 val auc: 0.982995,  test auc: 0.982170
epoch 786, loss: 0.036587
epoch 786, 
 train loss: 0.036587, val loss: 0.193721 
 val auc: 0.982995,  test auc: 0.982179
epoch 787, loss: 0.036544
epoch 787, 
 train loss: 0.036544, val loss: 0.193763 
 val auc: 0.982920,  test auc: 0.982132
epoch 788, loss: 0.036502
epoch 788, 
 train loss: 0.036502, val loss: 0.193730 
 val auc: 0.982958,  test auc: 0.982160
epoch 789, loss: 0.036459
epoch 789, 
 train loss: 0.036459, val loss: 0.193755 
 val auc: 0.982958,  test auc: 0.982142
epoch 790, loss: 0.036416
epoch 790, 
 train loss: 0.036416, val loss: 0.193938 
 val auc: 0.982958,  test auc: 0.982179
epoch 791, loss: 0.036374
epoch 791, 
 train loss: 0.036374, val loss: 0.194040 
 val auc: 0.982995,  test auc: 0.982188
epoch 792, loss: 0.036331
epoch 792, 
 train loss: 0.036331, val loss: 0.194132 
 val auc: 0.982995,  test auc: 0.982207
epoch 793, loss: 0.036289
epoch 793, 
 train loss: 0.036289, val loss: 0.193979 
 val auc: 0.982995,  test auc: 0.982198
epoch 794, loss: 0.036247
epoch 794, 
 train loss: 0.036247, val loss: 0.194019 
 val auc: 0.982958,  test auc: 0.982188
epoch 795, loss: 0.036205
epoch 795, 
 train loss: 0.036205, val loss: 0.194397 
 val auc: 0.982958,  test auc: 0.982207
epoch 796, loss: 0.036164
epoch 796, 
 train loss: 0.036164, val loss: 0.194441 
 val auc: 0.982995,  test auc: 0.982207
epoch 797, loss: 0.036123
epoch 797, 
 train loss: 0.036123, val loss: 0.194437 
 val auc: 0.982995,  test auc: 0.982217
epoch 798, loss: 0.036083
epoch 798, 
 train loss: 0.036083, val loss: 0.194620 
 val auc: 0.982958,  test auc: 0.982217
epoch 799, loss: 0.036043
epoch 799, 
 train loss: 0.036043, val loss: 0.194566 
 val auc: 0.982995,  test auc: 0.982188
epoch 800, loss: 0.036001
epoch 800, 
 train loss: 0.036001, val loss: 0.194617 
 val auc: 0.982958,  test auc: 0.982217
epoch 801, loss: 0.035961
epoch 801, 
 train loss: 0.035961, val loss: 0.194770 
 val auc: 0.983033,  test auc: 0.982273
epoch 802, loss: 0.035921
epoch 802, 
 train loss: 0.035921, val loss: 0.194748 
 val auc: 0.983071,  test auc: 0.982217
epoch 803, loss: 0.035880
epoch 803, 
 train loss: 0.035880, val loss: 0.194708 
 val auc: 0.983071,  test auc: 0.982207
epoch 804, loss: 0.035841
epoch 804, 
 train loss: 0.035841, val loss: 0.194678 
 val auc: 0.983071,  test auc: 0.982217
epoch 805, loss: 0.035800
epoch 805, 
 train loss: 0.035800, val loss: 0.194915 
 val auc: 0.983071,  test auc: 0.982226
epoch 806, loss: 0.035762
epoch 806, 
 train loss: 0.035762, val loss: 0.195018 
 val auc: 0.983071,  test auc: 0.982226
epoch 807, loss: 0.035720
epoch 807, 
 train loss: 0.035720, val loss: 0.195229 
 val auc: 0.983108,  test auc: 0.982207
epoch 808, loss: 0.035680
epoch 808, 
 train loss: 0.035680, val loss: 0.195236 
 val auc: 0.983146,  test auc: 0.982264
epoch 809, loss: 0.035639
epoch 809, 
 train loss: 0.035639, val loss: 0.195034 
 val auc: 0.983183,  test auc: 0.982235
epoch 810, loss: 0.035597
epoch 810, 
 train loss: 0.035597, val loss: 0.195096 
 val auc: 0.983146,  test auc: 0.982226
epoch 811, loss: 0.035558
epoch 811, 
 train loss: 0.035558, val loss: 0.195195 
 val auc: 0.983221,  test auc: 0.982292
epoch 812, loss: 0.035521
epoch 812, 
 train loss: 0.035521, val loss: 0.195183 
 val auc: 0.983183,  test auc: 0.982245
epoch 813, loss: 0.035482
epoch 813, 
 train loss: 0.035482, val loss: 0.195226 
 val auc: 0.983146,  test auc: 0.982235
epoch 814, loss: 0.035442
epoch 814, 
 train loss: 0.035442, val loss: 0.195629 
 val auc: 0.983183,  test auc: 0.982282
epoch 815, loss: 0.035401
epoch 815, 
 train loss: 0.035401, val loss: 0.195541 
 val auc: 0.983183,  test auc: 0.982235
epoch 816, loss: 0.035359
epoch 816, 
 train loss: 0.035359, val loss: 0.195674 
 val auc: 0.983221,  test auc: 0.982282
epoch 817, loss: 0.035319
epoch 817, 
 train loss: 0.035319, val loss: 0.195700 
 val auc: 0.983221,  test auc: 0.982329
epoch 818, loss: 0.035283
epoch 818, 
 train loss: 0.035283, val loss: 0.195543 
 val auc: 0.983221,  test auc: 0.982245
epoch 819, loss: 0.035244
epoch 819, 
 train loss: 0.035244, val loss: 0.195648 
 val auc: 0.983221,  test auc: 0.982273
epoch 820, loss: 0.035207
epoch 820, 
 train loss: 0.035207, val loss: 0.195668 
 val auc: 0.983221,  test auc: 0.982320
epoch 821, loss: 0.035168
epoch 821, 
 train loss: 0.035168, val loss: 0.195711 
 val auc: 0.983221,  test auc: 0.982292
epoch 822, loss: 0.035128
epoch 822, 
 train loss: 0.035128, val loss: 0.195572 
 val auc: 0.983221,  test auc: 0.982282
epoch 823, loss: 0.035089
epoch 823, 
 train loss: 0.035089, val loss: 0.195700 
 val auc: 0.983221,  test auc: 0.982320
epoch 824, loss: 0.035052
epoch 824, 
 train loss: 0.035052, val loss: 0.195525 
 val auc: 0.983221,  test auc: 0.982282
epoch 825, loss: 0.035014
epoch 825, 
 train loss: 0.035014, val loss: 0.195805 
 val auc: 0.983221,  test auc: 0.982310
epoch 826, loss: 0.034977
epoch 826, 
 train loss: 0.034977, val loss: 0.195961 
 val auc: 0.983258,  test auc: 0.982339
epoch 827, loss: 0.034940
epoch 827, 
 train loss: 0.034940, val loss: 0.195895 
 val auc: 0.983296,  test auc: 0.982329
epoch 828, loss: 0.034902
epoch 828, 
 train loss: 0.034902, val loss: 0.196127 
 val auc: 0.983258,  test auc: 0.982292
epoch 829, loss: 0.034865
epoch 829, 
 train loss: 0.034865, val loss: 0.196132 
 val auc: 0.983258,  test auc: 0.982282
epoch 830, loss: 0.034828
epoch 830, 
 train loss: 0.034828, val loss: 0.196049 
 val auc: 0.983296,  test auc: 0.982292
epoch 831, loss: 0.034791
epoch 831, 
 train loss: 0.034791, val loss: 0.196117 
 val auc: 0.983296,  test auc: 0.982339
epoch 832, loss: 0.034754
epoch 832, 
 train loss: 0.034754, val loss: 0.196201 
 val auc: 0.983296,  test auc: 0.982320
epoch 833, loss: 0.034717
epoch 833, 
 train loss: 0.034717, val loss: 0.196182 
 val auc: 0.983333,  test auc: 0.982301
epoch 834, loss: 0.034681
epoch 834, 
 train loss: 0.034681, val loss: 0.196337 
 val auc: 0.983333,  test auc: 0.982348
epoch 835, loss: 0.034645
epoch 835, 
 train loss: 0.034645, val loss: 0.196276 
 val auc: 0.983333,  test auc: 0.982339
epoch 836, loss: 0.034609
epoch 836, 
 train loss: 0.034609, val loss: 0.196438 
 val auc: 0.983296,  test auc: 0.982329
epoch 837, loss: 0.034573
epoch 837, 
 train loss: 0.034573, val loss: 0.196199 
 val auc: 0.983446,  test auc: 0.982367
epoch 838, loss: 0.034538
epoch 838, 
 train loss: 0.034538, val loss: 0.196155 
 val auc: 0.983408,  test auc: 0.982404
epoch 839, loss: 0.034502
epoch 839, 
 train loss: 0.034502, val loss: 0.196241 
 val auc: 0.983408,  test auc: 0.982357
epoch 840, loss: 0.034467
epoch 840, 
 train loss: 0.034467, val loss: 0.196611 
 val auc: 0.983371,  test auc: 0.982348
epoch 841, loss: 0.034431
epoch 841, 
 train loss: 0.034431, val loss: 0.196670 
 val auc: 0.983408,  test auc: 0.982376
epoch 842, loss: 0.034395
epoch 842, 
 train loss: 0.034395, val loss: 0.196757 
 val auc: 0.983521,  test auc: 0.982404
epoch 843, loss: 0.034358
epoch 843, 
 train loss: 0.034358, val loss: 0.196527 
 val auc: 0.983559,  test auc: 0.982386
epoch 844, loss: 0.034324
epoch 844, 
 train loss: 0.034324, val loss: 0.196500 
 val auc: 0.983596,  test auc: 0.982461
epoch 845, loss: 0.034289
epoch 845, 
 train loss: 0.034289, val loss: 0.196341 
 val auc: 0.983596,  test auc: 0.982517
epoch 846, loss: 0.034254
epoch 846, 
 train loss: 0.034254, val loss: 0.196595 
 val auc: 0.983596,  test auc: 0.982461
epoch 847, loss: 0.034219
epoch 847, 
 train loss: 0.034219, val loss: 0.196833 
 val auc: 0.983596,  test auc: 0.982442
epoch 848, loss: 0.034186
epoch 848, 
 train loss: 0.034186, val loss: 0.196914 
 val auc: 0.983521,  test auc: 0.982442
epoch 849, loss: 0.034151
epoch 849, 
 train loss: 0.034151, val loss: 0.197037 
 val auc: 0.983596,  test auc: 0.982442
epoch 850, loss: 0.034116
epoch 850, 
 train loss: 0.034116, val loss: 0.196911 
 val auc: 0.983596,  test auc: 0.982451
epoch 851, loss: 0.034084
epoch 851, 
 train loss: 0.034084, val loss: 0.196911 
 val auc: 0.983559,  test auc: 0.982451
epoch 852, loss: 0.034049
epoch 852, 
 train loss: 0.034049, val loss: 0.196905 
 val auc: 0.983634,  test auc: 0.982517
epoch 853, loss: 0.034017
epoch 853, 
 train loss: 0.034017, val loss: 0.197066 
 val auc: 0.983596,  test auc: 0.982517
epoch 854, loss: 0.033985
epoch 854, 
 train loss: 0.033985, val loss: 0.196765 
 val auc: 0.983596,  test auc: 0.982451
epoch 855, loss: 0.033952
epoch 855, 
 train loss: 0.033952, val loss: 0.197049 
 val auc: 0.983634,  test auc: 0.982479
epoch 856, loss: 0.033918
epoch 856, 
 train loss: 0.033918, val loss: 0.196961 
 val auc: 0.983671,  test auc: 0.982470
epoch 857, loss: 0.033884
epoch 857, 
 train loss: 0.033884, val loss: 0.196954 
 val auc: 0.983596,  test auc: 0.982423
epoch 858, loss: 0.033849
epoch 858, 
 train loss: 0.033849, val loss: 0.196946 
 val auc: 0.983671,  test auc: 0.982461
epoch 859, loss: 0.033815
epoch 859, 
 train loss: 0.033815, val loss: 0.197059 
 val auc: 0.983671,  test auc: 0.982451
epoch 860, loss: 0.033782
epoch 860, 
 train loss: 0.033782, val loss: 0.197158 
 val auc: 0.983671,  test auc: 0.982461
epoch 861, loss: 0.033750
epoch 861, 
 train loss: 0.033750, val loss: 0.197224 
 val auc: 0.983709,  test auc: 0.982479
epoch 862, loss: 0.033717
epoch 862, 
 train loss: 0.033717, val loss: 0.197390 
 val auc: 0.983709,  test auc: 0.982451
epoch 863, loss: 0.033684
epoch 863, 
 train loss: 0.033684, val loss: 0.197356 
 val auc: 0.983784,  test auc: 0.982489
epoch 864, loss: 0.033650
epoch 864, 
 train loss: 0.033650, val loss: 0.197488 
 val auc: 0.983784,  test auc: 0.982489
epoch 865, loss: 0.033618
epoch 865, 
 train loss: 0.033618, val loss: 0.197416 
 val auc: 0.983784,  test auc: 0.982489
epoch 866, loss: 0.033584
epoch 866, 
 train loss: 0.033584, val loss: 0.197490 
 val auc: 0.983746,  test auc: 0.982517
epoch 867, loss: 0.033549
epoch 867, 
 train loss: 0.033549, val loss: 0.197512 
 val auc: 0.983784,  test auc: 0.982508
epoch 868, loss: 0.033520
epoch 868, 
 train loss: 0.033520, val loss: 0.197477 
 val auc: 0.983859,  test auc: 0.982517
epoch 869, loss: 0.033488
epoch 869, 
 train loss: 0.033488, val loss: 0.197447 
 val auc: 0.983896,  test auc: 0.982554
epoch 870, loss: 0.033456
epoch 870, 
 train loss: 0.033456, val loss: 0.197318 
 val auc: 0.983934,  test auc: 0.982564
epoch 871, loss: 0.033424
epoch 871, 
 train loss: 0.033424, val loss: 0.197482 
 val auc: 0.983859,  test auc: 0.982554
epoch 872, loss: 0.033391
epoch 872, 
 train loss: 0.033391, val loss: 0.197555 
 val auc: 0.983896,  test auc: 0.982536
epoch 873, loss: 0.033359
epoch 873, 
 train loss: 0.033359, val loss: 0.197686 
 val auc: 0.983859,  test auc: 0.982526
epoch 874, loss: 0.033326
epoch 874, 
 train loss: 0.033326, val loss: 0.197546 
 val auc: 0.983859,  test auc: 0.982554
epoch 875, loss: 0.033296
epoch 875, 
 train loss: 0.033296, val loss: 0.197595 
 val auc: 0.983859,  test auc: 0.982554
epoch 876, loss: 0.033263
epoch 876, 
 train loss: 0.033263, val loss: 0.197808 
 val auc: 0.983859,  test auc: 0.982536
epoch 877, loss: 0.033233
epoch 877, 
 train loss: 0.033233, val loss: 0.197873 
 val auc: 0.983784,  test auc: 0.982517
epoch 878, loss: 0.033201
epoch 878, 
 train loss: 0.033201, val loss: 0.197749 
 val auc: 0.983859,  test auc: 0.982545
epoch 879, loss: 0.033171
epoch 879, 
 train loss: 0.033171, val loss: 0.197582 
 val auc: 0.983896,  test auc: 0.982554
epoch 880, loss: 0.033141
epoch 880, 
 train loss: 0.033141, val loss: 0.197773 
 val auc: 0.983896,  test auc: 0.982545
epoch 881, loss: 0.033110
epoch 881, 
 train loss: 0.033110, val loss: 0.197706 
 val auc: 0.983896,  test auc: 0.982573
epoch 882, loss: 0.033077
epoch 882, 
 train loss: 0.033077, val loss: 0.197885 
 val auc: 0.983859,  test auc: 0.982536
epoch 883, loss: 0.033046
epoch 883, 
 train loss: 0.033046, val loss: 0.197792 
 val auc: 0.983896,  test auc: 0.982545
epoch 884, loss: 0.033016
epoch 884, 
 train loss: 0.033016, val loss: 0.197891 
 val auc: 0.983896,  test auc: 0.982526
epoch 885, loss: 0.032985
epoch 885, 
 train loss: 0.032985, val loss: 0.197930 
 val auc: 0.983896,  test auc: 0.982526
epoch 886, loss: 0.032955
epoch 886, 
 train loss: 0.032955, val loss: 0.197859 
 val auc: 0.983896,  test auc: 0.982526
epoch 887, loss: 0.032926
epoch 887, 
 train loss: 0.032926, val loss: 0.198117 
 val auc: 0.983859,  test auc: 0.982554
epoch 888, loss: 0.032898
epoch 888, 
 train loss: 0.032898, val loss: 0.198062 
 val auc: 0.983971,  test auc: 0.982573
epoch 889, loss: 0.032867
epoch 889, 
 train loss: 0.032867, val loss: 0.198148 
 val auc: 0.983934,  test auc: 0.982573
epoch 890, loss: 0.032835
epoch 890, 
 train loss: 0.032835, val loss: 0.198049 
 val auc: 0.984084,  test auc: 0.982639
epoch 891, loss: 0.032804
epoch 891, 
 train loss: 0.032804, val loss: 0.198264 
 val auc: 0.983971,  test auc: 0.982630
epoch 892, loss: 0.032775
epoch 892, 
 train loss: 0.032775, val loss: 0.198051 
 val auc: 0.984084,  test auc: 0.982620
epoch 893, loss: 0.032748
epoch 893, 
 train loss: 0.032748, val loss: 0.198251 
 val auc: 0.983934,  test auc: 0.982601
epoch 894, loss: 0.032731
epoch 894, 
 train loss: 0.032731, val loss: 0.198210 
 val auc: 0.984197,  test auc: 0.982630
epoch 895, loss: 0.032752
epoch 895, 
 train loss: 0.032752, val loss: 0.198522 
 val auc: 0.983934,  test auc: 0.982545
epoch 896, loss: 0.032894
epoch 896, 
 train loss: 0.032894, val loss: 0.198328 
 val auc: 0.984347,  test auc: 0.982554
epoch 897, loss: 0.033406
epoch 897, 
 train loss: 0.033406, val loss: 0.200181 
 val auc: 0.983746,  test auc: 0.982517
epoch 898, loss: 0.034065
epoch 898, 
 train loss: 0.034065, val loss: 0.199539 
 val auc: 0.984159,  test auc: 0.982357
epoch 899, loss: 0.034635
epoch 899, 
 train loss: 0.034635, val loss: 0.203961 
 val auc: 0.983821,  test auc: 0.982489
epoch 900, loss: 0.034613
epoch 900, 
 train loss: 0.034613, val loss: 0.200160 
 val auc: 0.984234,  test auc: 0.982423
epoch 901, loss: 0.033778
epoch 901, 
 train loss: 0.033778, val loss: 0.202480 
 val auc: 0.983821,  test auc: 0.982686
epoch 902, loss: 0.032615
epoch 902, 
 train loss: 0.032615, val loss: 0.198560 
 val auc: 0.984347,  test auc: 0.982798
epoch 903, loss: 0.033042
epoch 903, 
 train loss: 0.033042, val loss: 0.198028 
 val auc: 0.984459,  test auc: 0.982601
epoch 904, loss: 0.033655
epoch 904, 
 train loss: 0.033655, val loss: 0.202316 
 val auc: 0.983896,  test auc: 0.982554
epoch 905, loss: 0.033024
epoch 905, 
 train loss: 0.033024, val loss: 0.199713 
 val auc: 0.984309,  test auc: 0.982554
epoch 906, loss: 0.032471
epoch 906, 
 train loss: 0.032471, val loss: 0.198289 
 val auc: 0.984272,  test auc: 0.982827
epoch 907, loss: 0.032884
epoch 907, 
 train loss: 0.032884, val loss: 0.200316 
 val auc: 0.984009,  test auc: 0.982639
epoch 908, loss: 0.032925
epoch 908, 
 train loss: 0.032925, val loss: 0.198999 
 val auc: 0.984459,  test auc: 0.982592
epoch 909, loss: 0.032467
epoch 909, 
 train loss: 0.032467, val loss: 0.198576 
 val auc: 0.984047,  test auc: 0.982761
epoch 910, loss: 0.032469
epoch 910, 
 train loss: 0.032469, val loss: 0.200181 
 val auc: 0.984009,  test auc: 0.982761
epoch 911, loss: 0.032730
epoch 911, 
 train loss: 0.032730, val loss: 0.199428 
 val auc: 0.984384,  test auc: 0.982639
epoch 912, loss: 0.032477
epoch 912, 
 train loss: 0.032477, val loss: 0.199113 
 val auc: 0.984122,  test auc: 0.982686
epoch 913, loss: 0.032227
epoch 913, 
 train loss: 0.032227, val loss: 0.199113 
 val auc: 0.984197,  test auc: 0.982770
epoch 914, loss: 0.032483
epoch 914, 
 train loss: 0.032483, val loss: 0.199102 
 val auc: 0.984459,  test auc: 0.982742
epoch 915, loss: 0.032409
epoch 915, 
 train loss: 0.032409, val loss: 0.199783 
 val auc: 0.983934,  test auc: 0.982592
epoch 916, loss: 0.032121
epoch 916, 
 train loss: 0.032121, val loss: 0.199701 
 val auc: 0.984009,  test auc: 0.982620
epoch 917, loss: 0.032275
epoch 917, 
 train loss: 0.032275, val loss: 0.200059 
 val auc: 0.984272,  test auc: 0.982639
epoch 918, loss: 0.032315
epoch 918, 
 train loss: 0.032315, val loss: 0.200124 
 val auc: 0.983934,  test auc: 0.982630
epoch 919, loss: 0.032052
epoch 919, 
 train loss: 0.032052, val loss: 0.199097 
 val auc: 0.984197,  test auc: 0.982705
epoch 920, loss: 0.032102
epoch 920, 
 train loss: 0.032102, val loss: 0.199196 
 val auc: 0.984384,  test auc: 0.982770
epoch 921, loss: 0.032180
epoch 921, 
 train loss: 0.032180, val loss: 0.199383 
 val auc: 0.983971,  test auc: 0.982667
epoch 922, loss: 0.031986
epoch 922, 
 train loss: 0.031986, val loss: 0.198914 
 val auc: 0.984384,  test auc: 0.982770
epoch 923, loss: 0.031974
epoch 923, 
 train loss: 0.031974, val loss: 0.199532 
 val auc: 0.984347,  test auc: 0.982798
epoch 924, loss: 0.032042
epoch 924, 
 train loss: 0.032042, val loss: 0.199389 
 val auc: 0.984159,  test auc: 0.982723
epoch 925, loss: 0.031912
epoch 925, 
 train loss: 0.031912, val loss: 0.198576 
 val auc: 0.984347,  test auc: 0.982817
epoch 926, loss: 0.031866
epoch 926, 
 train loss: 0.031866, val loss: 0.199271 
 val auc: 0.984309,  test auc: 0.982770
epoch 927, loss: 0.031907
epoch 927, 
 train loss: 0.031907, val loss: 0.199545 
 val auc: 0.984009,  test auc: 0.982733
epoch 928, loss: 0.031836
epoch 928, 
 train loss: 0.031836, val loss: 0.199251 
 val auc: 0.984309,  test auc: 0.982723
epoch 929, loss: 0.031782
epoch 929, 
 train loss: 0.031782, val loss: 0.200280 
 val auc: 0.984272,  test auc: 0.982742
epoch 930, loss: 0.031787
epoch 930, 
 train loss: 0.031787, val loss: 0.199760 
 val auc: 0.984084,  test auc: 0.982714
epoch 931, loss: 0.031748
epoch 931, 
 train loss: 0.031748, val loss: 0.199001 
 val auc: 0.984309,  test auc: 0.982798
epoch 932, loss: 0.031696
epoch 932, 
 train loss: 0.031696, val loss: 0.199555 
 val auc: 0.984422,  test auc: 0.982855
epoch 933, loss: 0.031683
epoch 933, 
 train loss: 0.031683, val loss: 0.199093 
 val auc: 0.984122,  test auc: 0.982752
epoch 934, loss: 0.031660
epoch 934, 
 train loss: 0.031660, val loss: 0.199083 
 val auc: 0.984347,  test auc: 0.982827
epoch 935, loss: 0.031623
epoch 935, 
 train loss: 0.031623, val loss: 0.200128 
 val auc: 0.984272,  test auc: 0.982892
epoch 936, loss: 0.031588
epoch 936, 
 train loss: 0.031588, val loss: 0.199529 
 val auc: 0.984234,  test auc: 0.982892
epoch 937, loss: 0.031576
epoch 937, 
 train loss: 0.031576, val loss: 0.199248 
 val auc: 0.984309,  test auc: 0.982845
epoch 938, loss: 0.031551
epoch 938, 
 train loss: 0.031551, val loss: 0.200028 
 val auc: 0.984347,  test auc: 0.982892
epoch 939, loss: 0.031512
epoch 939, 
 train loss: 0.031512, val loss: 0.199579 
 val auc: 0.984234,  test auc: 0.982827
epoch 940, loss: 0.031493
epoch 940, 
 train loss: 0.031493, val loss: 0.199686 
 val auc: 0.984309,  test auc: 0.982864
epoch 941, loss: 0.031473
epoch 941, 
 train loss: 0.031473, val loss: 0.200219 
 val auc: 0.984272,  test auc: 0.982892
epoch 942, loss: 0.031435
epoch 942, 
 train loss: 0.031435, val loss: 0.199302 
 val auc: 0.984272,  test auc: 0.982883
epoch 943, loss: 0.031408
epoch 943, 
 train loss: 0.031408, val loss: 0.199440 
 val auc: 0.984309,  test auc: 0.982855
epoch 944, loss: 0.031391
epoch 944, 
 train loss: 0.031391, val loss: 0.200125 
 val auc: 0.984272,  test auc: 0.982892
epoch 945, loss: 0.031362
epoch 945, 
 train loss: 0.031362, val loss: 0.199683 
 val auc: 0.984272,  test auc: 0.982902
epoch 946, loss: 0.031329
epoch 946, 
 train loss: 0.031329, val loss: 0.200139 
 val auc: 0.984272,  test auc: 0.982836
epoch 947, loss: 0.031311
epoch 947, 
 train loss: 0.031311, val loss: 0.200421 
 val auc: 0.984272,  test auc: 0.982855
epoch 948, loss: 0.031288
epoch 948, 
 train loss: 0.031288, val loss: 0.199764 
 val auc: 0.984272,  test auc: 0.982845
epoch 949, loss: 0.031256
epoch 949, 
 train loss: 0.031256, val loss: 0.200160 
 val auc: 0.984234,  test auc: 0.982845
epoch 950, loss: 0.031232
epoch 950, 
 train loss: 0.031232, val loss: 0.200276 
 val auc: 0.984234,  test auc: 0.982836
epoch 951, loss: 0.031213
epoch 951, 
 train loss: 0.031213, val loss: 0.200012 
 val auc: 0.984272,  test auc: 0.982855
epoch 952, loss: 0.031183
epoch 952, 
 train loss: 0.031183, val loss: 0.200444 
 val auc: 0.984234,  test auc: 0.982827
epoch 953, loss: 0.031157
epoch 953, 
 train loss: 0.031157, val loss: 0.200227 
 val auc: 0.984197,  test auc: 0.982836
epoch 954, loss: 0.031137
epoch 954, 
 train loss: 0.031137, val loss: 0.199910 
 val auc: 0.984234,  test auc: 0.982855
epoch 955, loss: 0.031110
epoch 955, 
 train loss: 0.031110, val loss: 0.200367 
 val auc: 0.984197,  test auc: 0.982845
epoch 956, loss: 0.031083
epoch 956, 
 train loss: 0.031083, val loss: 0.200247 
 val auc: 0.984234,  test auc: 0.982855
epoch 957, loss: 0.031062
epoch 957, 
 train loss: 0.031062, val loss: 0.200076 
 val auc: 0.984234,  test auc: 0.982873
epoch 958, loss: 0.031038
epoch 958, 
 train loss: 0.031038, val loss: 0.200455 
 val auc: 0.984234,  test auc: 0.982836
epoch 959, loss: 0.031012
epoch 959, 
 train loss: 0.031012, val loss: 0.200320 
 val auc: 0.984234,  test auc: 0.982883
epoch 960, loss: 0.030988
epoch 960, 
 train loss: 0.030988, val loss: 0.200308 
 val auc: 0.984272,  test auc: 0.982902
epoch 961, loss: 0.030969
epoch 961, 
 train loss: 0.030969, val loss: 0.200548 
 val auc: 0.984272,  test auc: 0.982855
epoch 962, loss: 0.030943
epoch 962, 
 train loss: 0.030943, val loss: 0.200125 
 val auc: 0.984234,  test auc: 0.982827
epoch 963, loss: 0.030917
epoch 963, 
 train loss: 0.030917, val loss: 0.200376 
 val auc: 0.984272,  test auc: 0.982836
epoch 964, loss: 0.030896
epoch 964, 
 train loss: 0.030896, val loss: 0.200542 
 val auc: 0.984272,  test auc: 0.982873
epoch 965, loss: 0.030872
epoch 965, 
 train loss: 0.030872, val loss: 0.200324 
 val auc: 0.984347,  test auc: 0.982930
epoch 966, loss: 0.030848
epoch 966, 
 train loss: 0.030848, val loss: 0.200452 
 val auc: 0.984309,  test auc: 0.982892
epoch 967, loss: 0.030824
epoch 967, 
 train loss: 0.030824, val loss: 0.200448 
 val auc: 0.984347,  test auc: 0.982883
epoch 968, loss: 0.030798
epoch 968, 
 train loss: 0.030798, val loss: 0.200509 
 val auc: 0.984347,  test auc: 0.982864
epoch 969, loss: 0.030775
epoch 969, 
 train loss: 0.030775, val loss: 0.200906 
 val auc: 0.984272,  test auc: 0.982902
epoch 970, loss: 0.030749
epoch 970, 
 train loss: 0.030749, val loss: 0.200731 
 val auc: 0.984347,  test auc: 0.982902
epoch 971, loss: 0.030726
epoch 971, 
 train loss: 0.030726, val loss: 0.200742 
 val auc: 0.984347,  test auc: 0.982855
epoch 972, loss: 0.030703
epoch 972, 
 train loss: 0.030703, val loss: 0.201017 
 val auc: 0.984347,  test auc: 0.982855
epoch 973, loss: 0.030678
epoch 973, 
 train loss: 0.030678, val loss: 0.200871 
 val auc: 0.984347,  test auc: 0.982911
epoch 974, loss: 0.030656
epoch 974, 
 train loss: 0.030656, val loss: 0.200905 
 val auc: 0.984347,  test auc: 0.982911
epoch 975, loss: 0.030636
epoch 975, 
 train loss: 0.030636, val loss: 0.200901 
 val auc: 0.984384,  test auc: 0.982873
epoch 976, loss: 0.030623
epoch 976, 
 train loss: 0.030623, val loss: 0.200779 
 val auc: 0.984309,  test auc: 0.982920
epoch 977, loss: 0.030616
epoch 977, 
 train loss: 0.030616, val loss: 0.201015 
 val auc: 0.984384,  test auc: 0.982939
epoch 978, loss: 0.030631
epoch 978, 
 train loss: 0.030631, val loss: 0.201168 
 val auc: 0.984272,  test auc: 0.982892
epoch 979, loss: 0.030630
epoch 979, 
 train loss: 0.030630, val loss: 0.201046 
 val auc: 0.984572,  test auc: 0.982939
epoch 980, loss: 0.030586
epoch 980, 
 train loss: 0.030586, val loss: 0.201296 
 val auc: 0.984309,  test auc: 0.982883
epoch 981, loss: 0.030509
epoch 981, 
 train loss: 0.030509, val loss: 0.201009 
 val auc: 0.984309,  test auc: 0.982939
epoch 982, loss: 0.030493
epoch 982, 
 train loss: 0.030493, val loss: 0.201094 
 val auc: 0.984272,  test auc: 0.982883
epoch 983, loss: 0.030509
epoch 983, 
 train loss: 0.030509, val loss: 0.201476 
 val auc: 0.984384,  test auc: 0.982967
epoch 984, loss: 0.030461
epoch 984, 
 train loss: 0.030461, val loss: 0.201351 
 val auc: 0.984497,  test auc: 0.982986
epoch 985, loss: 0.030412
epoch 985, 
 train loss: 0.030412, val loss: 0.201563 
 val auc: 0.984535,  test auc: 0.983005
epoch 986, loss: 0.030416
epoch 986, 
 train loss: 0.030416, val loss: 0.201811 
 val auc: 0.984459,  test auc: 0.982949
epoch 987, loss: 0.030396
epoch 987, 
 train loss: 0.030396, val loss: 0.201721 
 val auc: 0.984497,  test auc: 0.982892
epoch 988, loss: 0.030346
epoch 988, 
 train loss: 0.030346, val loss: 0.201912 
 val auc: 0.984422,  test auc: 0.982939
epoch 989, loss: 0.030331
epoch 989, 
 train loss: 0.030331, val loss: 0.201793 
 val auc: 0.984422,  test auc: 0.982930
epoch 990, loss: 0.030323
epoch 990, 
 train loss: 0.030323, val loss: 0.201714 
 val auc: 0.984610,  test auc: 0.982967
epoch 991, loss: 0.030286
epoch 991, 
 train loss: 0.030286, val loss: 0.201683 
 val auc: 0.984459,  test auc: 0.982930
epoch 992, loss: 0.030257
epoch 992, 
 train loss: 0.030257, val loss: 0.201837 
 val auc: 0.984422,  test auc: 0.982949
epoch 993, loss: 0.030250
epoch 993, 
 train loss: 0.030250, val loss: 0.201681 
 val auc: 0.984459,  test auc: 0.982930
epoch 994, loss: 0.030226
epoch 994, 
 train loss: 0.030226, val loss: 0.201720 
 val auc: 0.984422,  test auc: 0.982977
epoch 995, loss: 0.030191
epoch 995, 
 train loss: 0.030191, val loss: 0.201706 
 val auc: 0.984535,  test auc: 0.982986
epoch 996, loss: 0.030169
epoch 996, 
 train loss: 0.030169, val loss: 0.201809 
 val auc: 0.984497,  test auc: 0.982958
epoch 997, loss: 0.030160
epoch 997, 
 train loss: 0.030160, val loss: 0.201963 
 val auc: 0.984535,  test auc: 0.982958
epoch 998, loss: 0.030136
epoch 998, 
 train loss: 0.030136, val loss: 0.201952 
 val auc: 0.984535,  test auc: 0.982949
epoch 999, loss: 0.030104
epoch 999, 
 train loss: 0.030104, val loss: 0.201875 
 val auc: 0.984535,  test auc: 0.982967
AUC: 0.979326
