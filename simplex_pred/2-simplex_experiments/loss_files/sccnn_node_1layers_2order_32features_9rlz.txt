epoch 0, loss: 0.691260
model updated at epoch 0 
epoch 0, 
 train loss: 0.691260, val loss: 0.691325 
 val auc: 0.544257,  test auc: 0.546368
epoch 1, loss: 0.687109
model updated at epoch 1 
epoch 1, 
 train loss: 0.687109, val loss: 0.687944 
 val auc: 0.542868,  test auc: 0.545608
epoch 2, loss: 0.684069
model updated at epoch 2 
epoch 2, 
 train loss: 0.684069, val loss: 0.685816 
 val auc: 0.564940,  test auc: 0.556438
epoch 3, loss: 0.681772
model updated at epoch 3 
epoch 3, 
 train loss: 0.681772, val loss: 0.684371 
 val auc: 0.581081,  test auc: 0.574324
epoch 4, loss: 0.679682
model updated at epoch 4 
epoch 4, 
 train loss: 0.679682, val loss: 0.683026 
 val auc: 0.589039,  test auc: 0.586618
epoch 5, loss: 0.677561
model updated at epoch 5 
epoch 5, 
 train loss: 0.677561, val loss: 0.681540 
 val auc: 0.593468,  test auc: 0.598921
epoch 6, loss: 0.675337
model updated at epoch 6 
epoch 6, 
 train loss: 0.675337, val loss: 0.679798 
 val auc: 0.601464,  test auc: 0.612838
epoch 7, loss: 0.673070
model updated at epoch 7 
epoch 7, 
 train loss: 0.673070, val loss: 0.677968 
 val auc: 0.608821,  test auc: 0.624381
epoch 8, loss: 0.670845
model updated at epoch 8 
epoch 8, 
 train loss: 0.670845, val loss: 0.676127 
 val auc: 0.616104,  test auc: 0.633784
epoch 9, loss: 0.668736
model updated at epoch 9 
epoch 9, 
 train loss: 0.668736, val loss: 0.674389 
 val auc: 0.622860,  test auc: 0.643440
epoch 10, loss: 0.666661
model updated at epoch 10 
epoch 10, 
 train loss: 0.666661, val loss: 0.672767 
 val auc: 0.627778,  test auc: 0.650901
epoch 11, loss: 0.664570
model updated at epoch 11 
epoch 11, 
 train loss: 0.664570, val loss: 0.671224 
 val auc: 0.630068,  test auc: 0.654242
epoch 12, loss: 0.662425
model updated at epoch 12 
epoch 12, 
 train loss: 0.662425, val loss: 0.669767 
 val auc: 0.631944,  test auc: 0.656306
epoch 13, loss: 0.660199
model updated at epoch 13 
epoch 13, 
 train loss: 0.660199, val loss: 0.668398 
 val auc: 0.633559,  test auc: 0.657592
epoch 14, loss: 0.657923
model updated at epoch 14 
epoch 14, 
 train loss: 0.657923, val loss: 0.667183 
 val auc: 0.635023,  test auc: 0.658793
epoch 15, loss: 0.655578
model updated at epoch 15 
epoch 15, 
 train loss: 0.655578, val loss: 0.666064 
 val auc: 0.637500,  test auc: 0.659422
epoch 16, loss: 0.653159
model updated at epoch 16 
epoch 16, 
 train loss: 0.653159, val loss: 0.665002 
 val auc: 0.637913,  test auc: 0.659694
epoch 17, loss: 0.650671
model updated at epoch 17 
epoch 17, 
 train loss: 0.650671, val loss: 0.663929 
 val auc: 0.638063,  test auc: 0.659075
epoch 18, loss: 0.648146
model updated at epoch 18 
epoch 18, 
 train loss: 0.648146, val loss: 0.662777 
 val auc: 0.639302,  test auc: 0.659178
epoch 19, loss: 0.645613
model updated at epoch 19 
epoch 19, 
 train loss: 0.645613, val loss: 0.661512 
 val auc: 0.640991,  test auc: 0.660154
epoch 20, loss: 0.643025
model updated at epoch 20 
epoch 20, 
 train loss: 0.643025, val loss: 0.659946 
 val auc: 0.644407,  test auc: 0.662303
epoch 21, loss: 0.640391
model updated at epoch 21 
epoch 21, 
 train loss: 0.640391, val loss: 0.658063 
 val auc: 0.647635,  test auc: 0.666319
epoch 22, loss: 0.637737
model updated at epoch 22 
epoch 22, 
 train loss: 0.637737, val loss: 0.655865 
 val auc: 0.652890,  test auc: 0.671077
epoch 23, loss: 0.635082
model updated at epoch 23 
epoch 23, 
 train loss: 0.635082, val loss: 0.653406 
 val auc: 0.658821,  test auc: 0.676117
epoch 24, loss: 0.632430
model updated at epoch 24 
epoch 24, 
 train loss: 0.632430, val loss: 0.650832 
 val auc: 0.664227,  test auc: 0.681419
epoch 25, loss: 0.629721
model updated at epoch 25 
epoch 25, 
 train loss: 0.629721, val loss: 0.648210 
 val auc: 0.668919,  test auc: 0.685792
epoch 26, loss: 0.626968
model updated at epoch 26 
epoch 26, 
 train loss: 0.626968, val loss: 0.645654 
 val auc: 0.673649,  test auc: 0.690146
epoch 27, loss: 0.624199
model updated at epoch 27 
epoch 27, 
 train loss: 0.624199, val loss: 0.643273 
 val auc: 0.676727,  test auc: 0.693750
epoch 28, loss: 0.621423
model updated at epoch 28 
epoch 28, 
 train loss: 0.621423, val loss: 0.640975 
 val auc: 0.680593,  test auc: 0.696284
epoch 29, loss: 0.618659
model updated at epoch 29 
epoch 29, 
 train loss: 0.618659, val loss: 0.638711 
 val auc: 0.682545,  test auc: 0.698921
epoch 30, loss: 0.615912
model updated at epoch 30 
epoch 30, 
 train loss: 0.615912, val loss: 0.636292 
 val auc: 0.686299,  test auc: 0.701595
epoch 31, loss: 0.613140
model updated at epoch 31 
epoch 31, 
 train loss: 0.613140, val loss: 0.633602 
 val auc: 0.691554,  test auc: 0.705377
epoch 32, loss: 0.610312
model updated at epoch 32 
epoch 32, 
 train loss: 0.610312, val loss: 0.630679 
 val auc: 0.696134,  test auc: 0.709450
epoch 33, loss: 0.607543
model updated at epoch 33 
epoch 33, 
 train loss: 0.607543, val loss: 0.627738 
 val auc: 0.700375,  test auc: 0.713739
epoch 34, loss: 0.604794
model updated at epoch 34 
epoch 34, 
 train loss: 0.604794, val loss: 0.624961 
 val auc: 0.704617,  test auc: 0.718046
epoch 35, loss: 0.602016
model updated at epoch 35 
epoch 35, 
 train loss: 0.602016, val loss: 0.622465 
 val auc: 0.708746,  test auc: 0.721706
epoch 36, loss: 0.599218
model updated at epoch 36 
epoch 36, 
 train loss: 0.599218, val loss: 0.620300 
 val auc: 0.712913,  test auc: 0.724859
epoch 37, loss: 0.596460
model updated at epoch 37 
epoch 37, 
 train loss: 0.596460, val loss: 0.618431 
 val auc: 0.715991,  test auc: 0.727102
epoch 38, loss: 0.593686
model updated at epoch 38 
epoch 38, 
 train loss: 0.593686, val loss: 0.616421 
 val auc: 0.717868,  test auc: 0.728998
epoch 39, loss: 0.590794
model updated at epoch 39 
epoch 39, 
 train loss: 0.590794, val loss: 0.613958 
 val auc: 0.721997,  test auc: 0.732526
epoch 40, loss: 0.587853
model updated at epoch 40 
epoch 40, 
 train loss: 0.587853, val loss: 0.610922 
 val auc: 0.725263,  test auc: 0.736524
epoch 41, loss: 0.584906
model updated at epoch 41 
epoch 41, 
 train loss: 0.584906, val loss: 0.607501 
 val auc: 0.730330,  test auc: 0.741995
epoch 42, loss: 0.581971
model updated at epoch 42 
epoch 42, 
 train loss: 0.581971, val loss: 0.604029 
 val auc: 0.735248,  test auc: 0.746931
epoch 43, loss: 0.578961
model updated at epoch 43 
epoch 43, 
 train loss: 0.578961, val loss: 0.600921 
 val auc: 0.740841,  test auc: 0.751614
epoch 44, loss: 0.575812
model updated at epoch 44 
epoch 44, 
 train loss: 0.575812, val loss: 0.598349 
 val auc: 0.744632,  test auc: 0.754964
epoch 45, loss: 0.572696
model updated at epoch 45 
epoch 45, 
 train loss: 0.572696, val loss: 0.596302 
 val auc: 0.748348,  test auc: 0.757292
epoch 46, loss: 0.569502
model updated at epoch 46 
epoch 46, 
 train loss: 0.569502, val loss: 0.594008 
 val auc: 0.751689,  test auc: 0.759957
epoch 47, loss: 0.566173
model updated at epoch 47 
epoch 47, 
 train loss: 0.566173, val loss: 0.591051 
 val auc: 0.755218,  test auc: 0.763504
epoch 48, loss: 0.562798
model updated at epoch 48 
epoch 48, 
 train loss: 0.562798, val loss: 0.587619 
 val auc: 0.758821,  test auc: 0.767774
epoch 49, loss: 0.559352
model updated at epoch 49 
epoch 49, 
 train loss: 0.559352, val loss: 0.583928 
 val auc: 0.764077,  test auc: 0.773029
epoch 50, loss: 0.555812
model updated at epoch 50 
epoch 50, 
 train loss: 0.555812, val loss: 0.580538 
 val auc: 0.767868,  test auc: 0.777280
epoch 51, loss: 0.552085
model updated at epoch 51 
epoch 51, 
 train loss: 0.552085, val loss: 0.577519 
 val auc: 0.771284,  test auc: 0.780114
epoch 52, loss: 0.548352
model updated at epoch 52 
epoch 52, 
 train loss: 0.548352, val loss: 0.574582 
 val auc: 0.774662,  test auc: 0.783061
epoch 53, loss: 0.544507
model updated at epoch 53 
epoch 53, 
 train loss: 0.544507, val loss: 0.570876 
 val auc: 0.779842,  test auc: 0.787462
epoch 54, loss: 0.540460
model updated at epoch 54 
epoch 54, 
 train loss: 0.540460, val loss: 0.566254 
 val auc: 0.786299,  test auc: 0.793562
epoch 55, loss: 0.536279
model updated at epoch 55 
epoch 55, 
 train loss: 0.536279, val loss: 0.561758 
 val auc: 0.791892,  test auc: 0.799493
epoch 56, loss: 0.531905
model updated at epoch 56 
epoch 56, 
 train loss: 0.531905, val loss: 0.557931 
 val auc: 0.795758,  test auc: 0.803819
epoch 57, loss: 0.527428
model updated at epoch 57 
epoch 57, 
 train loss: 0.527428, val loss: 0.554254 
 val auc: 0.799662,  test auc: 0.807864
epoch 58, loss: 0.522777
model updated at epoch 58 
epoch 58, 
 train loss: 0.522777, val loss: 0.549833 
 val auc: 0.805255,  test auc: 0.813260
epoch 59, loss: 0.518075
model updated at epoch 59 
epoch 59, 
 train loss: 0.518075, val loss: 0.544822 
 val auc: 0.811149,  test auc: 0.819313
epoch 60, loss: 0.513183
model updated at epoch 60 
epoch 60, 
 train loss: 0.513183, val loss: 0.540408 
 val auc: 0.816216,  test auc: 0.823958
epoch 61, loss: 0.508106
model updated at epoch 61 
epoch 61, 
 train loss: 0.508106, val loss: 0.535833 
 val auc: 0.821584,  test auc: 0.828425
epoch 62, loss: 0.502842
model updated at epoch 62 
epoch 62, 
 train loss: 0.502842, val loss: 0.530343 
 val auc: 0.827928,  test auc: 0.833868
epoch 63, loss: 0.497473
model updated at epoch 63 
epoch 63, 
 train loss: 0.497473, val loss: 0.524430 
 val auc: 0.834272,  test auc: 0.840203
epoch 64, loss: 0.491874
model updated at epoch 64 
epoch 64, 
 train loss: 0.491874, val loss: 0.519509 
 val auc: 0.838964,  test auc: 0.844970
epoch 65, loss: 0.486127
model updated at epoch 65 
epoch 65, 
 train loss: 0.486127, val loss: 0.514807 
 val auc: 0.842417,  test auc: 0.849033
epoch 66, loss: 0.480238
model updated at epoch 66 
epoch 66, 
 train loss: 0.480238, val loss: 0.509397 
 val auc: 0.846922,  test auc: 0.853697
epoch 67, loss: 0.474100
model updated at epoch 67 
epoch 67, 
 train loss: 0.474100, val loss: 0.503233 
 val auc: 0.852703,  test auc: 0.859413
epoch 68, loss: 0.467660
model updated at epoch 68 
epoch 68, 
 train loss: 0.467660, val loss: 0.497145 
 val auc: 0.858071,  test auc: 0.863898
epoch 69, loss: 0.460973
model updated at epoch 69 
epoch 69, 
 train loss: 0.460973, val loss: 0.490572 
 val auc: 0.863664,  test auc: 0.868628
epoch 70, loss: 0.453960
model updated at epoch 70 
epoch 70, 
 train loss: 0.453960, val loss: 0.483135 
 val auc: 0.869632,  test auc: 0.875122
epoch 71, loss: 0.446703
model updated at epoch 71 
epoch 71, 
 train loss: 0.446703, val loss: 0.475993 
 val auc: 0.874399,  test auc: 0.879946
epoch 72, loss: 0.439344
model updated at epoch 72 
epoch 72, 
 train loss: 0.439344, val loss: 0.469273 
 val auc: 0.878378,  test auc: 0.883662
epoch 73, loss: 0.431829
model updated at epoch 73 
epoch 73, 
 train loss: 0.431829, val loss: 0.462133 
 val auc: 0.882658,  test auc: 0.888335
epoch 74, loss: 0.424183
model updated at epoch 74 
epoch 74, 
 train loss: 0.424183, val loss: 0.454726 
 val auc: 0.886599,  test auc: 0.893102
epoch 75, loss: 0.416274
model updated at epoch 75 
epoch 75, 
 train loss: 0.416274, val loss: 0.447557 
 val auc: 0.889790,  test auc: 0.896396
epoch 76, loss: 0.408209
model updated at epoch 76 
epoch 76, 
 train loss: 0.408209, val loss: 0.439621 
 val auc: 0.894219,  test auc: 0.900385
epoch 77, loss: 0.400147
model updated at epoch 77 
epoch 77, 
 train loss: 0.400147, val loss: 0.430745 
 val auc: 0.899775,  test auc: 0.905734
epoch 78, loss: 0.391987
model updated at epoch 78 
epoch 78, 
 train loss: 0.391987, val loss: 0.423008 
 val auc: 0.904017,  test auc: 0.908718
epoch 79, loss: 0.383819
model updated at epoch 79 
epoch 79, 
 train loss: 0.383819, val loss: 0.414180 
 val auc: 0.908859,  test auc: 0.913082
epoch 80, loss: 0.375740
model updated at epoch 80 
epoch 80, 
 train loss: 0.375740, val loss: 0.405746 
 val auc: 0.912988,  test auc: 0.916610
epoch 81, loss: 0.367996
model updated at epoch 81 
epoch 81, 
 train loss: 0.367996, val loss: 0.398876 
 val auc: 0.914640,  test auc: 0.917783
epoch 82, loss: 0.360380
model updated at epoch 82 
epoch 82, 
 train loss: 0.360380, val loss: 0.390953 
 val auc: 0.919107,  test auc: 0.921518
epoch 83, loss: 0.353016
model updated at epoch 83 
epoch 83, 
 train loss: 0.353016, val loss: 0.384154 
 val auc: 0.921209,  test auc: 0.923320
epoch 84, loss: 0.345729
model updated at epoch 84 
epoch 84, 
 train loss: 0.345729, val loss: 0.376674 
 val auc: 0.924887,  test auc: 0.926258
epoch 85, loss: 0.338588
model updated at epoch 85 
epoch 85, 
 train loss: 0.338588, val loss: 0.368983 
 val auc: 0.928754,  test auc: 0.929570
epoch 86, loss: 0.331775
model updated at epoch 86 
epoch 86, 
 train loss: 0.331775, val loss: 0.362656 
 val auc: 0.929767,  test auc: 0.930143
epoch 87, loss: 0.325157
model updated at epoch 87 
epoch 87, 
 train loss: 0.325157, val loss: 0.354749 
 val auc: 0.933634,  test auc: 0.933493
epoch 88, loss: 0.318664
model updated at epoch 88 
epoch 88, 
 train loss: 0.318664, val loss: 0.351741 
 val auc: 0.931344,  test auc: 0.932226
epoch 89, loss: 0.312553
model updated at epoch 89 
epoch 89, 
 train loss: 0.312553, val loss: 0.341473 
 val auc: 0.939302,  test auc: 0.938711
epoch 90, loss: 0.306560
epoch 90, 
 train loss: 0.306560, val loss: 0.342048 
 val auc: 0.932658,  test auc: 0.933361
epoch 91, loss: 0.299766
model updated at epoch 91 
epoch 91, 
 train loss: 0.299766, val loss: 0.333473 
 val auc: 0.939302,  test auc: 0.939790
epoch 92, loss: 0.294823
model updated at epoch 92 
epoch 92, 
 train loss: 0.294823, val loss: 0.326956 
 val auc: 0.943131,  test auc: 0.942849
epoch 93, loss: 0.289426
model updated at epoch 93 
epoch 93, 
 train loss: 0.289426, val loss: 0.326726 
 val auc: 0.938926,  test auc: 0.939959
epoch 94, loss: 0.283792
model updated at epoch 94 
epoch 94, 
 train loss: 0.283792, val loss: 0.320657 
 val auc: 0.941892,  test auc: 0.942774
epoch 95, loss: 0.279680
model updated at epoch 95 
epoch 95, 
 train loss: 0.279680, val loss: 0.313432 
 val auc: 0.945908,  test auc: 0.946828
epoch 96, loss: 0.274439
epoch 96, 
 train loss: 0.274439, val loss: 0.314466 
 val auc: 0.943093,  test auc: 0.944585
epoch 97, loss: 0.270241
model updated at epoch 97 
epoch 97, 
 train loss: 0.270241, val loss: 0.312518 
 val auc: 0.943581,  test auc: 0.945289
epoch 98, loss: 0.266315
model updated at epoch 98 
epoch 98, 
 train loss: 0.266315, val loss: 0.306281 
 val auc: 0.947785,  test auc: 0.949324
epoch 99, loss: 0.261846
model updated at epoch 99 
epoch 99, 
 train loss: 0.261846, val loss: 0.305189 
 val auc: 0.947222,  test auc: 0.948677
epoch 100, loss: 0.258356
model updated at epoch 100 
epoch 100, 
 train loss: 0.258356, val loss: 0.304865 
 val auc: 0.946396,  test auc: 0.947907
epoch 101, loss: 0.254339
model updated at epoch 101 
epoch 101, 
 train loss: 0.254339, val loss: 0.299028 
 val auc: 0.950075,  test auc: 0.951267
epoch 102, loss: 0.250945
model updated at epoch 102 
epoch 102, 
 train loss: 0.250945, val loss: 0.296022 
 val auc: 0.951201,  test auc: 0.952140
epoch 103, loss: 0.247866
epoch 103, 
 train loss: 0.247866, val loss: 0.296432 
 val auc: 0.950225,  test auc: 0.951023
epoch 104, loss: 0.244415
model updated at epoch 104 
epoch 104, 
 train loss: 0.244415, val loss: 0.291519 
 val auc: 0.951952,  test auc: 0.952721
epoch 105, loss: 0.241580
model updated at epoch 105 
epoch 105, 
 train loss: 0.241580, val loss: 0.287640 
 val auc: 0.952853,  test auc: 0.954214
epoch 106, loss: 0.238651
epoch 106, 
 train loss: 0.238651, val loss: 0.289409 
 val auc: 0.952027,  test auc: 0.952825
epoch 107, loss: 0.235545
model updated at epoch 107 
epoch 107, 
 train loss: 0.235545, val loss: 0.285591 
 val auc: 0.953416,  test auc: 0.954533
epoch 108, loss: 0.233129
model updated at epoch 108 
epoch 108, 
 train loss: 0.233129, val loss: 0.281238 
 val auc: 0.954805,  test auc: 0.956025
epoch 109, loss: 0.230713
epoch 109, 
 train loss: 0.230713, val loss: 0.283469 
 val auc: 0.953866,  test auc: 0.954664
epoch 110, loss: 0.227614
model updated at epoch 110 
epoch 110, 
 train loss: 0.227614, val loss: 0.276960 
 val auc: 0.955255,  test auc: 0.956898
epoch 111, loss: 0.225286
model updated at epoch 111 
epoch 111, 
 train loss: 0.225286, val loss: 0.273562 
 val auc: 0.956194,  test auc: 0.957845
epoch 112, loss: 0.223383
epoch 112, 
 train loss: 0.223383, val loss: 0.276379 
 val auc: 0.955556,  test auc: 0.956747
epoch 113, loss: 0.220688
model updated at epoch 113 
epoch 113, 
 train loss: 0.220688, val loss: 0.267715 
 val auc: 0.958221,  test auc: 0.959572
epoch 114, loss: 0.218043
model updated at epoch 114 
epoch 114, 
 train loss: 0.218043, val loss: 0.267518 
 val auc: 0.958108,  test auc: 0.959535
epoch 115, loss: 0.216014
model updated at epoch 115 
epoch 115, 
 train loss: 0.216014, val loss: 0.266924 
 val auc: 0.957883,  test auc: 0.959628
epoch 116, loss: 0.214235
model updated at epoch 116 
epoch 116, 
 train loss: 0.214235, val loss: 0.261279 
 val auc: 0.959947,  test auc: 0.961646
epoch 117, loss: 0.212298
epoch 117, 
 train loss: 0.212298, val loss: 0.265338 
 val auc: 0.958108,  test auc: 0.959994
epoch 118, loss: 0.210011
model updated at epoch 118 
epoch 118, 
 train loss: 0.210011, val loss: 0.259975 
 val auc: 0.959610,  test auc: 0.961693
epoch 119, loss: 0.208098
model updated at epoch 119 
epoch 119, 
 train loss: 0.208098, val loss: 0.259298 
 val auc: 0.959722,  test auc: 0.961768
epoch 120, loss: 0.206548
epoch 120, 
 train loss: 0.206548, val loss: 0.262149 
 val auc: 0.958784,  test auc: 0.961027
epoch 121, loss: 0.204941
model updated at epoch 121 
epoch 121, 
 train loss: 0.204941, val loss: 0.256311 
 val auc: 0.960435,  test auc: 0.963082
epoch 122, loss: 0.203183
epoch 122, 
 train loss: 0.203183, val loss: 0.261131 
 val auc: 0.958634,  test auc: 0.961458
epoch 123, loss: 0.201180
model updated at epoch 123 
epoch 123, 
 train loss: 0.201180, val loss: 0.256096 
 val auc: 0.960098,  test auc: 0.962988
epoch 124, loss: 0.199508
model updated at epoch 124 
epoch 124, 
 train loss: 0.199508, val loss: 0.254760 
 val auc: 0.960548,  test auc: 0.963326
epoch 125, loss: 0.198178
epoch 125, 
 train loss: 0.198178, val loss: 0.256995 
 val auc: 0.959384,  test auc: 0.962434
epoch 126, loss: 0.196699
model updated at epoch 126 
epoch 126, 
 train loss: 0.196699, val loss: 0.250656 
 val auc: 0.961599,  test auc: 0.964227
epoch 127, loss: 0.195130
epoch 127, 
 train loss: 0.195130, val loss: 0.254360 
 val auc: 0.959760,  test auc: 0.963054
epoch 128, loss: 0.193442
model updated at epoch 128 
epoch 128, 
 train loss: 0.193442, val loss: 0.249485 
 val auc: 0.961336,  test auc: 0.964461
epoch 129, loss: 0.191984
model updated at epoch 129 
epoch 129, 
 train loss: 0.191984, val loss: 0.248620 
 val auc: 0.961186,  test auc: 0.964593
epoch 130, loss: 0.190768
epoch 130, 
 train loss: 0.190768, val loss: 0.249908 
 val auc: 0.960998,  test auc: 0.964255
epoch 131, loss: 0.189608
model updated at epoch 131 
epoch 131, 
 train loss: 0.189608, val loss: 0.244552 
 val auc: 0.962500,  test auc: 0.965372
epoch 132, loss: 0.188520
epoch 132, 
 train loss: 0.188520, val loss: 0.249469 
 val auc: 0.960923,  test auc: 0.964405
epoch 133, loss: 0.187174
model updated at epoch 133 
epoch 133, 
 train loss: 0.187174, val loss: 0.242259 
 val auc: 0.962950,  test auc: 0.966047
epoch 134, loss: 0.185871
epoch 134, 
 train loss: 0.185871, val loss: 0.247260 
 val auc: 0.961186,  test auc: 0.965034
epoch 135, loss: 0.184442
model updated at epoch 135 
epoch 135, 
 train loss: 0.184442, val loss: 0.241945 
 val auc: 0.962575,  test auc: 0.966263
epoch 136, loss: 0.183173
epoch 136, 
 train loss: 0.183173, val loss: 0.243025 
 val auc: 0.962275,  test auc: 0.966160
epoch 137, loss: 0.182076
epoch 137, 
 train loss: 0.182076, val loss: 0.242534 
 val auc: 0.962387,  test auc: 0.966273
epoch 138, loss: 0.181134
model updated at epoch 138 
epoch 138, 
 train loss: 0.181134, val loss: 0.239155 
 val auc: 0.962875,  test auc: 0.966826
epoch 139, loss: 0.180369
epoch 139, 
 train loss: 0.180369, val loss: 0.243333 
 val auc: 0.961974,  test auc: 0.965907
epoch 140, loss: 0.179509
model updated at epoch 140 
epoch 140, 
 train loss: 0.179509, val loss: 0.236180 
 val auc: 0.963589,  test auc: 0.967248
epoch 141, loss: 0.178850
epoch 141, 
 train loss: 0.178850, val loss: 0.243571 
 val auc: 0.961374,  test auc: 0.965597
epoch 142, loss: 0.177453
model updated at epoch 142 
epoch 142, 
 train loss: 0.177453, val loss: 0.234782 
 val auc: 0.963589,  test auc: 0.967389
epoch 143, loss: 0.176143
epoch 143, 
 train loss: 0.176143, val loss: 0.239471 
 val auc: 0.962538,  test auc: 0.966610
epoch 144, loss: 0.174953
epoch 144, 
 train loss: 0.174953, val loss: 0.236290 
 val auc: 0.963026,  test auc: 0.967136
epoch 145, loss: 0.174142
model updated at epoch 145 
epoch 145, 
 train loss: 0.174142, val loss: 0.234749 
 val auc: 0.963589,  test auc: 0.967511
epoch 146, loss: 0.173588
epoch 146, 
 train loss: 0.173588, val loss: 0.238994 
 val auc: 0.962613,  test auc: 0.966507
epoch 147, loss: 0.172816
model updated at epoch 147 
epoch 147, 
 train loss: 0.172816, val loss: 0.232183 
 val auc: 0.964339,  test auc: 0.967896
epoch 148, loss: 0.171987
epoch 148, 
 train loss: 0.171987, val loss: 0.238458 
 val auc: 0.962725,  test auc: 0.966441
epoch 149, loss: 0.170698
model updated at epoch 149 
epoch 149, 
 train loss: 0.170698, val loss: 0.232076 
 val auc: 0.964227,  test auc: 0.967877
epoch 150, loss: 0.169630
epoch 150, 
 train loss: 0.169630, val loss: 0.233553 
 val auc: 0.963889,  test auc: 0.967690
epoch 151, loss: 0.168886
epoch 151, 
 train loss: 0.168886, val loss: 0.234265 
 val auc: 0.963664,  test auc: 0.967455
epoch 152, loss: 0.168298
model updated at epoch 152 
epoch 152, 
 train loss: 0.168298, val loss: 0.230250 
 val auc: 0.964527,  test auc: 0.968187
epoch 153, loss: 0.167722
epoch 153, 
 train loss: 0.167722, val loss: 0.235520 
 val auc: 0.962950,  test auc: 0.967033
epoch 154, loss: 0.166734
model updated at epoch 154 
epoch 154, 
 train loss: 0.166734, val loss: 0.229048 
 val auc: 0.964527,  test auc: 0.968356
epoch 155, loss: 0.165736
epoch 155, 
 train loss: 0.165736, val loss: 0.232348 
 val auc: 0.964039,  test auc: 0.967671
epoch 156, loss: 0.164799
epoch 156, 
 train loss: 0.164799, val loss: 0.229293 
 val auc: 0.964715,  test auc: 0.968149
epoch 157, loss: 0.164043
model updated at epoch 157 
epoch 157, 
 train loss: 0.164043, val loss: 0.228406 
 val auc: 0.964602,  test auc: 0.968121
epoch 158, loss: 0.163431
epoch 158, 
 train loss: 0.163431, val loss: 0.230488 
 val auc: 0.964114,  test auc: 0.967830
epoch 159, loss: 0.162802
model updated at epoch 159 
epoch 159, 
 train loss: 0.162802, val loss: 0.226021 
 val auc: 0.964940,  test auc: 0.968637
epoch 160, loss: 0.162176
epoch 160, 
 train loss: 0.162176, val loss: 0.230586 
 val auc: 0.964077,  test auc: 0.967746
epoch 161, loss: 0.161336
model updated at epoch 161 
epoch 161, 
 train loss: 0.161336, val loss: 0.224855 
 val auc: 0.965203,  test auc: 0.968881
epoch 162, loss: 0.160508
epoch 162, 
 train loss: 0.160508, val loss: 0.228376 
 val auc: 0.964339,  test auc: 0.968224
epoch 163, loss: 0.159639
model updated at epoch 163 
epoch 163, 
 train loss: 0.159639, val loss: 0.224175 
 val auc: 0.965203,  test auc: 0.969022
epoch 164, loss: 0.158850
epoch 164, 
 train loss: 0.158850, val loss: 0.224914 
 val auc: 0.965165,  test auc: 0.968891
epoch 165, loss: 0.158137
model updated at epoch 165 
epoch 165, 
 train loss: 0.158137, val loss: 0.223403 
 val auc: 0.965428,  test auc: 0.969097
epoch 166, loss: 0.157455
model updated at epoch 166 
epoch 166, 
 train loss: 0.157455, val loss: 0.222074 
 val auc: 0.965878,  test auc: 0.969407
epoch 167, loss: 0.156812
epoch 167, 
 train loss: 0.156812, val loss: 0.222824 
 val auc: 0.965541,  test auc: 0.969210
epoch 168, loss: 0.156349
model updated at epoch 168 
epoch 168, 
 train loss: 0.156349, val loss: 0.219266 
 val auc: 0.966479,  test auc: 0.969839
epoch 169, loss: 0.156640
epoch 169, 
 train loss: 0.156640, val loss: 0.225981 
 val auc: 0.965015,  test auc: 0.968581
epoch 170, loss: 0.157715
model updated at epoch 170 
epoch 170, 
 train loss: 0.157715, val loss: 0.215668 
 val auc: 0.967455,  test auc: 0.970064
epoch 171, loss: 0.160660
epoch 171, 
 train loss: 0.160660, val loss: 0.235524 
 val auc: 0.963213,  test auc: 0.966545
epoch 172, loss: 0.153715
epoch 172, 
 train loss: 0.153715, val loss: 0.217604 
 val auc: 0.966854,  test auc: 0.970195
epoch 173, loss: 0.156711
model updated at epoch 173 
epoch 173, 
 train loss: 0.156711, val loss: 0.214832 
 val auc: 0.967680,  test auc: 0.970364
epoch 174, loss: 0.160715
epoch 174, 
 train loss: 0.160715, val loss: 0.238560 
 val auc: 0.962650,  test auc: 0.966132
epoch 175, loss: 0.152941
epoch 175, 
 train loss: 0.152941, val loss: 0.224270 
 val auc: 0.965503,  test auc: 0.969050
epoch 176, loss: 0.164849
epoch 176, 
 train loss: 0.164849, val loss: 0.216441 
 val auc: 0.968168,  test auc: 0.970458
epoch 177, loss: 0.154479
epoch 177, 
 train loss: 0.154479, val loss: 0.229695 
 val auc: 0.964114,  test auc: 0.967887
epoch 178, loss: 0.158685
epoch 178, 
 train loss: 0.158685, val loss: 0.237894 
 val auc: 0.962800,  test auc: 0.966282
epoch 179, loss: 0.150145
epoch 179, 
 train loss: 0.150145, val loss: 0.216051 
 val auc: 0.967417,  test auc: 0.970514
epoch 180, loss: 0.157696
model updated at epoch 180 
epoch 180, 
 train loss: 0.157696, val loss: 0.213960 
 val auc: 0.968168,  test auc: 0.970739
epoch 181, loss: 0.150510
epoch 181, 
 train loss: 0.150510, val loss: 0.223466 
 val auc: 0.965691,  test auc: 0.969229
epoch 182, loss: 0.154781
epoch 182, 
 train loss: 0.154781, val loss: 0.232449 
 val auc: 0.963776,  test auc: 0.967258
epoch 183, loss: 0.147902
epoch 183, 
 train loss: 0.147902, val loss: 0.216260 
 val auc: 0.966854,  test auc: 0.970223
epoch 184, loss: 0.154102
model updated at epoch 184 
epoch 184, 
 train loss: 0.154102, val loss: 0.211434 
 val auc: 0.968431,  test auc: 0.970899
epoch 185, loss: 0.147022
epoch 185, 
 train loss: 0.147022, val loss: 0.215598 
 val auc: 0.967305,  test auc: 0.970317
epoch 186, loss: 0.151062
epoch 186, 
 train loss: 0.151062, val loss: 0.227035 
 val auc: 0.965090,  test auc: 0.968318
epoch 187, loss: 0.146828
epoch 187, 
 train loss: 0.146828, val loss: 0.218025 
 val auc: 0.967080,  test auc: 0.970054
epoch 188, loss: 0.149054
model updated at epoch 188 
epoch 188, 
 train loss: 0.149054, val loss: 0.209963 
 val auc: 0.969144,  test auc: 0.971284
epoch 189, loss: 0.145888
epoch 189, 
 train loss: 0.145888, val loss: 0.210977 
 val auc: 0.968468,  test auc: 0.971284
epoch 190, loss: 0.146890
epoch 190, 
 train loss: 0.146890, val loss: 0.220411 
 val auc: 0.966441,  test auc: 0.969632
epoch 191, loss: 0.145941
epoch 191, 
 train loss: 0.145941, val loss: 0.218655 
 val auc: 0.966929,  test auc: 0.970036
epoch 192, loss: 0.144711
model updated at epoch 192 
epoch 192, 
 train loss: 0.144711, val loss: 0.209297 
 val auc: 0.968844,  test auc: 0.971443
epoch 193, loss: 0.145179
model updated at epoch 193 
epoch 193, 
 train loss: 0.145179, val loss: 0.208151 
 val auc: 0.969144,  test auc: 0.971584
epoch 194, loss: 0.143521
epoch 194, 
 train loss: 0.143521, val loss: 0.214088 
 val auc: 0.967793,  test auc: 0.970786
epoch 195, loss: 0.144315
epoch 195, 
 train loss: 0.144315, val loss: 0.217165 
 val auc: 0.967005,  test auc: 0.970242
epoch 196, loss: 0.142191
epoch 196, 
 train loss: 0.142191, val loss: 0.209705 
 val auc: 0.968956,  test auc: 0.971321
epoch 197, loss: 0.143411
model updated at epoch 197 
epoch 197, 
 train loss: 0.143411, val loss: 0.206603 
 val auc: 0.969632,  test auc: 0.971762
epoch 198, loss: 0.141339
epoch 198, 
 train loss: 0.141339, val loss: 0.209677 
 val auc: 0.969069,  test auc: 0.971359
epoch 199, loss: 0.142200
epoch 199, 
 train loss: 0.142200, val loss: 0.214113 
 val auc: 0.967868,  test auc: 0.970749
epoch 200, loss: 0.140582
epoch 200, 
 train loss: 0.140582, val loss: 0.209261 
 val auc: 0.969182,  test auc: 0.971434
epoch 201, loss: 0.141164
model updated at epoch 201 
epoch 201, 
 train loss: 0.141164, val loss: 0.205189 
 val auc: 0.969782,  test auc: 0.972016
epoch 202, loss: 0.139805
epoch 202, 
 train loss: 0.139805, val loss: 0.206675 
 val auc: 0.969444,  test auc: 0.971959
epoch 203, loss: 0.140040
epoch 203, 
 train loss: 0.140040, val loss: 0.211153 
 val auc: 0.968581,  test auc: 0.971265
epoch 204, loss: 0.139150
epoch 204, 
 train loss: 0.139150, val loss: 0.209126 
 val auc: 0.969032,  test auc: 0.971547
epoch 205, loss: 0.139025
model updated at epoch 205 
epoch 205, 
 train loss: 0.139025, val loss: 0.204897 
 val auc: 0.969670,  test auc: 0.972175
epoch 206, loss: 0.138374
epoch 206, 
 train loss: 0.138374, val loss: 0.205085 
 val auc: 0.969745,  test auc: 0.972203
epoch 207, loss: 0.138095
epoch 207, 
 train loss: 0.138095, val loss: 0.208576 
 val auc: 0.969294,  test auc: 0.971669
epoch 208, loss: 0.137657
epoch 208, 
 train loss: 0.137657, val loss: 0.207910 
 val auc: 0.969595,  test auc: 0.971791
epoch 209, loss: 0.137185
model updated at epoch 209 
epoch 209, 
 train loss: 0.137185, val loss: 0.203864 
 val auc: 0.970045,  test auc: 0.972447
epoch 210, loss: 0.136874
model updated at epoch 210 
epoch 210, 
 train loss: 0.136874, val loss: 0.203264 
 val auc: 0.970158,  test auc: 0.972513
epoch 211, loss: 0.136375
epoch 211, 
 train loss: 0.136375, val loss: 0.206035 
 val auc: 0.969970,  test auc: 0.972157
epoch 212, loss: 0.136102
epoch 212, 
 train loss: 0.136102, val loss: 0.206248 
 val auc: 0.969895,  test auc: 0.972072
epoch 213, loss: 0.135557
model updated at epoch 213 
epoch 213, 
 train loss: 0.135557, val loss: 0.203043 
 val auc: 0.970420,  test auc: 0.972701
epoch 214, loss: 0.135321
model updated at epoch 214 
epoch 214, 
 train loss: 0.135321, val loss: 0.202335 
 val auc: 0.970683,  test auc: 0.972748
epoch 215, loss: 0.134824
epoch 215, 
 train loss: 0.134824, val loss: 0.204578 
 val auc: 0.970233,  test auc: 0.972401
epoch 216, loss: 0.134555
epoch 216, 
 train loss: 0.134555, val loss: 0.204951 
 val auc: 0.970345,  test auc: 0.972344
epoch 217, loss: 0.134066
epoch 217, 
 train loss: 0.134066, val loss: 0.202386 
 val auc: 0.970833,  test auc: 0.972860
epoch 218, loss: 0.133794
model updated at epoch 218 
epoch 218, 
 train loss: 0.133794, val loss: 0.201752 
 val auc: 0.970871,  test auc: 0.972917
epoch 219, loss: 0.133348
epoch 219, 
 train loss: 0.133348, val loss: 0.203605 
 val auc: 0.970758,  test auc: 0.972748
epoch 220, loss: 0.133042
epoch 220, 
 train loss: 0.133042, val loss: 0.203794 
 val auc: 0.970721,  test auc: 0.972701
epoch 221, loss: 0.132610
model updated at epoch 221 
epoch 221, 
 train loss: 0.132610, val loss: 0.201562 
 val auc: 0.971246,  test auc: 0.973151
epoch 222, loss: 0.132287
model updated at epoch 222 
epoch 222, 
 train loss: 0.132287, val loss: 0.201054 
 val auc: 0.971509,  test auc: 0.973245
epoch 223, loss: 0.131903
epoch 223, 
 train loss: 0.131903, val loss: 0.202473 
 val auc: 0.971096,  test auc: 0.973039
epoch 224, loss: 0.131552
epoch 224, 
 train loss: 0.131552, val loss: 0.202178 
 val auc: 0.971284,  test auc: 0.973170
epoch 225, loss: 0.131179
model updated at epoch 225 
epoch 225, 
 train loss: 0.131179, val loss: 0.200206 
 val auc: 0.971959,  test auc: 0.973574
epoch 226, loss: 0.130813
model updated at epoch 226 
epoch 226, 
 train loss: 0.130813, val loss: 0.199955 
 val auc: 0.972072,  test auc: 0.973677
epoch 227, loss: 0.130475
epoch 227, 
 train loss: 0.130475, val loss: 0.201134 
 val auc: 0.971847,  test auc: 0.973574
epoch 228, loss: 0.130082
epoch 228, 
 train loss: 0.130082, val loss: 0.200614 
 val auc: 0.972072,  test auc: 0.973696
epoch 229, loss: 0.129766
model updated at epoch 229 
epoch 229, 
 train loss: 0.129766, val loss: 0.199161 
 val auc: 0.972410,  test auc: 0.973864
epoch 230, loss: 0.129375
epoch 230, 
 train loss: 0.129375, val loss: 0.199456 
 val auc: 0.972297,  test auc: 0.973902
epoch 231, loss: 0.129074
epoch 231, 
 train loss: 0.129074, val loss: 0.200247 
 val auc: 0.972147,  test auc: 0.973818
epoch 232, loss: 0.128681
epoch 232, 
 train loss: 0.128681, val loss: 0.199251 
 val auc: 0.972485,  test auc: 0.974062
epoch 233, loss: 0.128376
model updated at epoch 233 
epoch 233, 
 train loss: 0.128376, val loss: 0.198177 
 val auc: 0.972898,  test auc: 0.974296
epoch 234, loss: 0.127996
epoch 234, 
 train loss: 0.127996, val loss: 0.198594 
 val auc: 0.972710,  test auc: 0.974221
epoch 235, loss: 0.127686
epoch 235, 
 train loss: 0.127686, val loss: 0.198879 
 val auc: 0.972748,  test auc: 0.974174
epoch 236, loss: 0.127316
model updated at epoch 236 
epoch 236, 
 train loss: 0.127316, val loss: 0.197829 
 val auc: 0.973048,  test auc: 0.974521
epoch 237, loss: 0.126993
model updated at epoch 237 
epoch 237, 
 train loss: 0.126993, val loss: 0.197328 
 val auc: 0.973273,  test auc: 0.974672
epoch 238, loss: 0.126640
epoch 238, 
 train loss: 0.126640, val loss: 0.197889 
 val auc: 0.972898,  test auc: 0.974550
epoch 239, loss: 0.126308
epoch 239, 
 train loss: 0.126308, val loss: 0.197758 
 val auc: 0.973086,  test auc: 0.974625
epoch 240, loss: 0.125973
model updated at epoch 240 
epoch 240, 
 train loss: 0.125973, val loss: 0.196845 
 val auc: 0.973273,  test auc: 0.974784
epoch 241, loss: 0.125625
model updated at epoch 241 
epoch 241, 
 train loss: 0.125625, val loss: 0.196751 
 val auc: 0.973498,  test auc: 0.974850
epoch 242, loss: 0.125300
epoch 242, 
 train loss: 0.125300, val loss: 0.197014 
 val auc: 0.973461,  test auc: 0.974897
epoch 243, loss: 0.124951
model updated at epoch 243 
epoch 243, 
 train loss: 0.124951, val loss: 0.196362 
 val auc: 0.973724,  test auc: 0.975028
epoch 244, loss: 0.124625
model updated at epoch 244 
epoch 244, 
 train loss: 0.124625, val loss: 0.195703 
 val auc: 0.973911,  test auc: 0.975131
epoch 245, loss: 0.124278
epoch 245, 
 train loss: 0.124278, val loss: 0.195886 
 val auc: 0.973799,  test auc: 0.975150
epoch 246, loss: 0.123954
epoch 246, 
 train loss: 0.123954, val loss: 0.195830 
 val auc: 0.973836,  test auc: 0.975225
epoch 247, loss: 0.123616
model updated at epoch 247 
epoch 247, 
 train loss: 0.123616, val loss: 0.195129 
 val auc: 0.973949,  test auc: 0.975328
epoch 248, loss: 0.123286
model updated at epoch 248 
epoch 248, 
 train loss: 0.123286, val loss: 0.194899 
 val auc: 0.973986,  test auc: 0.975404
epoch 249, loss: 0.122960
epoch 249, 
 train loss: 0.122960, val loss: 0.195081 
 val auc: 0.974062,  test auc: 0.975413
epoch 250, loss: 0.122630
model updated at epoch 250 
epoch 250, 
 train loss: 0.122630, val loss: 0.194698 
 val auc: 0.974212,  test auc: 0.975460
epoch 251, loss: 0.122311
model updated at epoch 251 
epoch 251, 
 train loss: 0.122311, val loss: 0.194229 
 val auc: 0.974137,  test auc: 0.975535
epoch 252, loss: 0.121983
epoch 252, 
 train loss: 0.121983, val loss: 0.194442 
 val auc: 0.974137,  test auc: 0.975488
epoch 253, loss: 0.121661
epoch 253, 
 train loss: 0.121661, val loss: 0.194439 
 val auc: 0.974212,  test auc: 0.975535
epoch 254, loss: 0.121336
model updated at epoch 254 
epoch 254, 
 train loss: 0.121336, val loss: 0.193860 
 val auc: 0.974287,  test auc: 0.975666
epoch 255, loss: 0.121014
model updated at epoch 255 
epoch 255, 
 train loss: 0.121014, val loss: 0.193702 
 val auc: 0.974324,  test auc: 0.975713
epoch 256, loss: 0.120694
epoch 256, 
 train loss: 0.120694, val loss: 0.193866 
 val auc: 0.974399,  test auc: 0.975741
epoch 257, loss: 0.120370
model updated at epoch 257 
epoch 257, 
 train loss: 0.120370, val loss: 0.193481 
 val auc: 0.974550,  test auc: 0.975816
epoch 258, loss: 0.120048
model updated at epoch 258 
epoch 258, 
 train loss: 0.120048, val loss: 0.193057 
 val auc: 0.974625,  test auc: 0.975920
epoch 259, loss: 0.119719
model updated at epoch 259 
epoch 259, 
 train loss: 0.119719, val loss: 0.193027 
 val auc: 0.974587,  test auc: 0.975920
epoch 260, loss: 0.119392
model updated at epoch 260 
epoch 260, 
 train loss: 0.119392, val loss: 0.192716 
 val auc: 0.974662,  test auc: 0.975995
epoch 261, loss: 0.119067
model updated at epoch 261 
epoch 261, 
 train loss: 0.119067, val loss: 0.192263 
 val auc: 0.974812,  test auc: 0.976126
epoch 262, loss: 0.118734
model updated at epoch 262 
epoch 262, 
 train loss: 0.118734, val loss: 0.192241 
 val auc: 0.974775,  test auc: 0.976126
epoch 263, loss: 0.118409
epoch 263, 
 train loss: 0.118409, val loss: 0.192281 
 val auc: 0.974812,  test auc: 0.976164
epoch 264, loss: 0.118078
model updated at epoch 264 
epoch 264, 
 train loss: 0.118078, val loss: 0.191811 
 val auc: 0.975038,  test auc: 0.976295
epoch 265, loss: 0.117743
model updated at epoch 265 
epoch 265, 
 train loss: 0.117743, val loss: 0.191666 
 val auc: 0.975113,  test auc: 0.976370
epoch 266, loss: 0.117414
model updated at epoch 266 
epoch 266, 
 train loss: 0.117414, val loss: 0.191621 
 val auc: 0.975113,  test auc: 0.976408
epoch 267, loss: 0.117080
model updated at epoch 267 
epoch 267, 
 train loss: 0.117080, val loss: 0.191236 
 val auc: 0.975225,  test auc: 0.976530
epoch 268, loss: 0.116744
model updated at epoch 268 
epoch 268, 
 train loss: 0.116744, val loss: 0.191021 
 val auc: 0.975375,  test auc: 0.976586
epoch 269, loss: 0.116406
model updated at epoch 269 
epoch 269, 
 train loss: 0.116406, val loss: 0.190868 
 val auc: 0.975413,  test auc: 0.976614
epoch 270, loss: 0.116063
model updated at epoch 270 
epoch 270, 
 train loss: 0.116063, val loss: 0.190523 
 val auc: 0.975563,  test auc: 0.976727
epoch 271, loss: 0.115716
model updated at epoch 271 
epoch 271, 
 train loss: 0.115716, val loss: 0.190222 
 val auc: 0.975526,  test auc: 0.976708
epoch 272, loss: 0.115368
model updated at epoch 272 
epoch 272, 
 train loss: 0.115368, val loss: 0.189947 
 val auc: 0.975638,  test auc: 0.976792
epoch 273, loss: 0.115012
model updated at epoch 273 
epoch 273, 
 train loss: 0.115012, val loss: 0.189584 
 val auc: 0.975751,  test auc: 0.976886
epoch 274, loss: 0.114653
model updated at epoch 274 
epoch 274, 
 train loss: 0.114653, val loss: 0.189381 
 val auc: 0.975751,  test auc: 0.976933
epoch 275, loss: 0.114299
model updated at epoch 275 
epoch 275, 
 train loss: 0.114299, val loss: 0.189247 
 val auc: 0.975788,  test auc: 0.976961
epoch 276, loss: 0.113956
epoch 276, 
 train loss: 0.113956, val loss: 0.189478 
 val auc: 0.975676,  test auc: 0.976886
epoch 277, loss: 0.113618
model updated at epoch 277 
epoch 277, 
 train loss: 0.113618, val loss: 0.188683 
 val auc: 0.975938,  test auc: 0.976999
epoch 278, loss: 0.113276
epoch 278, 
 train loss: 0.113276, val loss: 0.189505 
 val auc: 0.975676,  test auc: 0.976886
epoch 279, loss: 0.112908
model updated at epoch 279 
epoch 279, 
 train loss: 0.112908, val loss: 0.188299 
 val auc: 0.976014,  test auc: 0.977102
epoch 280, loss: 0.112532
epoch 280, 
 train loss: 0.112532, val loss: 0.188893 
 val auc: 0.975901,  test auc: 0.976943
epoch 281, loss: 0.112154
model updated at epoch 281 
epoch 281, 
 train loss: 0.112154, val loss: 0.188220 
 val auc: 0.976126,  test auc: 0.977168
epoch 282, loss: 0.111787
model updated at epoch 282 
epoch 282, 
 train loss: 0.111787, val loss: 0.187952 
 val auc: 0.976201,  test auc: 0.977224
epoch 283, loss: 0.111437
epoch 283, 
 train loss: 0.111437, val loss: 0.188207 
 val auc: 0.976164,  test auc: 0.977262
epoch 284, loss: 0.111071
model updated at epoch 284 
epoch 284, 
 train loss: 0.111071, val loss: 0.187368 
 val auc: 0.976464,  test auc: 0.977327
epoch 285, loss: 0.110698
epoch 285, 
 train loss: 0.110698, val loss: 0.187701 
 val auc: 0.976389,  test auc: 0.977299
epoch 286, loss: 0.110327
model updated at epoch 286 
epoch 286, 
 train loss: 0.110327, val loss: 0.187059 
 val auc: 0.976614,  test auc: 0.977477
epoch 287, loss: 0.109965
model updated at epoch 287 
epoch 287, 
 train loss: 0.109965, val loss: 0.186715 
 val auc: 0.976614,  test auc: 0.977506
epoch 288, loss: 0.109610
epoch 288, 
 train loss: 0.109610, val loss: 0.186887 
 val auc: 0.976614,  test auc: 0.977515
epoch 289, loss: 0.109248
model updated at epoch 289 
epoch 289, 
 train loss: 0.109248, val loss: 0.186264 
 val auc: 0.976689,  test auc: 0.977553
epoch 290, loss: 0.108876
epoch 290, 
 train loss: 0.108876, val loss: 0.186278 
 val auc: 0.976689,  test auc: 0.977543
epoch 291, loss: 0.108500
model updated at epoch 291 
epoch 291, 
 train loss: 0.108500, val loss: 0.185506 
 val auc: 0.976914,  test auc: 0.977656
epoch 292, loss: 0.108121
model updated at epoch 292 
epoch 292, 
 train loss: 0.108121, val loss: 0.185064 
 val auc: 0.977140,  test auc: 0.977731
epoch 293, loss: 0.107735
model updated at epoch 293 
epoch 293, 
 train loss: 0.107735, val loss: 0.184789 
 val auc: 0.977102,  test auc: 0.977703
epoch 294, loss: 0.107343
model updated at epoch 294 
epoch 294, 
 train loss: 0.107343, val loss: 0.184179 
 val auc: 0.977327,  test auc: 0.977806
epoch 295, loss: 0.106951
epoch 295, 
 train loss: 0.106951, val loss: 0.184550 
 val auc: 0.977027,  test auc: 0.977665
epoch 296, loss: 0.106573
model updated at epoch 296 
epoch 296, 
 train loss: 0.106573, val loss: 0.183493 
 val auc: 0.977365,  test auc: 0.977919
epoch 297, loss: 0.106182
epoch 297, 
 train loss: 0.106182, val loss: 0.184265 
 val auc: 0.977140,  test auc: 0.977797
epoch 298, loss: 0.105805
model updated at epoch 298 
epoch 298, 
 train loss: 0.105805, val loss: 0.182583 
 val auc: 0.977365,  test auc: 0.978041
epoch 299, loss: 0.105462
epoch 299, 
 train loss: 0.105462, val loss: 0.184464 
 val auc: 0.977290,  test auc: 0.977975
epoch 300, loss: 0.105133
model updated at epoch 300 
epoch 300, 
 train loss: 0.105133, val loss: 0.182095 
 val auc: 0.977477,  test auc: 0.978153
epoch 301, loss: 0.104798
epoch 301, 
 train loss: 0.104798, val loss: 0.184345 
 val auc: 0.977290,  test auc: 0.977909
epoch 302, loss: 0.104368
model updated at epoch 302 
epoch 302, 
 train loss: 0.104368, val loss: 0.181120 
 val auc: 0.977778,  test auc: 0.978303
epoch 303, loss: 0.103905
epoch 303, 
 train loss: 0.103905, val loss: 0.182934 
 val auc: 0.977590,  test auc: 0.978050
epoch 304, loss: 0.103427
model updated at epoch 304 
epoch 304, 
 train loss: 0.103427, val loss: 0.180485 
 val auc: 0.977815,  test auc: 0.978275
epoch 305, loss: 0.102970
epoch 305, 
 train loss: 0.102970, val loss: 0.180811 
 val auc: 0.977628,  test auc: 0.978172
epoch 306, loss: 0.102566
model updated at epoch 306 
epoch 306, 
 train loss: 0.102566, val loss: 0.179901 
 val auc: 0.977740,  test auc: 0.978247
epoch 307, loss: 0.102209
model updated at epoch 307 
epoch 307, 
 train loss: 0.102209, val loss: 0.178904 
 val auc: 0.978228,  test auc: 0.978425
epoch 308, loss: 0.101860
epoch 308, 
 train loss: 0.101860, val loss: 0.179878 
 val auc: 0.978003,  test auc: 0.978294
epoch 309, loss: 0.101487
model updated at epoch 309 
epoch 309, 
 train loss: 0.101487, val loss: 0.178172 
 val auc: 0.978341,  test auc: 0.978557
epoch 310, loss: 0.101089
epoch 310, 
 train loss: 0.101089, val loss: 0.179390 
 val auc: 0.977965,  test auc: 0.978331
epoch 311, loss: 0.100668
model updated at epoch 311 
epoch 311, 
 train loss: 0.100668, val loss: 0.177835 
 val auc: 0.978341,  test auc: 0.978510
epoch 312, loss: 0.100263
epoch 312, 
 train loss: 0.100263, val loss: 0.178477 
 val auc: 0.978153,  test auc: 0.978444
epoch 313, loss: 0.099882
epoch 313, 
 train loss: 0.099882, val loss: 0.177968 
 val auc: 0.978303,  test auc: 0.978575
epoch 314, loss: 0.099519
model updated at epoch 314 
epoch 314, 
 train loss: 0.099519, val loss: 0.177020 
 val auc: 0.978341,  test auc: 0.978613
epoch 315, loss: 0.099174
epoch 315, 
 train loss: 0.099174, val loss: 0.177183 
 val auc: 0.978303,  test auc: 0.978613
epoch 316, loss: 0.098824
model updated at epoch 316 
epoch 316, 
 train loss: 0.098824, val loss: 0.175591 
 val auc: 0.978453,  test auc: 0.978716
epoch 317, loss: 0.098465
epoch 317, 
 train loss: 0.098465, val loss: 0.176327 
 val auc: 0.978491,  test auc: 0.978763
epoch 318, loss: 0.098095
model updated at epoch 318 
epoch 318, 
 train loss: 0.098095, val loss: 0.174862 
 val auc: 0.978791,  test auc: 0.978960
epoch 319, loss: 0.097725
epoch 319, 
 train loss: 0.097725, val loss: 0.174975 
 val auc: 0.978866,  test auc: 0.979017
epoch 320, loss: 0.097374
model updated at epoch 320 
epoch 320, 
 train loss: 0.097374, val loss: 0.174301 
 val auc: 0.979054,  test auc: 0.979092
epoch 321, loss: 0.097033
model updated at epoch 321 
epoch 321, 
 train loss: 0.097033, val loss: 0.173894 
 val auc: 0.979167,  test auc: 0.979148
epoch 322, loss: 0.096705
epoch 322, 
 train loss: 0.096705, val loss: 0.174076 
 val auc: 0.979317,  test auc: 0.979185
epoch 323, loss: 0.096374
model updated at epoch 323 
epoch 323, 
 train loss: 0.096374, val loss: 0.172955 
 val auc: 0.979279,  test auc: 0.979261
epoch 324, loss: 0.096037
epoch 324, 
 train loss: 0.096037, val loss: 0.173204 
 val auc: 0.979279,  test auc: 0.979307
epoch 325, loss: 0.095700
model updated at epoch 325 
epoch 325, 
 train loss: 0.095700, val loss: 0.172140 
 val auc: 0.979392,  test auc: 0.979392
epoch 326, loss: 0.095370
epoch 326, 
 train loss: 0.095370, val loss: 0.172250 
 val auc: 0.979542,  test auc: 0.979458
epoch 327, loss: 0.095043
model updated at epoch 327 
epoch 327, 
 train loss: 0.095043, val loss: 0.171654 
 val auc: 0.979505,  test auc: 0.979495
epoch 328, loss: 0.094722
model updated at epoch 328 
epoch 328, 
 train loss: 0.094722, val loss: 0.171361 
 val auc: 0.979542,  test auc: 0.979523
epoch 329, loss: 0.094411
model updated at epoch 329 
epoch 329, 
 train loss: 0.094411, val loss: 0.171284 
 val auc: 0.979692,  test auc: 0.979551
epoch 330, loss: 0.094105
model updated at epoch 330 
epoch 330, 
 train loss: 0.094105, val loss: 0.170650 
 val auc: 0.979692,  test auc: 0.979617
epoch 331, loss: 0.093803
epoch 331, 
 train loss: 0.093803, val loss: 0.170874 
 val auc: 0.979655,  test auc: 0.979598
epoch 332, loss: 0.093500
model updated at epoch 332 
epoch 332, 
 train loss: 0.093500, val loss: 0.170039 
 val auc: 0.979767,  test auc: 0.979673
epoch 333, loss: 0.093193
epoch 333, 
 train loss: 0.093193, val loss: 0.170392 
 val auc: 0.979767,  test auc: 0.979702
epoch 334, loss: 0.092887
epoch 334, 
 train loss: 0.092887, val loss: 0.170046 
 val auc: 0.979842,  test auc: 0.979758
epoch 335, loss: 0.092590
model updated at epoch 335 
epoch 335, 
 train loss: 0.092590, val loss: 0.169881 
 val auc: 0.979842,  test auc: 0.979795
epoch 336, loss: 0.092301
model updated at epoch 336 
epoch 336, 
 train loss: 0.092301, val loss: 0.169799 
 val auc: 0.979880,  test auc: 0.979777
epoch 337, loss: 0.092012
model updated at epoch 337 
epoch 337, 
 train loss: 0.092012, val loss: 0.169166 
 val auc: 0.980030,  test auc: 0.979833
epoch 338, loss: 0.091725
epoch 338, 
 train loss: 0.091725, val loss: 0.169624 
 val auc: 0.979955,  test auc: 0.979795
epoch 339, loss: 0.091436
epoch 339, 
 train loss: 0.091436, val loss: 0.169180 
 val auc: 0.980068,  test auc: 0.979861
epoch 340, loss: 0.091159
model updated at epoch 340 
epoch 340, 
 train loss: 0.091159, val loss: 0.168723 
 val auc: 0.980180,  test auc: 0.979955
epoch 341, loss: 0.090878
epoch 341, 
 train loss: 0.090878, val loss: 0.168782 
 val auc: 0.980105,  test auc: 0.979955
epoch 342, loss: 0.090604
model updated at epoch 342 
epoch 342, 
 train loss: 0.090604, val loss: 0.168239 
 val auc: 0.980330,  test auc: 0.980021
epoch 343, loss: 0.090330
epoch 343, 
 train loss: 0.090330, val loss: 0.168273 
 val auc: 0.980405,  test auc: 0.980096
epoch 344, loss: 0.090057
model updated at epoch 344 
epoch 344, 
 train loss: 0.090057, val loss: 0.167588 
 val auc: 0.980556,  test auc: 0.980161
epoch 345, loss: 0.089788
model updated at epoch 345 
epoch 345, 
 train loss: 0.089788, val loss: 0.167288 
 val auc: 0.980518,  test auc: 0.980171
epoch 346, loss: 0.089520
epoch 346, 
 train loss: 0.089520, val loss: 0.167611 
 val auc: 0.980556,  test auc: 0.980180
epoch 347, loss: 0.089257
model updated at epoch 347 
epoch 347, 
 train loss: 0.089257, val loss: 0.167185 
 val auc: 0.980518,  test auc: 0.980180
epoch 348, loss: 0.088989
epoch 348, 
 train loss: 0.088989, val loss: 0.167401 
 val auc: 0.980518,  test auc: 0.980208
epoch 349, loss: 0.088731
model updated at epoch 349 
epoch 349, 
 train loss: 0.088731, val loss: 0.167015 
 val auc: 0.980593,  test auc: 0.980255
epoch 350, loss: 0.088476
model updated at epoch 350 
epoch 350, 
 train loss: 0.088476, val loss: 0.166832 
 val auc: 0.980518,  test auc: 0.980227
epoch 351, loss: 0.088219
epoch 351, 
 train loss: 0.088219, val loss: 0.166995 
 val auc: 0.980443,  test auc: 0.980227
epoch 352, loss: 0.087964
model updated at epoch 352 
epoch 352, 
 train loss: 0.087964, val loss: 0.166298 
 val auc: 0.980405,  test auc: 0.980312
epoch 353, loss: 0.087708
model updated at epoch 353 
epoch 353, 
 train loss: 0.087708, val loss: 0.166148 
 val auc: 0.980668,  test auc: 0.980415
epoch 354, loss: 0.087450
model updated at epoch 354 
epoch 354, 
 train loss: 0.087450, val loss: 0.165544 
 val auc: 0.980706,  test auc: 0.980405
epoch 355, loss: 0.087199
epoch 355, 
 train loss: 0.087199, val loss: 0.165625 
 val auc: 0.980743,  test auc: 0.980424
epoch 356, loss: 0.086952
model updated at epoch 356 
epoch 356, 
 train loss: 0.086952, val loss: 0.164872 
 val auc: 0.980818,  test auc: 0.980490
epoch 357, loss: 0.086704
model updated at epoch 357 
epoch 357, 
 train loss: 0.086704, val loss: 0.164508 
 val auc: 0.980856,  test auc: 0.980518
epoch 358, loss: 0.086454
model updated at epoch 358 
epoch 358, 
 train loss: 0.086454, val loss: 0.164426 
 val auc: 0.980818,  test auc: 0.980509
epoch 359, loss: 0.086214
model updated at epoch 359 
epoch 359, 
 train loss: 0.086214, val loss: 0.164135 
 val auc: 0.980856,  test auc: 0.980546
epoch 360, loss: 0.085963
model updated at epoch 360 
epoch 360, 
 train loss: 0.085963, val loss: 0.164092 
 val auc: 0.980931,  test auc: 0.980546
epoch 361, loss: 0.085735
model updated at epoch 361 
epoch 361, 
 train loss: 0.085735, val loss: 0.163659 
 val auc: 0.981006,  test auc: 0.980621
epoch 362, loss: 0.085480
model updated at epoch 362 
epoch 362, 
 train loss: 0.085480, val loss: 0.163628 
 val auc: 0.980968,  test auc: 0.980584
epoch 363, loss: 0.085262
model updated at epoch 363 
epoch 363, 
 train loss: 0.085262, val loss: 0.163165 
 val auc: 0.980931,  test auc: 0.980602
epoch 364, loss: 0.085022
model updated at epoch 364 
epoch 364, 
 train loss: 0.085022, val loss: 0.162767 
 val auc: 0.981006,  test auc: 0.980621
epoch 365, loss: 0.084780
model updated at epoch 365 
epoch 365, 
 train loss: 0.084780, val loss: 0.162459 
 val auc: 0.980968,  test auc: 0.980659
epoch 366, loss: 0.084554
model updated at epoch 366 
epoch 366, 
 train loss: 0.084554, val loss: 0.162433 
 val auc: 0.981006,  test auc: 0.980753
epoch 367, loss: 0.084321
epoch 367, 
 train loss: 0.084321, val loss: 0.162437 
 val auc: 0.981006,  test auc: 0.980809
epoch 368, loss: 0.084096
model updated at epoch 368 
epoch 368, 
 train loss: 0.084096, val loss: 0.161896 
 val auc: 0.981006,  test auc: 0.980846
epoch 369, loss: 0.083864
model updated at epoch 369 
epoch 369, 
 train loss: 0.083864, val loss: 0.161827 
 val auc: 0.981044,  test auc: 0.980922
epoch 370, loss: 0.083633
model updated at epoch 370 
epoch 370, 
 train loss: 0.083633, val loss: 0.161494 
 val auc: 0.981081,  test auc: 0.980950
epoch 371, loss: 0.083408
epoch 371, 
 train loss: 0.083408, val loss: 0.161600 
 val auc: 0.981081,  test auc: 0.980978
epoch 372, loss: 0.083181
model updated at epoch 372 
epoch 372, 
 train loss: 0.083181, val loss: 0.160870 
 val auc: 0.981156,  test auc: 0.981006
epoch 373, loss: 0.082961
model updated at epoch 373 
epoch 373, 
 train loss: 0.082961, val loss: 0.160647 
 val auc: 0.981156,  test auc: 0.981006
epoch 374, loss: 0.082729
model updated at epoch 374 
epoch 374, 
 train loss: 0.082729, val loss: 0.160352 
 val auc: 0.981194,  test auc: 0.981053
epoch 375, loss: 0.082519
epoch 375, 
 train loss: 0.082519, val loss: 0.160590 
 val auc: 0.981231,  test auc: 0.981081
epoch 376, loss: 0.082290
epoch 376, 
 train loss: 0.082290, val loss: 0.160415 
 val auc: 0.981194,  test auc: 0.981147
epoch 377, loss: 0.082072
model updated at epoch 377 
epoch 377, 
 train loss: 0.082072, val loss: 0.160118 
 val auc: 0.981156,  test auc: 0.981194
epoch 378, loss: 0.081860
model updated at epoch 378 
epoch 378, 
 train loss: 0.081860, val loss: 0.159709 
 val auc: 0.981231,  test auc: 0.981222
epoch 379, loss: 0.081644
epoch 379, 
 train loss: 0.081644, val loss: 0.159765 
 val auc: 0.981306,  test auc: 0.981222
epoch 380, loss: 0.081431
model updated at epoch 380 
epoch 380, 
 train loss: 0.081431, val loss: 0.159639 
 val auc: 0.981306,  test auc: 0.981297
epoch 381, loss: 0.081217
epoch 381, 
 train loss: 0.081217, val loss: 0.159673 
 val auc: 0.981344,  test auc: 0.981344
epoch 382, loss: 0.081014
model updated at epoch 382 
epoch 382, 
 train loss: 0.081014, val loss: 0.159147 
 val auc: 0.981381,  test auc: 0.981391
epoch 383, loss: 0.080803
epoch 383, 
 train loss: 0.080803, val loss: 0.159240 
 val auc: 0.981419,  test auc: 0.981419
epoch 384, loss: 0.080613
model updated at epoch 384 
epoch 384, 
 train loss: 0.080613, val loss: 0.158439 
 val auc: 0.981306,  test auc: 0.981438
epoch 385, loss: 0.080404
epoch 385, 
 train loss: 0.080404, val loss: 0.159151 
 val auc: 0.981344,  test auc: 0.981438
epoch 386, loss: 0.080226
model updated at epoch 386 
epoch 386, 
 train loss: 0.080226, val loss: 0.158107 
 val auc: 0.981306,  test auc: 0.981541
epoch 387, loss: 0.080039
epoch 387, 
 train loss: 0.080039, val loss: 0.159029 
 val auc: 0.981381,  test auc: 0.981522
epoch 388, loss: 0.079844
model updated at epoch 388 
epoch 388, 
 train loss: 0.079844, val loss: 0.157414 
 val auc: 0.981644,  test auc: 0.981663
epoch 389, loss: 0.079659
epoch 389, 
 train loss: 0.079659, val loss: 0.159141 
 val auc: 0.981269,  test auc: 0.981466
epoch 390, loss: 0.079477
model updated at epoch 390 
epoch 390, 
 train loss: 0.079477, val loss: 0.157218 
 val auc: 0.981381,  test auc: 0.981607
epoch 391, loss: 0.079301
epoch 391, 
 train loss: 0.079301, val loss: 0.158758 
 val auc: 0.981306,  test auc: 0.981616
epoch 392, loss: 0.079120
model updated at epoch 392 
epoch 392, 
 train loss: 0.079120, val loss: 0.156503 
 val auc: 0.981569,  test auc: 0.981700
epoch 393, loss: 0.078941
epoch 393, 
 train loss: 0.078941, val loss: 0.158708 
 val auc: 0.981344,  test auc: 0.981607
epoch 394, loss: 0.078753
model updated at epoch 394 
epoch 394, 
 train loss: 0.078753, val loss: 0.156202 
 val auc: 0.981494,  test auc: 0.981672
epoch 395, loss: 0.078532
epoch 395, 
 train loss: 0.078532, val loss: 0.158338 
 val auc: 0.981344,  test auc: 0.981625
epoch 396, loss: 0.078305
model updated at epoch 396 
epoch 396, 
 train loss: 0.078305, val loss: 0.156134 
 val auc: 0.981532,  test auc: 0.981663
epoch 397, loss: 0.078057
epoch 397, 
 train loss: 0.078057, val loss: 0.157700 
 val auc: 0.981532,  test auc: 0.981635
epoch 398, loss: 0.077819
model updated at epoch 398 
epoch 398, 
 train loss: 0.077819, val loss: 0.155944 
 val auc: 0.981607,  test auc: 0.981691
epoch 399, loss: 0.077601
epoch 399, 
 train loss: 0.077601, val loss: 0.156618 
 val auc: 0.981494,  test auc: 0.981682
epoch 400, loss: 0.077390
model updated at epoch 400 
epoch 400, 
 train loss: 0.077390, val loss: 0.155683 
 val auc: 0.981644,  test auc: 0.981804
epoch 401, loss: 0.077192
epoch 401, 
 train loss: 0.077192, val loss: 0.155828 
 val auc: 0.981644,  test auc: 0.981860
epoch 402, loss: 0.077004
epoch 402, 
 train loss: 0.077004, val loss: 0.155916 
 val auc: 0.981644,  test auc: 0.981841
epoch 403, loss: 0.076821
epoch 403, 
 train loss: 0.076821, val loss: 0.155795 
 val auc: 0.981644,  test auc: 0.981879
epoch 404, loss: 0.076638
epoch 404, 
 train loss: 0.076638, val loss: 0.156074 
 val auc: 0.981569,  test auc: 0.981860
epoch 405, loss: 0.076455
model updated at epoch 405 
epoch 405, 
 train loss: 0.076455, val loss: 0.155065 
 val auc: 0.981719,  test auc: 0.981935
epoch 406, loss: 0.076270
epoch 406, 
 train loss: 0.076270, val loss: 0.155730 
 val auc: 0.981532,  test auc: 0.981898
epoch 407, loss: 0.076090
model updated at epoch 407 
epoch 407, 
 train loss: 0.076090, val loss: 0.154852 
 val auc: 0.981607,  test auc: 0.981954
epoch 408, loss: 0.075908
epoch 408, 
 train loss: 0.075908, val loss: 0.155461 
 val auc: 0.981682,  test auc: 0.981982
epoch 409, loss: 0.075734
model updated at epoch 409 
epoch 409, 
 train loss: 0.075734, val loss: 0.154185 
 val auc: 0.981794,  test auc: 0.982057
epoch 410, loss: 0.075559
epoch 410, 
 train loss: 0.075559, val loss: 0.155339 
 val auc: 0.981494,  test auc: 0.981954
epoch 411, loss: 0.075381
model updated at epoch 411 
epoch 411, 
 train loss: 0.075381, val loss: 0.153724 
 val auc: 0.981757,  test auc: 0.982113
epoch 412, loss: 0.075210
epoch 412, 
 train loss: 0.075210, val loss: 0.154460 
 val auc: 0.981794,  test auc: 0.982076
epoch 413, loss: 0.075038
model updated at epoch 413 
epoch 413, 
 train loss: 0.075038, val loss: 0.152909 
 val auc: 0.981907,  test auc: 0.982170
epoch 414, loss: 0.074872
epoch 414, 
 train loss: 0.074872, val loss: 0.154768 
 val auc: 0.981757,  test auc: 0.982076
epoch 415, loss: 0.074702
epoch 415, 
 train loss: 0.074702, val loss: 0.152927 
 val auc: 0.981832,  test auc: 0.982113
epoch 416, loss: 0.074535
epoch 416, 
 train loss: 0.074535, val loss: 0.154378 
 val auc: 0.981982,  test auc: 0.982179
epoch 417, loss: 0.074359
model updated at epoch 417 
epoch 417, 
 train loss: 0.074359, val loss: 0.152499 
 val auc: 0.981869,  test auc: 0.982217
epoch 418, loss: 0.074178
epoch 418, 
 train loss: 0.074178, val loss: 0.154426 
 val auc: 0.981757,  test auc: 0.982142
epoch 419, loss: 0.073994
model updated at epoch 419 
epoch 419, 
 train loss: 0.073994, val loss: 0.152267 
 val auc: 0.981832,  test auc: 0.982235
epoch 420, loss: 0.073806
epoch 420, 
 train loss: 0.073806, val loss: 0.153506 
 val auc: 0.981944,  test auc: 0.982301
epoch 421, loss: 0.073611
model updated at epoch 421 
epoch 421, 
 train loss: 0.073611, val loss: 0.151663 
 val auc: 0.981869,  test auc: 0.982414
epoch 422, loss: 0.073410
epoch 422, 
 train loss: 0.073410, val loss: 0.153176 
 val auc: 0.981719,  test auc: 0.982273
epoch 423, loss: 0.073216
epoch 423, 
 train loss: 0.073216, val loss: 0.151881 
 val auc: 0.981869,  test auc: 0.982386
epoch 424, loss: 0.073035
epoch 424, 
 train loss: 0.073035, val loss: 0.152536 
 val auc: 0.981719,  test auc: 0.982310
epoch 425, loss: 0.072863
model updated at epoch 425 
epoch 425, 
 train loss: 0.072863, val loss: 0.151500 
 val auc: 0.981794,  test auc: 0.982423
epoch 426, loss: 0.072690
epoch 426, 
 train loss: 0.072690, val loss: 0.152390 
 val auc: 0.981719,  test auc: 0.982339
epoch 427, loss: 0.072520
model updated at epoch 427 
epoch 427, 
 train loss: 0.072520, val loss: 0.151340 
 val auc: 0.981719,  test auc: 0.982432
epoch 428, loss: 0.072354
epoch 428, 
 train loss: 0.072354, val loss: 0.152048 
 val auc: 0.981794,  test auc: 0.982414
epoch 429, loss: 0.072197
model updated at epoch 429 
epoch 429, 
 train loss: 0.072197, val loss: 0.150841 
 val auc: 0.981757,  test auc: 0.982508
epoch 430, loss: 0.072048
epoch 430, 
 train loss: 0.072048, val loss: 0.152072 
 val auc: 0.981794,  test auc: 0.982395
epoch 431, loss: 0.071899
model updated at epoch 431 
epoch 431, 
 train loss: 0.071899, val loss: 0.150541 
 val auc: 0.981794,  test auc: 0.982583
epoch 432, loss: 0.071746
epoch 432, 
 train loss: 0.071746, val loss: 0.151876 
 val auc: 0.981794,  test auc: 0.982442
epoch 433, loss: 0.071603
model updated at epoch 433 
epoch 433, 
 train loss: 0.071603, val loss: 0.150090 
 val auc: 0.981719,  test auc: 0.982601
epoch 434, loss: 0.071464
epoch 434, 
 train loss: 0.071464, val loss: 0.151941 
 val auc: 0.981607,  test auc: 0.982404
epoch 435, loss: 0.071315
model updated at epoch 435 
epoch 435, 
 train loss: 0.071315, val loss: 0.149756 
 val auc: 0.981569,  test auc: 0.982536
epoch 436, loss: 0.071162
epoch 436, 
 train loss: 0.071162, val loss: 0.151654 
 val auc: 0.981569,  test auc: 0.982386
epoch 437, loss: 0.070993
model updated at epoch 437 
epoch 437, 
 train loss: 0.070993, val loss: 0.149494 
 val auc: 0.981419,  test auc: 0.982489
epoch 438, loss: 0.070819
epoch 438, 
 train loss: 0.070819, val loss: 0.151638 
 val auc: 0.981231,  test auc: 0.982310
epoch 439, loss: 0.070645
epoch 439, 
 train loss: 0.070645, val loss: 0.149569 
 val auc: 0.981419,  test auc: 0.982498
epoch 440, loss: 0.070456
epoch 440, 
 train loss: 0.070456, val loss: 0.151307 
 val auc: 0.981306,  test auc: 0.982339
epoch 441, loss: 0.070267
epoch 441, 
 train loss: 0.070267, val loss: 0.149543 
 val auc: 0.981419,  test auc: 0.982526
epoch 442, loss: 0.070083
epoch 442, 
 train loss: 0.070083, val loss: 0.150679 
 val auc: 0.981344,  test auc: 0.982386
epoch 443, loss: 0.069899
model updated at epoch 443 
epoch 443, 
 train loss: 0.069899, val loss: 0.149205 
 val auc: 0.981419,  test auc: 0.982564
epoch 444, loss: 0.069718
epoch 444, 
 train loss: 0.069718, val loss: 0.149866 
 val auc: 0.981456,  test auc: 0.982489
epoch 445, loss: 0.069545
epoch 445, 
 train loss: 0.069545, val loss: 0.149326 
 val auc: 0.981456,  test auc: 0.982564
epoch 446, loss: 0.069384
epoch 446, 
 train loss: 0.069384, val loss: 0.149556 
 val auc: 0.981306,  test auc: 0.982536
epoch 447, loss: 0.069227
epoch 447, 
 train loss: 0.069227, val loss: 0.149455 
 val auc: 0.981156,  test auc: 0.982489
epoch 448, loss: 0.069078
model updated at epoch 448 
epoch 448, 
 train loss: 0.069078, val loss: 0.148984 
 val auc: 0.981381,  test auc: 0.982573
epoch 449, loss: 0.068933
epoch 449, 
 train loss: 0.068933, val loss: 0.149639 
 val auc: 0.981231,  test auc: 0.982573
epoch 450, loss: 0.068790
model updated at epoch 450 
epoch 450, 
 train loss: 0.068790, val loss: 0.148723 
 val auc: 0.981231,  test auc: 0.982667
epoch 451, loss: 0.068656
epoch 451, 
 train loss: 0.068656, val loss: 0.149760 
 val auc: 0.981344,  test auc: 0.982686
epoch 452, loss: 0.068528
model updated at epoch 452 
epoch 452, 
 train loss: 0.068528, val loss: 0.148316 
 val auc: 0.981381,  test auc: 0.982676
epoch 453, loss: 0.068401
epoch 453, 
 train loss: 0.068401, val loss: 0.150151 
 val auc: 0.981269,  test auc: 0.982648
epoch 454, loss: 0.068227
model updated at epoch 454 
epoch 454, 
 train loss: 0.068227, val loss: 0.148230 
 val auc: 0.981419,  test auc: 0.982761
epoch 455, loss: 0.068012
epoch 455, 
 train loss: 0.068012, val loss: 0.149144 
 val auc: 0.981231,  test auc: 0.982723
epoch 456, loss: 0.067822
epoch 456, 
 train loss: 0.067822, val loss: 0.148320 
 val auc: 0.981381,  test auc: 0.982714
epoch 457, loss: 0.067680
model updated at epoch 457 
epoch 457, 
 train loss: 0.067680, val loss: 0.148156 
 val auc: 0.981306,  test auc: 0.982723
epoch 458, loss: 0.067570
epoch 458, 
 train loss: 0.067570, val loss: 0.149215 
 val auc: 0.981419,  test auc: 0.982827
epoch 459, loss: 0.067432
model updated at epoch 459 
epoch 459, 
 train loss: 0.067432, val loss: 0.147806 
 val auc: 0.981456,  test auc: 0.982873
epoch 460, loss: 0.067255
epoch 460, 
 train loss: 0.067255, val loss: 0.148979 
 val auc: 0.981344,  test auc: 0.982892
epoch 461, loss: 0.067073
epoch 461, 
 train loss: 0.067073, val loss: 0.148212 
 val auc: 0.981344,  test auc: 0.982892
epoch 462, loss: 0.066909
epoch 462, 
 train loss: 0.066909, val loss: 0.148234 
 val auc: 0.981344,  test auc: 0.982986
epoch 463, loss: 0.066782
epoch 463, 
 train loss: 0.066782, val loss: 0.148340 
 val auc: 0.981419,  test auc: 0.983005
epoch 464, loss: 0.066664
model updated at epoch 464 
epoch 464, 
 train loss: 0.066664, val loss: 0.147437 
 val auc: 0.981456,  test auc: 0.982995
epoch 465, loss: 0.066525
epoch 465, 
 train loss: 0.066525, val loss: 0.148871 
 val auc: 0.981381,  test auc: 0.983005
epoch 466, loss: 0.066361
epoch 466, 
 train loss: 0.066361, val loss: 0.147549 
 val auc: 0.981494,  test auc: 0.983033
epoch 467, loss: 0.066191
epoch 467, 
 train loss: 0.066191, val loss: 0.148219 
 val auc: 0.981532,  test auc: 0.983136
epoch 468, loss: 0.066025
epoch 468, 
 train loss: 0.066025, val loss: 0.147588 
 val auc: 0.981607,  test auc: 0.983146
epoch 469, loss: 0.065880
epoch 469, 
 train loss: 0.065880, val loss: 0.147559 
 val auc: 0.981532,  test auc: 0.983136
epoch 470, loss: 0.065748
epoch 470, 
 train loss: 0.065748, val loss: 0.147970 
 val auc: 0.981494,  test auc: 0.983174
epoch 471, loss: 0.065613
model updated at epoch 471 
epoch 471, 
 train loss: 0.065613, val loss: 0.147069 
 val auc: 0.981569,  test auc: 0.983239
epoch 472, loss: 0.065465
epoch 472, 
 train loss: 0.065465, val loss: 0.148032 
 val auc: 0.981569,  test auc: 0.983249
epoch 473, loss: 0.065310
epoch 473, 
 train loss: 0.065310, val loss: 0.147313 
 val auc: 0.981532,  test auc: 0.983277
epoch 474, loss: 0.065150
epoch 474, 
 train loss: 0.065150, val loss: 0.147626 
 val auc: 0.981607,  test auc: 0.983277
epoch 475, loss: 0.065000
epoch 475, 
 train loss: 0.065000, val loss: 0.147195 
 val auc: 0.981644,  test auc: 0.983315
epoch 476, loss: 0.064857
model updated at epoch 476 
epoch 476, 
 train loss: 0.064857, val loss: 0.147004 
 val auc: 0.981682,  test auc: 0.983390
epoch 477, loss: 0.064716
epoch 477, 
 train loss: 0.064716, val loss: 0.147420 
 val auc: 0.981682,  test auc: 0.983371
epoch 478, loss: 0.064573
model updated at epoch 478 
epoch 478, 
 train loss: 0.064573, val loss: 0.146756 
 val auc: 0.981757,  test auc: 0.983465
epoch 479, loss: 0.064430
epoch 479, 
 train loss: 0.064430, val loss: 0.147286 
 val auc: 0.981757,  test auc: 0.983427
epoch 480, loss: 0.064410
model updated at epoch 480 
epoch 480, 
 train loss: 0.064410, val loss: 0.145597 
 val auc: 0.982020,  test auc: 0.983540
epoch 481, loss: 0.064908
epoch 481, 
 train loss: 0.064908, val loss: 0.150333 
 val auc: 0.981419,  test auc: 0.983108
epoch 482, loss: 0.066134
epoch 482, 
 train loss: 0.066134, val loss: 0.145838 
 val auc: 0.981907,  test auc: 0.983380
epoch 483, loss: 0.067906
epoch 483, 
 train loss: 0.067906, val loss: 0.156338 
 val auc: 0.980668,  test auc: 0.982564
epoch 484, loss: 0.067109
model updated at epoch 484 
epoch 484, 
 train loss: 0.067109, val loss: 0.145411 
 val auc: 0.982095,  test auc: 0.983333
epoch 485, loss: 0.064459
epoch 485, 
 train loss: 0.064459, val loss: 0.149807 
 val auc: 0.981532,  test auc: 0.983221
epoch 486, loss: 0.064074
epoch 486, 
 train loss: 0.064074, val loss: 0.150054 
 val auc: 0.981456,  test auc: 0.983239
epoch 487, loss: 0.065668
epoch 487, 
 train loss: 0.065668, val loss: 0.147186 
 val auc: 0.981869,  test auc: 0.983465
epoch 488, loss: 0.065126
epoch 488, 
 train loss: 0.065126, val loss: 0.153231 
 val auc: 0.981119,  test auc: 0.982958
epoch 489, loss: 0.063472
epoch 489, 
 train loss: 0.063472, val loss: 0.146765 
 val auc: 0.981982,  test auc: 0.983662
epoch 490, loss: 0.063702
epoch 490, 
 train loss: 0.063702, val loss: 0.145913 
 val auc: 0.982170,  test auc: 0.983821
epoch 491, loss: 0.064491
epoch 491, 
 train loss: 0.064491, val loss: 0.151717 
 val auc: 0.981306,  test auc: 0.983352
epoch 492, loss: 0.063598
model updated at epoch 492 
epoch 492, 
 train loss: 0.063598, val loss: 0.145389 
 val auc: 0.981982,  test auc: 0.983821
epoch 493, loss: 0.062757
epoch 493, 
 train loss: 0.062757, val loss: 0.146709 
 val auc: 0.981832,  test auc: 0.983746
epoch 494, loss: 0.063357
epoch 494, 
 train loss: 0.063357, val loss: 0.149852 
 val auc: 0.981494,  test auc: 0.983399
epoch 495, loss: 0.063371
model updated at epoch 495 
epoch 495, 
 train loss: 0.063371, val loss: 0.145136 
 val auc: 0.982057,  test auc: 0.983812
epoch 496, loss: 0.062428
epoch 496, 
 train loss: 0.062428, val loss: 0.147511 
 val auc: 0.981757,  test auc: 0.983718
epoch 497, loss: 0.062455
epoch 497, 
 train loss: 0.062455, val loss: 0.148133 
 val auc: 0.981719,  test auc: 0.983652
epoch 498, loss: 0.062796
model updated at epoch 498 
epoch 498, 
 train loss: 0.062796, val loss: 0.144974 
 val auc: 0.981907,  test auc: 0.983887
epoch 499, loss: 0.062203
epoch 499, 
 train loss: 0.062203, val loss: 0.148087 
 val auc: 0.981682,  test auc: 0.983634
epoch 500, loss: 0.061817
epoch 500, 
 train loss: 0.061817, val loss: 0.146641 
 val auc: 0.981832,  test auc: 0.983793
epoch 501, loss: 0.062083
model updated at epoch 501 
epoch 501, 
 train loss: 0.062083, val loss: 0.144689 
 val auc: 0.982170,  test auc: 0.984028
epoch 502, loss: 0.061884
epoch 502, 
 train loss: 0.061884, val loss: 0.148044 
 val auc: 0.981644,  test auc: 0.983699
epoch 503, loss: 0.061400
epoch 503, 
 train loss: 0.061400, val loss: 0.145687 
 val auc: 0.981944,  test auc: 0.983962
epoch 504, loss: 0.061434
epoch 504, 
 train loss: 0.061434, val loss: 0.145200 
 val auc: 0.981944,  test auc: 0.983943
epoch 505, loss: 0.061455
epoch 505, 
 train loss: 0.061455, val loss: 0.148269 
 val auc: 0.981682,  test auc: 0.983821
epoch 506, loss: 0.061067
epoch 506, 
 train loss: 0.061067, val loss: 0.145901 
 val auc: 0.981907,  test auc: 0.983962
epoch 507, loss: 0.060917
epoch 507, 
 train loss: 0.060917, val loss: 0.146093 
 val auc: 0.982020,  test auc: 0.984028
epoch 508, loss: 0.060978
epoch 508, 
 train loss: 0.060978, val loss: 0.148084 
 val auc: 0.981607,  test auc: 0.983840
epoch 509, loss: 0.060759
epoch 509, 
 train loss: 0.060759, val loss: 0.145470 
 val auc: 0.982057,  test auc: 0.984065
epoch 510, loss: 0.060502
epoch 510, 
 train loss: 0.060502, val loss: 0.146189 
 val auc: 0.982020,  test auc: 0.984028
epoch 511, loss: 0.060494
epoch 511, 
 train loss: 0.060494, val loss: 0.147176 
 val auc: 0.981794,  test auc: 0.983953
epoch 512, loss: 0.060399
epoch 512, 
 train loss: 0.060399, val loss: 0.145022 
 val auc: 0.982207,  test auc: 0.984112
epoch 513, loss: 0.060143
epoch 513, 
 train loss: 0.060143, val loss: 0.146423 
 val auc: 0.981982,  test auc: 0.984065
epoch 514, loss: 0.060043
epoch 514, 
 train loss: 0.060043, val loss: 0.146696 
 val auc: 0.981907,  test auc: 0.984065
epoch 515, loss: 0.060014
epoch 515, 
 train loss: 0.060014, val loss: 0.145170 
 val auc: 0.982170,  test auc: 0.984159
epoch 516, loss: 0.059826
epoch 516, 
 train loss: 0.059826, val loss: 0.146598 
 val auc: 0.981907,  test auc: 0.984103
epoch 517, loss: 0.059648
epoch 517, 
 train loss: 0.059648, val loss: 0.145828 
 val auc: 0.982057,  test auc: 0.984131
epoch 518, loss: 0.059593
epoch 518, 
 train loss: 0.059593, val loss: 0.144995 
 val auc: 0.982207,  test auc: 0.984187
epoch 519, loss: 0.059481
epoch 519, 
 train loss: 0.059481, val loss: 0.146465 
 val auc: 0.981944,  test auc: 0.984122
epoch 520, loss: 0.059301
epoch 520, 
 train loss: 0.059301, val loss: 0.145318 
 val auc: 0.982245,  test auc: 0.984244
epoch 521, loss: 0.059192
epoch 521, 
 train loss: 0.059192, val loss: 0.145215 
 val auc: 0.982282,  test auc: 0.984262
epoch 522, loss: 0.059120
epoch 522, 
 train loss: 0.059120, val loss: 0.146374 
 val auc: 0.981907,  test auc: 0.984159
epoch 523, loss: 0.058969
epoch 523, 
 train loss: 0.058969, val loss: 0.144950 
 val auc: 0.982282,  test auc: 0.984244
epoch 524, loss: 0.058820
epoch 524, 
 train loss: 0.058820, val loss: 0.145306 
 val auc: 0.982170,  test auc: 0.984215
epoch 525, loss: 0.058731
epoch 525, 
 train loss: 0.058731, val loss: 0.145942 
 val auc: 0.981982,  test auc: 0.984178
epoch 526, loss: 0.058620
epoch 526, 
 train loss: 0.058620, val loss: 0.144862 
 val auc: 0.982245,  test auc: 0.984309
epoch 527, loss: 0.058469
epoch 527, 
 train loss: 0.058469, val loss: 0.145370 
 val auc: 0.982207,  test auc: 0.984253
epoch 528, loss: 0.058350
epoch 528, 
 train loss: 0.058350, val loss: 0.145071 
 val auc: 0.982245,  test auc: 0.984300
epoch 529, loss: 0.058249
model updated at epoch 529 
epoch 529, 
 train loss: 0.058249, val loss: 0.144391 
 val auc: 0.982320,  test auc: 0.984413
epoch 530, loss: 0.058121
epoch 530, 
 train loss: 0.058121, val loss: 0.145286 
 val auc: 0.982245,  test auc: 0.984384
epoch 531, loss: 0.057982
epoch 531, 
 train loss: 0.057982, val loss: 0.144670 
 val auc: 0.982282,  test auc: 0.984441
epoch 532, loss: 0.057876
model updated at epoch 532 
epoch 532, 
 train loss: 0.057876, val loss: 0.144293 
 val auc: 0.982357,  test auc: 0.984450
epoch 533, loss: 0.057767
epoch 533, 
 train loss: 0.057767, val loss: 0.145112 
 val auc: 0.982320,  test auc: 0.984422
epoch 534, loss: 0.057632
epoch 534, 
 train loss: 0.057632, val loss: 0.144523 
 val auc: 0.982357,  test auc: 0.984478
epoch 535, loss: 0.057506
epoch 535, 
 train loss: 0.057506, val loss: 0.144568 
 val auc: 0.982357,  test auc: 0.984488
epoch 536, loss: 0.057400
epoch 536, 
 train loss: 0.057400, val loss: 0.144832 
 val auc: 0.982282,  test auc: 0.984478
epoch 537, loss: 0.057285
epoch 537, 
 train loss: 0.057285, val loss: 0.144407 
 val auc: 0.982282,  test auc: 0.984506
epoch 538, loss: 0.057159
epoch 538, 
 train loss: 0.057159, val loss: 0.144741 
 val auc: 0.982320,  test auc: 0.984525
epoch 539, loss: 0.057044
epoch 539, 
 train loss: 0.057044, val loss: 0.144754 
 val auc: 0.982357,  test auc: 0.984535
epoch 540, loss: 0.056933
model updated at epoch 540 
epoch 540, 
 train loss: 0.056933, val loss: 0.144189 
 val auc: 0.982470,  test auc: 0.984619
epoch 541, loss: 0.056815
epoch 541, 
 train loss: 0.056815, val loss: 0.144485 
 val auc: 0.982357,  test auc: 0.984628
epoch 542, loss: 0.056702
epoch 542, 
 train loss: 0.056702, val loss: 0.144405 
 val auc: 0.982357,  test auc: 0.984666
epoch 543, loss: 0.056590
model updated at epoch 543 
epoch 543, 
 train loss: 0.056590, val loss: 0.143995 
 val auc: 0.982470,  test auc: 0.984713
epoch 544, loss: 0.056477
epoch 544, 
 train loss: 0.056477, val loss: 0.144283 
 val auc: 0.982432,  test auc: 0.984703
epoch 545, loss: 0.056363
epoch 545, 
 train loss: 0.056363, val loss: 0.144293 
 val auc: 0.982395,  test auc: 0.984703
epoch 546, loss: 0.056253
epoch 546, 
 train loss: 0.056253, val loss: 0.144306 
 val auc: 0.982357,  test auc: 0.984703
epoch 547, loss: 0.056143
epoch 547, 
 train loss: 0.056143, val loss: 0.144439 
 val auc: 0.982357,  test auc: 0.984694
epoch 548, loss: 0.056030
epoch 548, 
 train loss: 0.056030, val loss: 0.144101 
 val auc: 0.982432,  test auc: 0.984769
epoch 549, loss: 0.055922
model updated at epoch 549 
epoch 549, 
 train loss: 0.055922, val loss: 0.143955 
 val auc: 0.982357,  test auc: 0.984779
epoch 550, loss: 0.055831
epoch 550, 
 train loss: 0.055831, val loss: 0.144843 
 val auc: 0.982132,  test auc: 0.984703
epoch 551, loss: 0.055727
model updated at epoch 551 
epoch 551, 
 train loss: 0.055727, val loss: 0.143884 
 val auc: 0.982320,  test auc: 0.984835
epoch 552, loss: 0.055588
epoch 552, 
 train loss: 0.055588, val loss: 0.144395 
 val auc: 0.982245,  test auc: 0.984807
epoch 553, loss: 0.055484
epoch 553, 
 train loss: 0.055484, val loss: 0.144438 
 val auc: 0.982245,  test auc: 0.984797
epoch 554, loss: 0.055391
model updated at epoch 554 
epoch 554, 
 train loss: 0.055391, val loss: 0.143667 
 val auc: 0.982357,  test auc: 0.984929
epoch 555, loss: 0.055272
epoch 555, 
 train loss: 0.055272, val loss: 0.144339 
 val auc: 0.982132,  test auc: 0.984910
epoch 556, loss: 0.055143
epoch 556, 
 train loss: 0.055143, val loss: 0.143889 
 val auc: 0.982282,  test auc: 0.984938
epoch 557, loss: 0.055039
epoch 557, 
 train loss: 0.055039, val loss: 0.143776 
 val auc: 0.982320,  test auc: 0.984985
epoch 558, loss: 0.054935
epoch 558, 
 train loss: 0.054935, val loss: 0.144522 
 val auc: 0.982132,  test auc: 0.984872
epoch 559, loss: 0.054816
epoch 559, 
 train loss: 0.054816, val loss: 0.143842 
 val auc: 0.982207,  test auc: 0.984957
epoch 560, loss: 0.054698
epoch 560, 
 train loss: 0.054698, val loss: 0.144054 
 val auc: 0.982207,  test auc: 0.984947
epoch 561, loss: 0.054601
epoch 561, 
 train loss: 0.054601, val loss: 0.144499 
 val auc: 0.982170,  test auc: 0.984976
epoch 562, loss: 0.054493
epoch 562, 
 train loss: 0.054493, val loss: 0.143688 
 val auc: 0.982282,  test auc: 0.985032
epoch 563, loss: 0.054375
epoch 563, 
 train loss: 0.054375, val loss: 0.144126 
 val auc: 0.982245,  test auc: 0.985304
epoch 564, loss: 0.054261
epoch 564, 
 train loss: 0.054261, val loss: 0.144262 
 val auc: 0.982207,  test auc: 0.985464
epoch 565, loss: 0.054166
epoch 565, 
 train loss: 0.054166, val loss: 0.143764 
 val auc: 0.982320,  test auc: 0.985473
epoch 566, loss: 0.054068
epoch 566, 
 train loss: 0.054068, val loss: 0.144741 
 val auc: 0.982132,  test auc: 0.985482
epoch 567, loss: 0.053954
epoch 567, 
 train loss: 0.053954, val loss: 0.143887 
 val auc: 0.982320,  test auc: 0.985548
epoch 568, loss: 0.053831
epoch 568, 
 train loss: 0.053831, val loss: 0.144690 
 val auc: 0.982207,  test auc: 0.985567
epoch 569, loss: 0.053710
epoch 569, 
 train loss: 0.053710, val loss: 0.144224 
 val auc: 0.982207,  test auc: 0.985633
epoch 570, loss: 0.053607
epoch 570, 
 train loss: 0.053607, val loss: 0.143842 
 val auc: 0.982282,  test auc: 0.985698
epoch 571, loss: 0.053505
epoch 571, 
 train loss: 0.053505, val loss: 0.144356 
 val auc: 0.982132,  test auc: 0.985661
epoch 572, loss: 0.053400
model updated at epoch 572 
epoch 572, 
 train loss: 0.053400, val loss: 0.143650 
 val auc: 0.982245,  test auc: 0.985726
epoch 573, loss: 0.053297
epoch 573, 
 train loss: 0.053297, val loss: 0.144635 
 val auc: 0.982020,  test auc: 0.985670
epoch 574, loss: 0.053190
epoch 574, 
 train loss: 0.053190, val loss: 0.143954 
 val auc: 0.982245,  test auc: 0.985755
epoch 575, loss: 0.053078
epoch 575, 
 train loss: 0.053078, val loss: 0.144777 
 val auc: 0.982057,  test auc: 0.985726
epoch 576, loss: 0.052962
epoch 576, 
 train loss: 0.052962, val loss: 0.144313 
 val auc: 0.982132,  test auc: 0.985792
epoch 577, loss: 0.052850
epoch 577, 
 train loss: 0.052850, val loss: 0.144146 
 val auc: 0.982207,  test auc: 0.985839
epoch 578, loss: 0.052749
epoch 578, 
 train loss: 0.052749, val loss: 0.144391 
 val auc: 0.982245,  test auc: 0.985914
epoch 579, loss: 0.052646
epoch 579, 
 train loss: 0.052646, val loss: 0.144051 
 val auc: 0.982245,  test auc: 0.985952
epoch 580, loss: 0.052537
epoch 580, 
 train loss: 0.052537, val loss: 0.144481 
 val auc: 0.982170,  test auc: 0.985914
epoch 581, loss: 0.052427
epoch 581, 
 train loss: 0.052427, val loss: 0.143811 
 val auc: 0.982245,  test auc: 0.985998
epoch 582, loss: 0.052332
epoch 582, 
 train loss: 0.052332, val loss: 0.144655 
 val auc: 0.982132,  test auc: 0.985961
epoch 583, loss: 0.052257
model updated at epoch 583 
epoch 583, 
 train loss: 0.052257, val loss: 0.143537 
 val auc: 0.982357,  test auc: 0.986064
epoch 584, loss: 0.052251
epoch 584, 
 train loss: 0.052251, val loss: 0.145715 
 val auc: 0.982057,  test auc: 0.985952
epoch 585, loss: 0.052441
model updated at epoch 585 
epoch 585, 
 train loss: 0.052441, val loss: 0.141800 
 val auc: 0.982620,  test auc: 0.986102
epoch 586, loss: 0.052602
epoch 586, 
 train loss: 0.052602, val loss: 0.146989 
 val auc: 0.981944,  test auc: 0.985811
epoch 587, loss: 0.052468
epoch 587, 
 train loss: 0.052468, val loss: 0.141973 
 val auc: 0.982545,  test auc: 0.986130
epoch 588, loss: 0.052024
epoch 588, 
 train loss: 0.052024, val loss: 0.146538 
 val auc: 0.982057,  test auc: 0.985905
epoch 589, loss: 0.051655
epoch 589, 
 train loss: 0.051655, val loss: 0.143979 
 val auc: 0.982282,  test auc: 0.986111
epoch 590, loss: 0.051581
epoch 590, 
 train loss: 0.051581, val loss: 0.144054 
 val auc: 0.982282,  test auc: 0.986139
epoch 591, loss: 0.051693
epoch 591, 
 train loss: 0.051693, val loss: 0.146809 
 val auc: 0.981907,  test auc: 0.985970
epoch 592, loss: 0.051701
epoch 592, 
 train loss: 0.051701, val loss: 0.142640 
 val auc: 0.982508,  test auc: 0.986205
epoch 593, loss: 0.051465
epoch 593, 
 train loss: 0.051465, val loss: 0.146009 
 val auc: 0.982095,  test auc: 0.986017
epoch 594, loss: 0.051171
epoch 594, 
 train loss: 0.051171, val loss: 0.143510 
 val auc: 0.982357,  test auc: 0.986261
epoch 595, loss: 0.051029
epoch 595, 
 train loss: 0.051029, val loss: 0.145027 
 val auc: 0.982207,  test auc: 0.986158
epoch 596, loss: 0.050946
epoch 596, 
 train loss: 0.050946, val loss: 0.145288 
 val auc: 0.982132,  test auc: 0.986177
epoch 597, loss: 0.050928
epoch 597, 
 train loss: 0.050928, val loss: 0.143119 
 val auc: 0.982282,  test auc: 0.986261
epoch 598, loss: 0.051031
epoch 598, 
 train loss: 0.051031, val loss: 0.146589 
 val auc: 0.982095,  test auc: 0.986186
epoch 599, loss: 0.051436
model updated at epoch 599 
epoch 599, 
 train loss: 0.051436, val loss: 0.140711 
 val auc: 0.982770,  test auc: 0.986402
epoch 600, loss: 0.052490
epoch 600, 
 train loss: 0.052490, val loss: 0.150707 
 val auc: 0.981719,  test auc: 0.985961
epoch 601, loss: 0.054553
model updated at epoch 601 
epoch 601, 
 train loss: 0.054553, val loss: 0.139692 
 val auc: 0.982920,  test auc: 0.986402
epoch 602, loss: 0.055930
epoch 602, 
 train loss: 0.055930, val loss: 0.158334 
 val auc: 0.980893,  test auc: 0.985511
epoch 603, loss: 0.055430
epoch 603, 
 train loss: 0.055430, val loss: 0.141044 
 val auc: 0.982808,  test auc: 0.986440
epoch 604, loss: 0.051494
epoch 604, 
 train loss: 0.051494, val loss: 0.149378 
 val auc: 0.981832,  test auc: 0.986055
epoch 605, loss: 0.050531
epoch 605, 
 train loss: 0.050531, val loss: 0.146961 
 val auc: 0.982095,  test auc: 0.986336
epoch 606, loss: 0.052872
epoch 606, 
 train loss: 0.052872, val loss: 0.141275 
 val auc: 0.982845,  test auc: 0.986524
epoch 607, loss: 0.051805
epoch 607, 
 train loss: 0.051805, val loss: 0.150939 
 val auc: 0.981569,  test auc: 0.985933
epoch 608, loss: 0.049936
epoch 608, 
 train loss: 0.049936, val loss: 0.143707 
 val auc: 0.982320,  test auc: 0.986440
epoch 609, loss: 0.050854
epoch 609, 
 train loss: 0.050854, val loss: 0.141904 
 val auc: 0.982583,  test auc: 0.986515
epoch 610, loss: 0.051139
epoch 610, 
 train loss: 0.051139, val loss: 0.150976 
 val auc: 0.981607,  test auc: 0.985980
epoch 611, loss: 0.049850
epoch 611, 
 train loss: 0.049850, val loss: 0.143293 
 val auc: 0.982357,  test auc: 0.986505
epoch 612, loss: 0.049846
epoch 612, 
 train loss: 0.049846, val loss: 0.142831 
 val auc: 0.982545,  test auc: 0.986533
epoch 613, loss: 0.050456
epoch 613, 
 train loss: 0.050456, val loss: 0.149653 
 val auc: 0.981682,  test auc: 0.986083
epoch 614, loss: 0.049725
epoch 614, 
 train loss: 0.049725, val loss: 0.142665 
 val auc: 0.982583,  test auc: 0.986571
epoch 615, loss: 0.049322
epoch 615, 
 train loss: 0.049322, val loss: 0.143187 
 val auc: 0.982357,  test auc: 0.986580
epoch 616, loss: 0.049940
epoch 616, 
 train loss: 0.049940, val loss: 0.148462 
 val auc: 0.981869,  test auc: 0.986233
epoch 617, loss: 0.049555
epoch 617, 
 train loss: 0.049555, val loss: 0.142767 
 val auc: 0.982583,  test auc: 0.986590
epoch 618, loss: 0.049029
epoch 618, 
 train loss: 0.049029, val loss: 0.144851 
 val auc: 0.982282,  test auc: 0.986552
epoch 619, loss: 0.049463
epoch 619, 
 train loss: 0.049463, val loss: 0.148108 
 val auc: 0.981907,  test auc: 0.986318
epoch 620, loss: 0.049351
epoch 620, 
 train loss: 0.049351, val loss: 0.142364 
 val auc: 0.982620,  test auc: 0.986655
epoch 621, loss: 0.048745
epoch 621, 
 train loss: 0.048745, val loss: 0.145064 
 val auc: 0.982207,  test auc: 0.986486
epoch 622, loss: 0.049012
epoch 622, 
 train loss: 0.049012, val loss: 0.148096 
 val auc: 0.981794,  test auc: 0.986308
epoch 623, loss: 0.049031
epoch 623, 
 train loss: 0.049031, val loss: 0.143362 
 val auc: 0.982508,  test auc: 0.986693
epoch 624, loss: 0.048488
epoch 624, 
 train loss: 0.048488, val loss: 0.146116 
 val auc: 0.982095,  test auc: 0.986468
epoch 625, loss: 0.048602
epoch 625, 
 train loss: 0.048602, val loss: 0.147874 
 val auc: 0.981794,  test auc: 0.986336
epoch 626, loss: 0.048724
epoch 626, 
 train loss: 0.048724, val loss: 0.143976 
 val auc: 0.982508,  test auc: 0.986749
epoch 627, loss: 0.048268
epoch 627, 
 train loss: 0.048268, val loss: 0.146673 
 val auc: 0.982132,  test auc: 0.986486
epoch 628, loss: 0.048245
epoch 628, 
 train loss: 0.048245, val loss: 0.146640 
 val auc: 0.982132,  test auc: 0.986458
epoch 629, loss: 0.048368
epoch 629, 
 train loss: 0.048368, val loss: 0.143289 
 val auc: 0.982620,  test auc: 0.986796
epoch 630, loss: 0.048029
epoch 630, 
 train loss: 0.048029, val loss: 0.146582 
 val auc: 0.982170,  test auc: 0.986486
epoch 631, loss: 0.047914
epoch 631, 
 train loss: 0.047914, val loss: 0.146312 
 val auc: 0.982170,  test auc: 0.986562
epoch 632, loss: 0.048026
epoch 632, 
 train loss: 0.048026, val loss: 0.143715 
 val auc: 0.982545,  test auc: 0.986787
epoch 633, loss: 0.047803
epoch 633, 
 train loss: 0.047803, val loss: 0.146920 
 val auc: 0.982095,  test auc: 0.986524
epoch 634, loss: 0.047630
epoch 634, 
 train loss: 0.047630, val loss: 0.146188 
 val auc: 0.982320,  test auc: 0.986665
epoch 635, loss: 0.047692
epoch 635, 
 train loss: 0.047692, val loss: 0.144248 
 val auc: 0.982658,  test auc: 0.986890
epoch 636, loss: 0.047570
epoch 636, 
 train loss: 0.047570, val loss: 0.146784 
 val auc: 0.982132,  test auc: 0.986571
epoch 637, loss: 0.047378
epoch 637, 
 train loss: 0.047378, val loss: 0.145522 
 val auc: 0.982508,  test auc: 0.986759
epoch 638, loss: 0.047376
epoch 638, 
 train loss: 0.047376, val loss: 0.144712 
 val auc: 0.982583,  test auc: 0.986843
epoch 639, loss: 0.047312
epoch 639, 
 train loss: 0.047312, val loss: 0.147069 
 val auc: 0.982095,  test auc: 0.986543
epoch 640, loss: 0.047149
epoch 640, 
 train loss: 0.047149, val loss: 0.145399 
 val auc: 0.982470,  test auc: 0.986768
epoch 641, loss: 0.047088
epoch 641, 
 train loss: 0.047088, val loss: 0.145241 
 val auc: 0.982508,  test auc: 0.986787
epoch 642, loss: 0.047072
epoch 642, 
 train loss: 0.047072, val loss: 0.147320 
 val auc: 0.982207,  test auc: 0.986562
epoch 643, loss: 0.046935
epoch 643, 
 train loss: 0.046935, val loss: 0.145139 
 val auc: 0.982545,  test auc: 0.986806
epoch 644, loss: 0.046825
epoch 644, 
 train loss: 0.046825, val loss: 0.145587 
 val auc: 0.982470,  test auc: 0.986787
epoch 645, loss: 0.046804
epoch 645, 
 train loss: 0.046804, val loss: 0.147194 
 val auc: 0.982170,  test auc: 0.986590
epoch 646, loss: 0.046715
epoch 646, 
 train loss: 0.046715, val loss: 0.145635 
 val auc: 0.982432,  test auc: 0.986871
epoch 647, loss: 0.046585
epoch 647, 
 train loss: 0.046585, val loss: 0.146771 
 val auc: 0.982320,  test auc: 0.986777
epoch 648, loss: 0.046538
epoch 648, 
 train loss: 0.046538, val loss: 0.147408 
 val auc: 0.982207,  test auc: 0.986674
epoch 649, loss: 0.046483
epoch 649, 
 train loss: 0.046483, val loss: 0.145737 
 val auc: 0.982432,  test auc: 0.986852
epoch 650, loss: 0.046363
epoch 650, 
 train loss: 0.046363, val loss: 0.146905 
 val auc: 0.982395,  test auc: 0.986787
epoch 651, loss: 0.046283
epoch 651, 
 train loss: 0.046283, val loss: 0.146706 
 val auc: 0.982395,  test auc: 0.986806
epoch 652, loss: 0.046241
epoch 652, 
 train loss: 0.046241, val loss: 0.145656 
 val auc: 0.982470,  test auc: 0.986918
epoch 653, loss: 0.046158
epoch 653, 
 train loss: 0.046158, val loss: 0.147517 
 val auc: 0.982282,  test auc: 0.986721
epoch 654, loss: 0.046049
epoch 654, 
 train loss: 0.046049, val loss: 0.146894 
 val auc: 0.982395,  test auc: 0.986843
epoch 655, loss: 0.045984
epoch 655, 
 train loss: 0.045984, val loss: 0.146742 
 val auc: 0.982470,  test auc: 0.986871
epoch 656, loss: 0.045927
epoch 656, 
 train loss: 0.045927, val loss: 0.147824 
 val auc: 0.982282,  test auc: 0.986749
epoch 657, loss: 0.045831
epoch 657, 
 train loss: 0.045831, val loss: 0.146628 
 val auc: 0.982376,  test auc: 0.986895
epoch 658, loss: 0.045745
epoch 658, 
 train loss: 0.045745, val loss: 0.146855 
 val auc: 0.982470,  test auc: 0.986928
epoch 659, loss: 0.045686
epoch 659, 
 train loss: 0.045686, val loss: 0.147434 
 val auc: 0.982357,  test auc: 0.986796
epoch 660, loss: 0.045608
epoch 660, 
 train loss: 0.045608, val loss: 0.146472 
 val auc: 0.982432,  test auc: 0.986899
epoch 661, loss: 0.045515
epoch 661, 
 train loss: 0.045515, val loss: 0.147598 
 val auc: 0.982282,  test auc: 0.986834
epoch 662, loss: 0.045445
epoch 662, 
 train loss: 0.045445, val loss: 0.148055 
 val auc: 0.982245,  test auc: 0.986815
epoch 663, loss: 0.045382
epoch 663, 
 train loss: 0.045382, val loss: 0.147016 
 val auc: 0.982357,  test auc: 0.986890
epoch 664, loss: 0.045296
epoch 664, 
 train loss: 0.045296, val loss: 0.147712 
 val auc: 0.982282,  test auc: 0.986806
epoch 665, loss: 0.045211
epoch 665, 
 train loss: 0.045211, val loss: 0.147450 
 val auc: 0.982357,  test auc: 0.986871
epoch 666, loss: 0.045148
epoch 666, 
 train loss: 0.045148, val loss: 0.147111 
 val auc: 0.982395,  test auc: 0.986918
epoch 667, loss: 0.045080
epoch 667, 
 train loss: 0.045080, val loss: 0.148198 
 val auc: 0.982282,  test auc: 0.986815
epoch 668, loss: 0.045003
epoch 668, 
 train loss: 0.045003, val loss: 0.147173 
 val auc: 0.982395,  test auc: 0.986909
epoch 669, loss: 0.044912
epoch 669, 
 train loss: 0.044912, val loss: 0.148143 
 val auc: 0.982320,  test auc: 0.986871
epoch 670, loss: 0.044834
epoch 670, 
 train loss: 0.044834, val loss: 0.148307 
 val auc: 0.982282,  test auc: 0.986852
epoch 671, loss: 0.044772
epoch 671, 
 train loss: 0.044772, val loss: 0.147771 
 val auc: 0.982320,  test auc: 0.986909
epoch 672, loss: 0.044698
epoch 672, 
 train loss: 0.044698, val loss: 0.148690 
 val auc: 0.982320,  test auc: 0.986843
epoch 673, loss: 0.044616
epoch 673, 
 train loss: 0.044616, val loss: 0.147826 
 val auc: 0.982357,  test auc: 0.986871
epoch 674, loss: 0.044534
epoch 674, 
 train loss: 0.044534, val loss: 0.148424 
 val auc: 0.982282,  test auc: 0.986871
epoch 675, loss: 0.044458
epoch 675, 
 train loss: 0.044458, val loss: 0.148573 
 val auc: 0.982245,  test auc: 0.986852
epoch 676, loss: 0.044391
epoch 676, 
 train loss: 0.044391, val loss: 0.148263 
 val auc: 0.982320,  test auc: 0.986909
epoch 677, loss: 0.044316
epoch 677, 
 train loss: 0.044316, val loss: 0.149135 
 val auc: 0.982170,  test auc: 0.986843
epoch 678, loss: 0.044239
epoch 678, 
 train loss: 0.044239, val loss: 0.148536 
 val auc: 0.982320,  test auc: 0.986881
epoch 679, loss: 0.044162
epoch 679, 
 train loss: 0.044162, val loss: 0.148897 
 val auc: 0.982245,  test auc: 0.986852
epoch 680, loss: 0.044086
epoch 680, 
 train loss: 0.044086, val loss: 0.148884 
 val auc: 0.982282,  test auc: 0.986862
epoch 681, loss: 0.044016
epoch 681, 
 train loss: 0.044016, val loss: 0.148777 
 val auc: 0.982320,  test auc: 0.986890
epoch 682, loss: 0.043942
epoch 682, 
 train loss: 0.043942, val loss: 0.149379 
 val auc: 0.982207,  test auc: 0.986871
epoch 683, loss: 0.043866
epoch 683, 
 train loss: 0.043866, val loss: 0.148843 
 val auc: 0.982282,  test auc: 0.986909
epoch 684, loss: 0.043792
epoch 684, 
 train loss: 0.043792, val loss: 0.149296 
 val auc: 0.982207,  test auc: 0.986862
epoch 685, loss: 0.043717
epoch 685, 
 train loss: 0.043717, val loss: 0.149350 
 val auc: 0.982245,  test auc: 0.986871
epoch 686, loss: 0.043644
epoch 686, 
 train loss: 0.043644, val loss: 0.149571 
 val auc: 0.982207,  test auc: 0.986881
epoch 687, loss: 0.043572
epoch 687, 
 train loss: 0.043572, val loss: 0.149619 
 val auc: 0.982207,  test auc: 0.986899
epoch 688, loss: 0.043500
epoch 688, 
 train loss: 0.043500, val loss: 0.149264 
 val auc: 0.982320,  test auc: 0.986928
epoch 689, loss: 0.043428
epoch 689, 
 train loss: 0.043428, val loss: 0.149859 
 val auc: 0.982207,  test auc: 0.986890
epoch 690, loss: 0.043356
epoch 690, 
 train loss: 0.043356, val loss: 0.149641 
 val auc: 0.982320,  test auc: 0.986937
epoch 691, loss: 0.043280
epoch 691, 
 train loss: 0.043280, val loss: 0.149979 
 val auc: 0.982207,  test auc: 0.986899
epoch 692, loss: 0.043210
epoch 692, 
 train loss: 0.043210, val loss: 0.150165 
 val auc: 0.982207,  test auc: 0.986899
epoch 693, loss: 0.043137
epoch 693, 
 train loss: 0.043137, val loss: 0.150148 
 val auc: 0.982282,  test auc: 0.986928
epoch 694, loss: 0.043067
epoch 694, 
 train loss: 0.043067, val loss: 0.150532 
 val auc: 0.982170,  test auc: 0.986881
epoch 695, loss: 0.042996
epoch 695, 
 train loss: 0.042996, val loss: 0.150292 
 val auc: 0.982245,  test auc: 0.986937
epoch 696, loss: 0.042924
epoch 696, 
 train loss: 0.042924, val loss: 0.150567 
 val auc: 0.982245,  test auc: 0.986928
epoch 697, loss: 0.042852
epoch 697, 
 train loss: 0.042852, val loss: 0.150451 
 val auc: 0.982320,  test auc: 0.986946
epoch 698, loss: 0.042780
epoch 698, 
 train loss: 0.042780, val loss: 0.150665 
 val auc: 0.982245,  test auc: 0.986937
epoch 699, loss: 0.042710
epoch 699, 
 train loss: 0.042710, val loss: 0.150894 
 val auc: 0.982245,  test auc: 0.986928
epoch 700, loss: 0.042640
epoch 700, 
 train loss: 0.042640, val loss: 0.150905 
 val auc: 0.982245,  test auc: 0.986918
epoch 701, loss: 0.042571
epoch 701, 
 train loss: 0.042571, val loss: 0.151005 
 val auc: 0.982207,  test auc: 0.986899
epoch 702, loss: 0.042500
epoch 702, 
 train loss: 0.042500, val loss: 0.151020 
 val auc: 0.982282,  test auc: 0.986937
epoch 703, loss: 0.042431
epoch 703, 
 train loss: 0.042431, val loss: 0.151213 
 val auc: 0.982282,  test auc: 0.986946
epoch 704, loss: 0.042361
epoch 704, 
 train loss: 0.042361, val loss: 0.151276 
 val auc: 0.982282,  test auc: 0.986956
epoch 705, loss: 0.042292
epoch 705, 
 train loss: 0.042292, val loss: 0.151496 
 val auc: 0.982245,  test auc: 0.986918
epoch 706, loss: 0.042222
epoch 706, 
 train loss: 0.042222, val loss: 0.151602 
 val auc: 0.982282,  test auc: 0.986928
epoch 707, loss: 0.042151
epoch 707, 
 train loss: 0.042151, val loss: 0.151594 
 val auc: 0.982282,  test auc: 0.986937
epoch 708, loss: 0.042081
epoch 708, 
 train loss: 0.042081, val loss: 0.151700 
 val auc: 0.982245,  test auc: 0.986937
epoch 709, loss: 0.042011
epoch 709, 
 train loss: 0.042011, val loss: 0.151684 
 val auc: 0.982320,  test auc: 0.986965
epoch 710, loss: 0.041942
epoch 710, 
 train loss: 0.041942, val loss: 0.152263 
 val auc: 0.982207,  test auc: 0.986918
epoch 711, loss: 0.041877
epoch 711, 
 train loss: 0.041877, val loss: 0.151828 
 val auc: 0.982320,  test auc: 0.986956
epoch 712, loss: 0.041807
epoch 712, 
 train loss: 0.041807, val loss: 0.152391 
 val auc: 0.982207,  test auc: 0.986909
epoch 713, loss: 0.041737
epoch 713, 
 train loss: 0.041737, val loss: 0.152119 
 val auc: 0.982282,  test auc: 0.986937
epoch 714, loss: 0.041668
epoch 714, 
 train loss: 0.041668, val loss: 0.152576 
 val auc: 0.982207,  test auc: 0.986946
epoch 715, loss: 0.041598
epoch 715, 
 train loss: 0.041598, val loss: 0.152331 
 val auc: 0.982245,  test auc: 0.986946
epoch 716, loss: 0.041531
epoch 716, 
 train loss: 0.041531, val loss: 0.152406 
 val auc: 0.982282,  test auc: 0.986965
epoch 717, loss: 0.041464
epoch 717, 
 train loss: 0.041464, val loss: 0.152698 
 val auc: 0.982282,  test auc: 0.986965
epoch 718, loss: 0.041396
epoch 718, 
 train loss: 0.041396, val loss: 0.152405 
 val auc: 0.982245,  test auc: 0.986956
epoch 719, loss: 0.041330
epoch 719, 
 train loss: 0.041330, val loss: 0.152797 
 val auc: 0.982207,  test auc: 0.986928
epoch 720, loss: 0.041263
epoch 720, 
 train loss: 0.041263, val loss: 0.152715 
 val auc: 0.982245,  test auc: 0.986937
epoch 721, loss: 0.041196
epoch 721, 
 train loss: 0.041196, val loss: 0.153138 
 val auc: 0.982207,  test auc: 0.986909
epoch 722, loss: 0.041129
epoch 722, 
 train loss: 0.041129, val loss: 0.153123 
 val auc: 0.982207,  test auc: 0.986918
epoch 723, loss: 0.041061
epoch 723, 
 train loss: 0.041061, val loss: 0.152926 
 val auc: 0.982207,  test auc: 0.986918
epoch 724, loss: 0.040996
epoch 724, 
 train loss: 0.040996, val loss: 0.153214 
 val auc: 0.982207,  test auc: 0.986946
epoch 725, loss: 0.040937
epoch 725, 
 train loss: 0.040937, val loss: 0.152770 
 val auc: 0.982207,  test auc: 0.986937
epoch 726, loss: 0.040869
epoch 726, 
 train loss: 0.040869, val loss: 0.153577 
 val auc: 0.982095,  test auc: 0.986918
epoch 727, loss: 0.040800
epoch 727, 
 train loss: 0.040800, val loss: 0.153197 
 val auc: 0.982095,  test auc: 0.986899
epoch 728, loss: 0.040736
epoch 728, 
 train loss: 0.040736, val loss: 0.153742 
 val auc: 0.982020,  test auc: 0.986918
epoch 729, loss: 0.040672
epoch 729, 
 train loss: 0.040672, val loss: 0.153457 
 val auc: 0.982095,  test auc: 0.986909
epoch 730, loss: 0.040605
epoch 730, 
 train loss: 0.040605, val loss: 0.153839 
 val auc: 0.982020,  test auc: 0.986899
epoch 731, loss: 0.040542
epoch 731, 
 train loss: 0.040542, val loss: 0.153785 
 val auc: 0.982057,  test auc: 0.986871
epoch 732, loss: 0.040478
epoch 732, 
 train loss: 0.040478, val loss: 0.153857 
 val auc: 0.982057,  test auc: 0.986890
epoch 733, loss: 0.040415
epoch 733, 
 train loss: 0.040415, val loss: 0.154012 
 val auc: 0.982095,  test auc: 0.986899
epoch 734, loss: 0.040350
epoch 734, 
 train loss: 0.040350, val loss: 0.153917 
 val auc: 0.982095,  test auc: 0.986890
epoch 735, loss: 0.040285
epoch 735, 
 train loss: 0.040285, val loss: 0.154101 
 val auc: 0.982057,  test auc: 0.986890
epoch 736, loss: 0.040222
epoch 736, 
 train loss: 0.040222, val loss: 0.153776 
 val auc: 0.982095,  test auc: 0.986881
epoch 737, loss: 0.040158
epoch 737, 
 train loss: 0.040158, val loss: 0.154327 
 val auc: 0.982020,  test auc: 0.986852
epoch 738, loss: 0.040094
epoch 738, 
 train loss: 0.040094, val loss: 0.154356 
 val auc: 0.982057,  test auc: 0.986890
epoch 739, loss: 0.040028
epoch 739, 
 train loss: 0.040028, val loss: 0.154493 
 val auc: 0.982020,  test auc: 0.986881
epoch 740, loss: 0.039967
epoch 740, 
 train loss: 0.039967, val loss: 0.154497 
 val auc: 0.981982,  test auc: 0.986852
epoch 741, loss: 0.039905
epoch 741, 
 train loss: 0.039905, val loss: 0.154668 
 val auc: 0.982020,  test auc: 0.986871
epoch 742, loss: 0.039847
epoch 742, 
 train loss: 0.039847, val loss: 0.154914 
 val auc: 0.981982,  test auc: 0.986881
epoch 743, loss: 0.039785
epoch 743, 
 train loss: 0.039785, val loss: 0.154651 
 val auc: 0.981982,  test auc: 0.986881
epoch 744, loss: 0.039722
epoch 744, 
 train loss: 0.039722, val loss: 0.155259 
 val auc: 0.981907,  test auc: 0.986871
epoch 745, loss: 0.039663
epoch 745, 
 train loss: 0.039663, val loss: 0.154936 
 val auc: 0.981944,  test auc: 0.986862
epoch 746, loss: 0.039599
epoch 746, 
 train loss: 0.039599, val loss: 0.155372 
 val auc: 0.981869,  test auc: 0.986881
epoch 747, loss: 0.039541
epoch 747, 
 train loss: 0.039541, val loss: 0.154883 
 val auc: 0.981907,  test auc: 0.986881
epoch 748, loss: 0.039478
epoch 748, 
 train loss: 0.039478, val loss: 0.155599 
 val auc: 0.981869,  test auc: 0.986918
epoch 749, loss: 0.039421
epoch 749, 
 train loss: 0.039421, val loss: 0.155188 
 val auc: 0.981907,  test auc: 0.986871
epoch 750, loss: 0.039362
epoch 750, 
 train loss: 0.039362, val loss: 0.155660 
 val auc: 0.981869,  test auc: 0.986881
epoch 751, loss: 0.039300
epoch 751, 
 train loss: 0.039300, val loss: 0.155079 
 val auc: 0.981869,  test auc: 0.986871
epoch 752, loss: 0.039243
epoch 752, 
 train loss: 0.039243, val loss: 0.156111 
 val auc: 0.981832,  test auc: 0.986918
epoch 753, loss: 0.039185
epoch 753, 
 train loss: 0.039185, val loss: 0.155288 
 val auc: 0.981907,  test auc: 0.986881
epoch 754, loss: 0.039138
epoch 754, 
 train loss: 0.039138, val loss: 0.156659 
 val auc: 0.981757,  test auc: 0.986890
epoch 755, loss: 0.039098
epoch 755, 
 train loss: 0.039098, val loss: 0.155447 
 val auc: 0.981869,  test auc: 0.986862
epoch 756, loss: 0.039041
epoch 756, 
 train loss: 0.039041, val loss: 0.157277 
 val auc: 0.981757,  test auc: 0.986871
epoch 757, loss: 0.038983
epoch 757, 
 train loss: 0.038983, val loss: 0.155005 
 val auc: 0.981907,  test auc: 0.986871
epoch 758, loss: 0.038920
epoch 758, 
 train loss: 0.038920, val loss: 0.156873 
 val auc: 0.981719,  test auc: 0.986918
epoch 759, loss: 0.038845
epoch 759, 
 train loss: 0.038845, val loss: 0.155747 
 val auc: 0.981907,  test auc: 0.986937
epoch 760, loss: 0.038778
epoch 760, 
 train loss: 0.038778, val loss: 0.157332 
 val auc: 0.981757,  test auc: 0.986918
epoch 761, loss: 0.038713
epoch 761, 
 train loss: 0.038713, val loss: 0.156705 
 val auc: 0.981832,  test auc: 0.986909
epoch 762, loss: 0.038651
epoch 762, 
 train loss: 0.038651, val loss: 0.157280 
 val auc: 0.981794,  test auc: 0.986899
epoch 763, loss: 0.038590
epoch 763, 
 train loss: 0.038590, val loss: 0.157221 
 val auc: 0.981794,  test auc: 0.986918
epoch 764, loss: 0.038531
epoch 764, 
 train loss: 0.038531, val loss: 0.156474 
 val auc: 0.981832,  test auc: 0.986928
epoch 765, loss: 0.038483
epoch 765, 
 train loss: 0.038483, val loss: 0.156978 
 val auc: 0.981757,  test auc: 0.986918
epoch 766, loss: 0.038427
epoch 766, 
 train loss: 0.038427, val loss: 0.156359 
 val auc: 0.981869,  test auc: 0.986918
epoch 767, loss: 0.038370
epoch 767, 
 train loss: 0.038370, val loss: 0.157938 
 val auc: 0.981644,  test auc: 0.986862
epoch 768, loss: 0.038317
epoch 768, 
 train loss: 0.038317, val loss: 0.156559 
 val auc: 0.981869,  test auc: 0.986899
epoch 769, loss: 0.038257
epoch 769, 
 train loss: 0.038257, val loss: 0.157969 
 val auc: 0.981644,  test auc: 0.986909
epoch 770, loss: 0.038204
epoch 770, 
 train loss: 0.038204, val loss: 0.156577 
 val auc: 0.981907,  test auc: 0.986965
epoch 771, loss: 0.038150
epoch 771, 
 train loss: 0.038150, val loss: 0.158083 
 val auc: 0.981607,  test auc: 0.986862
epoch 772, loss: 0.038092
epoch 772, 
 train loss: 0.038092, val loss: 0.156291 
 val auc: 0.981907,  test auc: 0.986974
epoch 773, loss: 0.038034
epoch 773, 
 train loss: 0.038034, val loss: 0.158411 
 val auc: 0.981569,  test auc: 0.986899
epoch 774, loss: 0.037978
epoch 774, 
 train loss: 0.037978, val loss: 0.157205 
 val auc: 0.981757,  test auc: 0.986928
epoch 775, loss: 0.037915
epoch 775, 
 train loss: 0.037915, val loss: 0.158864 
 val auc: 0.981532,  test auc: 0.986852
epoch 776, loss: 0.037858
epoch 776, 
 train loss: 0.037858, val loss: 0.157362 
 val auc: 0.981719,  test auc: 0.986918
epoch 777, loss: 0.037795
epoch 777, 
 train loss: 0.037795, val loss: 0.159033 
 val auc: 0.981607,  test auc: 0.986881
epoch 778, loss: 0.037738
epoch 778, 
 train loss: 0.037738, val loss: 0.157672 
 val auc: 0.981794,  test auc: 0.986937
epoch 779, loss: 0.037680
epoch 779, 
 train loss: 0.037680, val loss: 0.158868 
 val auc: 0.981607,  test auc: 0.986890
epoch 780, loss: 0.037621
epoch 780, 
 train loss: 0.037621, val loss: 0.158047 
 val auc: 0.981757,  test auc: 0.986881
epoch 781, loss: 0.037566
epoch 781, 
 train loss: 0.037566, val loss: 0.159568 
 val auc: 0.981532,  test auc: 0.986843
epoch 782, loss: 0.037505
epoch 782, 
 train loss: 0.037505, val loss: 0.158672 
 val auc: 0.981719,  test auc: 0.986871
epoch 783, loss: 0.037449
epoch 783, 
 train loss: 0.037449, val loss: 0.159539 
 val auc: 0.981494,  test auc: 0.986852
epoch 784, loss: 0.037392
epoch 784, 
 train loss: 0.037392, val loss: 0.158836 
 val auc: 0.981757,  test auc: 0.986899
epoch 785, loss: 0.037339
epoch 785, 
 train loss: 0.037339, val loss: 0.159906 
 val auc: 0.981569,  test auc: 0.986843
epoch 786, loss: 0.037289
epoch 786, 
 train loss: 0.037289, val loss: 0.158642 
 val auc: 0.981757,  test auc: 0.986881
epoch 787, loss: 0.037242
epoch 787, 
 train loss: 0.037242, val loss: 0.160004 
 val auc: 0.981494,  test auc: 0.986862
epoch 788, loss: 0.037203
epoch 788, 
 train loss: 0.037203, val loss: 0.158806 
 val auc: 0.981682,  test auc: 0.986881
epoch 789, loss: 0.037173
epoch 789, 
 train loss: 0.037173, val loss: 0.161197 
 val auc: 0.981419,  test auc: 0.986852
epoch 790, loss: 0.037176
epoch 790, 
 train loss: 0.037176, val loss: 0.158322 
 val auc: 0.981644,  test auc: 0.986928
epoch 791, loss: 0.037208
epoch 791, 
 train loss: 0.037208, val loss: 0.162399 
 val auc: 0.981306,  test auc: 0.986806
epoch 792, loss: 0.037328
epoch 792, 
 train loss: 0.037328, val loss: 0.157080 
 val auc: 0.981907,  test auc: 0.987021
epoch 793, loss: 0.037509
epoch 793, 
 train loss: 0.037509, val loss: 0.164398 
 val auc: 0.981194,  test auc: 0.986665
epoch 794, loss: 0.037983
epoch 794, 
 train loss: 0.037983, val loss: 0.155466 
 val auc: 0.982020,  test auc: 0.986965
epoch 795, loss: 0.038463
epoch 795, 
 train loss: 0.038463, val loss: 0.168254 
 val auc: 0.980893,  test auc: 0.986533
epoch 796, loss: 0.039708
epoch 796, 
 train loss: 0.039708, val loss: 0.153910 
 val auc: 0.982095,  test auc: 0.987031
epoch 797, loss: 0.040481
epoch 797, 
 train loss: 0.040481, val loss: 0.173130 
 val auc: 0.980518,  test auc: 0.986308
epoch 798, loss: 0.042143
epoch 798, 
 train loss: 0.042143, val loss: 0.152425 
 val auc: 0.982170,  test auc: 0.986993
epoch 799, loss: 0.041265
epoch 799, 
 train loss: 0.041265, val loss: 0.174182 
 val auc: 0.980293,  test auc: 0.986196
epoch 800, loss: 0.039274
epoch 800, 
 train loss: 0.039274, val loss: 0.152965 
 val auc: 0.982282,  test auc: 0.987096
epoch 801, loss: 0.036654
epoch 801, 
 train loss: 0.036654, val loss: 0.159664 
 val auc: 0.981794,  test auc: 0.986909
epoch 802, loss: 0.038415
epoch 802, 
 train loss: 0.038415, val loss: 0.168683 
 val auc: 0.981006,  test auc: 0.986590
epoch 803, loss: 0.040586
epoch 803, 
 train loss: 0.040586, val loss: 0.154643 
 val auc: 0.982095,  test auc: 0.987059
epoch 804, loss: 0.038073
epoch 804, 
 train loss: 0.038073, val loss: 0.168437 
 val auc: 0.980931,  test auc: 0.986346
epoch 805, loss: 0.036918
epoch 805, 
 train loss: 0.036918, val loss: 0.164922 
 val auc: 0.981344,  test auc: 0.986637
epoch 806, loss: 0.038805
epoch 806, 
 train loss: 0.038805, val loss: 0.157328 
 val auc: 0.981869,  test auc: 0.986899
epoch 807, loss: 0.038349
epoch 807, 
 train loss: 0.038349, val loss: 0.168215 
 val auc: 0.981081,  test auc: 0.986449
epoch 808, loss: 0.037252
epoch 808, 
 train loss: 0.037252, val loss: 0.158704 
 val auc: 0.981794,  test auc: 0.986824
epoch 809, loss: 0.037106
epoch 809, 
 train loss: 0.037106, val loss: 0.159469 
 val auc: 0.981607,  test auc: 0.986740
epoch 810, loss: 0.037619
epoch 810, 
 train loss: 0.037619, val loss: 0.168541 
 val auc: 0.980631,  test auc: 0.986383
epoch 811, loss: 0.037042
epoch 811, 
 train loss: 0.037042, val loss: 0.159345 
 val auc: 0.981494,  test auc: 0.986824
epoch 812, loss: 0.036708
epoch 812, 
 train loss: 0.036708, val loss: 0.160277 
 val auc: 0.981682,  test auc: 0.986852
epoch 813, loss: 0.037125
epoch 813, 
 train loss: 0.037125, val loss: 0.167122 
 val auc: 0.980781,  test auc: 0.986383
epoch 814, loss: 0.036904
epoch 814, 
 train loss: 0.036904, val loss: 0.161945 
 val auc: 0.981231,  test auc: 0.986702
epoch 815, loss: 0.036352
epoch 815, 
 train loss: 0.036352, val loss: 0.164803 
 val auc: 0.981156,  test auc: 0.986590
epoch 816, loss: 0.036762
epoch 816, 
 train loss: 0.036762, val loss: 0.167636 
 val auc: 0.980818,  test auc: 0.986571
epoch 817, loss: 0.036732
epoch 817, 
 train loss: 0.036732, val loss: 0.160106 
 val auc: 0.981719,  test auc: 0.986956
epoch 818, loss: 0.036118
epoch 818, 
 train loss: 0.036118, val loss: 0.163743 
 val auc: 0.981532,  test auc: 0.986862
epoch 819, loss: 0.036484
epoch 819, 
 train loss: 0.036484, val loss: 0.167262 
 val auc: 0.981269,  test auc: 0.986712
epoch 820, loss: 0.036486
epoch 820, 
 train loss: 0.036486, val loss: 0.157977 
 val auc: 0.981869,  test auc: 0.987050
epoch 821, loss: 0.035933
epoch 821, 
 train loss: 0.035933, val loss: 0.161131 
 val auc: 0.981607,  test auc: 0.986928
epoch 822, loss: 0.036172
epoch 822, 
 train loss: 0.036172, val loss: 0.165844 
 val auc: 0.981306,  test auc: 0.986843
epoch 823, loss: 0.036215
epoch 823, 
 train loss: 0.036215, val loss: 0.159594 
 val auc: 0.981682,  test auc: 0.986965
epoch 824, loss: 0.035695
epoch 824, 
 train loss: 0.035695, val loss: 0.162389 
 val auc: 0.981532,  test auc: 0.986796
epoch 825, loss: 0.035900
epoch 825, 
 train loss: 0.035900, val loss: 0.164093 
 val auc: 0.981381,  test auc: 0.986740
epoch 826, loss: 0.035947
epoch 826, 
 train loss: 0.035947, val loss: 0.159140 
 val auc: 0.981757,  test auc: 0.987021
epoch 827, loss: 0.035555
epoch 827, 
 train loss: 0.035555, val loss: 0.163227 
 val auc: 0.981569,  test auc: 0.986871
epoch 828, loss: 0.035659
epoch 828, 
 train loss: 0.035659, val loss: 0.164442 
 val auc: 0.981419,  test auc: 0.986834
epoch 829, loss: 0.035709
epoch 829, 
 train loss: 0.035709, val loss: 0.159266 
 val auc: 0.981944,  test auc: 0.987078
epoch 830, loss: 0.035364
epoch 830, 
 train loss: 0.035364, val loss: 0.163404 
 val auc: 0.981569,  test auc: 0.986843
epoch 831, loss: 0.035449
epoch 831, 
 train loss: 0.035449, val loss: 0.165680 
 val auc: 0.981494,  test auc: 0.986815
epoch 832, loss: 0.035495
epoch 832, 
 train loss: 0.035495, val loss: 0.160183 
 val auc: 0.981607,  test auc: 0.986974
epoch 833, loss: 0.035214
epoch 833, 
 train loss: 0.035214, val loss: 0.163062 
 val auc: 0.981682,  test auc: 0.986909
epoch 834, loss: 0.035224
epoch 834, 
 train loss: 0.035224, val loss: 0.164275 
 val auc: 0.981532,  test auc: 0.986881
epoch 835, loss: 0.035303
epoch 835, 
 train loss: 0.035303, val loss: 0.160720 
 val auc: 0.981982,  test auc: 0.987003
epoch 836, loss: 0.035058
epoch 836, 
 train loss: 0.035058, val loss: 0.164461 
 val auc: 0.981794,  test auc: 0.986881
epoch 837, loss: 0.035019
epoch 837, 
 train loss: 0.035019, val loss: 0.164449 
 val auc: 0.981682,  test auc: 0.986909
epoch 838, loss: 0.035089
epoch 838, 
 train loss: 0.035089, val loss: 0.161016 
 val auc: 0.981832,  test auc: 0.987021
epoch 839, loss: 0.034902
epoch 839, 
 train loss: 0.034902, val loss: 0.164740 
 val auc: 0.981569,  test auc: 0.986974
epoch 840, loss: 0.034827
epoch 840, 
 train loss: 0.034827, val loss: 0.164787 
 val auc: 0.981607,  test auc: 0.986909
epoch 841, loss: 0.034874
epoch 841, 
 train loss: 0.034874, val loss: 0.161736 
 val auc: 0.981832,  test auc: 0.986946
epoch 842, loss: 0.034753
epoch 842, 
 train loss: 0.034753, val loss: 0.164615 
 val auc: 0.981644,  test auc: 0.986937
epoch 843, loss: 0.034658
epoch 843, 
 train loss: 0.034658, val loss: 0.164443 
 val auc: 0.981644,  test auc: 0.986909
epoch 844, loss: 0.034684
epoch 844, 
 train loss: 0.034684, val loss: 0.162761 
 val auc: 0.981532,  test auc: 0.986928
epoch 845, loss: 0.034596
epoch 845, 
 train loss: 0.034596, val loss: 0.165193 
 val auc: 0.981494,  test auc: 0.986890
epoch 846, loss: 0.034502
epoch 846, 
 train loss: 0.034502, val loss: 0.163703 
 val auc: 0.981644,  test auc: 0.986956
epoch 847, loss: 0.034488
epoch 847, 
 train loss: 0.034488, val loss: 0.162969 
 val auc: 0.981644,  test auc: 0.986918
epoch 848, loss: 0.034443
epoch 848, 
 train loss: 0.034443, val loss: 0.165776 
 val auc: 0.981569,  test auc: 0.986890
epoch 849, loss: 0.034350
epoch 849, 
 train loss: 0.034350, val loss: 0.164134 
 val auc: 0.981682,  test auc: 0.986965
epoch 850, loss: 0.034317
epoch 850, 
 train loss: 0.034317, val loss: 0.163486 
 val auc: 0.981682,  test auc: 0.986956
epoch 851, loss: 0.034283
epoch 851, 
 train loss: 0.034283, val loss: 0.165580 
 val auc: 0.981532,  test auc: 0.986862
epoch 852, loss: 0.034208
epoch 852, 
 train loss: 0.034208, val loss: 0.164364 
 val auc: 0.981682,  test auc: 0.986928
epoch 853, loss: 0.034154
epoch 853, 
 train loss: 0.034154, val loss: 0.164430 
 val auc: 0.981644,  test auc: 0.986909
epoch 854, loss: 0.034123
epoch 854, 
 train loss: 0.034123, val loss: 0.165492 
 val auc: 0.981644,  test auc: 0.986965
epoch 855, loss: 0.034068
epoch 855, 
 train loss: 0.034068, val loss: 0.164129 
 val auc: 0.981869,  test auc: 0.986993
epoch 856, loss: 0.034001
epoch 856, 
 train loss: 0.034001, val loss: 0.165273 
 val auc: 0.981682,  test auc: 0.986918
epoch 857, loss: 0.033964
epoch 857, 
 train loss: 0.033964, val loss: 0.166214 
 val auc: 0.981569,  test auc: 0.986871
epoch 858, loss: 0.033917
epoch 858, 
 train loss: 0.033917, val loss: 0.164760 
 val auc: 0.981757,  test auc: 0.986937
epoch 859, loss: 0.033855
epoch 859, 
 train loss: 0.033855, val loss: 0.165467 
 val auc: 0.981644,  test auc: 0.986937
epoch 860, loss: 0.033806
epoch 860, 
 train loss: 0.033806, val loss: 0.165564 
 val auc: 0.981644,  test auc: 0.986918
epoch 861, loss: 0.033765
epoch 861, 
 train loss: 0.033765, val loss: 0.164989 
 val auc: 0.981757,  test auc: 0.986909
epoch 862, loss: 0.033709
epoch 862, 
 train loss: 0.033709, val loss: 0.166120 
 val auc: 0.981644,  test auc: 0.986909
epoch 863, loss: 0.033654
epoch 863, 
 train loss: 0.033654, val loss: 0.165755 
 val auc: 0.981644,  test auc: 0.986918
epoch 864, loss: 0.033609
epoch 864, 
 train loss: 0.033609, val loss: 0.165756 
 val auc: 0.981757,  test auc: 0.986899
epoch 865, loss: 0.033563
epoch 865, 
 train loss: 0.033563, val loss: 0.166946 
 val auc: 0.981532,  test auc: 0.986834
epoch 866, loss: 0.033504
epoch 866, 
 train loss: 0.033504, val loss: 0.166172 
 val auc: 0.981719,  test auc: 0.986881
epoch 867, loss: 0.033455
epoch 867, 
 train loss: 0.033455, val loss: 0.165776 
 val auc: 0.981832,  test auc: 0.986909
epoch 868, loss: 0.033408
epoch 868, 
 train loss: 0.033408, val loss: 0.166296 
 val auc: 0.981719,  test auc: 0.986881
epoch 869, loss: 0.033354
epoch 869, 
 train loss: 0.033354, val loss: 0.165860 
 val auc: 0.981794,  test auc: 0.986899
epoch 870, loss: 0.033302
epoch 870, 
 train loss: 0.033302, val loss: 0.166356 
 val auc: 0.981719,  test auc: 0.986881
epoch 871, loss: 0.033250
epoch 871, 
 train loss: 0.033250, val loss: 0.166662 
 val auc: 0.981757,  test auc: 0.986881
epoch 872, loss: 0.033202
epoch 872, 
 train loss: 0.033202, val loss: 0.166198 
 val auc: 0.981719,  test auc: 0.986871
epoch 873, loss: 0.033149
epoch 873, 
 train loss: 0.033149, val loss: 0.166864 
 val auc: 0.981682,  test auc: 0.986852
epoch 874, loss: 0.033098
epoch 874, 
 train loss: 0.033098, val loss: 0.166974 
 val auc: 0.981682,  test auc: 0.986852
epoch 875, loss: 0.033046
epoch 875, 
 train loss: 0.033046, val loss: 0.166545 
 val auc: 0.981682,  test auc: 0.986871
epoch 876, loss: 0.032996
epoch 876, 
 train loss: 0.032996, val loss: 0.166989 
 val auc: 0.981719,  test auc: 0.986881
epoch 877, loss: 0.032945
epoch 877, 
 train loss: 0.032945, val loss: 0.166838 
 val auc: 0.981682,  test auc: 0.986871
epoch 878, loss: 0.032895
epoch 878, 
 train loss: 0.032895, val loss: 0.166627 
 val auc: 0.981719,  test auc: 0.986871
epoch 879, loss: 0.032849
epoch 879, 
 train loss: 0.032849, val loss: 0.166972 
 val auc: 0.981757,  test auc: 0.986899
epoch 880, loss: 0.032797
epoch 880, 
 train loss: 0.032797, val loss: 0.166673 
 val auc: 0.981719,  test auc: 0.986881
epoch 881, loss: 0.032749
epoch 881, 
 train loss: 0.032749, val loss: 0.166906 
 val auc: 0.981757,  test auc: 0.986890
epoch 882, loss: 0.032699
epoch 882, 
 train loss: 0.032699, val loss: 0.167319 
 val auc: 0.981794,  test auc: 0.986909
epoch 883, loss: 0.032650
epoch 883, 
 train loss: 0.032650, val loss: 0.166895 
 val auc: 0.981832,  test auc: 0.986946
epoch 884, loss: 0.032600
epoch 884, 
 train loss: 0.032600, val loss: 0.167024 
 val auc: 0.981794,  test auc: 0.986918
epoch 885, loss: 0.032552
epoch 885, 
 train loss: 0.032552, val loss: 0.167109 
 val auc: 0.981832,  test auc: 0.986946
epoch 886, loss: 0.032506
epoch 886, 
 train loss: 0.032506, val loss: 0.167057 
 val auc: 0.981832,  test auc: 0.986946
epoch 887, loss: 0.032457
epoch 887, 
 train loss: 0.032457, val loss: 0.167511 
 val auc: 0.981832,  test auc: 0.986928
epoch 888, loss: 0.032409
epoch 888, 
 train loss: 0.032409, val loss: 0.167164 
 val auc: 0.981794,  test auc: 0.986909
epoch 889, loss: 0.032359
epoch 889, 
 train loss: 0.032359, val loss: 0.167386 
 val auc: 0.981794,  test auc: 0.986918
epoch 890, loss: 0.032313
epoch 890, 
 train loss: 0.032313, val loss: 0.167750 
 val auc: 0.981794,  test auc: 0.986890
epoch 891, loss: 0.032267
epoch 891, 
 train loss: 0.032267, val loss: 0.167539 
 val auc: 0.981794,  test auc: 0.986890
epoch 892, loss: 0.032219
epoch 892, 
 train loss: 0.032219, val loss: 0.167553 
 val auc: 0.981794,  test auc: 0.986909
epoch 893, loss: 0.032173
epoch 893, 
 train loss: 0.032173, val loss: 0.167498 
 val auc: 0.981757,  test auc: 0.986918
epoch 894, loss: 0.032129
epoch 894, 
 train loss: 0.032129, val loss: 0.167472 
 val auc: 0.981719,  test auc: 0.986918
epoch 895, loss: 0.032082
epoch 895, 
 train loss: 0.032082, val loss: 0.167874 
 val auc: 0.981719,  test auc: 0.986899
epoch 896, loss: 0.032038
epoch 896, 
 train loss: 0.032038, val loss: 0.167910 
 val auc: 0.981794,  test auc: 0.986899
epoch 897, loss: 0.031991
epoch 897, 
 train loss: 0.031991, val loss: 0.168023 
 val auc: 0.981794,  test auc: 0.986918
epoch 898, loss: 0.031947
epoch 898, 
 train loss: 0.031947, val loss: 0.168301 
 val auc: 0.981719,  test auc: 0.986890
epoch 899, loss: 0.031901
epoch 899, 
 train loss: 0.031901, val loss: 0.168283 
 val auc: 0.981757,  test auc: 0.986899
epoch 900, loss: 0.031857
epoch 900, 
 train loss: 0.031857, val loss: 0.168281 
 val auc: 0.981794,  test auc: 0.986862
epoch 901, loss: 0.031812
epoch 901, 
 train loss: 0.031812, val loss: 0.168245 
 val auc: 0.981869,  test auc: 0.986899
epoch 902, loss: 0.031769
epoch 902, 
 train loss: 0.031769, val loss: 0.168140 
 val auc: 0.981869,  test auc: 0.986881
epoch 903, loss: 0.031724
epoch 903, 
 train loss: 0.031724, val loss: 0.168238 
 val auc: 0.981832,  test auc: 0.986899
epoch 904, loss: 0.031679
epoch 904, 
 train loss: 0.031679, val loss: 0.168097 
 val auc: 0.981869,  test auc: 0.986928
epoch 905, loss: 0.031635
epoch 905, 
 train loss: 0.031635, val loss: 0.168013 
 val auc: 0.981869,  test auc: 0.986928
epoch 906, loss: 0.031591
epoch 906, 
 train loss: 0.031591, val loss: 0.168336 
 val auc: 0.981832,  test auc: 0.986909
epoch 907, loss: 0.031547
epoch 907, 
 train loss: 0.031547, val loss: 0.168393 
 val auc: 0.981794,  test auc: 0.986890
epoch 908, loss: 0.031504
epoch 908, 
 train loss: 0.031504, val loss: 0.168611 
 val auc: 0.981832,  test auc: 0.986899
epoch 909, loss: 0.031460
epoch 909, 
 train loss: 0.031460, val loss: 0.168667 
 val auc: 0.981869,  test auc: 0.986899
epoch 910, loss: 0.031415
epoch 910, 
 train loss: 0.031415, val loss: 0.168836 
 val auc: 0.981794,  test auc: 0.986871
epoch 911, loss: 0.031372
epoch 911, 
 train loss: 0.031372, val loss: 0.168872 
 val auc: 0.981832,  test auc: 0.986890
epoch 912, loss: 0.031330
epoch 912, 
 train loss: 0.031330, val loss: 0.168701 
 val auc: 0.981907,  test auc: 0.986918
epoch 913, loss: 0.031290
epoch 913, 
 train loss: 0.031290, val loss: 0.168726 
 val auc: 0.981907,  test auc: 0.986928
epoch 914, loss: 0.031244
epoch 914, 
 train loss: 0.031244, val loss: 0.168951 
 val auc: 0.981832,  test auc: 0.986918
epoch 915, loss: 0.031202
epoch 915, 
 train loss: 0.031202, val loss: 0.169188 
 val auc: 0.981832,  test auc: 0.986890
epoch 916, loss: 0.031160
epoch 916, 
 train loss: 0.031160, val loss: 0.169386 
 val auc: 0.981794,  test auc: 0.986899
epoch 917, loss: 0.031119
epoch 917, 
 train loss: 0.031119, val loss: 0.169189 
 val auc: 0.981794,  test auc: 0.986881
epoch 918, loss: 0.031076
epoch 918, 
 train loss: 0.031076, val loss: 0.169324 
 val auc: 0.981794,  test auc: 0.986899
epoch 919, loss: 0.031035
epoch 919, 
 train loss: 0.031035, val loss: 0.169244 
 val auc: 0.981794,  test auc: 0.986909
epoch 920, loss: 0.030994
epoch 920, 
 train loss: 0.030994, val loss: 0.169140 
 val auc: 0.981869,  test auc: 0.986928
epoch 921, loss: 0.030954
epoch 921, 
 train loss: 0.030954, val loss: 0.169202 
 val auc: 0.981794,  test auc: 0.986909
epoch 922, loss: 0.030913
epoch 922, 
 train loss: 0.030913, val loss: 0.169127 
 val auc: 0.981832,  test auc: 0.986909
epoch 923, loss: 0.030872
epoch 923, 
 train loss: 0.030872, val loss: 0.169471 
 val auc: 0.981869,  test auc: 0.986909
epoch 924, loss: 0.030833
epoch 924, 
 train loss: 0.030833, val loss: 0.169832 
 val auc: 0.981757,  test auc: 0.986899
epoch 925, loss: 0.030793
epoch 925, 
 train loss: 0.030793, val loss: 0.169594 
 val auc: 0.981757,  test auc: 0.986881
epoch 926, loss: 0.030754
epoch 926, 
 train loss: 0.030754, val loss: 0.169773 
 val auc: 0.981757,  test auc: 0.986899
epoch 927, loss: 0.030714
epoch 927, 
 train loss: 0.030714, val loss: 0.169938 
 val auc: 0.981794,  test auc: 0.986899
epoch 928, loss: 0.030675
epoch 928, 
 train loss: 0.030675, val loss: 0.169894 
 val auc: 0.981832,  test auc: 0.986946
epoch 929, loss: 0.030637
epoch 929, 
 train loss: 0.030637, val loss: 0.170180 
 val auc: 0.981832,  test auc: 0.986928
epoch 930, loss: 0.030598
epoch 930, 
 train loss: 0.030598, val loss: 0.169891 
 val auc: 0.981832,  test auc: 0.986918
epoch 931, loss: 0.030558
epoch 931, 
 train loss: 0.030558, val loss: 0.170079 
 val auc: 0.981832,  test auc: 0.986928
epoch 932, loss: 0.030520
epoch 932, 
 train loss: 0.030520, val loss: 0.170266 
 val auc: 0.981832,  test auc: 0.986928
epoch 933, loss: 0.030481
epoch 933, 
 train loss: 0.030481, val loss: 0.170023 
 val auc: 0.981794,  test auc: 0.986937
epoch 934, loss: 0.030443
epoch 934, 
 train loss: 0.030443, val loss: 0.170282 
 val auc: 0.981794,  test auc: 0.986928
epoch 935, loss: 0.030407
epoch 935, 
 train loss: 0.030407, val loss: 0.170185 
 val auc: 0.981794,  test auc: 0.986928
epoch 936, loss: 0.030367
epoch 936, 
 train loss: 0.030367, val loss: 0.170351 
 val auc: 0.981794,  test auc: 0.986937
epoch 937, loss: 0.030332
epoch 937, 
 train loss: 0.030332, val loss: 0.170434 
 val auc: 0.981757,  test auc: 0.986928
epoch 938, loss: 0.030295
epoch 938, 
 train loss: 0.030295, val loss: 0.170314 
 val auc: 0.981757,  test auc: 0.986946
epoch 939, loss: 0.030258
epoch 939, 
 train loss: 0.030258, val loss: 0.170719 
 val auc: 0.981719,  test auc: 0.986909
epoch 940, loss: 0.030220
epoch 940, 
 train loss: 0.030220, val loss: 0.170709 
 val auc: 0.981738,  test auc: 0.986923
epoch 941, loss: 0.030185
epoch 941, 
 train loss: 0.030185, val loss: 0.170674 
 val auc: 0.981757,  test auc: 0.986928
epoch 942, loss: 0.030148
epoch 942, 
 train loss: 0.030148, val loss: 0.170947 
 val auc: 0.981719,  test auc: 0.986928
epoch 943, loss: 0.030109
epoch 943, 
 train loss: 0.030109, val loss: 0.170842 
 val auc: 0.981719,  test auc: 0.986909
epoch 944, loss: 0.030072
epoch 944, 
 train loss: 0.030072, val loss: 0.170934 
 val auc: 0.981719,  test auc: 0.986909
epoch 945, loss: 0.030036
epoch 945, 
 train loss: 0.030036, val loss: 0.171040 
 val auc: 0.981794,  test auc: 0.986928
epoch 946, loss: 0.030001
epoch 946, 
 train loss: 0.030001, val loss: 0.170949 
 val auc: 0.981794,  test auc: 0.986937
epoch 947, loss: 0.029963
epoch 947, 
 train loss: 0.029963, val loss: 0.171055 
 val auc: 0.981794,  test auc: 0.986956
epoch 948, loss: 0.029927
epoch 948, 
 train loss: 0.029927, val loss: 0.171142 
 val auc: 0.981757,  test auc: 0.986937
epoch 949, loss: 0.029892
epoch 949, 
 train loss: 0.029892, val loss: 0.171189 
 val auc: 0.981757,  test auc: 0.986937
epoch 950, loss: 0.029856
epoch 950, 
 train loss: 0.029856, val loss: 0.171211 
 val auc: 0.981794,  test auc: 0.986956
epoch 951, loss: 0.029823
epoch 951, 
 train loss: 0.029823, val loss: 0.171372 
 val auc: 0.981794,  test auc: 0.986937
epoch 952, loss: 0.029787
epoch 952, 
 train loss: 0.029787, val loss: 0.171256 
 val auc: 0.981757,  test auc: 0.986946
epoch 953, loss: 0.029754
epoch 953, 
 train loss: 0.029754, val loss: 0.171349 
 val auc: 0.981757,  test auc: 0.986956
epoch 954, loss: 0.029719
epoch 954, 
 train loss: 0.029719, val loss: 0.171574 
 val auc: 0.981757,  test auc: 0.986946
epoch 955, loss: 0.029683
epoch 955, 
 train loss: 0.029683, val loss: 0.171739 
 val auc: 0.981719,  test auc: 0.986918
epoch 956, loss: 0.029651
epoch 956, 
 train loss: 0.029651, val loss: 0.171940 
 val auc: 0.981682,  test auc: 0.986918
epoch 957, loss: 0.029613
epoch 957, 
 train loss: 0.029613, val loss: 0.171788 
 val auc: 0.981682,  test auc: 0.986946
epoch 958, loss: 0.029582
epoch 958, 
 train loss: 0.029582, val loss: 0.171933 
 val auc: 0.981644,  test auc: 0.986899
epoch 959, loss: 0.029547
epoch 959, 
 train loss: 0.029547, val loss: 0.171966 
 val auc: 0.981607,  test auc: 0.986909
epoch 960, loss: 0.029515
epoch 960, 
 train loss: 0.029515, val loss: 0.171788 
 val auc: 0.981607,  test auc: 0.986909
epoch 961, loss: 0.029479
epoch 961, 
 train loss: 0.029479, val loss: 0.172049 
 val auc: 0.981644,  test auc: 0.986909
epoch 962, loss: 0.029446
epoch 962, 
 train loss: 0.029446, val loss: 0.172030 
 val auc: 0.981682,  test auc: 0.986899
epoch 963, loss: 0.029412
epoch 963, 
 train loss: 0.029412, val loss: 0.172423 
 val auc: 0.981644,  test auc: 0.986890
epoch 964, loss: 0.029376
epoch 964, 
 train loss: 0.029376, val loss: 0.172676 
 val auc: 0.981494,  test auc: 0.986862
epoch 965, loss: 0.029348
epoch 965, 
 train loss: 0.029348, val loss: 0.172405 
 val auc: 0.981532,  test auc: 0.986862
epoch 966, loss: 0.029311
epoch 966, 
 train loss: 0.029311, val loss: 0.172523 
 val auc: 0.981494,  test auc: 0.986852
epoch 967, loss: 0.029278
epoch 967, 
 train loss: 0.029278, val loss: 0.172584 
 val auc: 0.981569,  test auc: 0.986881
epoch 968, loss: 0.029245
epoch 968, 
 train loss: 0.029245, val loss: 0.172570 
 val auc: 0.981569,  test auc: 0.986862
epoch 969, loss: 0.029212
epoch 969, 
 train loss: 0.029212, val loss: 0.172806 
 val auc: 0.981456,  test auc: 0.986834
epoch 970, loss: 0.029179
epoch 970, 
 train loss: 0.029179, val loss: 0.172790 
 val auc: 0.981456,  test auc: 0.986834
epoch 971, loss: 0.029145
epoch 971, 
 train loss: 0.029145, val loss: 0.173360 
 val auc: 0.981456,  test auc: 0.986824
epoch 972, loss: 0.029112
epoch 972, 
 train loss: 0.029112, val loss: 0.173247 
 val auc: 0.981494,  test auc: 0.986843
epoch 973, loss: 0.029079
epoch 973, 
 train loss: 0.029079, val loss: 0.173104 
 val auc: 0.981494,  test auc: 0.986852
epoch 974, loss: 0.029048
epoch 974, 
 train loss: 0.029048, val loss: 0.173439 
 val auc: 0.981456,  test auc: 0.986824
epoch 975, loss: 0.029015
epoch 975, 
 train loss: 0.029015, val loss: 0.173393 
 val auc: 0.981419,  test auc: 0.986834
epoch 976, loss: 0.028982
epoch 976, 
 train loss: 0.028982, val loss: 0.173714 
 val auc: 0.981381,  test auc: 0.986834
epoch 977, loss: 0.028951
epoch 977, 
 train loss: 0.028951, val loss: 0.173659 
 val auc: 0.981344,  test auc: 0.986815
epoch 978, loss: 0.028919
epoch 978, 
 train loss: 0.028919, val loss: 0.173618 
 val auc: 0.981381,  test auc: 0.986815
epoch 979, loss: 0.028887
epoch 979, 
 train loss: 0.028887, val loss: 0.173946 
 val auc: 0.981344,  test auc: 0.986843
epoch 980, loss: 0.028857
epoch 980, 
 train loss: 0.028857, val loss: 0.173833 
 val auc: 0.981419,  test auc: 0.986843
epoch 981, loss: 0.028823
epoch 981, 
 train loss: 0.028823, val loss: 0.174075 
 val auc: 0.981344,  test auc: 0.986824
epoch 982, loss: 0.028791
epoch 982, 
 train loss: 0.028791, val loss: 0.174088 
 val auc: 0.981306,  test auc: 0.986796
epoch 983, loss: 0.028759
epoch 983, 
 train loss: 0.028759, val loss: 0.174341 
 val auc: 0.981306,  test auc: 0.986777
epoch 984, loss: 0.028728
epoch 984, 
 train loss: 0.028728, val loss: 0.174607 
 val auc: 0.981344,  test auc: 0.986777
epoch 985, loss: 0.028699
epoch 985, 
 train loss: 0.028699, val loss: 0.174385 
 val auc: 0.981306,  test auc: 0.986787
epoch 986, loss: 0.028663
epoch 986, 
 train loss: 0.028663, val loss: 0.174749 
 val auc: 0.981269,  test auc: 0.986768
epoch 987, loss: 0.028633
epoch 987, 
 train loss: 0.028633, val loss: 0.174798 
 val auc: 0.981269,  test auc: 0.986768
epoch 988, loss: 0.028602
epoch 988, 
 train loss: 0.028602, val loss: 0.174964 
 val auc: 0.981231,  test auc: 0.986768
epoch 989, loss: 0.028572
epoch 989, 
 train loss: 0.028572, val loss: 0.175204 
 val auc: 0.981231,  test auc: 0.986777
epoch 990, loss: 0.028538
epoch 990, 
 train loss: 0.028538, val loss: 0.175163 
 val auc: 0.981269,  test auc: 0.986777
epoch 991, loss: 0.028507
epoch 991, 
 train loss: 0.028507, val loss: 0.175333 
 val auc: 0.981269,  test auc: 0.986759
epoch 992, loss: 0.028476
epoch 992, 
 train loss: 0.028476, val loss: 0.175292 
 val auc: 0.981269,  test auc: 0.986759
epoch 993, loss: 0.028442
epoch 993, 
 train loss: 0.028442, val loss: 0.175550 
 val auc: 0.981269,  test auc: 0.986759
epoch 994, loss: 0.028413
epoch 994, 
 train loss: 0.028413, val loss: 0.175806 
 val auc: 0.981269,  test auc: 0.986740
epoch 995, loss: 0.028380
epoch 995, 
 train loss: 0.028380, val loss: 0.175742 
 val auc: 0.981306,  test auc: 0.986749
epoch 996, loss: 0.028350
epoch 996, 
 train loss: 0.028350, val loss: 0.175975 
 val auc: 0.981231,  test auc: 0.986730
epoch 997, loss: 0.028320
epoch 997, 
 train loss: 0.028320, val loss: 0.176132 
 val auc: 0.981231,  test auc: 0.986740
epoch 998, loss: 0.028290
epoch 998, 
 train loss: 0.028290, val loss: 0.176316 
 val auc: 0.981156,  test auc: 0.986721
epoch 999, loss: 0.028259
epoch 999, 
 train loss: 0.028259, val loss: 0.176520 
 val auc: 0.981119,  test auc: 0.986712
AUC: 0.986402
