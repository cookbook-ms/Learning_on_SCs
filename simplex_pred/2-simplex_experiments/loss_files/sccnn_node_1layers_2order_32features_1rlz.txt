epoch 0, loss: 0.704090
model updated at epoch 0 
epoch 0, 
 train loss: 0.704090, val loss: 0.706141 
 val auc: 0.493243,  test auc: 0.514330
epoch 1, loss: 0.697862
model updated at epoch 1 
epoch 1, 
 train loss: 0.697862, val loss: 0.699085 
 val auc: 0.503003,  test auc: 0.520777
epoch 2, loss: 0.692880
model updated at epoch 2 
epoch 2, 
 train loss: 0.692880, val loss: 0.693441 
 val auc: 0.513288,  test auc: 0.528641
epoch 3, loss: 0.688996
model updated at epoch 3 
epoch 3, 
 train loss: 0.688996, val loss: 0.688994 
 val auc: 0.529429,  test auc: 0.538523
epoch 4, loss: 0.686033
model updated at epoch 4 
epoch 4, 
 train loss: 0.686033, val loss: 0.685573 
 val auc: 0.546809,  test auc: 0.549080
epoch 5, loss: 0.683763
model updated at epoch 5 
epoch 5, 
 train loss: 0.683763, val loss: 0.682830 
 val auc: 0.559535,  test auc: 0.554842
epoch 6, loss: 0.681985
model updated at epoch 6 
epoch 6, 
 train loss: 0.681985, val loss: 0.680539 
 val auc: 0.572335,  test auc: 0.562064
epoch 7, loss: 0.680507
model updated at epoch 7 
epoch 7, 
 train loss: 0.680507, val loss: 0.678590 
 val auc: 0.583934,  test auc: 0.570223
epoch 8, loss: 0.679185
model updated at epoch 8 
epoch 8, 
 train loss: 0.679185, val loss: 0.676897 
 val auc: 0.593281,  test auc: 0.579364
epoch 9, loss: 0.677894
model updated at epoch 9 
epoch 9, 
 train loss: 0.677894, val loss: 0.675356 
 val auc: 0.603191,  test auc: 0.587556
epoch 10, loss: 0.676558
model updated at epoch 10 
epoch 10, 
 train loss: 0.676558, val loss: 0.673898 
 val auc: 0.608446,  test auc: 0.593825
epoch 11, loss: 0.675161
model updated at epoch 11 
epoch 11, 
 train loss: 0.675161, val loss: 0.672503 
 val auc: 0.616216,  test auc: 0.601708
epoch 12, loss: 0.673674
model updated at epoch 12 
epoch 12, 
 train loss: 0.673674, val loss: 0.671168 
 val auc: 0.624775,  test auc: 0.611271
epoch 13, loss: 0.672141
model updated at epoch 13 
epoch 13, 
 train loss: 0.672141, val loss: 0.669928 
 val auc: 0.627290,  test auc: 0.617924
epoch 14, loss: 0.670623
model updated at epoch 14 
epoch 14, 
 train loss: 0.670623, val loss: 0.668813 
 val auc: 0.628378,  test auc: 0.623255
epoch 15, loss: 0.669130
model updated at epoch 15 
epoch 15, 
 train loss: 0.669130, val loss: 0.667814 
 val auc: 0.630180,  test auc: 0.628594
epoch 16, loss: 0.667631
model updated at epoch 16 
epoch 16, 
 train loss: 0.667631, val loss: 0.666858 
 val auc: 0.633671,  test auc: 0.634497
epoch 17, loss: 0.666134
model updated at epoch 17 
epoch 17, 
 train loss: 0.666134, val loss: 0.665953 
 val auc: 0.637613,  test auc: 0.640831
epoch 18, loss: 0.664600
model updated at epoch 18 
epoch 18, 
 train loss: 0.664600, val loss: 0.665063 
 val auc: 0.641216,  test auc: 0.647128
epoch 19, loss: 0.663042
model updated at epoch 19 
epoch 19, 
 train loss: 0.663042, val loss: 0.664193 
 val auc: 0.644932,  test auc: 0.654157
epoch 20, loss: 0.661445
model updated at epoch 20 
epoch 20, 
 train loss: 0.661445, val loss: 0.663305 
 val auc: 0.648949,  test auc: 0.660745
epoch 21, loss: 0.659804
model updated at epoch 21 
epoch 21, 
 train loss: 0.659804, val loss: 0.662405 
 val auc: 0.652477,  test auc: 0.667746
epoch 22, loss: 0.658091
model updated at epoch 22 
epoch 22, 
 train loss: 0.658091, val loss: 0.661452 
 val auc: 0.656644,  test auc: 0.674306
epoch 23, loss: 0.656318
model updated at epoch 23 
epoch 23, 
 train loss: 0.656318, val loss: 0.660453 
 val auc: 0.660098,  test auc: 0.679655
epoch 24, loss: 0.654506
model updated at epoch 24 
epoch 24, 
 train loss: 0.654506, val loss: 0.659372 
 val auc: 0.663326,  test auc: 0.683324
epoch 25, loss: 0.652648
model updated at epoch 25 
epoch 25, 
 train loss: 0.652648, val loss: 0.658195 
 val auc: 0.665165,  test auc: 0.686815
epoch 26, loss: 0.650749
model updated at epoch 26 
epoch 26, 
 train loss: 0.650749, val loss: 0.656890 
 val auc: 0.666366,  test auc: 0.688739
epoch 27, loss: 0.648817
model updated at epoch 27 
epoch 27, 
 train loss: 0.648817, val loss: 0.655459 
 val auc: 0.668769,  test auc: 0.691723
epoch 28, loss: 0.646861
model updated at epoch 28 
epoch 28, 
 train loss: 0.646861, val loss: 0.653905 
 val auc: 0.672410,  test auc: 0.695693
epoch 29, loss: 0.644906
model updated at epoch 29 
epoch 29, 
 train loss: 0.644906, val loss: 0.652304 
 val auc: 0.677140,  test auc: 0.698864
epoch 30, loss: 0.642948
model updated at epoch 30 
epoch 30, 
 train loss: 0.642948, val loss: 0.650714 
 val auc: 0.680518,  test auc: 0.702008
epoch 31, loss: 0.640994
model updated at epoch 31 
epoch 31, 
 train loss: 0.640994, val loss: 0.649197 
 val auc: 0.682808,  test auc: 0.704739
epoch 32, loss: 0.639033
model updated at epoch 32 
epoch 32, 
 train loss: 0.639033, val loss: 0.647824 
 val auc: 0.685923,  test auc: 0.707920
epoch 33, loss: 0.637034
model updated at epoch 33 
epoch 33, 
 train loss: 0.637034, val loss: 0.646595 
 val auc: 0.687012,  test auc: 0.710060
epoch 34, loss: 0.635012
model updated at epoch 34 
epoch 34, 
 train loss: 0.635012, val loss: 0.645483 
 val auc: 0.687763,  test auc: 0.712031
epoch 35, loss: 0.633001
model updated at epoch 35 
epoch 35, 
 train loss: 0.633001, val loss: 0.644437 
 val auc: 0.688176,  test auc: 0.713654
epoch 36, loss: 0.631025
model updated at epoch 36 
epoch 36, 
 train loss: 0.631025, val loss: 0.643402 
 val auc: 0.687763,  test auc: 0.715597
epoch 37, loss: 0.629062
model updated at epoch 37 
epoch 37, 
 train loss: 0.629062, val loss: 0.642294 
 val auc: 0.688551,  test auc: 0.717258
epoch 38, loss: 0.627074
model updated at epoch 38 
epoch 38, 
 train loss: 0.627074, val loss: 0.641009 
 val auc: 0.688926,  test auc: 0.718853
epoch 39, loss: 0.625033
model updated at epoch 39 
epoch 39, 
 train loss: 0.625033, val loss: 0.639535 
 val auc: 0.690278,  test auc: 0.721181
epoch 40, loss: 0.622949
model updated at epoch 40 
epoch 40, 
 train loss: 0.622949, val loss: 0.637942 
 val auc: 0.694107,  test auc: 0.723752
epoch 41, loss: 0.620810
model updated at epoch 41 
epoch 41, 
 train loss: 0.620810, val loss: 0.636358 
 val auc: 0.696659,  test auc: 0.726633
epoch 42, loss: 0.618608
model updated at epoch 42 
epoch 42, 
 train loss: 0.618608, val loss: 0.634822 
 val auc: 0.700263,  test auc: 0.729589
epoch 43, loss: 0.616337
model updated at epoch 43 
epoch 43, 
 train loss: 0.616337, val loss: 0.633238 
 val auc: 0.702778,  test auc: 0.732911
epoch 44, loss: 0.614018
model updated at epoch 44 
epoch 44, 
 train loss: 0.614018, val loss: 0.631611 
 val auc: 0.704692,  test auc: 0.735811
epoch 45, loss: 0.611608
model updated at epoch 45 
epoch 45, 
 train loss: 0.611608, val loss: 0.629946 
 val auc: 0.706719,  test auc: 0.738823
epoch 46, loss: 0.609099
model updated at epoch 46 
epoch 46, 
 train loss: 0.609099, val loss: 0.628121 
 val auc: 0.709234,  test auc: 0.742108
epoch 47, loss: 0.606451
model updated at epoch 47 
epoch 47, 
 train loss: 0.606451, val loss: 0.626094 
 val auc: 0.713326,  test auc: 0.746199
epoch 48, loss: 0.603688
model updated at epoch 48 
epoch 48, 
 train loss: 0.603688, val loss: 0.623933 
 val auc: 0.717192,  test auc: 0.750413
epoch 49, loss: 0.600820
model updated at epoch 49 
epoch 49, 
 train loss: 0.600820, val loss: 0.621567 
 val auc: 0.722710,  test auc: 0.755546
epoch 50, loss: 0.597881
model updated at epoch 50 
epoch 50, 
 train loss: 0.597881, val loss: 0.619085 
 val auc: 0.727477,  test auc: 0.760454
epoch 51, loss: 0.594870
model updated at epoch 51 
epoch 51, 
 train loss: 0.594870, val loss: 0.616660 
 val auc: 0.732282,  test auc: 0.765447
epoch 52, loss: 0.591780
model updated at epoch 52 
epoch 52, 
 train loss: 0.591780, val loss: 0.614172 
 val auc: 0.737312,  test auc: 0.770280
epoch 53, loss: 0.588639
model updated at epoch 53 
epoch 53, 
 train loss: 0.588639, val loss: 0.611619 
 val auc: 0.742643,  test auc: 0.775629
epoch 54, loss: 0.585401
model updated at epoch 54 
epoch 54, 
 train loss: 0.585401, val loss: 0.608887 
 val auc: 0.747710,  test auc: 0.780434
epoch 55, loss: 0.582010
model updated at epoch 55 
epoch 55, 
 train loss: 0.582010, val loss: 0.605883 
 val auc: 0.753453,  test auc: 0.785980
epoch 56, loss: 0.578308
model updated at epoch 56 
epoch 56, 
 train loss: 0.578308, val loss: 0.602491 
 val auc: 0.758709,  test auc: 0.791301
epoch 57, loss: 0.574319
model updated at epoch 57 
epoch 57, 
 train loss: 0.574319, val loss: 0.598770 
 val auc: 0.764377,  test auc: 0.796453
epoch 58, loss: 0.570241
model updated at epoch 58 
epoch 58, 
 train loss: 0.570241, val loss: 0.594905 
 val auc: 0.769482,  test auc: 0.800572
epoch 59, loss: 0.565982
model updated at epoch 59 
epoch 59, 
 train loss: 0.565982, val loss: 0.591192 
 val auc: 0.773836,  test auc: 0.804870
epoch 60, loss: 0.561511
model updated at epoch 60 
epoch 60, 
 train loss: 0.561511, val loss: 0.587382 
 val auc: 0.778416,  test auc: 0.809375
epoch 61, loss: 0.556768
model updated at epoch 61 
epoch 61, 
 train loss: 0.556768, val loss: 0.583182 
 val auc: 0.784347,  test auc: 0.815287
epoch 62, loss: 0.551750
model updated at epoch 62 
epoch 62, 
 train loss: 0.551750, val loss: 0.578519 
 val auc: 0.792718,  test auc: 0.822307
epoch 63, loss: 0.546501
model updated at epoch 63 
epoch 63, 
 train loss: 0.546501, val loss: 0.573660 
 val auc: 0.800113,  test auc: 0.828547
epoch 64, loss: 0.540970
model updated at epoch 64 
epoch 64, 
 train loss: 0.540970, val loss: 0.568605 
 val auc: 0.806944,  test auc: 0.835069
epoch 65, loss: 0.535384
model updated at epoch 65 
epoch 65, 
 train loss: 0.535384, val loss: 0.563359 
 val auc: 0.813288,  test auc: 0.840860
epoch 66, loss: 0.529545
model updated at epoch 66 
epoch 66, 
 train loss: 0.529545, val loss: 0.557668 
 val auc: 0.820758,  test auc: 0.846387
epoch 67, loss: 0.523559
model updated at epoch 67 
epoch 67, 
 train loss: 0.523559, val loss: 0.551996 
 val auc: 0.826539,  test auc: 0.851511
epoch 68, loss: 0.517340
model updated at epoch 68 
epoch 68, 
 train loss: 0.517340, val loss: 0.546460 
 val auc: 0.832320,  test auc: 0.856729
epoch 69, loss: 0.510894
model updated at epoch 69 
epoch 69, 
 train loss: 0.510894, val loss: 0.540793 
 val auc: 0.837613,  test auc: 0.861637
epoch 70, loss: 0.504270
model updated at epoch 70 
epoch 70, 
 train loss: 0.504270, val loss: 0.534512 
 val auc: 0.842849,  test auc: 0.867009
epoch 71, loss: 0.497392
model updated at epoch 71 
epoch 71, 
 train loss: 0.497392, val loss: 0.527880 
 val auc: 0.848574,  test auc: 0.872091
epoch 72, loss: 0.490160
model updated at epoch 72 
epoch 72, 
 train loss: 0.490160, val loss: 0.521378 
 val auc: 0.852402,  test auc: 0.876070
epoch 73, loss: 0.482881
model updated at epoch 73 
epoch 73, 
 train loss: 0.482881, val loss: 0.514898 
 val auc: 0.856607,  test auc: 0.879720
epoch 74, loss: 0.475536
model updated at epoch 74 
epoch 74, 
 train loss: 0.475536, val loss: 0.507940 
 val auc: 0.860360,  test auc: 0.883418
epoch 75, loss: 0.467985
model updated at epoch 75 
epoch 75, 
 train loss: 0.467985, val loss: 0.500955 
 val auc: 0.864189,  test auc: 0.887294
epoch 76, loss: 0.460271
model updated at epoch 76 
epoch 76, 
 train loss: 0.460271, val loss: 0.494540 
 val auc: 0.867943,  test auc: 0.890700
epoch 77, loss: 0.452488
model updated at epoch 77 
epoch 77, 
 train loss: 0.452488, val loss: 0.487986 
 val auc: 0.870871,  test auc: 0.893816
epoch 78, loss: 0.444567
model updated at epoch 78 
epoch 78, 
 train loss: 0.444567, val loss: 0.480887 
 val auc: 0.874812,  test auc: 0.897401
epoch 79, loss: 0.436653
model updated at epoch 79 
epoch 79, 
 train loss: 0.436653, val loss: 0.474354 
 val auc: 0.877477,  test auc: 0.900760
epoch 80, loss: 0.428699
model updated at epoch 80 
epoch 80, 
 train loss: 0.428699, val loss: 0.467791 
 val auc: 0.881644,  test auc: 0.904636
epoch 81, loss: 0.420643
model updated at epoch 81 
epoch 81, 
 train loss: 0.420643, val loss: 0.460269 
 val auc: 0.886899,  test auc: 0.908784
epoch 82, loss: 0.412519
model updated at epoch 82 
epoch 82, 
 train loss: 0.412519, val loss: 0.453939 
 val auc: 0.888476,  test auc: 0.911571
epoch 83, loss: 0.404385
model updated at epoch 83 
epoch 83, 
 train loss: 0.404385, val loss: 0.446321 
 val auc: 0.894182,  test auc: 0.915644
epoch 84, loss: 0.396219
model updated at epoch 84 
epoch 84, 
 train loss: 0.396219, val loss: 0.439275 
 val auc: 0.898386,  test auc: 0.919172
epoch 85, loss: 0.388091
model updated at epoch 85 
epoch 85, 
 train loss: 0.388091, val loss: 0.433065 
 val auc: 0.901314,  test auc: 0.921922
epoch 86, loss: 0.380235
model updated at epoch 86 
epoch 86, 
 train loss: 0.380235, val loss: 0.425900 
 val auc: 0.906456,  test auc: 0.925150
epoch 87, loss: 0.372579
model updated at epoch 87 
epoch 87, 
 train loss: 0.372579, val loss: 0.420367 
 val auc: 0.909234,  test auc: 0.927534
epoch 88, loss: 0.365048
model updated at epoch 88 
epoch 88, 
 train loss: 0.365048, val loss: 0.413315 
 val auc: 0.914077,  test auc: 0.930593
epoch 89, loss: 0.357685
model updated at epoch 89 
epoch 89, 
 train loss: 0.357685, val loss: 0.407458 
 val auc: 0.916517,  test auc: 0.933024
epoch 90, loss: 0.350499
model updated at epoch 90 
epoch 90, 
 train loss: 0.350499, val loss: 0.401768 
 val auc: 0.918731,  test auc: 0.935285
epoch 91, loss: 0.343587
model updated at epoch 91 
epoch 91, 
 train loss: 0.343587, val loss: 0.395237 
 val auc: 0.921697,  test auc: 0.937181
epoch 92, loss: 0.336880
model updated at epoch 92 
epoch 92, 
 train loss: 0.336880, val loss: 0.389756 
 val auc: 0.923423,  test auc: 0.938992
epoch 93, loss: 0.330372
model updated at epoch 93 
epoch 93, 
 train loss: 0.330372, val loss: 0.383369 
 val auc: 0.926727,  test auc: 0.940747
epoch 94, loss: 0.324131
model updated at epoch 94 
epoch 94, 
 train loss: 0.324131, val loss: 0.377982 
 val auc: 0.929017,  test auc: 0.942474
epoch 95, loss: 0.318174
model updated at epoch 95 
epoch 95, 
 train loss: 0.318174, val loss: 0.372527 
 val auc: 0.931644,  test auc: 0.943722
epoch 96, loss: 0.312486
model updated at epoch 96 
epoch 96, 
 train loss: 0.312486, val loss: 0.367553 
 val auc: 0.933333,  test auc: 0.944595
epoch 97, loss: 0.307082
model updated at epoch 97 
epoch 97, 
 train loss: 0.307082, val loss: 0.363443 
 val auc: 0.934497,  test auc: 0.945261
epoch 98, loss: 0.301857
model updated at epoch 98 
epoch 98, 
 train loss: 0.301857, val loss: 0.359049 
 val auc: 0.935811,  test auc: 0.945983
epoch 99, loss: 0.296869
model updated at epoch 99 
epoch 99, 
 train loss: 0.296869, val loss: 0.355839 
 val auc: 0.936637,  test auc: 0.946603
epoch 100, loss: 0.292081
model updated at epoch 100 
epoch 100, 
 train loss: 0.292081, val loss: 0.351525 
 val auc: 0.938101,  test auc: 0.947288
epoch 101, loss: 0.287584
model updated at epoch 101 
epoch 101, 
 train loss: 0.287584, val loss: 0.348915 
 val auc: 0.939189,  test auc: 0.947926
epoch 102, loss: 0.283112
model updated at epoch 102 
epoch 102, 
 train loss: 0.283112, val loss: 0.344337 
 val auc: 0.940390,  test auc: 0.948677
epoch 103, loss: 0.278712
model updated at epoch 103 
epoch 103, 
 train loss: 0.278712, val loss: 0.341329 
 val auc: 0.941929,  test auc: 0.949596
epoch 104, loss: 0.274330
model updated at epoch 104 
epoch 104, 
 train loss: 0.274330, val loss: 0.336528 
 val auc: 0.943206,  test auc: 0.950366
epoch 105, loss: 0.270305
model updated at epoch 105 
epoch 105, 
 train loss: 0.270305, val loss: 0.332778 
 val auc: 0.945120,  test auc: 0.951089
epoch 106, loss: 0.266690
model updated at epoch 106 
epoch 106, 
 train loss: 0.266690, val loss: 0.329599 
 val auc: 0.946284,  test auc: 0.951502
epoch 107, loss: 0.263193
model updated at epoch 107 
epoch 107, 
 train loss: 0.263193, val loss: 0.325667 
 val auc: 0.946922,  test auc: 0.952158
epoch 108, loss: 0.259852
model updated at epoch 108 
epoch 108, 
 train loss: 0.259852, val loss: 0.323489 
 val auc: 0.947598,  test auc: 0.952543
epoch 109, loss: 0.256264
model updated at epoch 109 
epoch 109, 
 train loss: 0.256264, val loss: 0.319438 
 val auc: 0.948273,  test auc: 0.953125
epoch 110, loss: 0.252740
model updated at epoch 110 
epoch 110, 
 train loss: 0.252740, val loss: 0.316876 
 val auc: 0.949587,  test auc: 0.953791
epoch 111, loss: 0.249505
model updated at epoch 111 
epoch 111, 
 train loss: 0.249505, val loss: 0.313922 
 val auc: 0.950450,  test auc: 0.954251
epoch 112, loss: 0.246506
model updated at epoch 112 
epoch 112, 
 train loss: 0.246506, val loss: 0.311338 
 val auc: 0.950413,  test auc: 0.954373
epoch 113, loss: 0.243668
model updated at epoch 113 
epoch 113, 
 train loss: 0.243668, val loss: 0.308875 
 val auc: 0.950976,  test auc: 0.954748
epoch 114, loss: 0.240985
model updated at epoch 114 
epoch 114, 
 train loss: 0.240985, val loss: 0.306101 
 val auc: 0.951164,  test auc: 0.955021
epoch 115, loss: 0.238720
model updated at epoch 115 
epoch 115, 
 train loss: 0.238720, val loss: 0.303942 
 val auc: 0.952065,  test auc: 0.955068
epoch 116, loss: 0.235968
model updated at epoch 116 
epoch 116, 
 train loss: 0.235968, val loss: 0.300620 
 val auc: 0.951952,  test auc: 0.955715
epoch 117, loss: 0.233214
model updated at epoch 117 
epoch 117, 
 train loss: 0.233214, val loss: 0.297612 
 val auc: 0.953378,  test auc: 0.956353
epoch 118, loss: 0.230052
model updated at epoch 118 
epoch 118, 
 train loss: 0.230052, val loss: 0.294111 
 val auc: 0.954392,  test auc: 0.957020
epoch 119, loss: 0.227826
model updated at epoch 119 
epoch 119, 
 train loss: 0.227826, val loss: 0.292088 
 val auc: 0.955030,  test auc: 0.957508
epoch 120, loss: 0.226171
model updated at epoch 120 
epoch 120, 
 train loss: 0.226171, val loss: 0.290993 
 val auc: 0.954467,  test auc: 0.957339
epoch 121, loss: 0.223434
model updated at epoch 121 
epoch 121, 
 train loss: 0.223434, val loss: 0.288762 
 val auc: 0.955068,  test auc: 0.957845
epoch 122, loss: 0.220845
model updated at epoch 122 
epoch 122, 
 train loss: 0.220845, val loss: 0.286614 
 val auc: 0.955443,  test auc: 0.958164
epoch 123, loss: 0.218801
model updated at epoch 123 
epoch 123, 
 train loss: 0.218801, val loss: 0.285127 
 val auc: 0.955593,  test auc: 0.958521
epoch 124, loss: 0.217076
model updated at epoch 124 
epoch 124, 
 train loss: 0.217076, val loss: 0.284023 
 val auc: 0.955556,  test auc: 0.958577
epoch 125, loss: 0.215253
model updated at epoch 125 
epoch 125, 
 train loss: 0.215253, val loss: 0.282320 
 val auc: 0.956006,  test auc: 0.958859
epoch 126, loss: 0.212881
model updated at epoch 126 
epoch 126, 
 train loss: 0.212881, val loss: 0.280102 
 val auc: 0.956231,  test auc: 0.959244
epoch 127, loss: 0.210882
model updated at epoch 127 
epoch 127, 
 train loss: 0.210882, val loss: 0.278088 
 val auc: 0.956944,  test auc: 0.959553
epoch 128, loss: 0.209342
model updated at epoch 128 
epoch 128, 
 train loss: 0.209342, val loss: 0.276580 
 val auc: 0.957357,  test auc: 0.959807
epoch 129, loss: 0.207770
model updated at epoch 129 
epoch 129, 
 train loss: 0.207770, val loss: 0.275520 
 val auc: 0.957095,  test auc: 0.959947
epoch 130, loss: 0.206116
model updated at epoch 130 
epoch 130, 
 train loss: 0.206116, val loss: 0.273725 
 val auc: 0.958033,  test auc: 0.960313
epoch 131, loss: 0.204050
model updated at epoch 131 
epoch 131, 
 train loss: 0.204050, val loss: 0.272393 
 val auc: 0.958033,  test auc: 0.960736
epoch 132, loss: 0.202326
model updated at epoch 132 
epoch 132, 
 train loss: 0.202326, val loss: 0.271106 
 val auc: 0.958071,  test auc: 0.960867
epoch 133, loss: 0.200986
model updated at epoch 133 
epoch 133, 
 train loss: 0.200986, val loss: 0.270110 
 val auc: 0.958408,  test auc: 0.960923
epoch 134, loss: 0.199739
model updated at epoch 134 
epoch 134, 
 train loss: 0.199739, val loss: 0.269491 
 val auc: 0.958146,  test auc: 0.961289
epoch 135, loss: 0.198709
model updated at epoch 135 
epoch 135, 
 train loss: 0.198709, val loss: 0.267987 
 val auc: 0.958784,  test auc: 0.961383
epoch 136, loss: 0.196898
model updated at epoch 136 
epoch 136, 
 train loss: 0.196898, val loss: 0.266549 
 val auc: 0.959084,  test auc: 0.962096
epoch 137, loss: 0.195195
model updated at epoch 137 
epoch 137, 
 train loss: 0.195195, val loss: 0.264266 
 val auc: 0.959760,  test auc: 0.962200
epoch 138, loss: 0.193758
model updated at epoch 138 
epoch 138, 
 train loss: 0.193758, val loss: 0.262786 
 val auc: 0.959947,  test auc: 0.962575
epoch 139, loss: 0.192668
model updated at epoch 139 
epoch 139, 
 train loss: 0.192668, val loss: 0.261869 
 val auc: 0.960285,  test auc: 0.963007
epoch 140, loss: 0.191786
model updated at epoch 140 
epoch 140, 
 train loss: 0.191786, val loss: 0.260501 
 val auc: 0.960511,  test auc: 0.962800
epoch 141, loss: 0.190557
model updated at epoch 141 
epoch 141, 
 train loss: 0.190557, val loss: 0.259914 
 val auc: 0.960323,  test auc: 0.963251
epoch 142, loss: 0.189311
model updated at epoch 142 
epoch 142, 
 train loss: 0.189311, val loss: 0.258121 
 val auc: 0.960886,  test auc: 0.963138
epoch 143, loss: 0.187777
model updated at epoch 143 
epoch 143, 
 train loss: 0.187777, val loss: 0.257161 
 val auc: 0.961149,  test auc: 0.963758
epoch 144, loss: 0.186427
model updated at epoch 144 
epoch 144, 
 train loss: 0.186427, val loss: 0.255693 
 val auc: 0.961674,  test auc: 0.963936
epoch 145, loss: 0.185306
model updated at epoch 145 
epoch 145, 
 train loss: 0.185306, val loss: 0.254834 
 val auc: 0.961824,  test auc: 0.963945
epoch 146, loss: 0.184336
model updated at epoch 146 
epoch 146, 
 train loss: 0.184336, val loss: 0.254598 
 val auc: 0.961937,  test auc: 0.964095
epoch 147, loss: 0.183414
model updated at epoch 147 
epoch 147, 
 train loss: 0.183414, val loss: 0.253528 
 val auc: 0.961674,  test auc: 0.963908
epoch 148, loss: 0.182289
model updated at epoch 148 
epoch 148, 
 train loss: 0.182289, val loss: 0.253156 
 val auc: 0.962162,  test auc: 0.964321
epoch 149, loss: 0.181113
model updated at epoch 149 
epoch 149, 
 train loss: 0.181113, val loss: 0.251598 
 val auc: 0.961899,  test auc: 0.964086
epoch 150, loss: 0.179925
model updated at epoch 150 
epoch 150, 
 train loss: 0.179925, val loss: 0.250814 
 val auc: 0.962650,  test auc: 0.964658
epoch 151, loss: 0.178837
model updated at epoch 151 
epoch 151, 
 train loss: 0.178837, val loss: 0.249604 
 val auc: 0.962500,  test auc: 0.964546
epoch 152, loss: 0.177846
model updated at epoch 152 
epoch 152, 
 train loss: 0.177846, val loss: 0.248642 
 val auc: 0.962988,  test auc: 0.964780
epoch 153, loss: 0.176940
model updated at epoch 153 
epoch 153, 
 train loss: 0.176940, val loss: 0.248082 
 val auc: 0.963213,  test auc: 0.964977
epoch 154, loss: 0.176182
model updated at epoch 154 
epoch 154, 
 train loss: 0.176182, val loss: 0.247028 
 val auc: 0.963101,  test auc: 0.964743
epoch 155, loss: 0.175633
epoch 155, 
 train loss: 0.175633, val loss: 0.247138 
 val auc: 0.963401,  test auc: 0.965118
epoch 156, loss: 0.175667
model updated at epoch 156 
epoch 156, 
 train loss: 0.175667, val loss: 0.246100 
 val auc: 0.963176,  test auc: 0.964518
epoch 157, loss: 0.174925
epoch 157, 
 train loss: 0.174925, val loss: 0.246436 
 val auc: 0.963664,  test auc: 0.965315
epoch 158, loss: 0.173963
model updated at epoch 158 
epoch 158, 
 train loss: 0.173963, val loss: 0.243960 
 val auc: 0.963626,  test auc: 0.964733
epoch 159, loss: 0.171652
model updated at epoch 159 
epoch 159, 
 train loss: 0.171652, val loss: 0.242183 
 val auc: 0.964527,  test auc: 0.965747
epoch 160, loss: 0.170909
model updated at epoch 160 
epoch 160, 
 train loss: 0.170909, val loss: 0.241552 
 val auc: 0.964414,  test auc: 0.965738
epoch 161, loss: 0.171366
model updated at epoch 161 
epoch 161, 
 train loss: 0.171366, val loss: 0.241282 
 val auc: 0.964114,  test auc: 0.965250
epoch 162, loss: 0.170480
epoch 162, 
 train loss: 0.170480, val loss: 0.241340 
 val auc: 0.964377,  test auc: 0.965972
epoch 163, loss: 0.168855
model updated at epoch 163 
epoch 163, 
 train loss: 0.168855, val loss: 0.238287 
 val auc: 0.965240,  test auc: 0.966197
epoch 164, loss: 0.167584
model updated at epoch 164 
epoch 164, 
 train loss: 0.167584, val loss: 0.237034 
 val auc: 0.965541,  test auc: 0.966207
epoch 165, loss: 0.167766
epoch 165, 
 train loss: 0.167766, val loss: 0.237825 
 val auc: 0.965240,  test auc: 0.966338
epoch 166, loss: 0.167787
model updated at epoch 166 
epoch 166, 
 train loss: 0.167787, val loss: 0.236720 
 val auc: 0.965390,  test auc: 0.966057
epoch 167, loss: 0.165509
model updated at epoch 167 
epoch 167, 
 train loss: 0.165509, val loss: 0.235022 
 val auc: 0.965691,  test auc: 0.966714
epoch 168, loss: 0.165142
epoch 168, 
 train loss: 0.165142, val loss: 0.235184 
 val auc: 0.965578,  test auc: 0.966676
epoch 169, loss: 0.166164
epoch 169, 
 train loss: 0.166164, val loss: 0.235636 
 val auc: 0.965390,  test auc: 0.965991
epoch 170, loss: 0.164584
model updated at epoch 170 
epoch 170, 
 train loss: 0.164584, val loss: 0.234453 
 val auc: 0.965953,  test auc: 0.967117
epoch 171, loss: 0.163371
model updated at epoch 171 
epoch 171, 
 train loss: 0.163371, val loss: 0.232357 
 val auc: 0.966554,  test auc: 0.967596
epoch 172, loss: 0.162817
model updated at epoch 172 
epoch 172, 
 train loss: 0.162817, val loss: 0.231432 
 val auc: 0.967080,  test auc: 0.967239
epoch 173, loss: 0.162117
epoch 173, 
 train loss: 0.162117, val loss: 0.232008 
 val auc: 0.966517,  test auc: 0.967098
epoch 174, loss: 0.161024
model updated at epoch 174 
epoch 174, 
 train loss: 0.161024, val loss: 0.230433 
 val auc: 0.966854,  test auc: 0.967202
epoch 175, loss: 0.160408
model updated at epoch 175 
epoch 175, 
 train loss: 0.160408, val loss: 0.228870 
 val auc: 0.967342,  test auc: 0.967765
epoch 176, loss: 0.160128
model updated at epoch 176 
epoch 176, 
 train loss: 0.160128, val loss: 0.228857 
 val auc: 0.967117,  test auc: 0.967934
epoch 177, loss: 0.159027
model updated at epoch 177 
epoch 177, 
 train loss: 0.159027, val loss: 0.227469 
 val auc: 0.967455,  test auc: 0.968074
epoch 178, loss: 0.158276
model updated at epoch 178 
epoch 178, 
 train loss: 0.158276, val loss: 0.226913 
 val auc: 0.967943,  test auc: 0.967840
epoch 179, loss: 0.158161
epoch 179, 
 train loss: 0.158161, val loss: 0.227723 
 val auc: 0.967605,  test auc: 0.968074
epoch 180, loss: 0.156960
model updated at epoch 180 
epoch 180, 
 train loss: 0.156960, val loss: 0.225738 
 val auc: 0.968206,  test auc: 0.968271
epoch 181, loss: 0.156547
model updated at epoch 181 
epoch 181, 
 train loss: 0.156547, val loss: 0.225067 
 val auc: 0.968431,  test auc: 0.968684
epoch 182, loss: 0.156139
epoch 182, 
 train loss: 0.156139, val loss: 0.225118 
 val auc: 0.967755,  test auc: 0.968712
epoch 183, loss: 0.155308
model updated at epoch 183 
epoch 183, 
 train loss: 0.155308, val loss: 0.224021 
 val auc: 0.968393,  test auc: 0.968515
epoch 184, loss: 0.154760
epoch 184, 
 train loss: 0.154760, val loss: 0.224158 
 val auc: 0.968206,  test auc: 0.968515
epoch 185, loss: 0.154009
model updated at epoch 185 
epoch 185, 
 train loss: 0.154009, val loss: 0.223002 
 val auc: 0.968581,  test auc: 0.968703
epoch 186, loss: 0.153613
model updated at epoch 186 
epoch 186, 
 train loss: 0.153613, val loss: 0.221669 
 val auc: 0.968956,  test auc: 0.968797
epoch 187, loss: 0.153115
model updated at epoch 187 
epoch 187, 
 train loss: 0.153115, val loss: 0.221669 
 val auc: 0.968919,  test auc: 0.969285
epoch 188, loss: 0.152307
model updated at epoch 188 
epoch 188, 
 train loss: 0.152307, val loss: 0.220653 
 val auc: 0.969107,  test auc: 0.969032
epoch 189, loss: 0.151712
epoch 189, 
 train loss: 0.151712, val loss: 0.220705 
 val auc: 0.968844,  test auc: 0.969088
epoch 190, loss: 0.151152
model updated at epoch 190 
epoch 190, 
 train loss: 0.151152, val loss: 0.220120 
 val auc: 0.969144,  test auc: 0.969191
epoch 191, loss: 0.150695
model updated at epoch 191 
epoch 191, 
 train loss: 0.150695, val loss: 0.218720 
 val auc: 0.969670,  test auc: 0.969332
epoch 192, loss: 0.150258
model updated at epoch 192 
epoch 192, 
 train loss: 0.150258, val loss: 0.218500 
 val auc: 0.969820,  test auc: 0.969839
epoch 193, loss: 0.149673
model updated at epoch 193 
epoch 193, 
 train loss: 0.149673, val loss: 0.217358 
 val auc: 0.970045,  test auc: 0.969642
epoch 194, loss: 0.149104
epoch 194, 
 train loss: 0.149104, val loss: 0.217634 
 val auc: 0.970195,  test auc: 0.969970
epoch 195, loss: 0.148540
model updated at epoch 195 
epoch 195, 
 train loss: 0.148540, val loss: 0.216536 
 val auc: 0.970308,  test auc: 0.969923
epoch 196, loss: 0.147966
model updated at epoch 196 
epoch 196, 
 train loss: 0.147966, val loss: 0.216110 
 val auc: 0.970571,  test auc: 0.970355
epoch 197, loss: 0.147467
model updated at epoch 197 
epoch 197, 
 train loss: 0.147467, val loss: 0.215028 
 val auc: 0.970608,  test auc: 0.970252
epoch 198, loss: 0.146835
model updated at epoch 198 
epoch 198, 
 train loss: 0.146835, val loss: 0.214906 
 val auc: 0.970683,  test auc: 0.970449
epoch 199, loss: 0.146388
model updated at epoch 199 
epoch 199, 
 train loss: 0.146388, val loss: 0.214201 
 val auc: 0.970796,  test auc: 0.970261
epoch 200, loss: 0.145866
model updated at epoch 200 
epoch 200, 
 train loss: 0.145866, val loss: 0.213650 
 val auc: 0.971059,  test auc: 0.970758
epoch 201, loss: 0.145538
model updated at epoch 201 
epoch 201, 
 train loss: 0.145538, val loss: 0.212442 
 val auc: 0.971246,  test auc: 0.970646
epoch 202, loss: 0.145152
epoch 202, 
 train loss: 0.145152, val loss: 0.212938 
 val auc: 0.971284,  test auc: 0.971040
epoch 203, loss: 0.145026
model updated at epoch 203 
epoch 203, 
 train loss: 0.145026, val loss: 0.212295 
 val auc: 0.971096,  test auc: 0.970467
epoch 204, loss: 0.144938
epoch 204, 
 train loss: 0.144938, val loss: 0.213524 
 val auc: 0.970946,  test auc: 0.971077
epoch 205, loss: 0.145379
epoch 205, 
 train loss: 0.145379, val loss: 0.212488 
 val auc: 0.971359,  test auc: 0.970289
epoch 206, loss: 0.144290
epoch 206, 
 train loss: 0.144290, val loss: 0.212469 
 val auc: 0.971396,  test auc: 0.971256
epoch 207, loss: 0.143146
model updated at epoch 207 
epoch 207, 
 train loss: 0.143146, val loss: 0.209846 
 val auc: 0.971922,  test auc: 0.970796
epoch 208, loss: 0.141902
model updated at epoch 208 
epoch 208, 
 train loss: 0.141902, val loss: 0.209280 
 val auc: 0.972035,  test auc: 0.971415
epoch 209, loss: 0.141618
epoch 209, 
 train loss: 0.141618, val loss: 0.209370 
 val auc: 0.971959,  test auc: 0.971415
epoch 210, loss: 0.141922
model updated at epoch 210 
epoch 210, 
 train loss: 0.141922, val loss: 0.208920 
 val auc: 0.972072,  test auc: 0.970918
epoch 211, loss: 0.141871
epoch 211, 
 train loss: 0.141871, val loss: 0.209591 
 val auc: 0.971734,  test auc: 0.971565
epoch 212, loss: 0.141241
model updated at epoch 212 
epoch 212, 
 train loss: 0.141241, val loss: 0.207490 
 val auc: 0.972710,  test auc: 0.971321
epoch 213, loss: 0.139734
model updated at epoch 213 
epoch 213, 
 train loss: 0.139734, val loss: 0.206670 
 val auc: 0.972598,  test auc: 0.971837
epoch 214, loss: 0.139368
model updated at epoch 214 
epoch 214, 
 train loss: 0.139368, val loss: 0.206443 
 val auc: 0.972710,  test auc: 0.971753
epoch 215, loss: 0.139404
model updated at epoch 215 
epoch 215, 
 train loss: 0.139404, val loss: 0.205535 
 val auc: 0.973236,  test auc: 0.971556
epoch 216, loss: 0.139271
epoch 216, 
 train loss: 0.139271, val loss: 0.206051 
 val auc: 0.972635,  test auc: 0.972072
epoch 217, loss: 0.138488
model updated at epoch 217 
epoch 217, 
 train loss: 0.138488, val loss: 0.204178 
 val auc: 0.973498,  test auc: 0.971922
epoch 218, loss: 0.137393
model updated at epoch 218 
epoch 218, 
 train loss: 0.137393, val loss: 0.203887 
 val auc: 0.973574,  test auc: 0.972138
epoch 219, loss: 0.137291
epoch 219, 
 train loss: 0.137291, val loss: 0.204126 
 val auc: 0.973649,  test auc: 0.972147
epoch 220, loss: 0.137160
model updated at epoch 220 
epoch 220, 
 train loss: 0.137160, val loss: 0.202657 
 val auc: 0.974024,  test auc: 0.972044
epoch 221, loss: 0.136866
epoch 221, 
 train loss: 0.136866, val loss: 0.202779 
 val auc: 0.973461,  test auc: 0.972466
epoch 222, loss: 0.136036
model updated at epoch 222 
epoch 222, 
 train loss: 0.136036, val loss: 0.201090 
 val auc: 0.974249,  test auc: 0.972551
epoch 223, loss: 0.135222
epoch 223, 
 train loss: 0.135222, val loss: 0.201158 
 val auc: 0.974137,  test auc: 0.972401
epoch 224, loss: 0.135204
epoch 224, 
 train loss: 0.135204, val loss: 0.201864 
 val auc: 0.974024,  test auc: 0.972485
epoch 225, loss: 0.134938
model updated at epoch 225 
epoch 225, 
 train loss: 0.134938, val loss: 0.200480 
 val auc: 0.973949,  test auc: 0.972316
epoch 226, loss: 0.134682
model updated at epoch 226 
epoch 226, 
 train loss: 0.134682, val loss: 0.200464 
 val auc: 0.973911,  test auc: 0.972813
epoch 227, loss: 0.133957
model updated at epoch 227 
epoch 227, 
 train loss: 0.133957, val loss: 0.198920 
 val auc: 0.974474,  test auc: 0.972813
epoch 228, loss: 0.133179
model updated at epoch 228 
epoch 228, 
 train loss: 0.133179, val loss: 0.198912 
 val auc: 0.974662,  test auc: 0.972813
epoch 229, loss: 0.133102
epoch 229, 
 train loss: 0.133102, val loss: 0.199420 
 val auc: 0.974324,  test auc: 0.972720
epoch 230, loss: 0.132709
model updated at epoch 230 
epoch 230, 
 train loss: 0.132709, val loss: 0.197874 
 val auc: 0.974662,  test auc: 0.972710
epoch 231, loss: 0.132503
model updated at epoch 231 
epoch 231, 
 train loss: 0.132503, val loss: 0.197759 
 val auc: 0.974700,  test auc: 0.973142
epoch 232, loss: 0.131856
model updated at epoch 232 
epoch 232, 
 train loss: 0.131856, val loss: 0.196497 
 val auc: 0.974887,  test auc: 0.973011
epoch 233, loss: 0.131165
epoch 233, 
 train loss: 0.131165, val loss: 0.196705 
 val auc: 0.974925,  test auc: 0.973133
epoch 234, loss: 0.130869
model updated at epoch 234 
epoch 234, 
 train loss: 0.130869, val loss: 0.196489 
 val auc: 0.974887,  test auc: 0.973076
epoch 235, loss: 0.130364
model updated at epoch 235 
epoch 235, 
 train loss: 0.130364, val loss: 0.194979 
 val auc: 0.975225,  test auc: 0.973311
epoch 236, loss: 0.130199
model updated at epoch 236 
epoch 236, 
 train loss: 0.130199, val loss: 0.194612 
 val auc: 0.975338,  test auc: 0.973508
epoch 237, loss: 0.129668
model updated at epoch 237 
epoch 237, 
 train loss: 0.129668, val loss: 0.193686 
 val auc: 0.975225,  test auc: 0.973283
epoch 238, loss: 0.129262
epoch 238, 
 train loss: 0.129262, val loss: 0.194079 
 val auc: 0.975375,  test auc: 0.973470
epoch 239, loss: 0.128815
model updated at epoch 239 
epoch 239, 
 train loss: 0.128815, val loss: 0.192902 
 val auc: 0.975450,  test auc: 0.973311
epoch 240, loss: 0.128372
model updated at epoch 240 
epoch 240, 
 train loss: 0.128372, val loss: 0.191903 
 val auc: 0.975826,  test auc: 0.973686
epoch 241, loss: 0.128034
model updated at epoch 241 
epoch 241, 
 train loss: 0.128034, val loss: 0.190934 
 val auc: 0.975863,  test auc: 0.973686
epoch 242, loss: 0.127468
model updated at epoch 242 
epoch 242, 
 train loss: 0.127468, val loss: 0.190929 
 val auc: 0.975901,  test auc: 0.973789
epoch 243, loss: 0.127214
model updated at epoch 243 
epoch 243, 
 train loss: 0.127214, val loss: 0.190636 
 val auc: 0.975938,  test auc: 0.973639
epoch 244, loss: 0.126699
model updated at epoch 244 
epoch 244, 
 train loss: 0.126699, val loss: 0.189628 
 val auc: 0.976014,  test auc: 0.973949
epoch 245, loss: 0.126501
model updated at epoch 245 
epoch 245, 
 train loss: 0.126501, val loss: 0.188435 
 val auc: 0.976577,  test auc: 0.974099
epoch 246, loss: 0.126122
epoch 246, 
 train loss: 0.126122, val loss: 0.188660 
 val auc: 0.976464,  test auc: 0.974221
epoch 247, loss: 0.125991
model updated at epoch 247 
epoch 247, 
 train loss: 0.125991, val loss: 0.188159 
 val auc: 0.976652,  test auc: 0.973958
epoch 248, loss: 0.125908
epoch 248, 
 train loss: 0.125908, val loss: 0.188883 
 val auc: 0.976539,  test auc: 0.974343
epoch 249, loss: 0.126339
model updated at epoch 249 
epoch 249, 
 train loss: 0.126339, val loss: 0.187970 
 val auc: 0.976689,  test auc: 0.973799
epoch 250, loss: 0.125807
epoch 250, 
 train loss: 0.125807, val loss: 0.188593 
 val auc: 0.976577,  test auc: 0.974371
epoch 251, loss: 0.125267
model updated at epoch 251 
epoch 251, 
 train loss: 0.125267, val loss: 0.186941 
 val auc: 0.976764,  test auc: 0.973846
epoch 252, loss: 0.124014
model updated at epoch 252 
epoch 252, 
 train loss: 0.124014, val loss: 0.186751 
 val auc: 0.976877,  test auc: 0.974559
epoch 253, loss: 0.123158
model updated at epoch 253 
epoch 253, 
 train loss: 0.123158, val loss: 0.185101 
 val auc: 0.977477,  test auc: 0.974512
epoch 254, loss: 0.122746
model updated at epoch 254 
epoch 254, 
 train loss: 0.122746, val loss: 0.184347 
 val auc: 0.977628,  test auc: 0.974540
epoch 255, loss: 0.122669
epoch 255, 
 train loss: 0.122669, val loss: 0.184665 
 val auc: 0.977290,  test auc: 0.974794
epoch 256, loss: 0.122689
model updated at epoch 256 
epoch 256, 
 train loss: 0.122689, val loss: 0.183944 
 val auc: 0.977928,  test auc: 0.974596
epoch 257, loss: 0.122294
epoch 257, 
 train loss: 0.122294, val loss: 0.184197 
 val auc: 0.977553,  test auc: 0.974925
epoch 258, loss: 0.121712
model updated at epoch 258 
epoch 258, 
 train loss: 0.121712, val loss: 0.182668 
 val auc: 0.978041,  test auc: 0.974906
epoch 259, loss: 0.120908
model updated at epoch 259 
epoch 259, 
 train loss: 0.120908, val loss: 0.182486 
 val auc: 0.978003,  test auc: 0.975009
epoch 260, loss: 0.120384
model updated at epoch 260 
epoch 260, 
 train loss: 0.120384, val loss: 0.182234 
 val auc: 0.978116,  test auc: 0.975000
epoch 261, loss: 0.120173
epoch 261, 
 train loss: 0.120173, val loss: 0.182299 
 val auc: 0.978341,  test auc: 0.975038
epoch 262, loss: 0.120069
epoch 262, 
 train loss: 0.120069, val loss: 0.182959 
 val auc: 0.977703,  test auc: 0.975075
epoch 263, loss: 0.119949
model updated at epoch 263 
epoch 263, 
 train loss: 0.119949, val loss: 0.182160 
 val auc: 0.978341,  test auc: 0.974953
epoch 264, loss: 0.119406
epoch 264, 
 train loss: 0.119406, val loss: 0.182407 
 val auc: 0.977778,  test auc: 0.975075
epoch 265, loss: 0.118948
model updated at epoch 265 
epoch 265, 
 train loss: 0.118948, val loss: 0.181610 
 val auc: 0.978116,  test auc: 0.974878
epoch 266, loss: 0.118353
model updated at epoch 266 
epoch 266, 
 train loss: 0.118353, val loss: 0.181562 
 val auc: 0.978041,  test auc: 0.975075
epoch 267, loss: 0.117835
model updated at epoch 267 
epoch 267, 
 train loss: 0.117835, val loss: 0.180562 
 val auc: 0.978341,  test auc: 0.975075
epoch 268, loss: 0.117376
model updated at epoch 268 
epoch 268, 
 train loss: 0.117376, val loss: 0.180223 
 val auc: 0.978341,  test auc: 0.975253
epoch 269, loss: 0.117083
model updated at epoch 269 
epoch 269, 
 train loss: 0.117083, val loss: 0.179966 
 val auc: 0.978341,  test auc: 0.975375
epoch 270, loss: 0.116822
model updated at epoch 270 
epoch 270, 
 train loss: 0.116822, val loss: 0.179112 
 val auc: 0.978566,  test auc: 0.975347
epoch 271, loss: 0.116534
epoch 271, 
 train loss: 0.116534, val loss: 0.179132 
 val auc: 0.978641,  test auc: 0.975648
epoch 272, loss: 0.116197
model updated at epoch 272 
epoch 272, 
 train loss: 0.116197, val loss: 0.178442 
 val auc: 0.978416,  test auc: 0.975422
epoch 273, loss: 0.115747
epoch 273, 
 train loss: 0.115747, val loss: 0.178832 
 val auc: 0.978416,  test auc: 0.975629
epoch 274, loss: 0.115316
model updated at epoch 274 
epoch 274, 
 train loss: 0.115316, val loss: 0.178107 
 val auc: 0.978416,  test auc: 0.975422
epoch 275, loss: 0.114885
model updated at epoch 275 
epoch 275, 
 train loss: 0.114885, val loss: 0.177945 
 val auc: 0.978679,  test auc: 0.975741
epoch 276, loss: 0.114475
model updated at epoch 276 
epoch 276, 
 train loss: 0.114475, val loss: 0.177448 
 val auc: 0.978604,  test auc: 0.975563
epoch 277, loss: 0.114061
epoch 277, 
 train loss: 0.114061, val loss: 0.177546 
 val auc: 0.978716,  test auc: 0.975751
epoch 278, loss: 0.113688
model updated at epoch 278 
epoch 278, 
 train loss: 0.113688, val loss: 0.177273 
 val auc: 0.978716,  test auc: 0.975713
epoch 279, loss: 0.113310
model updated at epoch 279 
epoch 279, 
 train loss: 0.113310, val loss: 0.176510 
 val auc: 0.978979,  test auc: 0.975788
epoch 280, loss: 0.112975
model updated at epoch 280 
epoch 280, 
 train loss: 0.112975, val loss: 0.175955 
 val auc: 0.979054,  test auc: 0.975910
epoch 281, loss: 0.112630
model updated at epoch 281 
epoch 281, 
 train loss: 0.112630, val loss: 0.175493 
 val auc: 0.979129,  test auc: 0.975967
epoch 282, loss: 0.112316
epoch 282, 
 train loss: 0.112316, val loss: 0.175664 
 val auc: 0.978979,  test auc: 0.975957
epoch 283, loss: 0.112006
model updated at epoch 283 
epoch 283, 
 train loss: 0.112006, val loss: 0.175013 
 val auc: 0.979129,  test auc: 0.975976
epoch 284, loss: 0.111736
epoch 284, 
 train loss: 0.111736, val loss: 0.175361 
 val auc: 0.978941,  test auc: 0.976051
epoch 285, loss: 0.111536
model updated at epoch 285 
epoch 285, 
 train loss: 0.111536, val loss: 0.174699 
 val auc: 0.979167,  test auc: 0.975929
epoch 286, loss: 0.111342
epoch 286, 
 train loss: 0.111342, val loss: 0.175498 
 val auc: 0.979017,  test auc: 0.976239
epoch 287, loss: 0.111359
model updated at epoch 287 
epoch 287, 
 train loss: 0.111359, val loss: 0.174270 
 val auc: 0.979279,  test auc: 0.975910
epoch 288, loss: 0.111154
epoch 288, 
 train loss: 0.111154, val loss: 0.175010 
 val auc: 0.979129,  test auc: 0.976380
epoch 289, loss: 0.110979
model updated at epoch 289 
epoch 289, 
 train loss: 0.110979, val loss: 0.173513 
 val auc: 0.979429,  test auc: 0.975976
epoch 290, loss: 0.110072
epoch 290, 
 train loss: 0.110072, val loss: 0.174041 
 val auc: 0.979129,  test auc: 0.976464
epoch 291, loss: 0.109384
model updated at epoch 291 
epoch 291, 
 train loss: 0.109384, val loss: 0.172261 
 val auc: 0.979617,  test auc: 0.976267
epoch 292, loss: 0.108782
model updated at epoch 292 
epoch 292, 
 train loss: 0.108782, val loss: 0.171787 
 val auc: 0.979692,  test auc: 0.976502
epoch 293, loss: 0.108371
model updated at epoch 293 
epoch 293, 
 train loss: 0.108371, val loss: 0.171080 
 val auc: 0.979842,  test auc: 0.976548
epoch 294, loss: 0.108084
model updated at epoch 294 
epoch 294, 
 train loss: 0.108084, val loss: 0.170983 
 val auc: 0.979805,  test auc: 0.976478
epoch 295, loss: 0.107936
epoch 295, 
 train loss: 0.107936, val loss: 0.171693 
 val auc: 0.979730,  test auc: 0.976661
epoch 296, loss: 0.107921
model updated at epoch 296 
epoch 296, 
 train loss: 0.107921, val loss: 0.170950 
 val auc: 0.979692,  test auc: 0.976389
epoch 297, loss: 0.107801
epoch 297, 
 train loss: 0.107801, val loss: 0.172050 
 val auc: 0.979580,  test auc: 0.976764
epoch 298, loss: 0.107677
model updated at epoch 298 
epoch 298, 
 train loss: 0.107677, val loss: 0.170828 
 val auc: 0.979880,  test auc: 0.976408
epoch 299, loss: 0.107058
epoch 299, 
 train loss: 0.107058, val loss: 0.171547 
 val auc: 0.979692,  test auc: 0.976811
epoch 300, loss: 0.106560
model updated at epoch 300 
epoch 300, 
 train loss: 0.106560, val loss: 0.169673 
 val auc: 0.979842,  test auc: 0.976642
epoch 301, loss: 0.105927
model updated at epoch 301 
epoch 301, 
 train loss: 0.105927, val loss: 0.169653 
 val auc: 0.980180,  test auc: 0.977008
epoch 302, loss: 0.105392
model updated at epoch 302 
epoch 302, 
 train loss: 0.105392, val loss: 0.168558 
 val auc: 0.980068,  test auc: 0.976849
epoch 303, loss: 0.104991
epoch 303, 
 train loss: 0.104991, val loss: 0.168700 
 val auc: 0.980405,  test auc: 0.977055
epoch 304, loss: 0.104725
epoch 304, 
 train loss: 0.104725, val loss: 0.168664 
 val auc: 0.980443,  test auc: 0.977111
epoch 305, loss: 0.104544
model updated at epoch 305 
epoch 305, 
 train loss: 0.104544, val loss: 0.167768 
 val auc: 0.980218,  test auc: 0.976952
epoch 306, loss: 0.104357
epoch 306, 
 train loss: 0.104357, val loss: 0.168280 
 val auc: 0.980556,  test auc: 0.977309
epoch 307, loss: 0.104147
model updated at epoch 307 
epoch 307, 
 train loss: 0.104147, val loss: 0.167406 
 val auc: 0.980518,  test auc: 0.976971
epoch 308, loss: 0.103806
epoch 308, 
 train loss: 0.103806, val loss: 0.167979 
 val auc: 0.980631,  test auc: 0.977393
epoch 309, loss: 0.103470
model updated at epoch 309 
epoch 309, 
 train loss: 0.103470, val loss: 0.166600 
 val auc: 0.980480,  test auc: 0.977046
epoch 310, loss: 0.103012
epoch 310, 
 train loss: 0.103012, val loss: 0.166815 
 val auc: 0.980668,  test auc: 0.977449
epoch 311, loss: 0.102583
model updated at epoch 311 
epoch 311, 
 train loss: 0.102583, val loss: 0.165711 
 val auc: 0.980706,  test auc: 0.977196
epoch 312, loss: 0.102180
epoch 312, 
 train loss: 0.102180, val loss: 0.165711 
 val auc: 0.980931,  test auc: 0.977524
epoch 313, loss: 0.101828
model updated at epoch 313 
epoch 313, 
 train loss: 0.101828, val loss: 0.165105 
 val auc: 0.980856,  test auc: 0.977402
epoch 314, loss: 0.101520
model updated at epoch 314 
epoch 314, 
 train loss: 0.101520, val loss: 0.164893 
 val auc: 0.980781,  test auc: 0.977477
epoch 315, loss: 0.101231
model updated at epoch 315 
epoch 315, 
 train loss: 0.101231, val loss: 0.164746 
 val auc: 0.980818,  test auc: 0.977599
epoch 316, loss: 0.100986
model updated at epoch 316 
epoch 316, 
 train loss: 0.100986, val loss: 0.164017 
 val auc: 0.981081,  test auc: 0.977534
epoch 317, loss: 0.100802
epoch 317, 
 train loss: 0.100802, val loss: 0.164302 
 val auc: 0.980968,  test auc: 0.977712
epoch 318, loss: 0.100685
model updated at epoch 318 
epoch 318, 
 train loss: 0.100685, val loss: 0.163478 
 val auc: 0.981081,  test auc: 0.977440
epoch 319, loss: 0.100577
epoch 319, 
 train loss: 0.100577, val loss: 0.164662 
 val auc: 0.980818,  test auc: 0.977806
epoch 320, loss: 0.100544
model updated at epoch 320 
epoch 320, 
 train loss: 0.100544, val loss: 0.163361 
 val auc: 0.981006,  test auc: 0.977337
epoch 321, loss: 0.100247
epoch 321, 
 train loss: 0.100247, val loss: 0.164553 
 val auc: 0.980856,  test auc: 0.977872
epoch 322, loss: 0.100021
model updated at epoch 322 
epoch 322, 
 train loss: 0.100021, val loss: 0.162773 
 val auc: 0.981081,  test auc: 0.977421
epoch 323, loss: 0.099425
epoch 323, 
 train loss: 0.099425, val loss: 0.163564 
 val auc: 0.981269,  test auc: 0.977994
epoch 324, loss: 0.098853
model updated at epoch 324 
epoch 324, 
 train loss: 0.098853, val loss: 0.161896 
 val auc: 0.981306,  test auc: 0.977675
epoch 325, loss: 0.098295
epoch 325, 
 train loss: 0.098295, val loss: 0.162312 
 val auc: 0.981306,  test auc: 0.977994
epoch 326, loss: 0.097921
model updated at epoch 326 
epoch 326, 
 train loss: 0.097921, val loss: 0.161708 
 val auc: 0.981494,  test auc: 0.978041
epoch 327, loss: 0.097715
model updated at epoch 327 
epoch 327, 
 train loss: 0.097715, val loss: 0.161120 
 val auc: 0.981607,  test auc: 0.978031
epoch 328, loss: 0.097582
epoch 328, 
 train loss: 0.097582, val loss: 0.161641 
 val auc: 0.981494,  test auc: 0.978247
epoch 329, loss: 0.097536
model updated at epoch 329 
epoch 329, 
 train loss: 0.097536, val loss: 0.160447 
 val auc: 0.981644,  test auc: 0.977909
epoch 330, loss: 0.097403
epoch 330, 
 train loss: 0.097403, val loss: 0.161361 
 val auc: 0.981494,  test auc: 0.978350
epoch 331, loss: 0.097282
model updated at epoch 331 
epoch 331, 
 train loss: 0.097282, val loss: 0.160009 
 val auc: 0.981757,  test auc: 0.977881
epoch 332, loss: 0.096953
epoch 332, 
 train loss: 0.096953, val loss: 0.161292 
 val auc: 0.981456,  test auc: 0.978331
epoch 333, loss: 0.097029
epoch 333, 
 train loss: 0.097029, val loss: 0.160292 
 val auc: 0.981607,  test auc: 0.977731
epoch 334, loss: 0.096715
epoch 334, 
 train loss: 0.096715, val loss: 0.161649 
 val auc: 0.981419,  test auc: 0.978397
epoch 335, loss: 0.096279
model updated at epoch 335 
epoch 335, 
 train loss: 0.096279, val loss: 0.159549 
 val auc: 0.981794,  test auc: 0.977947
epoch 336, loss: 0.095457
epoch 336, 
 train loss: 0.095457, val loss: 0.159998 
 val auc: 0.981682,  test auc: 0.978472
epoch 337, loss: 0.094961
model updated at epoch 337 
epoch 337, 
 train loss: 0.094961, val loss: 0.158968 
 val auc: 0.981907,  test auc: 0.978500
epoch 338, loss: 0.094778
model updated at epoch 338 
epoch 338, 
 train loss: 0.094778, val loss: 0.158313 
 val auc: 0.982095,  test auc: 0.978510
epoch 339, loss: 0.094766
epoch 339, 
 train loss: 0.094766, val loss: 0.158817 
 val auc: 0.981794,  test auc: 0.978660
epoch 340, loss: 0.094659
model updated at epoch 340 
epoch 340, 
 train loss: 0.094659, val loss: 0.157566 
 val auc: 0.982095,  test auc: 0.978285
epoch 341, loss: 0.094315
epoch 341, 
 train loss: 0.094315, val loss: 0.158144 
 val auc: 0.981682,  test auc: 0.978716
epoch 342, loss: 0.093901
model updated at epoch 342 
epoch 342, 
 train loss: 0.093901, val loss: 0.156573 
 val auc: 0.982170,  test auc: 0.978463
epoch 343, loss: 0.093408
epoch 343, 
 train loss: 0.093408, val loss: 0.157152 
 val auc: 0.982020,  test auc: 0.978782
epoch 344, loss: 0.093049
epoch 344, 
 train loss: 0.093049, val loss: 0.157143 
 val auc: 0.981982,  test auc: 0.978707
epoch 345, loss: 0.092821
epoch 345, 
 train loss: 0.092821, val loss: 0.157022 
 val auc: 0.982132,  test auc: 0.978688
epoch 346, loss: 0.092682
epoch 346, 
 train loss: 0.092682, val loss: 0.157127 
 val auc: 0.982020,  test auc: 0.978876
epoch 347, loss: 0.092605
model updated at epoch 347 
epoch 347, 
 train loss: 0.092605, val loss: 0.155937 
 val auc: 0.982282,  test auc: 0.978585
epoch 348, loss: 0.092421
epoch 348, 
 train loss: 0.092421, val loss: 0.156790 
 val auc: 0.981982,  test auc: 0.978913
epoch 349, loss: 0.092205
model updated at epoch 349 
epoch 349, 
 train loss: 0.092205, val loss: 0.155436 
 val auc: 0.982282,  test auc: 0.978472
epoch 350, loss: 0.091797
epoch 350, 
 train loss: 0.091797, val loss: 0.156258 
 val auc: 0.981944,  test auc: 0.979002
epoch 351, loss: 0.091388
model updated at epoch 351 
epoch 351, 
 train loss: 0.091388, val loss: 0.155201 
 val auc: 0.982432,  test auc: 0.978763
epoch 352, loss: 0.090965
epoch 352, 
 train loss: 0.090965, val loss: 0.155787 
 val auc: 0.982245,  test auc: 0.979054
epoch 353, loss: 0.090622
model updated at epoch 353 
epoch 353, 
 train loss: 0.090622, val loss: 0.155197 
 val auc: 0.982320,  test auc: 0.978979
epoch 354, loss: 0.090365
model updated at epoch 354 
epoch 354, 
 train loss: 0.090365, val loss: 0.154810 
 val auc: 0.982395,  test auc: 0.979026
epoch 355, loss: 0.090156
epoch 355, 
 train loss: 0.090156, val loss: 0.154932 
 val auc: 0.982395,  test auc: 0.979214
epoch 356, loss: 0.089983
model updated at epoch 356 
epoch 356, 
 train loss: 0.089983, val loss: 0.154392 
 val auc: 0.982695,  test auc: 0.978988
epoch 357, loss: 0.089821
epoch 357, 
 train loss: 0.089821, val loss: 0.155172 
 val auc: 0.982245,  test auc: 0.979251
epoch 358, loss: 0.089700
model updated at epoch 358 
epoch 358, 
 train loss: 0.089700, val loss: 0.154280 
 val auc: 0.982508,  test auc: 0.978885
epoch 359, loss: 0.089476
epoch 359, 
 train loss: 0.089476, val loss: 0.155554 
 val auc: 0.982057,  test auc: 0.979279
epoch 360, loss: 0.089253
epoch 360, 
 train loss: 0.089253, val loss: 0.154368 
 val auc: 0.982583,  test auc: 0.978904
epoch 361, loss: 0.088913
epoch 361, 
 train loss: 0.088913, val loss: 0.155288 
 val auc: 0.982170,  test auc: 0.979373
epoch 362, loss: 0.088576
model updated at epoch 362 
epoch 362, 
 train loss: 0.088576, val loss: 0.153759 
 val auc: 0.982658,  test auc: 0.979120
epoch 363, loss: 0.088159
epoch 363, 
 train loss: 0.088159, val loss: 0.154144 
 val auc: 0.982470,  test auc: 0.979514
epoch 364, loss: 0.087802
model updated at epoch 364 
epoch 364, 
 train loss: 0.087802, val loss: 0.153160 
 val auc: 0.982695,  test auc: 0.979364
epoch 365, loss: 0.087506
epoch 365, 
 train loss: 0.087506, val loss: 0.153234 
 val auc: 0.982620,  test auc: 0.979523
epoch 366, loss: 0.087253
epoch 366, 
 train loss: 0.087253, val loss: 0.153404 
 val auc: 0.982583,  test auc: 0.979551
epoch 367, loss: 0.087060
epoch 367, 
 train loss: 0.087060, val loss: 0.153341 
 val auc: 0.982470,  test auc: 0.979420
epoch 368, loss: 0.086897
epoch 368, 
 train loss: 0.086897, val loss: 0.153787 
 val auc: 0.982432,  test auc: 0.979589
epoch 369, loss: 0.086738
model updated at epoch 369 
epoch 369, 
 train loss: 0.086738, val loss: 0.152503 
 val auc: 0.982808,  test auc: 0.979439
epoch 370, loss: 0.086602
epoch 370, 
 train loss: 0.086602, val loss: 0.153122 
 val auc: 0.982620,  test auc: 0.979758
epoch 371, loss: 0.086506
model updated at epoch 371 
epoch 371, 
 train loss: 0.086506, val loss: 0.152061 
 val auc: 0.982845,  test auc: 0.979307
epoch 372, loss: 0.086375
epoch 372, 
 train loss: 0.086375, val loss: 0.153362 
 val auc: 0.982733,  test auc: 0.979842
epoch 373, loss: 0.086313
model updated at epoch 373 
epoch 373, 
 train loss: 0.086313, val loss: 0.152045 
 val auc: 0.982770,  test auc: 0.979214
epoch 374, loss: 0.086011
epoch 374, 
 train loss: 0.086011, val loss: 0.153348 
 val auc: 0.982658,  test auc: 0.979908
epoch 375, loss: 0.085741
model updated at epoch 375 
epoch 375, 
 train loss: 0.085741, val loss: 0.151734 
 val auc: 0.982883,  test auc: 0.979373
epoch 376, loss: 0.085271
epoch 376, 
 train loss: 0.085271, val loss: 0.152591 
 val auc: 0.982733,  test auc: 0.979946
epoch 377, loss: 0.084865
model updated at epoch 377 
epoch 377, 
 train loss: 0.084865, val loss: 0.151335 
 val auc: 0.982808,  test auc: 0.979523
epoch 378, loss: 0.084440
epoch 378, 
 train loss: 0.084440, val loss: 0.151760 
 val auc: 0.982695,  test auc: 0.979795
epoch 379, loss: 0.084113
model updated at epoch 379 
epoch 379, 
 train loss: 0.084113, val loss: 0.151051 
 val auc: 0.982883,  test auc: 0.979833
epoch 380, loss: 0.083880
model updated at epoch 380 
epoch 380, 
 train loss: 0.083880, val loss: 0.150924 
 val auc: 0.982845,  test auc: 0.979842
epoch 381, loss: 0.083708
epoch 381, 
 train loss: 0.083708, val loss: 0.151395 
 val auc: 0.982658,  test auc: 0.979842
epoch 382, loss: 0.083609
model updated at epoch 382 
epoch 382, 
 train loss: 0.083609, val loss: 0.150817 
 val auc: 0.982883,  test auc: 0.979711
epoch 383, loss: 0.083486
epoch 383, 
 train loss: 0.083486, val loss: 0.151539 
 val auc: 0.982658,  test auc: 0.980058
epoch 384, loss: 0.083378
model updated at epoch 384 
epoch 384, 
 train loss: 0.083378, val loss: 0.150319 
 val auc: 0.982995,  test auc: 0.979659
epoch 385, loss: 0.083175
epoch 385, 
 train loss: 0.083175, val loss: 0.151464 
 val auc: 0.982733,  test auc: 0.980152
epoch 386, loss: 0.082962
model updated at epoch 386 
epoch 386, 
 train loss: 0.082962, val loss: 0.150313 
 val auc: 0.983033,  test auc: 0.979692
epoch 387, loss: 0.082677
epoch 387, 
 train loss: 0.082677, val loss: 0.151412 
 val auc: 0.982733,  test auc: 0.980143
epoch 388, loss: 0.082391
model updated at epoch 388 
epoch 388, 
 train loss: 0.082391, val loss: 0.150000 
 val auc: 0.983033,  test auc: 0.979739
epoch 389, loss: 0.082004
epoch 389, 
 train loss: 0.082004, val loss: 0.150907 
 val auc: 0.982733,  test auc: 0.980133
epoch 390, loss: 0.081654
model updated at epoch 390 
epoch 390, 
 train loss: 0.081654, val loss: 0.149816 
 val auc: 0.982920,  test auc: 0.979917
epoch 391, loss: 0.081313
epoch 391, 
 train loss: 0.081313, val loss: 0.150408 
 val auc: 0.982770,  test auc: 0.980190
epoch 392, loss: 0.081026
model updated at epoch 392 
epoch 392, 
 train loss: 0.081026, val loss: 0.149798 
 val auc: 0.982920,  test auc: 0.980091
epoch 393, loss: 0.080758
model updated at epoch 393 
epoch 393, 
 train loss: 0.080758, val loss: 0.149607 
 val auc: 0.982995,  test auc: 0.980236
epoch 394, loss: 0.080515
model updated at epoch 394 
epoch 394, 
 train loss: 0.080515, val loss: 0.149208 
 val auc: 0.982995,  test auc: 0.980283
epoch 395, loss: 0.080300
model updated at epoch 395 
epoch 395, 
 train loss: 0.080300, val loss: 0.148996 
 val auc: 0.982995,  test auc: 0.980246
epoch 396, loss: 0.080095
epoch 396, 
 train loss: 0.080095, val loss: 0.149386 
 val auc: 0.982958,  test auc: 0.980293
epoch 397, loss: 0.079929
model updated at epoch 397 
epoch 397, 
 train loss: 0.079929, val loss: 0.148937 
 val auc: 0.982920,  test auc: 0.980236
epoch 398, loss: 0.079783
epoch 398, 
 train loss: 0.079783, val loss: 0.149582 
 val auc: 0.982958,  test auc: 0.980415
epoch 399, loss: 0.079668
model updated at epoch 399 
epoch 399, 
 train loss: 0.079668, val loss: 0.148513 
 val auc: 0.983108,  test auc: 0.980171
epoch 400, loss: 0.079564
epoch 400, 
 train loss: 0.079564, val loss: 0.149860 
 val auc: 0.982958,  test auc: 0.980537
epoch 401, loss: 0.079516
epoch 401, 
 train loss: 0.079516, val loss: 0.148635 
 val auc: 0.983108,  test auc: 0.980011
epoch 402, loss: 0.079303
epoch 402, 
 train loss: 0.079303, val loss: 0.150008 
 val auc: 0.983033,  test auc: 0.980631
epoch 403, loss: 0.079050
model updated at epoch 403 
epoch 403, 
 train loss: 0.079050, val loss: 0.148069 
 val auc: 0.983071,  test auc: 0.980105
epoch 404, loss: 0.078583
epoch 404, 
 train loss: 0.078583, val loss: 0.148924 
 val auc: 0.983258,  test auc: 0.980659
epoch 405, loss: 0.078149
model updated at epoch 405 
epoch 405, 
 train loss: 0.078149, val loss: 0.147784 
 val auc: 0.983108,  test auc: 0.980377
epoch 406, loss: 0.077772
epoch 406, 
 train loss: 0.077772, val loss: 0.148381 
 val auc: 0.983108,  test auc: 0.980593
epoch 407, loss: 0.077488
epoch 407, 
 train loss: 0.077488, val loss: 0.148053 
 val auc: 0.983146,  test auc: 0.980518
epoch 408, loss: 0.077292
model updated at epoch 408 
epoch 408, 
 train loss: 0.077292, val loss: 0.147674 
 val auc: 0.983146,  test auc: 0.980480
epoch 409, loss: 0.077143
epoch 409, 
 train loss: 0.077143, val loss: 0.147980 
 val auc: 0.983221,  test auc: 0.980659
epoch 410, loss: 0.077034
model updated at epoch 410 
epoch 410, 
 train loss: 0.077034, val loss: 0.147349 
 val auc: 0.983221,  test auc: 0.980443
epoch 411, loss: 0.076903
epoch 411, 
 train loss: 0.076903, val loss: 0.148654 
 val auc: 0.983071,  test auc: 0.980602
epoch 412, loss: 0.076801
model updated at epoch 412 
epoch 412, 
 train loss: 0.076801, val loss: 0.147291 
 val auc: 0.983146,  test auc: 0.980274
epoch 413, loss: 0.076629
epoch 413, 
 train loss: 0.076629, val loss: 0.148271 
 val auc: 0.983221,  test auc: 0.980753
epoch 414, loss: 0.076495
model updated at epoch 414 
epoch 414, 
 train loss: 0.076495, val loss: 0.146795 
 val auc: 0.983108,  test auc: 0.980368
epoch 415, loss: 0.076189
epoch 415, 
 train loss: 0.076189, val loss: 0.148173 
 val auc: 0.983183,  test auc: 0.980743
epoch 416, loss: 0.075858
model updated at epoch 416 
epoch 416, 
 train loss: 0.075858, val loss: 0.146402 
 val auc: 0.983258,  test auc: 0.980443
epoch 417, loss: 0.075489
epoch 417, 
 train loss: 0.075489, val loss: 0.147129 
 val auc: 0.983296,  test auc: 0.980612
epoch 418, loss: 0.075113
model updated at epoch 418 
epoch 418, 
 train loss: 0.075113, val loss: 0.146023 
 val auc: 0.983296,  test auc: 0.980415
epoch 419, loss: 0.074795
epoch 419, 
 train loss: 0.074795, val loss: 0.146405 
 val auc: 0.983446,  test auc: 0.980678
epoch 420, loss: 0.074507
model updated at epoch 420 
epoch 420, 
 train loss: 0.074507, val loss: 0.145731 
 val auc: 0.983559,  test auc: 0.980602
epoch 421, loss: 0.074241
model updated at epoch 421 
epoch 421, 
 train loss: 0.074241, val loss: 0.145639 
 val auc: 0.983521,  test auc: 0.980649
epoch 422, loss: 0.074043
epoch 422, 
 train loss: 0.074043, val loss: 0.145644 
 val auc: 0.983521,  test auc: 0.980668
epoch 423, loss: 0.073841
model updated at epoch 423 
epoch 423, 
 train loss: 0.073841, val loss: 0.145474 
 val auc: 0.983521,  test auc: 0.980556
epoch 424, loss: 0.073688
epoch 424, 
 train loss: 0.073688, val loss: 0.146235 
 val auc: 0.983408,  test auc: 0.980659
epoch 425, loss: 0.073545
epoch 425, 
 train loss: 0.073545, val loss: 0.145703 
 val auc: 0.983408,  test auc: 0.980518
epoch 426, loss: 0.073390
epoch 426, 
 train loss: 0.073390, val loss: 0.146320 
 val auc: 0.983371,  test auc: 0.980668
epoch 427, loss: 0.073258
model updated at epoch 427 
epoch 427, 
 train loss: 0.073258, val loss: 0.145222 
 val auc: 0.983521,  test auc: 0.980499
epoch 428, loss: 0.073047
epoch 428, 
 train loss: 0.073047, val loss: 0.146079 
 val auc: 0.983258,  test auc: 0.980715
epoch 429, loss: 0.072909
model updated at epoch 429 
epoch 429, 
 train loss: 0.072909, val loss: 0.145017 
 val auc: 0.983671,  test auc: 0.980513
epoch 430, loss: 0.072701
epoch 430, 
 train loss: 0.072701, val loss: 0.146149 
 val auc: 0.983333,  test auc: 0.980696
epoch 431, loss: 0.072479
model updated at epoch 431 
epoch 431, 
 train loss: 0.072479, val loss: 0.144851 
 val auc: 0.983634,  test auc: 0.980556
epoch 432, loss: 0.072232
epoch 432, 
 train loss: 0.072232, val loss: 0.145861 
 val auc: 0.983296,  test auc: 0.980743
epoch 433, loss: 0.071976
model updated at epoch 433 
epoch 433, 
 train loss: 0.071976, val loss: 0.144658 
 val auc: 0.983483,  test auc: 0.980556
epoch 434, loss: 0.071697
epoch 434, 
 train loss: 0.071697, val loss: 0.145211 
 val auc: 0.983521,  test auc: 0.980875
epoch 435, loss: 0.071431
model updated at epoch 435 
epoch 435, 
 train loss: 0.071431, val loss: 0.143932 
 val auc: 0.983671,  test auc: 0.980734
epoch 436, loss: 0.071114
epoch 436, 
 train loss: 0.071114, val loss: 0.144622 
 val auc: 0.983521,  test auc: 0.980846
epoch 437, loss: 0.070855
epoch 437, 
 train loss: 0.070855, val loss: 0.143986 
 val auc: 0.983709,  test auc: 0.980724
epoch 438, loss: 0.070603
epoch 438, 
 train loss: 0.070603, val loss: 0.144101 
 val auc: 0.983596,  test auc: 0.980790
epoch 439, loss: 0.070350
model updated at epoch 439 
epoch 439, 
 train loss: 0.070350, val loss: 0.143220 
 val auc: 0.983784,  test auc: 0.980884
epoch 440, loss: 0.070138
model updated at epoch 440 
epoch 440, 
 train loss: 0.070138, val loss: 0.142990 
 val auc: 0.983746,  test auc: 0.980931
epoch 441, loss: 0.069923
model updated at epoch 441 
epoch 441, 
 train loss: 0.069923, val loss: 0.142704 
 val auc: 0.983859,  test auc: 0.980931
epoch 442, loss: 0.069711
epoch 442, 
 train loss: 0.069711, val loss: 0.142871 
 val auc: 0.983896,  test auc: 0.980922
epoch 443, loss: 0.069520
model updated at epoch 443 
epoch 443, 
 train loss: 0.069520, val loss: 0.142640 
 val auc: 0.983821,  test auc: 0.980875
epoch 444, loss: 0.069319
model updated at epoch 444 
epoch 444, 
 train loss: 0.069319, val loss: 0.142291 
 val auc: 0.983784,  test auc: 0.980856
epoch 445, loss: 0.069131
epoch 445, 
 train loss: 0.069131, val loss: 0.142402 
 val auc: 0.983859,  test auc: 0.980903
epoch 446, loss: 0.068954
model updated at epoch 446 
epoch 446, 
 train loss: 0.068954, val loss: 0.142237 
 val auc: 0.983859,  test auc: 0.980922
epoch 447, loss: 0.068786
epoch 447, 
 train loss: 0.068786, val loss: 0.142422 
 val auc: 0.983859,  test auc: 0.980922
epoch 448, loss: 0.068650
model updated at epoch 448 
epoch 448, 
 train loss: 0.068650, val loss: 0.141968 
 val auc: 0.983821,  test auc: 0.980903
epoch 449, loss: 0.068550
epoch 449, 
 train loss: 0.068550, val loss: 0.142540 
 val auc: 0.983746,  test auc: 0.980875
epoch 450, loss: 0.068511
model updated at epoch 450 
epoch 450, 
 train loss: 0.068511, val loss: 0.141706 
 val auc: 0.983859,  test auc: 0.980715
epoch 451, loss: 0.068528
epoch 451, 
 train loss: 0.068528, val loss: 0.143312 
 val auc: 0.983746,  test auc: 0.980875
epoch 452, loss: 0.068701
epoch 452, 
 train loss: 0.068701, val loss: 0.142092 
 val auc: 0.983746,  test auc: 0.980593
epoch 453, loss: 0.068790
epoch 453, 
 train loss: 0.068790, val loss: 0.144213 
 val auc: 0.983671,  test auc: 0.980922
epoch 454, loss: 0.068975
epoch 454, 
 train loss: 0.068975, val loss: 0.142576 
 val auc: 0.983859,  test auc: 0.980527
epoch 455, loss: 0.068602
epoch 455, 
 train loss: 0.068602, val loss: 0.144402 
 val auc: 0.983521,  test auc: 0.980790
epoch 456, loss: 0.068216
model updated at epoch 456 
epoch 456, 
 train loss: 0.068216, val loss: 0.141553 
 val auc: 0.983821,  test auc: 0.980546
epoch 457, loss: 0.067446
epoch 457, 
 train loss: 0.067446, val loss: 0.141949 
 val auc: 0.983896,  test auc: 0.981015
epoch 458, loss: 0.066842
model updated at epoch 458 
epoch 458, 
 train loss: 0.066842, val loss: 0.140785 
 val auc: 0.983971,  test auc: 0.980865
epoch 459, loss: 0.066554
epoch 459, 
 train loss: 0.066554, val loss: 0.141293 
 val auc: 0.983821,  test auc: 0.980706
epoch 460, loss: 0.066538
epoch 460, 
 train loss: 0.066538, val loss: 0.141544 
 val auc: 0.983896,  test auc: 0.980912
epoch 461, loss: 0.066696
model updated at epoch 461 
epoch 461, 
 train loss: 0.066696, val loss: 0.140705 
 val auc: 0.983784,  test auc: 0.980621
epoch 462, loss: 0.066649
epoch 462, 
 train loss: 0.066649, val loss: 0.142692 
 val auc: 0.983821,  test auc: 0.980875
epoch 463, loss: 0.066492
epoch 463, 
 train loss: 0.066492, val loss: 0.141235 
 val auc: 0.983821,  test auc: 0.980518
epoch 464, loss: 0.066034
epoch 464, 
 train loss: 0.066034, val loss: 0.141643 
 val auc: 0.983859,  test auc: 0.980922
epoch 465, loss: 0.065632
model updated at epoch 465 
epoch 465, 
 train loss: 0.065632, val loss: 0.139982 
 val auc: 0.983821,  test auc: 0.980781
epoch 466, loss: 0.065319
epoch 466, 
 train loss: 0.065319, val loss: 0.140442 
 val auc: 0.983859,  test auc: 0.980875
epoch 467, loss: 0.065228
epoch 467, 
 train loss: 0.065228, val loss: 0.141090 
 val auc: 0.983784,  test auc: 0.980753
epoch 468, loss: 0.065192
model updated at epoch 468 
epoch 468, 
 train loss: 0.065192, val loss: 0.139900 
 val auc: 0.983934,  test auc: 0.980800
epoch 469, loss: 0.065161
epoch 469, 
 train loss: 0.065161, val loss: 0.140193 
 val auc: 0.983934,  test auc: 0.981062
epoch 470, loss: 0.065008
model updated at epoch 470 
epoch 470, 
 train loss: 0.065008, val loss: 0.139515 
 val auc: 0.983859,  test auc: 0.980781
epoch 471, loss: 0.064756
epoch 471, 
 train loss: 0.064756, val loss: 0.141171 
 val auc: 0.983821,  test auc: 0.980828
epoch 472, loss: 0.064448
epoch 472, 
 train loss: 0.064448, val loss: 0.139911 
 val auc: 0.983784,  test auc: 0.980771
epoch 473, loss: 0.064178
model updated at epoch 473 
epoch 473, 
 train loss: 0.064178, val loss: 0.139513 
 val auc: 0.983896,  test auc: 0.981006
epoch 474, loss: 0.063976
model updated at epoch 474 
epoch 474, 
 train loss: 0.063976, val loss: 0.139338 
 val auc: 0.983896,  test auc: 0.980931
epoch 475, loss: 0.063854
epoch 475, 
 train loss: 0.063854, val loss: 0.139538 
 val auc: 0.983971,  test auc: 0.980781
epoch 476, loss: 0.063740
epoch 476, 
 train loss: 0.063740, val loss: 0.139824 
 val auc: 0.983896,  test auc: 0.980959
epoch 477, loss: 0.063639
model updated at epoch 477 
epoch 477, 
 train loss: 0.063639, val loss: 0.138987 
 val auc: 0.983896,  test auc: 0.980884
epoch 478, loss: 0.063507
epoch 478, 
 train loss: 0.063507, val loss: 0.140028 
 val auc: 0.983821,  test auc: 0.980931
epoch 479, loss: 0.063349
epoch 479, 
 train loss: 0.063349, val loss: 0.139421 
 val auc: 0.983859,  test auc: 0.980753
epoch 480, loss: 0.063132
epoch 480, 
 train loss: 0.063132, val loss: 0.139851 
 val auc: 0.983784,  test auc: 0.980940
epoch 481, loss: 0.062921
model updated at epoch 481 
epoch 481, 
 train loss: 0.062921, val loss: 0.138853 
 val auc: 0.983934,  test auc: 0.980893
epoch 482, loss: 0.062705
epoch 482, 
 train loss: 0.062705, val loss: 0.139395 
 val auc: 0.983896,  test auc: 0.980922
epoch 483, loss: 0.062533
epoch 483, 
 train loss: 0.062533, val loss: 0.139469 
 val auc: 0.983896,  test auc: 0.980818
epoch 484, loss: 0.062363
epoch 484, 
 train loss: 0.062363, val loss: 0.139013 
 val auc: 0.983971,  test auc: 0.980903
epoch 485, loss: 0.062208
model updated at epoch 485 
epoch 485, 
 train loss: 0.062208, val loss: 0.138682 
 val auc: 0.983896,  test auc: 0.980959
epoch 486, loss: 0.062078
model updated at epoch 486 
epoch 486, 
 train loss: 0.062078, val loss: 0.138657 
 val auc: 0.983896,  test auc: 0.980846
epoch 487, loss: 0.061946
epoch 487, 
 train loss: 0.061946, val loss: 0.139023 
 val auc: 0.983934,  test auc: 0.980893
epoch 488, loss: 0.061800
model updated at epoch 488 
epoch 488, 
 train loss: 0.061800, val loss: 0.138377 
 val auc: 0.983934,  test auc: 0.980828
epoch 489, loss: 0.061653
epoch 489, 
 train loss: 0.061653, val loss: 0.138874 
 val auc: 0.983934,  test auc: 0.980922
epoch 490, loss: 0.061496
epoch 490, 
 train loss: 0.061496, val loss: 0.138708 
 val auc: 0.983971,  test auc: 0.980828
epoch 491, loss: 0.061335
epoch 491, 
 train loss: 0.061335, val loss: 0.139174 
 val auc: 0.983896,  test auc: 0.980856
epoch 492, loss: 0.061174
model updated at epoch 492 
epoch 492, 
 train loss: 0.061174, val loss: 0.137933 
 val auc: 0.984047,  test auc: 0.980865
epoch 493, loss: 0.061012
epoch 493, 
 train loss: 0.061012, val loss: 0.138363 
 val auc: 0.983896,  test auc: 0.980846
epoch 494, loss: 0.060852
epoch 494, 
 train loss: 0.060852, val loss: 0.138564 
 val auc: 0.983934,  test auc: 0.980781
epoch 495, loss: 0.060684
epoch 495, 
 train loss: 0.060684, val loss: 0.138751 
 val auc: 0.983971,  test auc: 0.980875
epoch 496, loss: 0.060543
epoch 496, 
 train loss: 0.060543, val loss: 0.137936 
 val auc: 0.983971,  test auc: 0.980893
epoch 497, loss: 0.060383
epoch 497, 
 train loss: 0.060383, val loss: 0.138453 
 val auc: 0.983971,  test auc: 0.980893
epoch 498, loss: 0.060234
epoch 498, 
 train loss: 0.060234, val loss: 0.138696 
 val auc: 0.983934,  test auc: 0.980743
epoch 499, loss: 0.060086
epoch 499, 
 train loss: 0.060086, val loss: 0.138857 
 val auc: 0.983896,  test auc: 0.980743
epoch 500, loss: 0.059939
model updated at epoch 500 
epoch 500, 
 train loss: 0.059939, val loss: 0.137842 
 val auc: 0.983896,  test auc: 0.980856
epoch 501, loss: 0.059784
epoch 501, 
 train loss: 0.059784, val loss: 0.137926 
 val auc: 0.984009,  test auc: 0.980856
epoch 502, loss: 0.059639
epoch 502, 
 train loss: 0.059639, val loss: 0.138254 
 val auc: 0.983934,  test auc: 0.980696
epoch 503, loss: 0.059482
epoch 503, 
 train loss: 0.059482, val loss: 0.138412 
 val auc: 0.983971,  test auc: 0.980800
epoch 504, loss: 0.059345
model updated at epoch 504 
epoch 504, 
 train loss: 0.059345, val loss: 0.137777 
 val auc: 0.984047,  test auc: 0.980828
epoch 505, loss: 0.059234
epoch 505, 
 train loss: 0.059234, val loss: 0.138322 
 val auc: 0.984047,  test auc: 0.980790
epoch 506, loss: 0.059096
epoch 506, 
 train loss: 0.059096, val loss: 0.137969 
 val auc: 0.984009,  test auc: 0.980743
epoch 507, loss: 0.058964
epoch 507, 
 train loss: 0.058964, val loss: 0.138294 
 val auc: 0.984084,  test auc: 0.980865
epoch 508, loss: 0.058855
model updated at epoch 508 
epoch 508, 
 train loss: 0.058855, val loss: 0.137540 
 val auc: 0.983971,  test auc: 0.980753
epoch 509, loss: 0.058731
epoch 509, 
 train loss: 0.058731, val loss: 0.138443 
 val auc: 0.984047,  test auc: 0.980912
epoch 510, loss: 0.058647
epoch 510, 
 train loss: 0.058647, val loss: 0.137760 
 val auc: 0.984009,  test auc: 0.980687
epoch 511, loss: 0.058531
epoch 511, 
 train loss: 0.058531, val loss: 0.138055 
 val auc: 0.984122,  test auc: 0.980884
epoch 512, loss: 0.058454
model updated at epoch 512 
epoch 512, 
 train loss: 0.058454, val loss: 0.136850 
 val auc: 0.984234,  test auc: 0.980781
epoch 513, loss: 0.058322
epoch 513, 
 train loss: 0.058322, val loss: 0.138386 
 val auc: 0.984084,  test auc: 0.980903
epoch 514, loss: 0.058199
epoch 514, 
 train loss: 0.058199, val loss: 0.137700 
 val auc: 0.984047,  test auc: 0.980649
epoch 515, loss: 0.058011
epoch 515, 
 train loss: 0.058011, val loss: 0.138454 
 val auc: 0.984084,  test auc: 0.980912
epoch 516, loss: 0.057812
epoch 516, 
 train loss: 0.057812, val loss: 0.137175 
 val auc: 0.984197,  test auc: 0.980734
epoch 517, loss: 0.057570
epoch 517, 
 train loss: 0.057570, val loss: 0.138276 
 val auc: 0.984122,  test auc: 0.980743
epoch 518, loss: 0.057357
epoch 518, 
 train loss: 0.057357, val loss: 0.137391 
 val auc: 0.984197,  test auc: 0.980574
epoch 519, loss: 0.057164
epoch 519, 
 train loss: 0.057164, val loss: 0.137100 
 val auc: 0.984009,  test auc: 0.980762
epoch 520, loss: 0.056987
epoch 520, 
 train loss: 0.056987, val loss: 0.136877 
 val auc: 0.984084,  test auc: 0.980790
epoch 521, loss: 0.056857
epoch 521, 
 train loss: 0.056857, val loss: 0.137649 
 val auc: 0.984009,  test auc: 0.980678
epoch 522, loss: 0.056694
epoch 522, 
 train loss: 0.056694, val loss: 0.137211 
 val auc: 0.984047,  test auc: 0.980706
epoch 523, loss: 0.056588
model updated at epoch 523 
epoch 523, 
 train loss: 0.056588, val loss: 0.136586 
 val auc: 0.984159,  test auc: 0.980762
epoch 524, loss: 0.056467
epoch 524, 
 train loss: 0.056467, val loss: 0.137486 
 val auc: 0.984122,  test auc: 0.980696
epoch 525, loss: 0.056377
epoch 525, 
 train loss: 0.056377, val loss: 0.137457 
 val auc: 0.984197,  test auc: 0.980574
epoch 526, loss: 0.056265
epoch 526, 
 train loss: 0.056265, val loss: 0.137757 
 val auc: 0.984197,  test auc: 0.980800
epoch 527, loss: 0.056178
model updated at epoch 527 
epoch 527, 
 train loss: 0.056178, val loss: 0.136561 
 val auc: 0.984122,  test auc: 0.980753
epoch 528, loss: 0.056071
epoch 528, 
 train loss: 0.056071, val loss: 0.137816 
 val auc: 0.984197,  test auc: 0.980856
epoch 529, loss: 0.056018
epoch 529, 
 train loss: 0.056018, val loss: 0.137127 
 val auc: 0.984084,  test auc: 0.980574
epoch 530, loss: 0.055904
epoch 530, 
 train loss: 0.055904, val loss: 0.137740 
 val auc: 0.984197,  test auc: 0.980997
epoch 531, loss: 0.055804
epoch 531, 
 train loss: 0.055804, val loss: 0.136680 
 val auc: 0.984159,  test auc: 0.980734
epoch 532, loss: 0.055633
epoch 532, 
 train loss: 0.055633, val loss: 0.138631 
 val auc: 0.984234,  test auc: 0.980837
epoch 533, loss: 0.055581
epoch 533, 
 train loss: 0.055581, val loss: 0.137443 
 val auc: 0.984047,  test auc: 0.980396
epoch 534, loss: 0.055439
epoch 534, 
 train loss: 0.055439, val loss: 0.137903 
 val auc: 0.984309,  test auc: 0.980997
epoch 535, loss: 0.055287
model updated at epoch 535 
epoch 535, 
 train loss: 0.055287, val loss: 0.136513 
 val auc: 0.984122,  test auc: 0.980734
epoch 536, loss: 0.055069
epoch 536, 
 train loss: 0.055069, val loss: 0.138328 
 val auc: 0.984197,  test auc: 0.980922
epoch 537, loss: 0.054871
epoch 537, 
 train loss: 0.054871, val loss: 0.137135 
 val auc: 0.984122,  test auc: 0.980678
epoch 538, loss: 0.054654
epoch 538, 
 train loss: 0.054654, val loss: 0.137044 
 val auc: 0.984159,  test auc: 0.980922
epoch 539, loss: 0.054467
model updated at epoch 539 
epoch 539, 
 train loss: 0.054467, val loss: 0.135810 
 val auc: 0.984159,  test auc: 0.980912
epoch 540, loss: 0.054297
epoch 540, 
 train loss: 0.054297, val loss: 0.136174 
 val auc: 0.984384,  test auc: 0.980959
epoch 541, loss: 0.054150
epoch 541, 
 train loss: 0.054150, val loss: 0.135973 
 val auc: 0.984347,  test auc: 0.980922
epoch 542, loss: 0.054009
epoch 542, 
 train loss: 0.054009, val loss: 0.135878 
 val auc: 0.984347,  test auc: 0.980931
epoch 543, loss: 0.053907
epoch 543, 
 train loss: 0.053907, val loss: 0.136094 
 val auc: 0.984272,  test auc: 0.980959
epoch 544, loss: 0.053795
epoch 544, 
 train loss: 0.053795, val loss: 0.136079 
 val auc: 0.984234,  test auc: 0.980903
epoch 545, loss: 0.053689
epoch 545, 
 train loss: 0.053689, val loss: 0.136658 
 val auc: 0.984309,  test auc: 0.980931
epoch 546, loss: 0.053579
model updated at epoch 546 
epoch 546, 
 train loss: 0.053579, val loss: 0.135431 
 val auc: 0.984384,  test auc: 0.980997
epoch 547, loss: 0.053458
epoch 547, 
 train loss: 0.053458, val loss: 0.135769 
 val auc: 0.984347,  test auc: 0.981006
epoch 548, loss: 0.053329
model updated at epoch 548 
epoch 548, 
 train loss: 0.053329, val loss: 0.135419 
 val auc: 0.984347,  test auc: 0.980875
epoch 549, loss: 0.053205
epoch 549, 
 train loss: 0.053205, val loss: 0.136549 
 val auc: 0.984159,  test auc: 0.980922
epoch 550, loss: 0.053086
epoch 550, 
 train loss: 0.053086, val loss: 0.135871 
 val auc: 0.984234,  test auc: 0.980959
epoch 551, loss: 0.052968
epoch 551, 
 train loss: 0.052968, val loss: 0.136298 
 val auc: 0.984309,  test auc: 0.981044
epoch 552, loss: 0.052844
epoch 552, 
 train loss: 0.052844, val loss: 0.135514 
 val auc: 0.984347,  test auc: 0.980959
epoch 553, loss: 0.052712
epoch 553, 
 train loss: 0.052712, val loss: 0.136158 
 val auc: 0.984272,  test auc: 0.980940
epoch 554, loss: 0.052582
epoch 554, 
 train loss: 0.052582, val loss: 0.135571 
 val auc: 0.984384,  test auc: 0.980931
epoch 555, loss: 0.052444
epoch 555, 
 train loss: 0.052444, val loss: 0.136109 
 val auc: 0.984309,  test auc: 0.980936
epoch 556, loss: 0.052327
epoch 556, 
 train loss: 0.052327, val loss: 0.135681 
 val auc: 0.984347,  test auc: 0.981006
epoch 557, loss: 0.052200
epoch 557, 
 train loss: 0.052200, val loss: 0.135860 
 val auc: 0.984459,  test auc: 0.980968
epoch 558, loss: 0.052071
model updated at epoch 558 
epoch 558, 
 train loss: 0.052071, val loss: 0.135132 
 val auc: 0.984497,  test auc: 0.980968
epoch 559, loss: 0.051949
epoch 559, 
 train loss: 0.051949, val loss: 0.135234 
 val auc: 0.984459,  test auc: 0.980922
epoch 560, loss: 0.051839
epoch 560, 
 train loss: 0.051839, val loss: 0.135138 
 val auc: 0.984384,  test auc: 0.980903
epoch 561, loss: 0.051717
epoch 561, 
 train loss: 0.051717, val loss: 0.135645 
 val auc: 0.984384,  test auc: 0.980884
epoch 562, loss: 0.051596
epoch 562, 
 train loss: 0.051596, val loss: 0.135252 
 val auc: 0.984422,  test auc: 0.980978
epoch 563, loss: 0.051484
epoch 563, 
 train loss: 0.051484, val loss: 0.135326 
 val auc: 0.984497,  test auc: 0.981034
epoch 564, loss: 0.051370
epoch 564, 
 train loss: 0.051370, val loss: 0.135322 
 val auc: 0.984459,  test auc: 0.980997
epoch 565, loss: 0.051249
epoch 565, 
 train loss: 0.051249, val loss: 0.135821 
 val auc: 0.984422,  test auc: 0.980968
epoch 566, loss: 0.051136
epoch 566, 
 train loss: 0.051136, val loss: 0.135699 
 val auc: 0.984347,  test auc: 0.980968
epoch 567, loss: 0.051027
epoch 567, 
 train loss: 0.051027, val loss: 0.135663 
 val auc: 0.984309,  test auc: 0.981001
epoch 568, loss: 0.050916
epoch 568, 
 train loss: 0.050916, val loss: 0.135165 
 val auc: 0.984384,  test auc: 0.981015
epoch 569, loss: 0.050808
epoch 569, 
 train loss: 0.050808, val loss: 0.135433 
 val auc: 0.984459,  test auc: 0.981034
epoch 570, loss: 0.050699
epoch 570, 
 train loss: 0.050699, val loss: 0.135207 
 val auc: 0.984347,  test auc: 0.980978
epoch 571, loss: 0.050593
epoch 571, 
 train loss: 0.050593, val loss: 0.135663 
 val auc: 0.984497,  test auc: 0.981090
epoch 572, loss: 0.050492
epoch 572, 
 train loss: 0.050492, val loss: 0.135695 
 val auc: 0.984234,  test auc: 0.980997
epoch 573, loss: 0.050393
epoch 573, 
 train loss: 0.050393, val loss: 0.136137 
 val auc: 0.984422,  test auc: 0.981072
epoch 574, loss: 0.050298
epoch 574, 
 train loss: 0.050298, val loss: 0.135319 
 val auc: 0.984422,  test auc: 0.981062
epoch 575, loss: 0.050212
epoch 575, 
 train loss: 0.050212, val loss: 0.135897 
 val auc: 0.984497,  test auc: 0.981072
epoch 576, loss: 0.050131
epoch 576, 
 train loss: 0.050131, val loss: 0.135528 
 val auc: 0.984309,  test auc: 0.980940
epoch 577, loss: 0.050055
epoch 577, 
 train loss: 0.050055, val loss: 0.136552 
 val auc: 0.984459,  test auc: 0.981128
epoch 578, loss: 0.049987
epoch 578, 
 train loss: 0.049987, val loss: 0.135274 
 val auc: 0.984234,  test auc: 0.980978
epoch 579, loss: 0.049909
epoch 579, 
 train loss: 0.049909, val loss: 0.136174 
 val auc: 0.984384,  test auc: 0.981128
epoch 580, loss: 0.049825
model updated at epoch 580 
epoch 580, 
 train loss: 0.049825, val loss: 0.135127 
 val auc: 0.984309,  test auc: 0.980940
epoch 581, loss: 0.049731
epoch 581, 
 train loss: 0.049731, val loss: 0.136723 
 val auc: 0.984497,  test auc: 0.981109
epoch 582, loss: 0.049675
model updated at epoch 582 
epoch 582, 
 train loss: 0.049675, val loss: 0.135080 
 val auc: 0.984309,  test auc: 0.980950
epoch 583, loss: 0.049575
epoch 583, 
 train loss: 0.049575, val loss: 0.136575 
 val auc: 0.984422,  test auc: 0.981194
epoch 584, loss: 0.049501
epoch 584, 
 train loss: 0.049501, val loss: 0.135635 
 val auc: 0.984309,  test auc: 0.980856
epoch 585, loss: 0.049380
epoch 585, 
 train loss: 0.049380, val loss: 0.137001 
 val auc: 0.984422,  test auc: 0.981072
epoch 586, loss: 0.049277
epoch 586, 
 train loss: 0.049277, val loss: 0.135185 
 val auc: 0.984309,  test auc: 0.981034
epoch 587, loss: 0.049128
epoch 587, 
 train loss: 0.049128, val loss: 0.136797 
 val auc: 0.984497,  test auc: 0.981119
epoch 588, loss: 0.048961
epoch 588, 
 train loss: 0.048961, val loss: 0.135435 
 val auc: 0.984347,  test auc: 0.980978
epoch 589, loss: 0.048798
epoch 589, 
 train loss: 0.048798, val loss: 0.135841 
 val auc: 0.984459,  test auc: 0.981156
epoch 590, loss: 0.048643
epoch 590, 
 train loss: 0.048643, val loss: 0.135339 
 val auc: 0.984422,  test auc: 0.981090
epoch 591, loss: 0.048511
epoch 591, 
 train loss: 0.048511, val loss: 0.136243 
 val auc: 0.984384,  test auc: 0.981044
epoch 592, loss: 0.048400
epoch 592, 
 train loss: 0.048400, val loss: 0.135809 
 val auc: 0.984422,  test auc: 0.981044
epoch 593, loss: 0.048310
epoch 593, 
 train loss: 0.048310, val loss: 0.135422 
 val auc: 0.984497,  test auc: 0.981128
epoch 594, loss: 0.048235
epoch 594, 
 train loss: 0.048235, val loss: 0.135531 
 val auc: 0.984497,  test auc: 0.981119
epoch 595, loss: 0.048165
epoch 595, 
 train loss: 0.048165, val loss: 0.135163 
 val auc: 0.984497,  test auc: 0.981090
epoch 596, loss: 0.048094
epoch 596, 
 train loss: 0.048094, val loss: 0.136014 
 val auc: 0.984422,  test auc: 0.981156
epoch 597, loss: 0.048040
epoch 597, 
 train loss: 0.048040, val loss: 0.135213 
 val auc: 0.984422,  test auc: 0.981062
epoch 598, loss: 0.047987
epoch 598, 
 train loss: 0.047987, val loss: 0.136297 
 val auc: 0.984422,  test auc: 0.981109
epoch 599, loss: 0.047951
model updated at epoch 599 
epoch 599, 
 train loss: 0.047951, val loss: 0.134927 
 val auc: 0.984497,  test auc: 0.981025
epoch 600, loss: 0.047887
epoch 600, 
 train loss: 0.047887, val loss: 0.136006 
 val auc: 0.984459,  test auc: 0.981166
epoch 601, loss: 0.047791
model updated at epoch 601 
epoch 601, 
 train loss: 0.047791, val loss: 0.134912 
 val auc: 0.984422,  test auc: 0.981006
epoch 602, loss: 0.047650
epoch 602, 
 train loss: 0.047650, val loss: 0.136548 
 val auc: 0.984497,  test auc: 0.981184
epoch 603, loss: 0.047493
epoch 603, 
 train loss: 0.047493, val loss: 0.135037 
 val auc: 0.984535,  test auc: 0.981090
epoch 604, loss: 0.047340
epoch 604, 
 train loss: 0.047340, val loss: 0.135810 
 val auc: 0.984497,  test auc: 0.981090
epoch 605, loss: 0.047217
epoch 605, 
 train loss: 0.047217, val loss: 0.135237 
 val auc: 0.984535,  test auc: 0.981025
epoch 606, loss: 0.047118
model updated at epoch 606 
epoch 606, 
 train loss: 0.047118, val loss: 0.134905 
 val auc: 0.984572,  test auc: 0.981175
epoch 607, loss: 0.047028
epoch 607, 
 train loss: 0.047028, val loss: 0.135578 
 val auc: 0.984422,  test auc: 0.981081
epoch 608, loss: 0.046961
epoch 608, 
 train loss: 0.046961, val loss: 0.135813 
 val auc: 0.984459,  test auc: 0.980987
epoch 609, loss: 0.046898
epoch 609, 
 train loss: 0.046898, val loss: 0.135885 
 val auc: 0.984422,  test auc: 0.981175
epoch 610, loss: 0.046830
epoch 610, 
 train loss: 0.046830, val loss: 0.134912 
 val auc: 0.984572,  test auc: 0.981081
epoch 611, loss: 0.046766
epoch 611, 
 train loss: 0.046766, val loss: 0.136060 
 val auc: 0.984497,  test auc: 0.981081
epoch 612, loss: 0.046702
model updated at epoch 612 
epoch 612, 
 train loss: 0.046702, val loss: 0.134887 
 val auc: 0.984535,  test auc: 0.981006
epoch 613, loss: 0.046634
epoch 613, 
 train loss: 0.046634, val loss: 0.136032 
 val auc: 0.984459,  test auc: 0.981203
epoch 614, loss: 0.046558
epoch 614, 
 train loss: 0.046558, val loss: 0.135160 
 val auc: 0.984384,  test auc: 0.980978
epoch 615, loss: 0.046434
epoch 615, 
 train loss: 0.046434, val loss: 0.136439 
 val auc: 0.984459,  test auc: 0.981062
epoch 616, loss: 0.046317
epoch 616, 
 train loss: 0.046317, val loss: 0.135265 
 val auc: 0.984459,  test auc: 0.980959
epoch 617, loss: 0.046198
epoch 617, 
 train loss: 0.046198, val loss: 0.135945 
 val auc: 0.984497,  test auc: 0.981072
epoch 618, loss: 0.046075
epoch 618, 
 train loss: 0.046075, val loss: 0.135422 
 val auc: 0.984535,  test auc: 0.981006
epoch 619, loss: 0.045983
epoch 619, 
 train loss: 0.045983, val loss: 0.135774 
 val auc: 0.984459,  test auc: 0.980997
epoch 620, loss: 0.045899
epoch 620, 
 train loss: 0.045899, val loss: 0.135235 
 val auc: 0.984535,  test auc: 0.981119
epoch 621, loss: 0.045818
epoch 621, 
 train loss: 0.045818, val loss: 0.135029 
 val auc: 0.984497,  test auc: 0.981100
epoch 622, loss: 0.045759
epoch 622, 
 train loss: 0.045759, val loss: 0.136043 
 val auc: 0.984497,  test auc: 0.981062
epoch 623, loss: 0.045697
epoch 623, 
 train loss: 0.045697, val loss: 0.135299 
 val auc: 0.984459,  test auc: 0.980997
epoch 624, loss: 0.045651
epoch 624, 
 train loss: 0.045651, val loss: 0.136030 
 val auc: 0.984647,  test auc: 0.981166
epoch 625, loss: 0.045606
epoch 625, 
 train loss: 0.045606, val loss: 0.135246 
 val auc: 0.984459,  test auc: 0.980959
epoch 626, loss: 0.045570
epoch 626, 
 train loss: 0.045570, val loss: 0.136664 
 val auc: 0.984572,  test auc: 0.981194
epoch 627, loss: 0.045515
model updated at epoch 627 
epoch 627, 
 train loss: 0.045515, val loss: 0.134834 
 val auc: 0.984497,  test auc: 0.981081
epoch 628, loss: 0.045399
epoch 628, 
 train loss: 0.045399, val loss: 0.137027 
 val auc: 0.984497,  test auc: 0.981109
epoch 629, loss: 0.045293
epoch 629, 
 train loss: 0.045293, val loss: 0.135673 
 val auc: 0.984347,  test auc: 0.980884
epoch 630, loss: 0.045161
epoch 630, 
 train loss: 0.045161, val loss: 0.136256 
 val auc: 0.984572,  test auc: 0.981156
epoch 631, loss: 0.045016
epoch 631, 
 train loss: 0.045016, val loss: 0.135051 
 val auc: 0.984459,  test auc: 0.981034
epoch 632, loss: 0.044890
epoch 632, 
 train loss: 0.044890, val loss: 0.135945 
 val auc: 0.984422,  test auc: 0.981034
epoch 633, loss: 0.044778
epoch 633, 
 train loss: 0.044778, val loss: 0.135484 
 val auc: 0.984347,  test auc: 0.981053
epoch 634, loss: 0.044694
epoch 634, 
 train loss: 0.044694, val loss: 0.135642 
 val auc: 0.984384,  test auc: 0.981044
epoch 635, loss: 0.044633
epoch 635, 
 train loss: 0.044633, val loss: 0.136485 
 val auc: 0.984384,  test auc: 0.981072
epoch 636, loss: 0.044579
epoch 636, 
 train loss: 0.044579, val loss: 0.135399 
 val auc: 0.984422,  test auc: 0.981053
epoch 637, loss: 0.044533
epoch 637, 
 train loss: 0.044533, val loss: 0.136187 
 val auc: 0.984459,  test auc: 0.981128
epoch 638, loss: 0.044483
epoch 638, 
 train loss: 0.044483, val loss: 0.135218 
 val auc: 0.984347,  test auc: 0.981006
epoch 639, loss: 0.044418
epoch 639, 
 train loss: 0.044418, val loss: 0.136724 
 val auc: 0.984497,  test auc: 0.981147
epoch 640, loss: 0.044336
epoch 640, 
 train loss: 0.044336, val loss: 0.135215 
 val auc: 0.984422,  test auc: 0.981034
epoch 641, loss: 0.044232
epoch 641, 
 train loss: 0.044232, val loss: 0.136693 
 val auc: 0.984422,  test auc: 0.981072
epoch 642, loss: 0.044124
epoch 642, 
 train loss: 0.044124, val loss: 0.135489 
 val auc: 0.984384,  test auc: 0.981015
epoch 643, loss: 0.044014
epoch 643, 
 train loss: 0.044014, val loss: 0.136032 
 val auc: 0.984384,  test auc: 0.981034
epoch 644, loss: 0.043926
epoch 644, 
 train loss: 0.043926, val loss: 0.134919 
 val auc: 0.984384,  test auc: 0.981053
epoch 645, loss: 0.043832
epoch 645, 
 train loss: 0.043832, val loss: 0.135972 
 val auc: 0.984422,  test auc: 0.981015
epoch 646, loss: 0.043737
epoch 646, 
 train loss: 0.043737, val loss: 0.135322 
 val auc: 0.984422,  test auc: 0.981044
epoch 647, loss: 0.043661
epoch 647, 
 train loss: 0.043661, val loss: 0.135162 
 val auc: 0.984422,  test auc: 0.981137
epoch 648, loss: 0.043584
epoch 648, 
 train loss: 0.043584, val loss: 0.135353 
 val auc: 0.984347,  test auc: 0.981072
epoch 649, loss: 0.043503
epoch 649, 
 train loss: 0.043503, val loss: 0.135307 
 val auc: 0.984459,  test auc: 0.981100
epoch 650, loss: 0.043439
epoch 650, 
 train loss: 0.043439, val loss: 0.135268 
 val auc: 0.984347,  test auc: 0.981062
epoch 651, loss: 0.043375
epoch 651, 
 train loss: 0.043375, val loss: 0.135423 
 val auc: 0.984384,  test auc: 0.981034
epoch 652, loss: 0.043314
epoch 652, 
 train loss: 0.043314, val loss: 0.136413 
 val auc: 0.984347,  test auc: 0.980959
epoch 653, loss: 0.043247
epoch 653, 
 train loss: 0.043247, val loss: 0.135367 
 val auc: 0.984422,  test auc: 0.981062
epoch 654, loss: 0.043183
epoch 654, 
 train loss: 0.043183, val loss: 0.135639 
 val auc: 0.984459,  test auc: 0.981072
epoch 655, loss: 0.043123
model updated at epoch 655 
epoch 655, 
 train loss: 0.043123, val loss: 0.134606 
 val auc: 0.984459,  test auc: 0.981034
epoch 656, loss: 0.043053
epoch 656, 
 train loss: 0.043053, val loss: 0.135555 
 val auc: 0.984459,  test auc: 0.981072
epoch 657, loss: 0.042970
epoch 657, 
 train loss: 0.042970, val loss: 0.135000 
 val auc: 0.984347,  test auc: 0.981025
epoch 658, loss: 0.042886
epoch 658, 
 train loss: 0.042886, val loss: 0.136321 
 val auc: 0.984384,  test auc: 0.981006
epoch 659, loss: 0.042807
epoch 659, 
 train loss: 0.042807, val loss: 0.135683 
 val auc: 0.984422,  test auc: 0.981025
epoch 660, loss: 0.042731
epoch 660, 
 train loss: 0.042731, val loss: 0.135668 
 val auc: 0.984422,  test auc: 0.981081
epoch 661, loss: 0.042646
epoch 661, 
 train loss: 0.042646, val loss: 0.135339 
 val auc: 0.984309,  test auc: 0.981053
epoch 662, loss: 0.042568
epoch 662, 
 train loss: 0.042568, val loss: 0.136016 
 val auc: 0.984347,  test auc: 0.981034
epoch 663, loss: 0.042496
epoch 663, 
 train loss: 0.042496, val loss: 0.135319 
 val auc: 0.984422,  test auc: 0.981062
epoch 664, loss: 0.042422
epoch 664, 
 train loss: 0.042422, val loss: 0.135297 
 val auc: 0.984422,  test auc: 0.981053
epoch 665, loss: 0.042355
epoch 665, 
 train loss: 0.042355, val loss: 0.135445 
 val auc: 0.984347,  test auc: 0.980997
epoch 666, loss: 0.042285
epoch 666, 
 train loss: 0.042285, val loss: 0.135247 
 val auc: 0.984347,  test auc: 0.981015
epoch 667, loss: 0.042218
epoch 667, 
 train loss: 0.042218, val loss: 0.135692 
 val auc: 0.984384,  test auc: 0.981062
epoch 668, loss: 0.042153
epoch 668, 
 train loss: 0.042153, val loss: 0.135637 
 val auc: 0.984309,  test auc: 0.981015
epoch 669, loss: 0.042091
epoch 669, 
 train loss: 0.042091, val loss: 0.136128 
 val auc: 0.984347,  test auc: 0.981025
epoch 670, loss: 0.042031
epoch 670, 
 train loss: 0.042031, val loss: 0.135584 
 val auc: 0.984384,  test auc: 0.980959
epoch 671, loss: 0.041968
epoch 671, 
 train loss: 0.041968, val loss: 0.136058 
 val auc: 0.984347,  test auc: 0.981062
epoch 672, loss: 0.041901
epoch 672, 
 train loss: 0.041901, val loss: 0.135427 
 val auc: 0.984459,  test auc: 0.981034
epoch 673, loss: 0.041831
epoch 673, 
 train loss: 0.041831, val loss: 0.136181 
 val auc: 0.984384,  test auc: 0.981081
epoch 674, loss: 0.041765
epoch 674, 
 train loss: 0.041765, val loss: 0.135479 
 val auc: 0.984459,  test auc: 0.981015
epoch 675, loss: 0.041702
epoch 675, 
 train loss: 0.041702, val loss: 0.136157 
 val auc: 0.984347,  test auc: 0.981100
epoch 676, loss: 0.041640
epoch 676, 
 train loss: 0.041640, val loss: 0.135647 
 val auc: 0.984535,  test auc: 0.981034
epoch 677, loss: 0.041573
epoch 677, 
 train loss: 0.041573, val loss: 0.135944 
 val auc: 0.984422,  test auc: 0.981137
epoch 678, loss: 0.041516
epoch 678, 
 train loss: 0.041516, val loss: 0.135408 
 val auc: 0.984497,  test auc: 0.981062
epoch 679, loss: 0.041478
epoch 679, 
 train loss: 0.041478, val loss: 0.136697 
 val auc: 0.984497,  test auc: 0.981175
epoch 680, loss: 0.041448
epoch 680, 
 train loss: 0.041448, val loss: 0.135330 
 val auc: 0.984459,  test auc: 0.981128
epoch 681, loss: 0.041410
epoch 681, 
 train loss: 0.041410, val loss: 0.137148 
 val auc: 0.984384,  test auc: 0.981156
epoch 682, loss: 0.041386
epoch 682, 
 train loss: 0.041386, val loss: 0.135624 
 val auc: 0.984384,  test auc: 0.981006
epoch 683, loss: 0.041347
epoch 683, 
 train loss: 0.041347, val loss: 0.137137 
 val auc: 0.984422,  test auc: 0.981194
epoch 684, loss: 0.041303
epoch 684, 
 train loss: 0.041303, val loss: 0.135177 
 val auc: 0.984422,  test auc: 0.981034
epoch 685, loss: 0.041244
epoch 685, 
 train loss: 0.041244, val loss: 0.137868 
 val auc: 0.984497,  test auc: 0.981147
epoch 686, loss: 0.041156
epoch 686, 
 train loss: 0.041156, val loss: 0.135055 
 val auc: 0.984459,  test auc: 0.981119
epoch 687, loss: 0.041034
epoch 687, 
 train loss: 0.041034, val loss: 0.137268 
 val auc: 0.984459,  test auc: 0.981119
epoch 688, loss: 0.040922
epoch 688, 
 train loss: 0.040922, val loss: 0.136214 
 val auc: 0.984459,  test auc: 0.981044
epoch 689, loss: 0.040802
epoch 689, 
 train loss: 0.040802, val loss: 0.136990 
 val auc: 0.984459,  test auc: 0.981128
epoch 690, loss: 0.040708
epoch 690, 
 train loss: 0.040708, val loss: 0.135966 
 val auc: 0.984422,  test auc: 0.981090
epoch 691, loss: 0.040641
epoch 691, 
 train loss: 0.040641, val loss: 0.136512 
 val auc: 0.984497,  test auc: 0.981081
epoch 692, loss: 0.040588
epoch 692, 
 train loss: 0.040588, val loss: 0.136569 
 val auc: 0.984422,  test auc: 0.981119
epoch 693, loss: 0.040552
epoch 693, 
 train loss: 0.040552, val loss: 0.135987 
 val auc: 0.984459,  test auc: 0.981119
epoch 694, loss: 0.040519
epoch 694, 
 train loss: 0.040519, val loss: 0.137589 
 val auc: 0.984497,  test auc: 0.981137
epoch 695, loss: 0.040496
epoch 695, 
 train loss: 0.040496, val loss: 0.135811 
 val auc: 0.984497,  test auc: 0.981119
epoch 696, loss: 0.040488
epoch 696, 
 train loss: 0.040488, val loss: 0.137150 
 val auc: 0.984572,  test auc: 0.981212
epoch 697, loss: 0.040477
epoch 697, 
 train loss: 0.040477, val loss: 0.135680 
 val auc: 0.984459,  test auc: 0.981090
epoch 698, loss: 0.040473
epoch 698, 
 train loss: 0.040473, val loss: 0.138571 
 val auc: 0.984572,  test auc: 0.981194
epoch 699, loss: 0.040446
epoch 699, 
 train loss: 0.040446, val loss: 0.135474 
 val auc: 0.984459,  test auc: 0.981175
epoch 700, loss: 0.040355
epoch 700, 
 train loss: 0.040355, val loss: 0.138368 
 val auc: 0.984572,  test auc: 0.981194
epoch 701, loss: 0.040257
epoch 701, 
 train loss: 0.040257, val loss: 0.135848 
 val auc: 0.984422,  test auc: 0.981053
epoch 702, loss: 0.040112
epoch 702, 
 train loss: 0.040112, val loss: 0.137663 
 val auc: 0.984610,  test auc: 0.981241
epoch 703, loss: 0.039968
epoch 703, 
 train loss: 0.039968, val loss: 0.136344 
 val auc: 0.984459,  test auc: 0.981175
epoch 704, loss: 0.039860
epoch 704, 
 train loss: 0.039860, val loss: 0.137841 
 val auc: 0.984422,  test auc: 0.981142
epoch 705, loss: 0.039770
epoch 705, 
 train loss: 0.039770, val loss: 0.136943 
 val auc: 0.984497,  test auc: 0.981166
epoch 706, loss: 0.039744
epoch 706, 
 train loss: 0.039744, val loss: 0.135966 
 val auc: 0.984459,  test auc: 0.981128
epoch 707, loss: 0.039730
epoch 707, 
 train loss: 0.039730, val loss: 0.137623 
 val auc: 0.984422,  test auc: 0.981128
epoch 708, loss: 0.039718
epoch 708, 
 train loss: 0.039718, val loss: 0.135988 
 val auc: 0.984422,  test auc: 0.981062
epoch 709, loss: 0.039685
epoch 709, 
 train loss: 0.039685, val loss: 0.138265 
 val auc: 0.984497,  test auc: 0.981184
epoch 710, loss: 0.039629
epoch 710, 
 train loss: 0.039629, val loss: 0.136518 
 val auc: 0.984384,  test auc: 0.981081
epoch 711, loss: 0.039548
epoch 711, 
 train loss: 0.039548, val loss: 0.138681 
 val auc: 0.984459,  test auc: 0.981147
epoch 712, loss: 0.039450
epoch 712, 
 train loss: 0.039450, val loss: 0.136058 
 val auc: 0.984497,  test auc: 0.981166
epoch 713, loss: 0.039332
epoch 713, 
 train loss: 0.039332, val loss: 0.137450 
 val auc: 0.984384,  test auc: 0.981222
epoch 714, loss: 0.039236
epoch 714, 
 train loss: 0.039236, val loss: 0.137234 
 val auc: 0.984497,  test auc: 0.981212
epoch 715, loss: 0.039164
epoch 715, 
 train loss: 0.039164, val loss: 0.137555 
 val auc: 0.984384,  test auc: 0.981194
epoch 716, loss: 0.039112
epoch 716, 
 train loss: 0.039112, val loss: 0.137315 
 val auc: 0.984384,  test auc: 0.981222
epoch 717, loss: 0.039063
epoch 717, 
 train loss: 0.039063, val loss: 0.136431 
 val auc: 0.984459,  test auc: 0.981156
epoch 718, loss: 0.039034
epoch 718, 
 train loss: 0.039034, val loss: 0.138157 
 val auc: 0.984459,  test auc: 0.981109
epoch 719, loss: 0.038987
epoch 719, 
 train loss: 0.038987, val loss: 0.136442 
 val auc: 0.984422,  test auc: 0.981156
epoch 720, loss: 0.038931
epoch 720, 
 train loss: 0.038931, val loss: 0.138558 
 val auc: 0.984459,  test auc: 0.981203
epoch 721, loss: 0.038874
epoch 721, 
 train loss: 0.038874, val loss: 0.137382 
 val auc: 0.984384,  test auc: 0.981062
epoch 722, loss: 0.038787
epoch 722, 
 train loss: 0.038787, val loss: 0.138253 
 val auc: 0.984384,  test auc: 0.981137
epoch 723, loss: 0.038706
epoch 723, 
 train loss: 0.038706, val loss: 0.136329 
 val auc: 0.984422,  test auc: 0.981109
epoch 724, loss: 0.038619
epoch 724, 
 train loss: 0.038619, val loss: 0.137879 
 val auc: 0.984422,  test auc: 0.981119
epoch 725, loss: 0.038533
epoch 725, 
 train loss: 0.038533, val loss: 0.137054 
 val auc: 0.984347,  test auc: 0.981119
epoch 726, loss: 0.038455
epoch 726, 
 train loss: 0.038455, val loss: 0.137879 
 val auc: 0.984422,  test auc: 0.981147
epoch 727, loss: 0.038381
epoch 727, 
 train loss: 0.038381, val loss: 0.138098 
 val auc: 0.984422,  test auc: 0.981137
epoch 728, loss: 0.038313
epoch 728, 
 train loss: 0.038313, val loss: 0.137542 
 val auc: 0.984384,  test auc: 0.981137
epoch 729, loss: 0.038251
epoch 729, 
 train loss: 0.038251, val loss: 0.137959 
 val auc: 0.984459,  test auc: 0.981166
epoch 730, loss: 0.038205
epoch 730, 
 train loss: 0.038205, val loss: 0.137272 
 val auc: 0.984459,  test auc: 0.981184
epoch 731, loss: 0.038176
epoch 731, 
 train loss: 0.038176, val loss: 0.138196 
 val auc: 0.984459,  test auc: 0.981203
epoch 732, loss: 0.038139
epoch 732, 
 train loss: 0.038139, val loss: 0.137433 
 val auc: 0.984497,  test auc: 0.981156
epoch 733, loss: 0.038097
epoch 733, 
 train loss: 0.038097, val loss: 0.138973 
 val auc: 0.984572,  test auc: 0.981212
epoch 734, loss: 0.038035
epoch 734, 
 train loss: 0.038035, val loss: 0.137171 
 val auc: 0.984497,  test auc: 0.981151
epoch 735, loss: 0.037952
epoch 735, 
 train loss: 0.037952, val loss: 0.138535 
 val auc: 0.984497,  test auc: 0.981147
epoch 736, loss: 0.037867
epoch 736, 
 train loss: 0.037867, val loss: 0.137406 
 val auc: 0.984497,  test auc: 0.981194
epoch 737, loss: 0.037797
epoch 737, 
 train loss: 0.037797, val loss: 0.137907 
 val auc: 0.984459,  test auc: 0.981222
epoch 738, loss: 0.037727
epoch 738, 
 train loss: 0.037727, val loss: 0.138181 
 val auc: 0.984459,  test auc: 0.981288
epoch 739, loss: 0.037681
epoch 739, 
 train loss: 0.037681, val loss: 0.138295 
 val auc: 0.984459,  test auc: 0.981203
epoch 740, loss: 0.037638
epoch 740, 
 train loss: 0.037638, val loss: 0.138487 
 val auc: 0.984459,  test auc: 0.981222
epoch 741, loss: 0.037594
epoch 741, 
 train loss: 0.037594, val loss: 0.137539 
 val auc: 0.984459,  test auc: 0.981166
epoch 742, loss: 0.037553
epoch 742, 
 train loss: 0.037553, val loss: 0.139117 
 val auc: 0.984497,  test auc: 0.981137
epoch 743, loss: 0.037499
epoch 743, 
 train loss: 0.037499, val loss: 0.138079 
 val auc: 0.984422,  test auc: 0.981156
epoch 744, loss: 0.037439
epoch 744, 
 train loss: 0.037439, val loss: 0.139040 
 val auc: 0.984497,  test auc: 0.981231
epoch 745, loss: 0.037364
epoch 745, 
 train loss: 0.037364, val loss: 0.138039 
 val auc: 0.984459,  test auc: 0.981128
epoch 746, loss: 0.037302
epoch 746, 
 train loss: 0.037302, val loss: 0.138312 
 val auc: 0.984535,  test auc: 0.981156
epoch 747, loss: 0.037236
epoch 747, 
 train loss: 0.037236, val loss: 0.138062 
 val auc: 0.984459,  test auc: 0.981212
epoch 748, loss: 0.037178
epoch 748, 
 train loss: 0.037178, val loss: 0.138903 
 val auc: 0.984459,  test auc: 0.981259
epoch 749, loss: 0.037134
epoch 749, 
 train loss: 0.037134, val loss: 0.138999 
 val auc: 0.984497,  test auc: 0.981222
epoch 750, loss: 0.037097
epoch 750, 
 train loss: 0.037097, val loss: 0.138540 
 val auc: 0.984459,  test auc: 0.981194
epoch 751, loss: 0.037056
epoch 751, 
 train loss: 0.037056, val loss: 0.139374 
 val auc: 0.984497,  test auc: 0.981194
epoch 752, loss: 0.037005
epoch 752, 
 train loss: 0.037005, val loss: 0.138131 
 val auc: 0.984422,  test auc: 0.981175
epoch 753, loss: 0.036941
epoch 753, 
 train loss: 0.036941, val loss: 0.139173 
 val auc: 0.984572,  test auc: 0.981250
epoch 754, loss: 0.036881
epoch 754, 
 train loss: 0.036881, val loss: 0.138523 
 val auc: 0.984497,  test auc: 0.981156
epoch 755, loss: 0.036817
epoch 755, 
 train loss: 0.036817, val loss: 0.138883 
 val auc: 0.984535,  test auc: 0.981184
epoch 756, loss: 0.036757
epoch 756, 
 train loss: 0.036757, val loss: 0.138491 
 val auc: 0.984535,  test auc: 0.981212
epoch 757, loss: 0.036709
epoch 757, 
 train loss: 0.036709, val loss: 0.138817 
 val auc: 0.984535,  test auc: 0.981166
epoch 758, loss: 0.036660
epoch 758, 
 train loss: 0.036660, val loss: 0.138881 
 val auc: 0.984572,  test auc: 0.981156
epoch 759, loss: 0.036632
epoch 759, 
 train loss: 0.036632, val loss: 0.138069 
 val auc: 0.984572,  test auc: 0.981212
epoch 760, loss: 0.036599
epoch 760, 
 train loss: 0.036599, val loss: 0.139534 
 val auc: 0.984685,  test auc: 0.981231
epoch 761, loss: 0.036560
epoch 761, 
 train loss: 0.036560, val loss: 0.138770 
 val auc: 0.984535,  test auc: 0.981166
epoch 762, loss: 0.036502
epoch 762, 
 train loss: 0.036502, val loss: 0.139661 
 val auc: 0.984760,  test auc: 0.981250
epoch 763, loss: 0.036431
epoch 763, 
 train loss: 0.036431, val loss: 0.138502 
 val auc: 0.984572,  test auc: 0.981137
epoch 764, loss: 0.036362
epoch 764, 
 train loss: 0.036362, val loss: 0.138967 
 val auc: 0.984535,  test auc: 0.981166
epoch 765, loss: 0.036313
epoch 765, 
 train loss: 0.036313, val loss: 0.139354 
 val auc: 0.984535,  test auc: 0.981184
epoch 766, loss: 0.036277
epoch 766, 
 train loss: 0.036277, val loss: 0.139092 
 val auc: 0.984535,  test auc: 0.981250
epoch 767, loss: 0.036232
epoch 767, 
 train loss: 0.036232, val loss: 0.139491 
 val auc: 0.984647,  test auc: 0.981212
epoch 768, loss: 0.036186
epoch 768, 
 train loss: 0.036186, val loss: 0.138216 
 val auc: 0.984647,  test auc: 0.981147
epoch 769, loss: 0.036130
epoch 769, 
 train loss: 0.036130, val loss: 0.138718 
 val auc: 0.984722,  test auc: 0.981166
epoch 770, loss: 0.036061
epoch 770, 
 train loss: 0.036061, val loss: 0.138761 
 val auc: 0.984647,  test auc: 0.981147
epoch 771, loss: 0.036007
epoch 771, 
 train loss: 0.036007, val loss: 0.139647 
 val auc: 0.984610,  test auc: 0.981222
epoch 772, loss: 0.035956
epoch 772, 
 train loss: 0.035956, val loss: 0.139365 
 val auc: 0.984610,  test auc: 0.981194
epoch 773, loss: 0.035907
epoch 773, 
 train loss: 0.035907, val loss: 0.138936 
 val auc: 0.984685,  test auc: 0.981128
epoch 774, loss: 0.035864
epoch 774, 
 train loss: 0.035864, val loss: 0.139412 
 val auc: 0.984685,  test auc: 0.981147
epoch 775, loss: 0.035821
epoch 775, 
 train loss: 0.035821, val loss: 0.138923 
 val auc: 0.984610,  test auc: 0.981175
epoch 776, loss: 0.035777
epoch 776, 
 train loss: 0.035777, val loss: 0.139457 
 val auc: 0.984685,  test auc: 0.981222
epoch 777, loss: 0.035723
epoch 777, 
 train loss: 0.035723, val loss: 0.139243 
 val auc: 0.984647,  test auc: 0.981175
epoch 778, loss: 0.035667
epoch 778, 
 train loss: 0.035667, val loss: 0.139941 
 val auc: 0.984722,  test auc: 0.981156
epoch 779, loss: 0.035625
epoch 779, 
 train loss: 0.035625, val loss: 0.139196 
 val auc: 0.984535,  test auc: 0.981156
epoch 780, loss: 0.035567
epoch 780, 
 train loss: 0.035567, val loss: 0.139351 
 val auc: 0.984572,  test auc: 0.981128
epoch 781, loss: 0.035536
epoch 781, 
 train loss: 0.035536, val loss: 0.140420 
 val auc: 0.984685,  test auc: 0.981062
epoch 782, loss: 0.035491
epoch 782, 
 train loss: 0.035491, val loss: 0.139033 
 val auc: 0.984572,  test auc: 0.981166
epoch 783, loss: 0.035441
epoch 783, 
 train loss: 0.035441, val loss: 0.139520 
 val auc: 0.984685,  test auc: 0.981184
epoch 784, loss: 0.035395
epoch 784, 
 train loss: 0.035395, val loss: 0.139722 
 val auc: 0.984610,  test auc: 0.981034
epoch 785, loss: 0.035333
epoch 785, 
 train loss: 0.035333, val loss: 0.139963 
 val auc: 0.984685,  test auc: 0.981119
epoch 786, loss: 0.035283
epoch 786, 
 train loss: 0.035283, val loss: 0.139321 
 val auc: 0.984610,  test auc: 0.981119
epoch 787, loss: 0.035231
epoch 787, 
 train loss: 0.035231, val loss: 0.139380 
 val auc: 0.984647,  test auc: 0.981156
epoch 788, loss: 0.035190
epoch 788, 
 train loss: 0.035190, val loss: 0.139941 
 val auc: 0.984685,  test auc: 0.981137
epoch 789, loss: 0.035137
epoch 789, 
 train loss: 0.035137, val loss: 0.139487 
 val auc: 0.984572,  test auc: 0.981081
epoch 790, loss: 0.035098
epoch 790, 
 train loss: 0.035098, val loss: 0.139628 
 val auc: 0.984647,  test auc: 0.981147
epoch 791, loss: 0.035049
epoch 791, 
 train loss: 0.035049, val loss: 0.139764 
 val auc: 0.984647,  test auc: 0.981072
epoch 792, loss: 0.035002
epoch 792, 
 train loss: 0.035002, val loss: 0.140102 
 val auc: 0.984685,  test auc: 0.981100
epoch 793, loss: 0.034952
epoch 793, 
 train loss: 0.034952, val loss: 0.139533 
 val auc: 0.984647,  test auc: 0.981119
epoch 794, loss: 0.034908
epoch 794, 
 train loss: 0.034908, val loss: 0.140162 
 val auc: 0.984647,  test auc: 0.981119
epoch 795, loss: 0.034852
epoch 795, 
 train loss: 0.034852, val loss: 0.140060 
 val auc: 0.984610,  test auc: 0.981090
epoch 796, loss: 0.034809
epoch 796, 
 train loss: 0.034809, val loss: 0.139748 
 val auc: 0.984647,  test auc: 0.981072
epoch 797, loss: 0.034762
epoch 797, 
 train loss: 0.034762, val loss: 0.140168 
 val auc: 0.984610,  test auc: 0.981072
epoch 798, loss: 0.034716
epoch 798, 
 train loss: 0.034716, val loss: 0.140293 
 val auc: 0.984610,  test auc: 0.981081
epoch 799, loss: 0.034673
epoch 799, 
 train loss: 0.034673, val loss: 0.139882 
 val auc: 0.984685,  test auc: 0.981100
epoch 800, loss: 0.034627
epoch 800, 
 train loss: 0.034627, val loss: 0.140050 
 val auc: 0.984685,  test auc: 0.981100
epoch 801, loss: 0.034582
epoch 801, 
 train loss: 0.034582, val loss: 0.140875 
 val auc: 0.984572,  test auc: 0.981081
epoch 802, loss: 0.034542
epoch 802, 
 train loss: 0.034542, val loss: 0.140099 
 val auc: 0.984535,  test auc: 0.981100
epoch 803, loss: 0.034494
epoch 803, 
 train loss: 0.034494, val loss: 0.140448 
 val auc: 0.984535,  test auc: 0.981081
epoch 804, loss: 0.034445
epoch 804, 
 train loss: 0.034445, val loss: 0.140195 
 val auc: 0.984685,  test auc: 0.981072
epoch 805, loss: 0.034397
epoch 805, 
 train loss: 0.034397, val loss: 0.140446 
 val auc: 0.984647,  test auc: 0.981109
epoch 806, loss: 0.034352
epoch 806, 
 train loss: 0.034352, val loss: 0.140363 
 val auc: 0.984647,  test auc: 0.981128
epoch 807, loss: 0.034317
epoch 807, 
 train loss: 0.034317, val loss: 0.140933 
 val auc: 0.984685,  test auc: 0.981147
epoch 808, loss: 0.034259
epoch 808, 
 train loss: 0.034259, val loss: 0.140168 
 val auc: 0.984647,  test auc: 0.981109
epoch 809, loss: 0.034216
epoch 809, 
 train loss: 0.034216, val loss: 0.140216 
 val auc: 0.984685,  test auc: 0.981147
epoch 810, loss: 0.034165
epoch 810, 
 train loss: 0.034165, val loss: 0.140406 
 val auc: 0.984647,  test auc: 0.981053
epoch 811, loss: 0.034120
epoch 811, 
 train loss: 0.034120, val loss: 0.140935 
 val auc: 0.984610,  test auc: 0.981090
epoch 812, loss: 0.034076
epoch 812, 
 train loss: 0.034076, val loss: 0.140526 
 val auc: 0.984610,  test auc: 0.981147
epoch 813, loss: 0.034030
epoch 813, 
 train loss: 0.034030, val loss: 0.140349 
 val auc: 0.984685,  test auc: 0.981109
epoch 814, loss: 0.033985
epoch 814, 
 train loss: 0.033985, val loss: 0.140600 
 val auc: 0.984685,  test auc: 0.981109
epoch 815, loss: 0.033949
epoch 815, 
 train loss: 0.033949, val loss: 0.140130 
 val auc: 0.984610,  test auc: 0.981090
epoch 816, loss: 0.033903
epoch 816, 
 train loss: 0.033903, val loss: 0.140438 
 val auc: 0.984572,  test auc: 0.981090
epoch 817, loss: 0.033856
epoch 817, 
 train loss: 0.033856, val loss: 0.140551 
 val auc: 0.984610,  test auc: 0.981100
epoch 818, loss: 0.033811
epoch 818, 
 train loss: 0.033811, val loss: 0.140885 
 val auc: 0.984647,  test auc: 0.981119
epoch 819, loss: 0.033768
epoch 819, 
 train loss: 0.033768, val loss: 0.140844 
 val auc: 0.984685,  test auc: 0.981128
epoch 820, loss: 0.033725
epoch 820, 
 train loss: 0.033725, val loss: 0.141172 
 val auc: 0.984685,  test auc: 0.981119
epoch 821, loss: 0.033683
epoch 821, 
 train loss: 0.033683, val loss: 0.140298 
 val auc: 0.984685,  test auc: 0.981119
epoch 822, loss: 0.033636
epoch 822, 
 train loss: 0.033636, val loss: 0.140753 
 val auc: 0.984647,  test auc: 0.981072
epoch 823, loss: 0.033593
epoch 823, 
 train loss: 0.033593, val loss: 0.140731 
 val auc: 0.984647,  test auc: 0.981100
epoch 824, loss: 0.033550
epoch 824, 
 train loss: 0.033550, val loss: 0.140747 
 val auc: 0.984610,  test auc: 0.981119
epoch 825, loss: 0.033502
epoch 825, 
 train loss: 0.033502, val loss: 0.140849 
 val auc: 0.984647,  test auc: 0.981090
epoch 826, loss: 0.033462
epoch 826, 
 train loss: 0.033462, val loss: 0.140581 
 val auc: 0.984647,  test auc: 0.981090
epoch 827, loss: 0.033426
epoch 827, 
 train loss: 0.033426, val loss: 0.140520 
 val auc: 0.984647,  test auc: 0.981156
epoch 828, loss: 0.033373
epoch 828, 
 train loss: 0.033373, val loss: 0.140942 
 val auc: 0.984647,  test auc: 0.981128
epoch 829, loss: 0.033340
epoch 829, 
 train loss: 0.033340, val loss: 0.141300 
 val auc: 0.984647,  test auc: 0.981081
epoch 830, loss: 0.033305
epoch 830, 
 train loss: 0.033305, val loss: 0.140332 
 val auc: 0.984722,  test auc: 0.981166
epoch 831, loss: 0.033252
epoch 831, 
 train loss: 0.033252, val loss: 0.140577 
 val auc: 0.984685,  test auc: 0.981090
epoch 832, loss: 0.033218
epoch 832, 
 train loss: 0.033218, val loss: 0.141296 
 val auc: 0.984647,  test auc: 0.981015
epoch 833, loss: 0.033172
epoch 833, 
 train loss: 0.033172, val loss: 0.141755 
 val auc: 0.984572,  test auc: 0.981025
epoch 834, loss: 0.033136
epoch 834, 
 train loss: 0.033136, val loss: 0.140419 
 val auc: 0.984685,  test auc: 0.981053
epoch 835, loss: 0.033095
epoch 835, 
 train loss: 0.033095, val loss: 0.141379 
 val auc: 0.984610,  test auc: 0.980968
epoch 836, loss: 0.033063
epoch 836, 
 train loss: 0.033063, val loss: 0.140662 
 val auc: 0.984685,  test auc: 0.980997
epoch 837, loss: 0.033027
epoch 837, 
 train loss: 0.033027, val loss: 0.141589 
 val auc: 0.984722,  test auc: 0.981100
epoch 838, loss: 0.032998
epoch 838, 
 train loss: 0.032998, val loss: 0.140481 
 val auc: 0.984685,  test auc: 0.981147
epoch 839, loss: 0.032957
epoch 839, 
 train loss: 0.032957, val loss: 0.141817 
 val auc: 0.984610,  test auc: 0.981062
epoch 840, loss: 0.032909
epoch 840, 
 train loss: 0.032909, val loss: 0.140297 
 val auc: 0.984760,  test auc: 0.981090
epoch 841, loss: 0.032853
epoch 841, 
 train loss: 0.032853, val loss: 0.141736 
 val auc: 0.984722,  test auc: 0.981147
epoch 842, loss: 0.032802
epoch 842, 
 train loss: 0.032802, val loss: 0.140853 
 val auc: 0.984760,  test auc: 0.981067
epoch 843, loss: 0.032750
epoch 843, 
 train loss: 0.032750, val loss: 0.141360 
 val auc: 0.984685,  test auc: 0.981025
epoch 844, loss: 0.032703
epoch 844, 
 train loss: 0.032703, val loss: 0.140885 
 val auc: 0.984835,  test auc: 0.981025
epoch 845, loss: 0.032662
epoch 845, 
 train loss: 0.032662, val loss: 0.141498 
 val auc: 0.984647,  test auc: 0.981044
epoch 846, loss: 0.032620
epoch 846, 
 train loss: 0.032620, val loss: 0.141154 
 val auc: 0.984872,  test auc: 0.981166
epoch 847, loss: 0.032579
epoch 847, 
 train loss: 0.032579, val loss: 0.141004 
 val auc: 0.984760,  test auc: 0.981137
epoch 848, loss: 0.032534
epoch 848, 
 train loss: 0.032534, val loss: 0.140851 
 val auc: 0.984760,  test auc: 0.981090
epoch 849, loss: 0.032493
epoch 849, 
 train loss: 0.032493, val loss: 0.141752 
 val auc: 0.984647,  test auc: 0.981081
epoch 850, loss: 0.032454
epoch 850, 
 train loss: 0.032454, val loss: 0.141002 
 val auc: 0.984835,  test auc: 0.981166
epoch 851, loss: 0.032414
epoch 851, 
 train loss: 0.032414, val loss: 0.141716 
 val auc: 0.984722,  test auc: 0.981119
epoch 852, loss: 0.032376
epoch 852, 
 train loss: 0.032376, val loss: 0.140903 
 val auc: 0.984722,  test auc: 0.981072
epoch 853, loss: 0.032340
epoch 853, 
 train loss: 0.032340, val loss: 0.141872 
 val auc: 0.984685,  test auc: 0.981039
epoch 854, loss: 0.032321
epoch 854, 
 train loss: 0.032321, val loss: 0.140616 
 val auc: 0.984835,  test auc: 0.981212
epoch 855, loss: 0.032300
epoch 855, 
 train loss: 0.032300, val loss: 0.141465 
 val auc: 0.984722,  test auc: 0.981053
epoch 856, loss: 0.032291
epoch 856, 
 train loss: 0.032291, val loss: 0.140424 
 val auc: 0.984910,  test auc: 0.981119
epoch 857, loss: 0.032279
epoch 857, 
 train loss: 0.032279, val loss: 0.142423 
 val auc: 0.984610,  test auc: 0.981128
epoch 858, loss: 0.032263
epoch 858, 
 train loss: 0.032263, val loss: 0.140995 
 val auc: 0.984797,  test auc: 0.981137
epoch 859, loss: 0.032235
epoch 859, 
 train loss: 0.032235, val loss: 0.143486 
 val auc: 0.984572,  test auc: 0.981100
epoch 860, loss: 0.032210
epoch 860, 
 train loss: 0.032210, val loss: 0.140491 
 val auc: 0.984797,  test auc: 0.981109
epoch 861, loss: 0.032204
epoch 861, 
 train loss: 0.032204, val loss: 0.142382 
 val auc: 0.984722,  test auc: 0.981184
epoch 862, loss: 0.032184
epoch 862, 
 train loss: 0.032184, val loss: 0.140101 
 val auc: 0.984872,  test auc: 0.981137
epoch 863, loss: 0.032154
epoch 863, 
 train loss: 0.032154, val loss: 0.143232 
 val auc: 0.984572,  test auc: 0.981166
epoch 864, loss: 0.032145
epoch 864, 
 train loss: 0.032145, val loss: 0.140748 
 val auc: 0.984797,  test auc: 0.981175
epoch 865, loss: 0.032067
epoch 865, 
 train loss: 0.032067, val loss: 0.143189 
 val auc: 0.984685,  test auc: 0.981166
epoch 866, loss: 0.031977
epoch 866, 
 train loss: 0.031977, val loss: 0.140340 
 val auc: 0.984760,  test auc: 0.981025
epoch 867, loss: 0.031844
epoch 867, 
 train loss: 0.031844, val loss: 0.142846 
 val auc: 0.984722,  test auc: 0.981109
epoch 868, loss: 0.031723
epoch 868, 
 train loss: 0.031723, val loss: 0.140869 
 val auc: 0.984722,  test auc: 0.981212
epoch 869, loss: 0.031634
epoch 869, 
 train loss: 0.031634, val loss: 0.142173 
 val auc: 0.984647,  test auc: 0.981194
epoch 870, loss: 0.031593
epoch 870, 
 train loss: 0.031593, val loss: 0.142518 
 val auc: 0.984535,  test auc: 0.981175
epoch 871, loss: 0.031596
epoch 871, 
 train loss: 0.031596, val loss: 0.141273 
 val auc: 0.984760,  test auc: 0.981137
epoch 872, loss: 0.031598
epoch 872, 
 train loss: 0.031598, val loss: 0.143300 
 val auc: 0.984610,  test auc: 0.981081
epoch 873, loss: 0.031580
epoch 873, 
 train loss: 0.031580, val loss: 0.141113 
 val auc: 0.984685,  test auc: 0.981109
epoch 874, loss: 0.031541
epoch 874, 
 train loss: 0.031541, val loss: 0.142839 
 val auc: 0.984572,  test auc: 0.981194
epoch 875, loss: 0.031495
epoch 875, 
 train loss: 0.031495, val loss: 0.140678 
 val auc: 0.984722,  test auc: 0.981137
epoch 876, loss: 0.031413
epoch 876, 
 train loss: 0.031413, val loss: 0.142305 
 val auc: 0.984572,  test auc: 0.981119
epoch 877, loss: 0.031322
epoch 877, 
 train loss: 0.031322, val loss: 0.140848 
 val auc: 0.984685,  test auc: 0.981203
epoch 878, loss: 0.031250
epoch 878, 
 train loss: 0.031250, val loss: 0.141649 
 val auc: 0.984722,  test auc: 0.981222
epoch 879, loss: 0.031195
epoch 879, 
 train loss: 0.031195, val loss: 0.141388 
 val auc: 0.984685,  test auc: 0.981184
epoch 880, loss: 0.031158
epoch 880, 
 train loss: 0.031158, val loss: 0.141808 
 val auc: 0.984610,  test auc: 0.981184
epoch 881, loss: 0.031137
epoch 881, 
 train loss: 0.031137, val loss: 0.142647 
 val auc: 0.984459,  test auc: 0.981137
epoch 882, loss: 0.031119
epoch 882, 
 train loss: 0.031119, val loss: 0.140953 
 val auc: 0.984685,  test auc: 0.981137
epoch 883, loss: 0.031103
epoch 883, 
 train loss: 0.031103, val loss: 0.142824 
 val auc: 0.984610,  test auc: 0.981062
epoch 884, loss: 0.031060
epoch 884, 
 train loss: 0.031060, val loss: 0.140522 
 val auc: 0.984797,  test auc: 0.981184
epoch 885, loss: 0.031019
epoch 885, 
 train loss: 0.031019, val loss: 0.142806 
 val auc: 0.984572,  test auc: 0.981137
epoch 886, loss: 0.030988
epoch 886, 
 train loss: 0.030988, val loss: 0.141442 
 val auc: 0.984610,  test auc: 0.981156
epoch 887, loss: 0.030931
epoch 887, 
 train loss: 0.030931, val loss: 0.142687 
 val auc: 0.984535,  test auc: 0.981081
epoch 888, loss: 0.030858
epoch 888, 
 train loss: 0.030858, val loss: 0.141323 
 val auc: 0.984610,  test auc: 0.981156
epoch 889, loss: 0.030786
epoch 889, 
 train loss: 0.030786, val loss: 0.142886 
 val auc: 0.984459,  test auc: 0.980997
epoch 890, loss: 0.030717
epoch 890, 
 train loss: 0.030717, val loss: 0.141594 
 val auc: 0.984535,  test auc: 0.981128
epoch 891, loss: 0.030666
epoch 891, 
 train loss: 0.030666, val loss: 0.141707 
 val auc: 0.984497,  test auc: 0.981175
epoch 892, loss: 0.030632
epoch 892, 
 train loss: 0.030632, val loss: 0.142176 
 val auc: 0.984497,  test auc: 0.981062
epoch 893, loss: 0.030605
epoch 893, 
 train loss: 0.030605, val loss: 0.141455 
 val auc: 0.984572,  test auc: 0.981128
epoch 894, loss: 0.030571
epoch 894, 
 train loss: 0.030571, val loss: 0.142646 
 val auc: 0.984497,  test auc: 0.981053
epoch 895, loss: 0.030554
epoch 895, 
 train loss: 0.030554, val loss: 0.141394 
 val auc: 0.984497,  test auc: 0.981100
epoch 896, loss: 0.030524
epoch 896, 
 train loss: 0.030524, val loss: 0.142588 
 val auc: 0.984535,  test auc: 0.981072
epoch 897, loss: 0.030497
epoch 897, 
 train loss: 0.030497, val loss: 0.141165 
 val auc: 0.984610,  test auc: 0.981156
epoch 898, loss: 0.030456
epoch 898, 
 train loss: 0.030456, val loss: 0.143256 
 val auc: 0.984497,  test auc: 0.981044
epoch 899, loss: 0.030396
epoch 899, 
 train loss: 0.030396, val loss: 0.141954 
 val auc: 0.984422,  test auc: 0.981062
epoch 900, loss: 0.030339
epoch 900, 
 train loss: 0.030339, val loss: 0.142702 
 val auc: 0.984459,  test auc: 0.981029
epoch 901, loss: 0.030267
epoch 901, 
 train loss: 0.030267, val loss: 0.141401 
 val auc: 0.984572,  test auc: 0.981090
epoch 902, loss: 0.030215
epoch 902, 
 train loss: 0.030215, val loss: 0.142538 
 val auc: 0.984459,  test auc: 0.981015
epoch 903, loss: 0.030162
epoch 903, 
 train loss: 0.030162, val loss: 0.141999 
 val auc: 0.984497,  test auc: 0.981100
epoch 904, loss: 0.030125
epoch 904, 
 train loss: 0.030125, val loss: 0.141585 
 val auc: 0.984497,  test auc: 0.981137
epoch 905, loss: 0.030102
epoch 905, 
 train loss: 0.030102, val loss: 0.142791 
 val auc: 0.984572,  test auc: 0.981015
epoch 906, loss: 0.030061
epoch 906, 
 train loss: 0.030061, val loss: 0.141363 
 val auc: 0.984497,  test auc: 0.981025
epoch 907, loss: 0.030033
epoch 907, 
 train loss: 0.030033, val loss: 0.142512 
 val auc: 0.984610,  test auc: 0.981015
epoch 908, loss: 0.030004
epoch 908, 
 train loss: 0.030004, val loss: 0.141667 
 val auc: 0.984422,  test auc: 0.980987
epoch 909, loss: 0.029965
epoch 909, 
 train loss: 0.029965, val loss: 0.142487 
 val auc: 0.984497,  test auc: 0.981025
epoch 910, loss: 0.029921
epoch 910, 
 train loss: 0.029921, val loss: 0.141052 
 val auc: 0.984497,  test auc: 0.981015
epoch 911, loss: 0.029874
epoch 911, 
 train loss: 0.029874, val loss: 0.143081 
 val auc: 0.984422,  test auc: 0.980922
epoch 912, loss: 0.029817
epoch 912, 
 train loss: 0.029817, val loss: 0.141648 
 val auc: 0.984459,  test auc: 0.980940
epoch 913, loss: 0.029754
epoch 913, 
 train loss: 0.029754, val loss: 0.142490 
 val auc: 0.984497,  test auc: 0.980978
epoch 914, loss: 0.029690
epoch 914, 
 train loss: 0.029690, val loss: 0.141688 
 val auc: 0.984459,  test auc: 0.980912
epoch 915, loss: 0.029643
epoch 915, 
 train loss: 0.029643, val loss: 0.142499 
 val auc: 0.984384,  test auc: 0.980912
epoch 916, loss: 0.029601
epoch 916, 
 train loss: 0.029601, val loss: 0.142601 
 val auc: 0.984459,  test auc: 0.980997
epoch 917, loss: 0.029574
epoch 917, 
 train loss: 0.029574, val loss: 0.141909 
 val auc: 0.984422,  test auc: 0.980940
epoch 918, loss: 0.029549
epoch 918, 
 train loss: 0.029549, val loss: 0.143477 
 val auc: 0.984459,  test auc: 0.980846
epoch 919, loss: 0.029521
epoch 919, 
 train loss: 0.029521, val loss: 0.142120 
 val auc: 0.984459,  test auc: 0.980950
epoch 920, loss: 0.029504
epoch 920, 
 train loss: 0.029504, val loss: 0.142851 
 val auc: 0.984497,  test auc: 0.980940
epoch 921, loss: 0.029480
epoch 921, 
 train loss: 0.029480, val loss: 0.141898 
 val auc: 0.984459,  test auc: 0.980931
epoch 922, loss: 0.029441
epoch 922, 
 train loss: 0.029441, val loss: 0.143115 
 val auc: 0.984384,  test auc: 0.980931
epoch 923, loss: 0.029398
epoch 923, 
 train loss: 0.029398, val loss: 0.141457 
 val auc: 0.984535,  test auc: 0.980987
epoch 924, loss: 0.029342
epoch 924, 
 train loss: 0.029342, val loss: 0.143870 
 val auc: 0.984422,  test auc: 0.980940
epoch 925, loss: 0.029266
epoch 925, 
 train loss: 0.029266, val loss: 0.141963 
 val auc: 0.984497,  test auc: 0.980968
epoch 926, loss: 0.029214
epoch 926, 
 train loss: 0.029214, val loss: 0.142697 
 val auc: 0.984572,  test auc: 0.980968
epoch 927, loss: 0.029160
epoch 927, 
 train loss: 0.029160, val loss: 0.142645 
 val auc: 0.984572,  test auc: 0.980922
epoch 928, loss: 0.029122
epoch 928, 
 train loss: 0.029122, val loss: 0.143204 
 val auc: 0.984422,  test auc: 0.980912
epoch 929, loss: 0.029091
epoch 929, 
 train loss: 0.029091, val loss: 0.143766 
 val auc: 0.984497,  test auc: 0.980959
epoch 930, loss: 0.029063
epoch 930, 
 train loss: 0.029063, val loss: 0.142174 
 val auc: 0.984572,  test auc: 0.980997
epoch 931, loss: 0.029043
epoch 931, 
 train loss: 0.029043, val loss: 0.143087 
 val auc: 0.984610,  test auc: 0.980922
epoch 932, loss: 0.029028
epoch 932, 
 train loss: 0.029028, val loss: 0.141994 
 val auc: 0.984535,  test auc: 0.980903
epoch 933, loss: 0.029033
epoch 933, 
 train loss: 0.029033, val loss: 0.144017 
 val auc: 0.984497,  test auc: 0.980931
epoch 934, loss: 0.029029
epoch 934, 
 train loss: 0.029029, val loss: 0.142236 
 val auc: 0.984497,  test auc: 0.980903
epoch 935, loss: 0.029009
epoch 935, 
 train loss: 0.029009, val loss: 0.144675 
 val auc: 0.984497,  test auc: 0.980912
epoch 936, loss: 0.028954
epoch 936, 
 train loss: 0.028954, val loss: 0.141794 
 val auc: 0.984572,  test auc: 0.980856
epoch 937, loss: 0.028884
epoch 937, 
 train loss: 0.028884, val loss: 0.143812 
 val auc: 0.984497,  test auc: 0.980931
epoch 938, loss: 0.028795
epoch 938, 
 train loss: 0.028795, val loss: 0.142431 
 val auc: 0.984535,  test auc: 0.980912
epoch 939, loss: 0.028715
epoch 939, 
 train loss: 0.028715, val loss: 0.143429 
 val auc: 0.984610,  test auc: 0.980940
epoch 940, loss: 0.028660
epoch 940, 
 train loss: 0.028660, val loss: 0.142883 
 val auc: 0.984647,  test auc: 0.980978
epoch 941, loss: 0.028640
epoch 941, 
 train loss: 0.028640, val loss: 0.142720 
 val auc: 0.984610,  test auc: 0.980978
epoch 942, loss: 0.028626
epoch 942, 
 train loss: 0.028626, val loss: 0.144380 
 val auc: 0.984610,  test auc: 0.980893
epoch 943, loss: 0.028603
epoch 943, 
 train loss: 0.028603, val loss: 0.142618 
 val auc: 0.984647,  test auc: 0.980931
epoch 944, loss: 0.028577
epoch 944, 
 train loss: 0.028577, val loss: 0.144127 
 val auc: 0.984572,  test auc: 0.980903
epoch 945, loss: 0.028533
epoch 945, 
 train loss: 0.028533, val loss: 0.142799 
 val auc: 0.984610,  test auc: 0.980940
epoch 946, loss: 0.028481
epoch 946, 
 train loss: 0.028481, val loss: 0.144176 
 val auc: 0.984572,  test auc: 0.980884
epoch 947, loss: 0.028424
epoch 947, 
 train loss: 0.028424, val loss: 0.142773 
 val auc: 0.984572,  test auc: 0.981015
epoch 948, loss: 0.028368
epoch 948, 
 train loss: 0.028368, val loss: 0.143584 
 val auc: 0.984647,  test auc: 0.980959
epoch 949, loss: 0.028326
epoch 949, 
 train loss: 0.028326, val loss: 0.143405 
 val auc: 0.984685,  test auc: 0.980968
epoch 950, loss: 0.028280
epoch 950, 
 train loss: 0.028280, val loss: 0.143680 
 val auc: 0.984760,  test auc: 0.981006
epoch 951, loss: 0.028248
epoch 951, 
 train loss: 0.028248, val loss: 0.143260 
 val auc: 0.984685,  test auc: 0.981006
epoch 952, loss: 0.028213
epoch 952, 
 train loss: 0.028213, val loss: 0.143454 
 val auc: 0.984722,  test auc: 0.980978
epoch 953, loss: 0.028177
epoch 953, 
 train loss: 0.028177, val loss: 0.144006 
 val auc: 0.984647,  test auc: 0.980903
epoch 954, loss: 0.028150
epoch 954, 
 train loss: 0.028150, val loss: 0.143269 
 val auc: 0.984610,  test auc: 0.980959
epoch 955, loss: 0.028110
epoch 955, 
 train loss: 0.028110, val loss: 0.144203 
 val auc: 0.984685,  test auc: 0.980931
epoch 956, loss: 0.028082
epoch 956, 
 train loss: 0.028082, val loss: 0.143644 
 val auc: 0.984760,  test auc: 0.980959
epoch 957, loss: 0.028052
epoch 957, 
 train loss: 0.028052, val loss: 0.144215 
 val auc: 0.984647,  test auc: 0.980931
epoch 958, loss: 0.028032
epoch 958, 
 train loss: 0.028032, val loss: 0.143180 
 val auc: 0.984572,  test auc: 0.980959
epoch 959, loss: 0.028000
epoch 959, 
 train loss: 0.028000, val loss: 0.144541 
 val auc: 0.984497,  test auc: 0.980875
epoch 960, loss: 0.027960
epoch 960, 
 train loss: 0.027960, val loss: 0.143170 
 val auc: 0.984722,  test auc: 0.980912
epoch 961, loss: 0.027914
epoch 961, 
 train loss: 0.027914, val loss: 0.144271 
 val auc: 0.984610,  test auc: 0.980922
epoch 962, loss: 0.027865
epoch 962, 
 train loss: 0.027865, val loss: 0.143283 
 val auc: 0.984647,  test auc: 0.980931
epoch 963, loss: 0.027818
epoch 963, 
 train loss: 0.027818, val loss: 0.143979 
 val auc: 0.984572,  test auc: 0.980903
epoch 964, loss: 0.027776
epoch 964, 
 train loss: 0.027776, val loss: 0.144021 
 val auc: 0.984722,  test auc: 0.980959
epoch 965, loss: 0.027730
epoch 965, 
 train loss: 0.027730, val loss: 0.144141 
 val auc: 0.984722,  test auc: 0.980978
epoch 966, loss: 0.027695
epoch 966, 
 train loss: 0.027695, val loss: 0.143987 
 val auc: 0.984685,  test auc: 0.980978
epoch 967, loss: 0.027666
epoch 967, 
 train loss: 0.027666, val loss: 0.143736 
 val auc: 0.984722,  test auc: 0.980865
epoch 968, loss: 0.027634
epoch 968, 
 train loss: 0.027634, val loss: 0.144302 
 val auc: 0.984572,  test auc: 0.980884
epoch 969, loss: 0.027614
epoch 969, 
 train loss: 0.027614, val loss: 0.143392 
 val auc: 0.984647,  test auc: 0.980978
epoch 970, loss: 0.027590
epoch 970, 
 train loss: 0.027590, val loss: 0.145027 
 val auc: 0.984535,  test auc: 0.980931
epoch 971, loss: 0.027569
epoch 971, 
 train loss: 0.027569, val loss: 0.143985 
 val auc: 0.984722,  test auc: 0.980837
epoch 972, loss: 0.027558
epoch 972, 
 train loss: 0.027558, val loss: 0.145440 
 val auc: 0.984535,  test auc: 0.980846
epoch 973, loss: 0.027538
epoch 973, 
 train loss: 0.027538, val loss: 0.143469 
 val auc: 0.984685,  test auc: 0.980800
epoch 974, loss: 0.027488
epoch 974, 
 train loss: 0.027488, val loss: 0.145847 
 val auc: 0.984535,  test auc: 0.980800
epoch 975, loss: 0.027426
epoch 975, 
 train loss: 0.027426, val loss: 0.143762 
 val auc: 0.984647,  test auc: 0.980809
epoch 976, loss: 0.027361
epoch 976, 
 train loss: 0.027361, val loss: 0.144863 
 val auc: 0.984610,  test auc: 0.980959
epoch 977, loss: 0.027293
epoch 977, 
 train loss: 0.027293, val loss: 0.144404 
 val auc: 0.984647,  test auc: 0.980893
epoch 978, loss: 0.027245
epoch 978, 
 train loss: 0.027245, val loss: 0.145388 
 val auc: 0.984610,  test auc: 0.980856
epoch 979, loss: 0.027206
epoch 979, 
 train loss: 0.027206, val loss: 0.145345 
 val auc: 0.984572,  test auc: 0.980846
epoch 980, loss: 0.027179
epoch 980, 
 train loss: 0.027179, val loss: 0.144647 
 val auc: 0.984610,  test auc: 0.980828
epoch 981, loss: 0.027161
epoch 981, 
 train loss: 0.027161, val loss: 0.145709 
 val auc: 0.984497,  test auc: 0.980776
epoch 982, loss: 0.027154
epoch 982, 
 train loss: 0.027154, val loss: 0.144207 
 val auc: 0.984610,  test auc: 0.980790
epoch 983, loss: 0.027141
epoch 983, 
 train loss: 0.027141, val loss: 0.146169 
 val auc: 0.984497,  test auc: 0.980837
epoch 984, loss: 0.027137
epoch 984, 
 train loss: 0.027137, val loss: 0.144253 
 val auc: 0.984610,  test auc: 0.980753
epoch 985, loss: 0.027111
epoch 985, 
 train loss: 0.027111, val loss: 0.146596 
 val auc: 0.984572,  test auc: 0.980790
epoch 986, loss: 0.027076
epoch 986, 
 train loss: 0.027076, val loss: 0.144433 
 val auc: 0.984572,  test auc: 0.980696
epoch 987, loss: 0.027002
epoch 987, 
 train loss: 0.027002, val loss: 0.147051 
 val auc: 0.984459,  test auc: 0.980753
epoch 988, loss: 0.026905
epoch 988, 
 train loss: 0.026905, val loss: 0.145067 
 val auc: 0.984535,  test auc: 0.980715
epoch 989, loss: 0.026799
epoch 989, 
 train loss: 0.026799, val loss: 0.146754 
 val auc: 0.984347,  test auc: 0.980715
epoch 990, loss: 0.026717
epoch 990, 
 train loss: 0.026717, val loss: 0.145506 
 val auc: 0.984422,  test auc: 0.980771
epoch 991, loss: 0.026673
epoch 991, 
 train loss: 0.026673, val loss: 0.145375 
 val auc: 0.984422,  test auc: 0.980790
epoch 992, loss: 0.026653
epoch 992, 
 train loss: 0.026653, val loss: 0.146089 
 val auc: 0.984497,  test auc: 0.980753
epoch 993, loss: 0.026643
epoch 993, 
 train loss: 0.026643, val loss: 0.145278 
 val auc: 0.984384,  test auc: 0.980631
epoch 994, loss: 0.026633
epoch 994, 
 train loss: 0.026633, val loss: 0.147666 
 val auc: 0.984422,  test auc: 0.980678
epoch 995, loss: 0.026613
epoch 995, 
 train loss: 0.026613, val loss: 0.145494 
 val auc: 0.984422,  test auc: 0.980602
epoch 996, loss: 0.026584
epoch 996, 
 train loss: 0.026584, val loss: 0.147178 
 val auc: 0.984459,  test auc: 0.980687
epoch 997, loss: 0.026547
epoch 997, 
 train loss: 0.026547, val loss: 0.145115 
 val auc: 0.984497,  test auc: 0.980565
epoch 998, loss: 0.026497
epoch 998, 
 train loss: 0.026497, val loss: 0.147334 
 val auc: 0.984422,  test auc: 0.980649
epoch 999, loss: 0.026435
epoch 999, 
 train loss: 0.026435, val loss: 0.145530 
 val auc: 0.984535,  test auc: 0.980631
AUC: 0.981034
