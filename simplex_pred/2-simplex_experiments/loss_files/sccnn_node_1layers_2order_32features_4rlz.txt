epoch 0, loss: 0.689372
model updated at epoch 0 
epoch 0, 
 train loss: 0.689372, val loss: 0.687879 
 val auc: 0.488438,  test auc: 0.503219
epoch 1, loss: 0.686880
model updated at epoch 1 
epoch 1, 
 train loss: 0.686880, val loss: 0.685246 
 val auc: 0.530593,  test auc: 0.529683
epoch 2, loss: 0.684689
model updated at epoch 2 
epoch 2, 
 train loss: 0.684689, val loss: 0.682879 
 val auc: 0.558934,  test auc: 0.550948
epoch 3, loss: 0.682710
model updated at epoch 3 
epoch 3, 
 train loss: 0.682710, val loss: 0.680777 
 val auc: 0.577965,  test auc: 0.569097
epoch 4, loss: 0.680859
model updated at epoch 4 
epoch 4, 
 train loss: 0.680859, val loss: 0.678867 
 val auc: 0.600788,  test auc: 0.589724
epoch 5, loss: 0.679048
model updated at epoch 5 
epoch 5, 
 train loss: 0.679048, val loss: 0.677084 
 val auc: 0.618956,  test auc: 0.604833
epoch 6, loss: 0.677242
model updated at epoch 6 
epoch 6, 
 train loss: 0.677242, val loss: 0.675390 
 val auc: 0.630480,  test auc: 0.612913
epoch 7, loss: 0.675398
model updated at epoch 7 
epoch 7, 
 train loss: 0.675398, val loss: 0.673703 
 val auc: 0.640578,  test auc: 0.619754
epoch 8, loss: 0.673508
model updated at epoch 8 
epoch 8, 
 train loss: 0.673508, val loss: 0.672029 
 val auc: 0.649962,  test auc: 0.625929
epoch 9, loss: 0.671555
model updated at epoch 9 
epoch 9, 
 train loss: 0.671555, val loss: 0.670320 
 val auc: 0.655856,  test auc: 0.630443
epoch 10, loss: 0.669560
model updated at epoch 10 
epoch 10, 
 train loss: 0.669560, val loss: 0.668578 
 val auc: 0.662575,  test auc: 0.635191
epoch 11, loss: 0.667512
model updated at epoch 11 
epoch 11, 
 train loss: 0.667512, val loss: 0.666808 
 val auc: 0.666667,  test auc: 0.639658
epoch 12, loss: 0.665421
model updated at epoch 12 
epoch 12, 
 train loss: 0.665421, val loss: 0.664985 
 val auc: 0.669369,  test auc: 0.643703
epoch 13, loss: 0.663225
model updated at epoch 13 
epoch 13, 
 train loss: 0.663225, val loss: 0.663056 
 val auc: 0.674212,  test auc: 0.649024
epoch 14, loss: 0.660937
model updated at epoch 14 
epoch 14, 
 train loss: 0.660937, val loss: 0.661055 
 val auc: 0.679655,  test auc: 0.655096
epoch 15, loss: 0.658536
model updated at epoch 15 
epoch 15, 
 train loss: 0.658536, val loss: 0.658955 
 val auc: 0.683258,  test auc: 0.659732
epoch 16, loss: 0.656056
model updated at epoch 16 
epoch 16, 
 train loss: 0.656056, val loss: 0.656823 
 val auc: 0.686937,  test auc: 0.665259
epoch 17, loss: 0.653508
model updated at epoch 17 
epoch 17, 
 train loss: 0.653508, val loss: 0.654665 
 val auc: 0.690090,  test auc: 0.669989
epoch 18, loss: 0.650886
model updated at epoch 18 
epoch 18, 
 train loss: 0.650886, val loss: 0.652523 
 val auc: 0.693281,  test auc: 0.674127
epoch 19, loss: 0.648163
model updated at epoch 19 
epoch 19, 
 train loss: 0.648163, val loss: 0.650359 
 val auc: 0.697410,  test auc: 0.677947
epoch 20, loss: 0.645349
model updated at epoch 20 
epoch 20, 
 train loss: 0.645349, val loss: 0.648190 
 val auc: 0.700826,  test auc: 0.681090
epoch 21, loss: 0.642455
model updated at epoch 21 
epoch 21, 
 train loss: 0.642455, val loss: 0.646023 
 val auc: 0.701276,  test auc: 0.683812
epoch 22, loss: 0.639500
model updated at epoch 22 
epoch 22, 
 train loss: 0.639500, val loss: 0.643857 
 val auc: 0.702853,  test auc: 0.686768
epoch 23, loss: 0.636533
model updated at epoch 23 
epoch 23, 
 train loss: 0.636533, val loss: 0.641709 
 val auc: 0.706907,  test auc: 0.690231
epoch 24, loss: 0.633547
model updated at epoch 24 
epoch 24, 
 train loss: 0.633547, val loss: 0.639587 
 val auc: 0.709947,  test auc: 0.694144
epoch 25, loss: 0.630492
model updated at epoch 25 
epoch 25, 
 train loss: 0.630492, val loss: 0.637308 
 val auc: 0.713101,  test auc: 0.698273
epoch 26, loss: 0.627422
model updated at epoch 26 
epoch 26, 
 train loss: 0.627422, val loss: 0.634855 
 val auc: 0.715766,  test auc: 0.702083
epoch 27, loss: 0.624356
model updated at epoch 27 
epoch 27, 
 train loss: 0.624356, val loss: 0.632321 
 val auc: 0.718581,  test auc: 0.705997
epoch 28, loss: 0.621334
model updated at epoch 28 
epoch 28, 
 train loss: 0.621334, val loss: 0.629820 
 val auc: 0.721059,  test auc: 0.710163
epoch 29, loss: 0.618297
model updated at epoch 29 
epoch 29, 
 train loss: 0.618297, val loss: 0.627349 
 val auc: 0.722260,  test auc: 0.713495
epoch 30, loss: 0.615288
model updated at epoch 30 
epoch 30, 
 train loss: 0.615288, val loss: 0.624948 
 val auc: 0.724024,  test auc: 0.716667
epoch 31, loss: 0.612234
model updated at epoch 31 
epoch 31, 
 train loss: 0.612234, val loss: 0.622533 
 val auc: 0.726201,  test auc: 0.719501
epoch 32, loss: 0.609119
model updated at epoch 32 
epoch 32, 
 train loss: 0.609119, val loss: 0.620083 
 val auc: 0.728679,  test auc: 0.722523
epoch 33, loss: 0.605984
model updated at epoch 33 
epoch 33, 
 train loss: 0.605984, val loss: 0.617708 
 val auc: 0.730443,  test auc: 0.725910
epoch 34, loss: 0.602749
model updated at epoch 34 
epoch 34, 
 train loss: 0.602749, val loss: 0.615368 
 val auc: 0.732995,  test auc: 0.729336
epoch 35, loss: 0.599427
model updated at epoch 35 
epoch 35, 
 train loss: 0.599427, val loss: 0.613004 
 val auc: 0.734159,  test auc: 0.732292
epoch 36, loss: 0.596090
model updated at epoch 36 
epoch 36, 
 train loss: 0.596090, val loss: 0.610719 
 val auc: 0.736299,  test auc: 0.735623
epoch 37, loss: 0.592749
model updated at epoch 37 
epoch 37, 
 train loss: 0.592749, val loss: 0.608468 
 val auc: 0.738363,  test auc: 0.739011
epoch 38, loss: 0.589343
model updated at epoch 38 
epoch 38, 
 train loss: 0.589343, val loss: 0.606098 
 val auc: 0.740878,  test auc: 0.742962
epoch 39, loss: 0.585834
model updated at epoch 39 
epoch 39, 
 train loss: 0.585834, val loss: 0.603472 
 val auc: 0.743731,  test auc: 0.747372
epoch 40, loss: 0.582221
model updated at epoch 40 
epoch 40, 
 train loss: 0.582221, val loss: 0.600626 
 val auc: 0.747973,  test auc: 0.752628
epoch 41, loss: 0.578514
model updated at epoch 41 
epoch 41, 
 train loss: 0.578514, val loss: 0.597699 
 val auc: 0.751577,  test auc: 0.757667
epoch 42, loss: 0.574695
model updated at epoch 42 
epoch 42, 
 train loss: 0.574695, val loss: 0.594778 
 val auc: 0.755668,  test auc: 0.762491
epoch 43, loss: 0.570759
model updated at epoch 43 
epoch 43, 
 train loss: 0.570759, val loss: 0.591923 
 val auc: 0.758971,  test auc: 0.767230
epoch 44, loss: 0.566695
model updated at epoch 44 
epoch 44, 
 train loss: 0.566695, val loss: 0.589067 
 val auc: 0.763101,  test auc: 0.772091
epoch 45, loss: 0.562427
model updated at epoch 45 
epoch 45, 
 train loss: 0.562427, val loss: 0.585889 
 val auc: 0.767155,  test auc: 0.777252
epoch 46, loss: 0.557994
model updated at epoch 46 
epoch 46, 
 train loss: 0.557994, val loss: 0.582355 
 val auc: 0.772485,  test auc: 0.782911
epoch 47, loss: 0.553506
model updated at epoch 47 
epoch 47, 
 train loss: 0.553506, val loss: 0.578618 
 val auc: 0.777815,  test auc: 0.788420
epoch 48, loss: 0.548842
model updated at epoch 48 
epoch 48, 
 train loss: 0.548842, val loss: 0.574724 
 val auc: 0.782845,  test auc: 0.793863
epoch 49, loss: 0.544016
model updated at epoch 49 
epoch 49, 
 train loss: 0.544016, val loss: 0.570827 
 val auc: 0.787050,  test auc: 0.798968
epoch 50, loss: 0.539057
model updated at epoch 50 
epoch 50, 
 train loss: 0.539057, val loss: 0.566828 
 val auc: 0.791254,  test auc: 0.804401
epoch 51, loss: 0.533902
model updated at epoch 51 
epoch 51, 
 train loss: 0.533902, val loss: 0.562404 
 val auc: 0.796847,  test auc: 0.810238
epoch 52, loss: 0.528583
model updated at epoch 52 
epoch 52, 
 train loss: 0.528583, val loss: 0.557651 
 val auc: 0.802590,  test auc: 0.815634
epoch 53, loss: 0.523085
model updated at epoch 53 
epoch 53, 
 train loss: 0.523085, val loss: 0.552840 
 val auc: 0.807920,  test auc: 0.821021
epoch 54, loss: 0.517400
model updated at epoch 54 
epoch 54, 
 train loss: 0.517400, val loss: 0.548017 
 val auc: 0.813363,  test auc: 0.826821
epoch 55, loss: 0.511465
model updated at epoch 55 
epoch 55, 
 train loss: 0.511465, val loss: 0.542940 
 val auc: 0.819482,  test auc: 0.832489
epoch 56, loss: 0.505314
model updated at epoch 56 
epoch 56, 
 train loss: 0.505314, val loss: 0.537333 
 val auc: 0.825863,  test auc: 0.838729
epoch 57, loss: 0.499010
model updated at epoch 57 
epoch 57, 
 train loss: 0.499010, val loss: 0.531358 
 val auc: 0.831907,  test auc: 0.844388
epoch 58, loss: 0.492593
model updated at epoch 58 
epoch 58, 
 train loss: 0.492593, val loss: 0.525244 
 val auc: 0.837538,  test auc: 0.850188
epoch 59, loss: 0.485985
model updated at epoch 59 
epoch 59, 
 train loss: 0.485985, val loss: 0.518997 
 val auc: 0.842417,  test auc: 0.855443
epoch 60, loss: 0.479235
model updated at epoch 60 
epoch 60, 
 train loss: 0.479235, val loss: 0.512402 
 val auc: 0.848386,  test auc: 0.861289
epoch 61, loss: 0.472244
model updated at epoch 61 
epoch 61, 
 train loss: 0.472244, val loss: 0.505622 
 val auc: 0.853904,  test auc: 0.866329
epoch 62, loss: 0.465102
model updated at epoch 62 
epoch 62, 
 train loss: 0.465102, val loss: 0.498964 
 val auc: 0.859272,  test auc: 0.870946
epoch 63, loss: 0.457753
model updated at epoch 63 
epoch 63, 
 train loss: 0.457753, val loss: 0.491838 
 val auc: 0.864339,  test auc: 0.875601
epoch 64, loss: 0.450258
model updated at epoch 64 
epoch 64, 
 train loss: 0.450258, val loss: 0.484633 
 val auc: 0.869107,  test auc: 0.880490
epoch 65, loss: 0.442688
model updated at epoch 65 
epoch 65, 
 train loss: 0.442688, val loss: 0.477387 
 val auc: 0.872710,  test auc: 0.884957
epoch 66, loss: 0.434953
model updated at epoch 66 
epoch 66, 
 train loss: 0.434953, val loss: 0.469826 
 val auc: 0.877215,  test auc: 0.889489
epoch 67, loss: 0.427089
model updated at epoch 67 
epoch 67, 
 train loss: 0.427089, val loss: 0.462201 
 val auc: 0.881419,  test auc: 0.894444
epoch 68, loss: 0.419025
model updated at epoch 68 
epoch 68, 
 train loss: 0.419025, val loss: 0.454613 
 val auc: 0.884797,  test auc: 0.898630
epoch 69, loss: 0.410890
model updated at epoch 69 
epoch 69, 
 train loss: 0.410890, val loss: 0.447037 
 val auc: 0.888251,  test auc: 0.902928
epoch 70, loss: 0.402715
model updated at epoch 70 
epoch 70, 
 train loss: 0.402715, val loss: 0.439387 
 val auc: 0.891929,  test auc: 0.906832
epoch 71, loss: 0.394483
model updated at epoch 71 
epoch 71, 
 train loss: 0.394483, val loss: 0.431364 
 val auc: 0.896321,  test auc: 0.911167
epoch 72, loss: 0.386273
model updated at epoch 72 
epoch 72, 
 train loss: 0.386273, val loss: 0.424041 
 val auc: 0.898724,  test auc: 0.914367
epoch 73, loss: 0.378044
model updated at epoch 73 
epoch 73, 
 train loss: 0.378044, val loss: 0.416317 
 val auc: 0.902065,  test auc: 0.917586
epoch 74, loss: 0.369972
model updated at epoch 74 
epoch 74, 
 train loss: 0.369972, val loss: 0.408521 
 val auc: 0.905631,  test auc: 0.920852
epoch 75, loss: 0.361962
model updated at epoch 75 
epoch 75, 
 train loss: 0.361962, val loss: 0.401516 
 val auc: 0.908033,  test auc: 0.923114
epoch 76, loss: 0.353847
model updated at epoch 76 
epoch 76, 
 train loss: 0.353847, val loss: 0.393915 
 val auc: 0.910998,  test auc: 0.925732
epoch 77, loss: 0.345909
model updated at epoch 77 
epoch 77, 
 train loss: 0.345909, val loss: 0.387467 
 val auc: 0.912462,  test auc: 0.927440
epoch 78, loss: 0.338234
model updated at epoch 78 
epoch 78, 
 train loss: 0.338234, val loss: 0.380988 
 val auc: 0.914902,  test auc: 0.929842
epoch 79, loss: 0.330814
model updated at epoch 79 
epoch 79, 
 train loss: 0.330814, val loss: 0.374914 
 val auc: 0.915991,  test auc: 0.931776
epoch 80, loss: 0.323678
model updated at epoch 80 
epoch 80, 
 train loss: 0.323678, val loss: 0.368074 
 val auc: 0.919369,  test auc: 0.934422
epoch 81, loss: 0.316728
model updated at epoch 81 
epoch 81, 
 train loss: 0.316728, val loss: 0.362347 
 val auc: 0.920270,  test auc: 0.935708
epoch 82, loss: 0.310011
model updated at epoch 82 
epoch 82, 
 train loss: 0.310011, val loss: 0.355269 
 val auc: 0.924174,  test auc: 0.938992
epoch 83, loss: 0.303741
model updated at epoch 83 
epoch 83, 
 train loss: 0.303741, val loss: 0.351451 
 val auc: 0.923123,  test auc: 0.938270
epoch 84, loss: 0.297696
model updated at epoch 84 
epoch 84, 
 train loss: 0.297696, val loss: 0.345116 
 val auc: 0.927140,  test auc: 0.941460
epoch 85, loss: 0.291757
model updated at epoch 85 
epoch 85, 
 train loss: 0.291757, val loss: 0.342247 
 val auc: 0.926764,  test auc: 0.940606
epoch 86, loss: 0.286081
model updated at epoch 86 
epoch 86, 
 train loss: 0.286081, val loss: 0.337152 
 val auc: 0.928641,  test auc: 0.942164
epoch 87, loss: 0.280876
model updated at epoch 87 
epoch 87, 
 train loss: 0.280876, val loss: 0.332446 
 val auc: 0.930480,  test auc: 0.943581
epoch 88, loss: 0.275941
model updated at epoch 88 
epoch 88, 
 train loss: 0.275941, val loss: 0.329896 
 val auc: 0.929617,  test auc: 0.942746
epoch 89, loss: 0.271056
model updated at epoch 89 
epoch 89, 
 train loss: 0.271056, val loss: 0.324613 
 val auc: 0.932095,  test auc: 0.944895
epoch 90, loss: 0.266322
model updated at epoch 90 
epoch 90, 
 train loss: 0.266322, val loss: 0.321939 
 val auc: 0.931832,  test auc: 0.944735
epoch 91, loss: 0.261882
model updated at epoch 91 
epoch 91, 
 train loss: 0.261882, val loss: 0.318651 
 val auc: 0.932808,  test auc: 0.945580
epoch 92, loss: 0.257702
model updated at epoch 92 
epoch 92, 
 train loss: 0.257702, val loss: 0.315249 
 val auc: 0.934272,  test auc: 0.946800
epoch 93, loss: 0.253767
model updated at epoch 93 
epoch 93, 
 train loss: 0.253767, val loss: 0.313865 
 val auc: 0.933446,  test auc: 0.945843
epoch 94, loss: 0.249986
model updated at epoch 94 
epoch 94, 
 train loss: 0.249986, val loss: 0.308806 
 val auc: 0.936562,  test auc: 0.948620
epoch 95, loss: 0.246434
model updated at epoch 95 
epoch 95, 
 train loss: 0.246434, val loss: 0.308274 
 val auc: 0.934797,  test auc: 0.946753
epoch 96, loss: 0.242375
model updated at epoch 96 
epoch 96, 
 train loss: 0.242375, val loss: 0.302978 
 val auc: 0.937988,  test auc: 0.949559
epoch 97, loss: 0.238656
model updated at epoch 97 
epoch 97, 
 train loss: 0.238656, val loss: 0.300722 
 val auc: 0.938101,  test auc: 0.949465
epoch 98, loss: 0.235456
model updated at epoch 98 
epoch 98, 
 train loss: 0.235456, val loss: 0.299057 
 val auc: 0.938288,  test auc: 0.949099
epoch 99, loss: 0.232332
model updated at epoch 99 
epoch 99, 
 train loss: 0.232332, val loss: 0.295023 
 val auc: 0.940691,  test auc: 0.951004
epoch 100, loss: 0.229177
model updated at epoch 100 
epoch 100, 
 train loss: 0.229177, val loss: 0.293652 
 val auc: 0.939602,  test auc: 0.949925
epoch 101, loss: 0.226012
model updated at epoch 101 
epoch 101, 
 train loss: 0.226012, val loss: 0.290435 
 val auc: 0.941254,  test auc: 0.951304
epoch 102, loss: 0.223195
model updated at epoch 102 
epoch 102, 
 train loss: 0.223195, val loss: 0.288322 
 val auc: 0.942080,  test auc: 0.951839
epoch 103, loss: 0.220580
model updated at epoch 103 
epoch 103, 
 train loss: 0.220580, val loss: 0.287295 
 val auc: 0.941141,  test auc: 0.951107
epoch 104, loss: 0.217887
model updated at epoch 104 
epoch 104, 
 train loss: 0.217887, val loss: 0.284416 
 val auc: 0.943356,  test auc: 0.952825
epoch 105, loss: 0.215264
model updated at epoch 105 
epoch 105, 
 train loss: 0.215264, val loss: 0.283475 
 val auc: 0.942230,  test auc: 0.951727
epoch 106, loss: 0.212647
model updated at epoch 106 
epoch 106, 
 train loss: 0.212647, val loss: 0.281232 
 val auc: 0.943769,  test auc: 0.952984
epoch 107, loss: 0.210277
model updated at epoch 107 
epoch 107, 
 train loss: 0.210277, val loss: 0.279703 
 val auc: 0.943544,  test auc: 0.952721
epoch 108, loss: 0.208063
model updated at epoch 108 
epoch 108, 
 train loss: 0.208063, val loss: 0.277788 
 val auc: 0.943769,  test auc: 0.952675
epoch 109, loss: 0.205994
model updated at epoch 109 
epoch 109, 
 train loss: 0.205994, val loss: 0.275735 
 val auc: 0.944895,  test auc: 0.953538
epoch 110, loss: 0.204029
model updated at epoch 110 
epoch 110, 
 train loss: 0.204029, val loss: 0.274766 
 val auc: 0.944595,  test auc: 0.952703
epoch 111, loss: 0.202126
model updated at epoch 111 
epoch 111, 
 train loss: 0.202126, val loss: 0.273076 
 val auc: 0.946246,  test auc: 0.954101
epoch 112, loss: 0.200493
model updated at epoch 112 
epoch 112, 
 train loss: 0.200493, val loss: 0.272528 
 val auc: 0.944520,  test auc: 0.952187
epoch 113, loss: 0.198627
model updated at epoch 113 
epoch 113, 
 train loss: 0.198627, val loss: 0.270247 
 val auc: 0.946734,  test auc: 0.954420
epoch 114, loss: 0.196669
model updated at epoch 114 
epoch 114, 
 train loss: 0.196669, val loss: 0.269025 
 val auc: 0.945571,  test auc: 0.952853
epoch 115, loss: 0.194652
model updated at epoch 115 
epoch 115, 
 train loss: 0.194652, val loss: 0.267439 
 val auc: 0.947335,  test auc: 0.954420
epoch 116, loss: 0.192934
model updated at epoch 116 
epoch 116, 
 train loss: 0.192934, val loss: 0.266682 
 val auc: 0.947297,  test auc: 0.954392
epoch 117, loss: 0.191499
model updated at epoch 117 
epoch 117, 
 train loss: 0.191499, val loss: 0.266291 
 val auc: 0.946509,  test auc: 0.953632
epoch 118, loss: 0.190432
model updated at epoch 118 
epoch 118, 
 train loss: 0.190432, val loss: 0.265931 
 val auc: 0.948011,  test auc: 0.955068
epoch 119, loss: 0.190080
epoch 119, 
 train loss: 0.190080, val loss: 0.266242 
 val auc: 0.945120,  test auc: 0.952055
epoch 120, loss: 0.187822
model updated at epoch 120 
epoch 120, 
 train loss: 0.187822, val loss: 0.264282 
 val auc: 0.948836,  test auc: 0.955692
epoch 121, loss: 0.185484
model updated at epoch 121 
epoch 121, 
 train loss: 0.185484, val loss: 0.262362 
 val auc: 0.948161,  test auc: 0.954772
epoch 122, loss: 0.184211
model updated at epoch 122 
epoch 122, 
 train loss: 0.184211, val loss: 0.261757 
 val auc: 0.947860,  test auc: 0.954584
epoch 123, loss: 0.183553
epoch 123, 
 train loss: 0.183553, val loss: 0.262041 
 val auc: 0.949437,  test auc: 0.956231
epoch 124, loss: 0.182381
model updated at epoch 124 
epoch 124, 
 train loss: 0.182381, val loss: 0.261385 
 val auc: 0.947297,  test auc: 0.954063
epoch 125, loss: 0.180100
model updated at epoch 125 
epoch 125, 
 train loss: 0.180100, val loss: 0.259589 
 val auc: 0.949399,  test auc: 0.956090
epoch 126, loss: 0.179073
model updated at epoch 126 
epoch 126, 
 train loss: 0.179073, val loss: 0.258711 
 val auc: 0.949887,  test auc: 0.956485
epoch 127, loss: 0.178520
model updated at epoch 127 
epoch 127, 
 train loss: 0.178520, val loss: 0.258002 
 val auc: 0.948874,  test auc: 0.954899
epoch 128, loss: 0.176534
model updated at epoch 128 
epoch 128, 
 train loss: 0.176534, val loss: 0.256715 
 val auc: 0.950488,  test auc: 0.956776
epoch 129, loss: 0.175238
model updated at epoch 129 
epoch 129, 
 train loss: 0.175238, val loss: 0.256028 
 val auc: 0.950751,  test auc: 0.956776
epoch 130, loss: 0.174709
model updated at epoch 130 
epoch 130, 
 train loss: 0.174709, val loss: 0.255969 
 val auc: 0.949362,  test auc: 0.955377
epoch 131, loss: 0.173221
model updated at epoch 131 
epoch 131, 
 train loss: 0.173221, val loss: 0.255567 
 val auc: 0.951539,  test auc: 0.957207
epoch 132, loss: 0.171722
model updated at epoch 132 
epoch 132, 
 train loss: 0.171722, val loss: 0.254431 
 val auc: 0.951389,  test auc: 0.957066
epoch 133, loss: 0.170904
model updated at epoch 133 
epoch 133, 
 train loss: 0.170904, val loss: 0.253751 
 val auc: 0.951014,  test auc: 0.956475
epoch 134, loss: 0.170024
model updated at epoch 134 
epoch 134, 
 train loss: 0.170024, val loss: 0.253494 
 val auc: 0.952477,  test auc: 0.957902
epoch 135, loss: 0.168769
model updated at epoch 135 
epoch 135, 
 train loss: 0.168769, val loss: 0.251995 
 val auc: 0.951727,  test auc: 0.957151
epoch 136, loss: 0.167539
model updated at epoch 136 
epoch 136, 
 train loss: 0.167539, val loss: 0.251377 
 val auc: 0.952440,  test auc: 0.957695
epoch 137, loss: 0.166775
epoch 137, 
 train loss: 0.166775, val loss: 0.251460 
 val auc: 0.952965,  test auc: 0.958183
epoch 138, loss: 0.166054
model updated at epoch 138 
epoch 138, 
 train loss: 0.166054, val loss: 0.250910 
 val auc: 0.951877,  test auc: 0.957095
epoch 139, loss: 0.164903
model updated at epoch 139 
epoch 139, 
 train loss: 0.164903, val loss: 0.250836 
 val auc: 0.953754,  test auc: 0.958596
epoch 140, loss: 0.163795
model updated at epoch 140 
epoch 140, 
 train loss: 0.163795, val loss: 0.249877 
 val auc: 0.953679,  test auc: 0.958174
epoch 141, loss: 0.162950
model updated at epoch 141 
epoch 141, 
 train loss: 0.162950, val loss: 0.249270 
 val auc: 0.953941,  test auc: 0.958277
epoch 142, loss: 0.162238
model updated at epoch 142 
epoch 142, 
 train loss: 0.162238, val loss: 0.249183 
 val auc: 0.954767,  test auc: 0.959056
epoch 143, loss: 0.161453
model updated at epoch 143 
epoch 143, 
 train loss: 0.161453, val loss: 0.248258 
 val auc: 0.954279,  test auc: 0.958291
epoch 144, loss: 0.160451
epoch 144, 
 train loss: 0.160451, val loss: 0.248326 
 val auc: 0.955293,  test auc: 0.959230
epoch 145, loss: 0.159479
model updated at epoch 145 
epoch 145, 
 train loss: 0.159479, val loss: 0.247745 
 val auc: 0.954992,  test auc: 0.958971
epoch 146, loss: 0.158605
model updated at epoch 146 
epoch 146, 
 train loss: 0.158605, val loss: 0.247566 
 val auc: 0.955255,  test auc: 0.959169
epoch 147, loss: 0.157845
model updated at epoch 147 
epoch 147, 
 train loss: 0.157845, val loss: 0.247263 
 val auc: 0.955743,  test auc: 0.959535
epoch 148, loss: 0.157125
model updated at epoch 148 
epoch 148, 
 train loss: 0.157125, val loss: 0.246359 
 val auc: 0.955724,  test auc: 0.959309
epoch 149, loss: 0.156385
model updated at epoch 149 
epoch 149, 
 train loss: 0.156385, val loss: 0.246193 
 val auc: 0.956757,  test auc: 0.960177
epoch 150, loss: 0.155696
model updated at epoch 150 
epoch 150, 
 train loss: 0.155696, val loss: 0.245249 
 val auc: 0.956269,  test auc: 0.959652
epoch 151, loss: 0.154878
epoch 151, 
 train loss: 0.154878, val loss: 0.245588 
 val auc: 0.957151,  test auc: 0.960459
epoch 152, loss: 0.154031
model updated at epoch 152 
epoch 152, 
 train loss: 0.154031, val loss: 0.245029 
 val auc: 0.956494,  test auc: 0.959802
epoch 153, loss: 0.153170
epoch 153, 
 train loss: 0.153170, val loss: 0.245168 
 val auc: 0.957151,  test auc: 0.960482
epoch 154, loss: 0.152375
model updated at epoch 154 
epoch 154, 
 train loss: 0.152375, val loss: 0.244659 
 val auc: 0.957132,  test auc: 0.960464
epoch 155, loss: 0.151652
model updated at epoch 155 
epoch 155, 
 train loss: 0.151652, val loss: 0.244085 
 val auc: 0.957432,  test auc: 0.960614
epoch 156, loss: 0.150986
model updated at epoch 156 
epoch 156, 
 train loss: 0.150986, val loss: 0.243813 
 val auc: 0.958183,  test auc: 0.961045
epoch 157, loss: 0.150382
model updated at epoch 157 
epoch 157, 
 train loss: 0.150382, val loss: 0.243077 
 val auc: 0.957920,  test auc: 0.960740
epoch 158, loss: 0.149882
epoch 158, 
 train loss: 0.149882, val loss: 0.243636 
 val auc: 0.958896,  test auc: 0.961820
epoch 159, loss: 0.149861
epoch 159, 
 train loss: 0.149861, val loss: 0.243105 
 val auc: 0.957920,  test auc: 0.960656
epoch 160, loss: 0.149456
epoch 160, 
 train loss: 0.149456, val loss: 0.244484 
 val auc: 0.959328,  test auc: 0.962228
epoch 161, loss: 0.148762
model updated at epoch 161 
epoch 161, 
 train loss: 0.148762, val loss: 0.242880 
 val auc: 0.957845,  test auc: 0.960787
epoch 162, loss: 0.147033
model updated at epoch 162 
epoch 162, 
 train loss: 0.147033, val loss: 0.242407 
 val auc: 0.959047,  test auc: 0.962148
epoch 163, loss: 0.146208
model updated at epoch 163 
epoch 163, 
 train loss: 0.146208, val loss: 0.241746 
 val auc: 0.959328,  test auc: 0.962172
epoch 164, loss: 0.146402
model updated at epoch 164 
epoch 164, 
 train loss: 0.146402, val loss: 0.241659 
 val auc: 0.958671,  test auc: 0.961388
epoch 165, loss: 0.145970
epoch 165, 
 train loss: 0.145970, val loss: 0.242784 
 val auc: 0.959703,  test auc: 0.962767
epoch 166, loss: 0.144847
model updated at epoch 166 
epoch 166, 
 train loss: 0.144847, val loss: 0.241238 
 val auc: 0.958840,  test auc: 0.961796
epoch 167, loss: 0.143697
model updated at epoch 167 
epoch 167, 
 train loss: 0.143697, val loss: 0.240910 
 val auc: 0.959610,  test auc: 0.962514
epoch 168, loss: 0.143568
epoch 168, 
 train loss: 0.143568, val loss: 0.241351 
 val auc: 0.960210,  test auc: 0.963011
epoch 169, loss: 0.143626
model updated at epoch 169 
epoch 169, 
 train loss: 0.143626, val loss: 0.240424 
 val auc: 0.959366,  test auc: 0.962251
epoch 170, loss: 0.142366
model updated at epoch 170 
epoch 170, 
 train loss: 0.142366, val loss: 0.240160 
 val auc: 0.960417,  test auc: 0.963401
epoch 171, loss: 0.141357
model updated at epoch 171 
epoch 171, 
 train loss: 0.141357, val loss: 0.239008 
 val auc: 0.960529,  test auc: 0.963213
epoch 172, loss: 0.141159
model updated at epoch 172 
epoch 172, 
 train loss: 0.141159, val loss: 0.238778 
 val auc: 0.960098,  test auc: 0.962875
epoch 173, loss: 0.141154
epoch 173, 
 train loss: 0.141154, val loss: 0.240246 
 val auc: 0.961186,  test auc: 0.964002
epoch 174, loss: 0.140979
epoch 174, 
 train loss: 0.140979, val loss: 0.238875 
 val auc: 0.959910,  test auc: 0.962791
epoch 175, loss: 0.139523
model updated at epoch 175 
epoch 175, 
 train loss: 0.139523, val loss: 0.238706 
 val auc: 0.961468,  test auc: 0.964081
epoch 176, loss: 0.138509
model updated at epoch 176 
epoch 176, 
 train loss: 0.138509, val loss: 0.237216 
 val auc: 0.961111,  test auc: 0.963795
epoch 177, loss: 0.138177
model updated at epoch 177 
epoch 177, 
 train loss: 0.138177, val loss: 0.236623 
 val auc: 0.960698,  test auc: 0.963560
epoch 178, loss: 0.138014
epoch 178, 
 train loss: 0.138014, val loss: 0.237200 
 val auc: 0.961712,  test auc: 0.964428
epoch 179, loss: 0.137515
model updated at epoch 179 
epoch 179, 
 train loss: 0.137515, val loss: 0.236144 
 val auc: 0.960811,  test auc: 0.963701
epoch 180, loss: 0.136527
model updated at epoch 180 
epoch 180, 
 train loss: 0.136527, val loss: 0.236120 
 val auc: 0.961749,  test auc: 0.964579
epoch 181, loss: 0.135883
model updated at epoch 181 
epoch 181, 
 train loss: 0.135883, val loss: 0.235546 
 val auc: 0.961674,  test auc: 0.964579
epoch 182, loss: 0.135628
model updated at epoch 182 
epoch 182, 
 train loss: 0.135628, val loss: 0.234913 
 val auc: 0.961543,  test auc: 0.964278
epoch 183, loss: 0.135295
epoch 183, 
 train loss: 0.135295, val loss: 0.235306 
 val auc: 0.962237,  test auc: 0.965043
epoch 184, loss: 0.134736
model updated at epoch 184 
epoch 184, 
 train loss: 0.134736, val loss: 0.234173 
 val auc: 0.961787,  test auc: 0.964461
epoch 185, loss: 0.133916
model updated at epoch 185 
epoch 185, 
 train loss: 0.133916, val loss: 0.234171 
 val auc: 0.962218,  test auc: 0.964992
epoch 186, loss: 0.133354
model updated at epoch 186 
epoch 186, 
 train loss: 0.133354, val loss: 0.233617 
 val auc: 0.962275,  test auc: 0.965001
epoch 187, loss: 0.133017
model updated at epoch 187 
epoch 187, 
 train loss: 0.133017, val loss: 0.232900 
 val auc: 0.962312,  test auc: 0.964832
epoch 188, loss: 0.132578
model updated at epoch 188 
epoch 188, 
 train loss: 0.132578, val loss: 0.232832 
 val auc: 0.962857,  test auc: 0.965489
epoch 189, loss: 0.131992
model updated at epoch 189 
epoch 189, 
 train loss: 0.131992, val loss: 0.231526 
 val auc: 0.962763,  test auc: 0.965142
epoch 190, loss: 0.131362
model updated at epoch 190 
epoch 190, 
 train loss: 0.131362, val loss: 0.231300 
 val auc: 0.962913,  test auc: 0.965484
epoch 191, loss: 0.130876
model updated at epoch 191 
epoch 191, 
 train loss: 0.130876, val loss: 0.231067 
 val auc: 0.963026,  test auc: 0.965620
epoch 192, loss: 0.130504
model updated at epoch 192 
epoch 192, 
 train loss: 0.130504, val loss: 0.230626 
 val auc: 0.963007,  test auc: 0.965470
epoch 193, loss: 0.130058
epoch 193, 
 train loss: 0.130058, val loss: 0.230740 
 val auc: 0.963401,  test auc: 0.965977
epoch 194, loss: 0.129520
model updated at epoch 194 
epoch 194, 
 train loss: 0.129520, val loss: 0.229764 
 val auc: 0.963438,  test auc: 0.965850
epoch 195, loss: 0.128926
model updated at epoch 195 
epoch 195, 
 train loss: 0.128926, val loss: 0.229639 
 val auc: 0.963720,  test auc: 0.966282
epoch 196, loss: 0.128413
model updated at epoch 196 
epoch 196, 
 train loss: 0.128413, val loss: 0.229182 
 val auc: 0.963776,  test auc: 0.966357
epoch 197, loss: 0.127991
model updated at epoch 197 
epoch 197, 
 train loss: 0.127991, val loss: 0.228700 
 val auc: 0.963964,  test auc: 0.966348
epoch 198, loss: 0.127582
model updated at epoch 198 
epoch 198, 
 train loss: 0.127582, val loss: 0.228604 
 val auc: 0.964133,  test auc: 0.966718
epoch 199, loss: 0.127149
model updated at epoch 199 
epoch 199, 
 train loss: 0.127149, val loss: 0.227862 
 val auc: 0.964189,  test auc: 0.966573
epoch 200, loss: 0.126632
model updated at epoch 200 
epoch 200, 
 train loss: 0.126632, val loss: 0.227718 
 val auc: 0.964471,  test auc: 0.967023
epoch 201, loss: 0.126116
model updated at epoch 201 
epoch 201, 
 train loss: 0.126116, val loss: 0.227030 
 val auc: 0.964602,  test auc: 0.966887
epoch 202, loss: 0.125595
model updated at epoch 202 
epoch 202, 
 train loss: 0.125595, val loss: 0.226820 
 val auc: 0.964696,  test auc: 0.967089
epoch 203, loss: 0.125104
model updated at epoch 203 
epoch 203, 
 train loss: 0.125104, val loss: 0.226369 
 val auc: 0.964977,  test auc: 0.967108
epoch 204, loss: 0.124651
model updated at epoch 204 
epoch 204, 
 train loss: 0.124651, val loss: 0.226003 
 val auc: 0.964959,  test auc: 0.967155
epoch 205, loss: 0.124235
model updated at epoch 205 
epoch 205, 
 train loss: 0.124235, val loss: 0.225752 
 val auc: 0.965221,  test auc: 0.967478
epoch 206, loss: 0.123856
model updated at epoch 206 
epoch 206, 
 train loss: 0.123856, val loss: 0.225135 
 val auc: 0.965447,  test auc: 0.967450
epoch 207, loss: 0.123513
model updated at epoch 207 
epoch 207, 
 train loss: 0.123513, val loss: 0.225050 
 val auc: 0.965803,  test auc: 0.967812
epoch 208, loss: 0.123243
model updated at epoch 208 
epoch 208, 
 train loss: 0.123243, val loss: 0.224307 
 val auc: 0.965616,  test auc: 0.967553
epoch 209, loss: 0.122949
epoch 209, 
 train loss: 0.122949, val loss: 0.224532 
 val auc: 0.966029,  test auc: 0.968159
epoch 210, loss: 0.122707
model updated at epoch 210 
epoch 210, 
 train loss: 0.122707, val loss: 0.223856 
 val auc: 0.965653,  test auc: 0.967643
epoch 211, loss: 0.121906
model updated at epoch 211 
epoch 211, 
 train loss: 0.121906, val loss: 0.223748 
 val auc: 0.966179,  test auc: 0.968262
epoch 212, loss: 0.121090
model updated at epoch 212 
epoch 212, 
 train loss: 0.121090, val loss: 0.222814 
 val auc: 0.965878,  test auc: 0.968009
epoch 213, loss: 0.120664
model updated at epoch 213 
epoch 213, 
 train loss: 0.120664, val loss: 0.222402 
 val auc: 0.966104,  test auc: 0.968140
epoch 214, loss: 0.120499
epoch 214, 
 train loss: 0.120499, val loss: 0.222432 
 val auc: 0.966197,  test auc: 0.968351
epoch 215, loss: 0.120193
model updated at epoch 215 
epoch 215, 
 train loss: 0.120193, val loss: 0.221996 
 val auc: 0.965916,  test auc: 0.968046
epoch 216, loss: 0.119464
model updated at epoch 216 
epoch 216, 
 train loss: 0.119464, val loss: 0.221682 
 val auc: 0.966310,  test auc: 0.968520
epoch 217, loss: 0.118828
model updated at epoch 217 
epoch 217, 
 train loss: 0.118828, val loss: 0.221103 
 val auc: 0.966592,  test auc: 0.968670
epoch 218, loss: 0.118475
model updated at epoch 218 
epoch 218, 
 train loss: 0.118475, val loss: 0.220747 
 val auc: 0.966629,  test auc: 0.968633
epoch 219, loss: 0.118281
model updated at epoch 219 
epoch 219, 
 train loss: 0.118281, val loss: 0.220705 
 val auc: 0.966798,  test auc: 0.968802
epoch 220, loss: 0.118268
model updated at epoch 220 
epoch 220, 
 train loss: 0.118268, val loss: 0.220581 
 val auc: 0.966648,  test auc: 0.968267
epoch 221, loss: 0.117831
model updated at epoch 221 
epoch 221, 
 train loss: 0.117831, val loss: 0.220570 
 val auc: 0.967005,  test auc: 0.969022
epoch 222, loss: 0.117143
model updated at epoch 222 
epoch 222, 
 train loss: 0.117143, val loss: 0.219908 
 val auc: 0.966911,  test auc: 0.968548
epoch 223, loss: 0.116348
model updated at epoch 223 
epoch 223, 
 train loss: 0.116348, val loss: 0.219370 
 val auc: 0.967117,  test auc: 0.969041
epoch 224, loss: 0.115901
model updated at epoch 224 
epoch 224, 
 train loss: 0.115901, val loss: 0.218915 
 val auc: 0.967173,  test auc: 0.969111
epoch 225, loss: 0.115725
model updated at epoch 225 
epoch 225, 
 train loss: 0.115725, val loss: 0.218561 
 val auc: 0.967324,  test auc: 0.968942
epoch 226, loss: 0.115424
model updated at epoch 226 
epoch 226, 
 train loss: 0.115424, val loss: 0.218347 
 val auc: 0.967474,  test auc: 0.969440
epoch 227, loss: 0.114905
model updated at epoch 227 
epoch 227, 
 train loss: 0.114905, val loss: 0.217944 
 val auc: 0.967173,  test auc: 0.968989
epoch 228, loss: 0.114213
model updated at epoch 228 
epoch 228, 
 train loss: 0.114213, val loss: 0.217618 
 val auc: 0.967549,  test auc: 0.969468
epoch 229, loss: 0.113687
model updated at epoch 229 
epoch 229, 
 train loss: 0.113687, val loss: 0.217379 
 val auc: 0.967586,  test auc: 0.969477
epoch 230, loss: 0.113376
model updated at epoch 230 
epoch 230, 
 train loss: 0.113376, val loss: 0.217153 
 val auc: 0.967492,  test auc: 0.969426
epoch 231, loss: 0.113120
model updated at epoch 231 
epoch 231, 
 train loss: 0.113120, val loss: 0.216730 
 val auc: 0.968262,  test auc: 0.969951
epoch 232, loss: 0.112839
model updated at epoch 232 
epoch 232, 
 train loss: 0.112839, val loss: 0.216488 
 val auc: 0.967905,  test auc: 0.969609
epoch 233, loss: 0.112250
model updated at epoch 233 
epoch 233, 
 train loss: 0.112250, val loss: 0.216009 
 val auc: 0.968224,  test auc: 0.969947
epoch 234, loss: 0.111657
model updated at epoch 234 
epoch 234, 
 train loss: 0.111657, val loss: 0.215815 
 val auc: 0.968243,  test auc: 0.970012
epoch 235, loss: 0.111292
model updated at epoch 235 
epoch 235, 
 train loss: 0.111292, val loss: 0.215720 
 val auc: 0.968131,  test auc: 0.970017
epoch 236, loss: 0.111045
model updated at epoch 236 
epoch 236, 
 train loss: 0.111045, val loss: 0.215493 
 val auc: 0.968562,  test auc: 0.970359
epoch 237, loss: 0.110700
model updated at epoch 237 
epoch 237, 
 train loss: 0.110700, val loss: 0.215357 
 val auc: 0.968318,  test auc: 0.969989
epoch 238, loss: 0.110163
model updated at epoch 238 
epoch 238, 
 train loss: 0.110163, val loss: 0.214923 
 val auc: 0.968712,  test auc: 0.970388
epoch 239, loss: 0.109645
model updated at epoch 239 
epoch 239, 
 train loss: 0.109645, val loss: 0.214646 
 val auc: 0.968712,  test auc: 0.970275
epoch 240, loss: 0.109279
model updated at epoch 240 
epoch 240, 
 train loss: 0.109279, val loss: 0.214414 
 val auc: 0.968712,  test auc: 0.970350
epoch 241, loss: 0.108990
model updated at epoch 241 
epoch 241, 
 train loss: 0.108990, val loss: 0.214030 
 val auc: 0.969032,  test auc: 0.970599
epoch 242, loss: 0.108645
model updated at epoch 242 
epoch 242, 
 train loss: 0.108645, val loss: 0.213918 
 val auc: 0.968769,  test auc: 0.970420
epoch 243, loss: 0.108176
model updated at epoch 243 
epoch 243, 
 train loss: 0.108176, val loss: 0.213510 
 val auc: 0.969182,  test auc: 0.970768
epoch 244, loss: 0.107692
model updated at epoch 244 
epoch 244, 
 train loss: 0.107692, val loss: 0.213465 
 val auc: 0.969182,  test auc: 0.970580
epoch 245, loss: 0.107283
model updated at epoch 245 
epoch 245, 
 train loss: 0.107283, val loss: 0.213351 
 val auc: 0.969520,  test auc: 0.970730
epoch 246, loss: 0.106945
model updated at epoch 246 
epoch 246, 
 train loss: 0.106945, val loss: 0.213291 
 val auc: 0.969501,  test auc: 0.970819
epoch 247, loss: 0.106624
epoch 247, 
 train loss: 0.106624, val loss: 0.213348 
 val auc: 0.969294,  test auc: 0.970655
epoch 248, loss: 0.106249
model updated at epoch 248 
epoch 248, 
 train loss: 0.106249, val loss: 0.212970 
 val auc: 0.969820,  test auc: 0.971030
epoch 249, loss: 0.105829
model updated at epoch 249 
epoch 249, 
 train loss: 0.105829, val loss: 0.212879 
 val auc: 0.969520,  test auc: 0.970890
epoch 250, loss: 0.105389
model updated at epoch 250 
epoch 250, 
 train loss: 0.105389, val loss: 0.212574 
 val auc: 0.970195,  test auc: 0.971256
epoch 251, loss: 0.104986
model updated at epoch 251 
epoch 251, 
 train loss: 0.104986, val loss: 0.212563 
 val auc: 0.970158,  test auc: 0.971199
epoch 252, loss: 0.104626
model updated at epoch 252 
epoch 252, 
 train loss: 0.104626, val loss: 0.212560 
 val auc: 0.970195,  test auc: 0.971152
epoch 253, loss: 0.104285
model updated at epoch 253 
epoch 253, 
 train loss: 0.104285, val loss: 0.212237 
 val auc: 0.970458,  test auc: 0.971490
epoch 254, loss: 0.103924
model updated at epoch 254 
epoch 254, 
 train loss: 0.103924, val loss: 0.212139 
 val auc: 0.970420,  test auc: 0.971368
epoch 255, loss: 0.103527
model updated at epoch 255 
epoch 255, 
 train loss: 0.103527, val loss: 0.211401 
 val auc: 0.970833,  test auc: 0.971781
epoch 256, loss: 0.103125
model updated at epoch 256 
epoch 256, 
 train loss: 0.103125, val loss: 0.211137 
 val auc: 0.970683,  test auc: 0.971612
epoch 257, loss: 0.102719
model updated at epoch 257 
epoch 257, 
 train loss: 0.102719, val loss: 0.210652 
 val auc: 0.971096,  test auc: 0.971931
epoch 258, loss: 0.102338
model updated at epoch 258 
epoch 258, 
 train loss: 0.102338, val loss: 0.210433 
 val auc: 0.971265,  test auc: 0.971992
epoch 259, loss: 0.101969
model updated at epoch 259 
epoch 259, 
 train loss: 0.101969, val loss: 0.210229 
 val auc: 0.971415,  test auc: 0.972030
epoch 260, loss: 0.101612
model updated at epoch 260 
epoch 260, 
 train loss: 0.101612, val loss: 0.209751 
 val auc: 0.971659,  test auc: 0.972203
epoch 261, loss: 0.101254
model updated at epoch 261 
epoch 261, 
 train loss: 0.101254, val loss: 0.209650 
 val auc: 0.971584,  test auc: 0.972119
epoch 262, loss: 0.100888
model updated at epoch 262 
epoch 262, 
 train loss: 0.100888, val loss: 0.209186 
 val auc: 0.971772,  test auc: 0.972429
epoch 263, loss: 0.100525
model updated at epoch 263 
epoch 263, 
 train loss: 0.100525, val loss: 0.209129 
 val auc: 0.971791,  test auc: 0.972274
epoch 264, loss: 0.100158
model updated at epoch 264 
epoch 264, 
 train loss: 0.100158, val loss: 0.208388 
 val auc: 0.971959,  test auc: 0.972513
epoch 265, loss: 0.099792
model updated at epoch 265 
epoch 265, 
 train loss: 0.099792, val loss: 0.208300 
 val auc: 0.971884,  test auc: 0.972447
epoch 266, loss: 0.099415
model updated at epoch 266 
epoch 266, 
 train loss: 0.099415, val loss: 0.207639 
 val auc: 0.972110,  test auc: 0.972635
epoch 267, loss: 0.099034
epoch 267, 
 train loss: 0.099034, val loss: 0.207660 
 val auc: 0.972147,  test auc: 0.972607
epoch 268, loss: 0.098657
model updated at epoch 268 
epoch 268, 
 train loss: 0.098657, val loss: 0.207143 
 val auc: 0.972110,  test auc: 0.972738
epoch 269, loss: 0.098284
model updated at epoch 269 
epoch 269, 
 train loss: 0.098284, val loss: 0.206903 
 val auc: 0.972185,  test auc: 0.972785
epoch 270, loss: 0.097914
model updated at epoch 270 
epoch 270, 
 train loss: 0.097914, val loss: 0.206472 
 val auc: 0.972297,  test auc: 0.972860
epoch 271, loss: 0.097550
model updated at epoch 271 
epoch 271, 
 train loss: 0.097550, val loss: 0.206150 
 val auc: 0.972485,  test auc: 0.972973
epoch 272, loss: 0.097191
model updated at epoch 272 
epoch 272, 
 train loss: 0.097191, val loss: 0.205890 
 val auc: 0.972504,  test auc: 0.972996
epoch 273, loss: 0.096837
model updated at epoch 273 
epoch 273, 
 train loss: 0.096837, val loss: 0.205265 
 val auc: 0.972785,  test auc: 0.973245
epoch 274, loss: 0.096486
model updated at epoch 274 
epoch 274, 
 train loss: 0.096486, val loss: 0.204963 
 val auc: 0.972785,  test auc: 0.973198
epoch 275, loss: 0.096150
model updated at epoch 275 
epoch 275, 
 train loss: 0.096150, val loss: 0.204341 
 val auc: 0.973067,  test auc: 0.973372
epoch 276, loss: 0.095835
epoch 276, 
 train loss: 0.095835, val loss: 0.204352 
 val auc: 0.973048,  test auc: 0.973292
epoch 277, loss: 0.095538
model updated at epoch 277 
epoch 277, 
 train loss: 0.095538, val loss: 0.203201 
 val auc: 0.973330,  test auc: 0.973653
epoch 278, loss: 0.095272
epoch 278, 
 train loss: 0.095272, val loss: 0.203678 
 val auc: 0.973161,  test auc: 0.973433
epoch 279, loss: 0.095041
model updated at epoch 279 
epoch 279, 
 train loss: 0.095041, val loss: 0.202046 
 val auc: 0.973705,  test auc: 0.974019
epoch 280, loss: 0.094917
epoch 280, 
 train loss: 0.094917, val loss: 0.203479 
 val auc: 0.972973,  test auc: 0.973405
epoch 281, loss: 0.094808
model updated at epoch 281 
epoch 281, 
 train loss: 0.094808, val loss: 0.201198 
 val auc: 0.973911,  test auc: 0.974352
epoch 282, loss: 0.094838
epoch 282, 
 train loss: 0.094838, val loss: 0.203767 
 val auc: 0.973048,  test auc: 0.973330
epoch 283, loss: 0.094523
model updated at epoch 283 
epoch 283, 
 train loss: 0.094523, val loss: 0.200593 
 val auc: 0.974080,  test auc: 0.974582
epoch 284, loss: 0.094468
epoch 284, 
 train loss: 0.094468, val loss: 0.203710 
 val auc: 0.973048,  test auc: 0.973236
epoch 285, loss: 0.093654
model updated at epoch 285 
epoch 285, 
 train loss: 0.093654, val loss: 0.200094 
 val auc: 0.974118,  test auc: 0.974526
epoch 286, loss: 0.092814
epoch 286, 
 train loss: 0.092814, val loss: 0.201391 
 val auc: 0.973574,  test auc: 0.973827
epoch 287, loss: 0.092274
model updated at epoch 287 
epoch 287, 
 train loss: 0.092274, val loss: 0.200019 
 val auc: 0.973836,  test auc: 0.974221
epoch 288, loss: 0.092184
model updated at epoch 288 
epoch 288, 
 train loss: 0.092184, val loss: 0.198925 
 val auc: 0.974174,  test auc: 0.974606
epoch 289, loss: 0.092418
epoch 289, 
 train loss: 0.092418, val loss: 0.200642 
 val auc: 0.973574,  test auc: 0.973921
epoch 290, loss: 0.092252
model updated at epoch 290 
epoch 290, 
 train loss: 0.092252, val loss: 0.197773 
 val auc: 0.974456,  test auc: 0.974930
epoch 291, loss: 0.091674
epoch 291, 
 train loss: 0.091674, val loss: 0.200104 
 val auc: 0.973649,  test auc: 0.974043
epoch 292, loss: 0.090883
epoch 292, 
 train loss: 0.090883, val loss: 0.198336 
 val auc: 0.974343,  test auc: 0.974761
epoch 293, loss: 0.090529
epoch 293, 
 train loss: 0.090529, val loss: 0.198450 
 val auc: 0.974399,  test auc: 0.974765
epoch 294, loss: 0.090522
epoch 294, 
 train loss: 0.090522, val loss: 0.199335 
 val auc: 0.973949,  test auc: 0.974268
epoch 295, loss: 0.090403
model updated at epoch 295 
epoch 295, 
 train loss: 0.090403, val loss: 0.197092 
 val auc: 0.974775,  test auc: 0.975131
epoch 296, loss: 0.089996
epoch 296, 
 train loss: 0.089996, val loss: 0.198750 
 val auc: 0.974062,  test auc: 0.974352
epoch 297, loss: 0.089422
epoch 297, 
 train loss: 0.089422, val loss: 0.197231 
 val auc: 0.974737,  test auc: 0.974916
epoch 298, loss: 0.089058
epoch 298, 
 train loss: 0.089058, val loss: 0.197506 
 val auc: 0.974662,  test auc: 0.974925
epoch 299, loss: 0.088943
epoch 299, 
 train loss: 0.088943, val loss: 0.198246 
 val auc: 0.974212,  test auc: 0.974690
epoch 300, loss: 0.088791
model updated at epoch 300 
epoch 300, 
 train loss: 0.088791, val loss: 0.196516 
 val auc: 0.974812,  test auc: 0.975253
epoch 301, loss: 0.088483
epoch 301, 
 train loss: 0.088483, val loss: 0.197620 
 val auc: 0.974512,  test auc: 0.974831
epoch 302, loss: 0.088019
model updated at epoch 302 
epoch 302, 
 train loss: 0.088019, val loss: 0.195911 
 val auc: 0.975038,  test auc: 0.975328
epoch 303, loss: 0.087655
epoch 303, 
 train loss: 0.087655, val loss: 0.196135 
 val auc: 0.974962,  test auc: 0.975328
epoch 304, loss: 0.087445
epoch 304, 
 train loss: 0.087445, val loss: 0.196402 
 val auc: 0.974925,  test auc: 0.975328
epoch 305, loss: 0.087271
model updated at epoch 305 
epoch 305, 
 train loss: 0.087271, val loss: 0.195356 
 val auc: 0.975188,  test auc: 0.975713
epoch 306, loss: 0.087039
epoch 306, 
 train loss: 0.087039, val loss: 0.196228 
 val auc: 0.974812,  test auc: 0.975244
epoch 307, loss: 0.086693
model updated at epoch 307 
epoch 307, 
 train loss: 0.086693, val loss: 0.194730 
 val auc: 0.975188,  test auc: 0.975704
epoch 308, loss: 0.086334
epoch 308, 
 train loss: 0.086334, val loss: 0.195208 
 val auc: 0.975075,  test auc: 0.975554
epoch 309, loss: 0.086045
epoch 309, 
 train loss: 0.086045, val loss: 0.194938 
 val auc: 0.975150,  test auc: 0.975638
epoch 310, loss: 0.085818
model updated at epoch 310 
epoch 310, 
 train loss: 0.085818, val loss: 0.194370 
 val auc: 0.975300,  test auc: 0.975779
epoch 311, loss: 0.085607
epoch 311, 
 train loss: 0.085607, val loss: 0.194648 
 val auc: 0.975188,  test auc: 0.975666
epoch 312, loss: 0.085359
model updated at epoch 312 
epoch 312, 
 train loss: 0.085359, val loss: 0.193441 
 val auc: 0.975526,  test auc: 0.975948
epoch 313, loss: 0.085059
epoch 313, 
 train loss: 0.085059, val loss: 0.194060 
 val auc: 0.975131,  test auc: 0.975793
epoch 314, loss: 0.084747
model updated at epoch 314 
epoch 314, 
 train loss: 0.084747, val loss: 0.193349 
 val auc: 0.975563,  test auc: 0.976014
epoch 315, loss: 0.084459
epoch 315, 
 train loss: 0.084459, val loss: 0.193354 
 val auc: 0.975413,  test auc: 0.975985
epoch 316, loss: 0.084220
model updated at epoch 316 
epoch 316, 
 train loss: 0.084220, val loss: 0.193307 
 val auc: 0.975413,  test auc: 0.975957
epoch 317, loss: 0.084007
model updated at epoch 317 
epoch 317, 
 train loss: 0.084007, val loss: 0.192670 
 val auc: 0.975713,  test auc: 0.976164
epoch 318, loss: 0.083787
epoch 318, 
 train loss: 0.083787, val loss: 0.193224 
 val auc: 0.975450,  test auc: 0.976042
epoch 319, loss: 0.083532
model updated at epoch 319 
epoch 319, 
 train loss: 0.083532, val loss: 0.192483 
 val auc: 0.975751,  test auc: 0.976295
epoch 320, loss: 0.083264
epoch 320, 
 train loss: 0.083264, val loss: 0.193052 
 val auc: 0.975488,  test auc: 0.976145
epoch 321, loss: 0.082983
model updated at epoch 321 
epoch 321, 
 train loss: 0.082983, val loss: 0.192310 
 val auc: 0.975713,  test auc: 0.976342
epoch 322, loss: 0.082709
epoch 322, 
 train loss: 0.082709, val loss: 0.192497 
 val auc: 0.975638,  test auc: 0.976295
epoch 323, loss: 0.082455
model updated at epoch 323 
epoch 323, 
 train loss: 0.082455, val loss: 0.192303 
 val auc: 0.975638,  test auc: 0.976323
epoch 324, loss: 0.082222
model updated at epoch 324 
epoch 324, 
 train loss: 0.082222, val loss: 0.192162 
 val auc: 0.975751,  test auc: 0.976473
epoch 325, loss: 0.081996
epoch 325, 
 train loss: 0.081996, val loss: 0.192365 
 val auc: 0.975526,  test auc: 0.976389
epoch 326, loss: 0.081771
model updated at epoch 326 
epoch 326, 
 train loss: 0.081771, val loss: 0.191981 
 val auc: 0.975676,  test auc: 0.976483
epoch 327, loss: 0.081560
epoch 327, 
 train loss: 0.081560, val loss: 0.192328 
 val auc: 0.975601,  test auc: 0.976417
epoch 328, loss: 0.081333
model updated at epoch 328 
epoch 328, 
 train loss: 0.081333, val loss: 0.191624 
 val auc: 0.975901,  test auc: 0.976586
epoch 329, loss: 0.081095
epoch 329, 
 train loss: 0.081095, val loss: 0.192083 
 val auc: 0.975676,  test auc: 0.976502
epoch 330, loss: 0.080842
model updated at epoch 330 
epoch 330, 
 train loss: 0.080842, val loss: 0.191422 
 val auc: 0.975901,  test auc: 0.976656
epoch 331, loss: 0.080596
epoch 331, 
 train loss: 0.080596, val loss: 0.191807 
 val auc: 0.975713,  test auc: 0.976558
epoch 332, loss: 0.080354
model updated at epoch 332 
epoch 332, 
 train loss: 0.080354, val loss: 0.191414 
 val auc: 0.975863,  test auc: 0.976713
epoch 333, loss: 0.080117
epoch 333, 
 train loss: 0.080117, val loss: 0.191562 
 val auc: 0.975751,  test auc: 0.976614
epoch 334, loss: 0.079883
model updated at epoch 334 
epoch 334, 
 train loss: 0.079883, val loss: 0.191192 
 val auc: 0.975901,  test auc: 0.976750
epoch 335, loss: 0.079655
epoch 335, 
 train loss: 0.079655, val loss: 0.191218 
 val auc: 0.975826,  test auc: 0.976717
epoch 336, loss: 0.079433
model updated at epoch 336 
epoch 336, 
 train loss: 0.079433, val loss: 0.191025 
 val auc: 0.975863,  test auc: 0.976792
epoch 337, loss: 0.079206
epoch 337, 
 train loss: 0.079206, val loss: 0.191066 
 val auc: 0.975751,  test auc: 0.976792
epoch 338, loss: 0.078982
model updated at epoch 338 
epoch 338, 
 train loss: 0.078982, val loss: 0.191023 
 val auc: 0.975751,  test auc: 0.976821
epoch 339, loss: 0.078761
epoch 339, 
 train loss: 0.078761, val loss: 0.191067 
 val auc: 0.975826,  test auc: 0.976891
epoch 340, loss: 0.078544
model updated at epoch 340 
epoch 340, 
 train loss: 0.078544, val loss: 0.191010 
 val auc: 0.975788,  test auc: 0.976896
epoch 341, loss: 0.078322
model updated at epoch 341 
epoch 341, 
 train loss: 0.078322, val loss: 0.190914 
 val auc: 0.975788,  test auc: 0.976924
epoch 342, loss: 0.078108
model updated at epoch 342 
epoch 342, 
 train loss: 0.078108, val loss: 0.190873 
 val auc: 0.975863,  test auc: 0.976966
epoch 343, loss: 0.077897
model updated at epoch 343 
epoch 343, 
 train loss: 0.077897, val loss: 0.190648 
 val auc: 0.976051,  test auc: 0.977074
epoch 344, loss: 0.077691
epoch 344, 
 train loss: 0.077691, val loss: 0.190788 
 val auc: 0.975938,  test auc: 0.977036
epoch 345, loss: 0.077499
model updated at epoch 345 
epoch 345, 
 train loss: 0.077499, val loss: 0.190417 
 val auc: 0.976051,  test auc: 0.977163
epoch 346, loss: 0.077324
epoch 346, 
 train loss: 0.077324, val loss: 0.190933 
 val auc: 0.975957,  test auc: 0.977055
epoch 347, loss: 0.077179
model updated at epoch 347 
epoch 347, 
 train loss: 0.077179, val loss: 0.190328 
 val auc: 0.976239,  test auc: 0.977393
epoch 348, loss: 0.077084
epoch 348, 
 train loss: 0.077084, val loss: 0.191269 
 val auc: 0.976014,  test auc: 0.977041
epoch 349, loss: 0.077050
model updated at epoch 349 
epoch 349, 
 train loss: 0.077050, val loss: 0.190172 
 val auc: 0.976314,  test auc: 0.977576
epoch 350, loss: 0.077121
epoch 350, 
 train loss: 0.077121, val loss: 0.192042 
 val auc: 0.975976,  test auc: 0.976957
epoch 351, loss: 0.077132
epoch 351, 
 train loss: 0.077132, val loss: 0.190380 
 val auc: 0.976314,  test auc: 0.977637
epoch 352, loss: 0.077254
epoch 352, 
 train loss: 0.077254, val loss: 0.192873 
 val auc: 0.975826,  test auc: 0.976797
epoch 353, loss: 0.076925
epoch 353, 
 train loss: 0.076925, val loss: 0.190434 
 val auc: 0.976426,  test auc: 0.977773
epoch 354, loss: 0.076515
epoch 354, 
 train loss: 0.076515, val loss: 0.192523 
 val auc: 0.975901,  test auc: 0.976985
epoch 355, loss: 0.075805
epoch 355, 
 train loss: 0.075805, val loss: 0.190381 
 val auc: 0.976351,  test auc: 0.977731
epoch 356, loss: 0.075272
epoch 356, 
 train loss: 0.075272, val loss: 0.191074 
 val auc: 0.976164,  test auc: 0.977262
epoch 357, loss: 0.075048
epoch 357, 
 train loss: 0.075048, val loss: 0.190934 
 val auc: 0.976164,  test auc: 0.977337
epoch 358, loss: 0.075061
epoch 358, 
 train loss: 0.075061, val loss: 0.190332 
 val auc: 0.976464,  test auc: 0.977773
epoch 359, loss: 0.075112
epoch 359, 
 train loss: 0.075112, val loss: 0.191952 
 val auc: 0.976201,  test auc: 0.977262
epoch 360, loss: 0.074942
epoch 360, 
 train loss: 0.074942, val loss: 0.190334 
 val auc: 0.976539,  test auc: 0.977858
epoch 361, loss: 0.074627
epoch 361, 
 train loss: 0.074627, val loss: 0.191753 
 val auc: 0.976239,  test auc: 0.977313
epoch 362, loss: 0.074188
epoch 362, 
 train loss: 0.074188, val loss: 0.190375 
 val auc: 0.976389,  test auc: 0.977660
epoch 363, loss: 0.073875
epoch 363, 
 train loss: 0.073875, val loss: 0.190747 
 val auc: 0.976351,  test auc: 0.977487
epoch 364, loss: 0.073735
epoch 364, 
 train loss: 0.073735, val loss: 0.190897 
 val auc: 0.976351,  test auc: 0.977435
epoch 365, loss: 0.073687
model updated at epoch 365 
epoch 365, 
 train loss: 0.073687, val loss: 0.190077 
 val auc: 0.976539,  test auc: 0.977782
epoch 366, loss: 0.073643
epoch 366, 
 train loss: 0.073643, val loss: 0.191265 
 val auc: 0.976351,  test auc: 0.977416
epoch 367, loss: 0.073648
model updated at epoch 367 
epoch 367, 
 train loss: 0.073648, val loss: 0.189909 
 val auc: 0.976764,  test auc: 0.977942
epoch 368, loss: 0.073841
epoch 368, 
 train loss: 0.073841, val loss: 0.192365 
 val auc: 0.976201,  test auc: 0.977276
epoch 369, loss: 0.073904
epoch 369, 
 train loss: 0.073904, val loss: 0.190386 
 val auc: 0.976764,  test auc: 0.978092
epoch 370, loss: 0.074100
epoch 370, 
 train loss: 0.074100, val loss: 0.193292 
 val auc: 0.975976,  test auc: 0.977182
epoch 371, loss: 0.073588
epoch 371, 
 train loss: 0.073588, val loss: 0.190282 
 val auc: 0.976839,  test auc: 0.978139
epoch 372, loss: 0.072951
epoch 372, 
 train loss: 0.072951, val loss: 0.191964 
 val auc: 0.976276,  test auc: 0.977440
epoch 373, loss: 0.072196
epoch 373, 
 train loss: 0.072196, val loss: 0.189943 
 val auc: 0.976689,  test auc: 0.977923
epoch 374, loss: 0.071899
epoch 374, 
 train loss: 0.071899, val loss: 0.190022 
 val auc: 0.976539,  test auc: 0.977820
epoch 375, loss: 0.072020
epoch 375, 
 train loss: 0.072020, val loss: 0.190988 
 val auc: 0.976389,  test auc: 0.977595
epoch 376, loss: 0.072145
model updated at epoch 376 
epoch 376, 
 train loss: 0.072145, val loss: 0.189565 
 val auc: 0.976952,  test auc: 0.978270
epoch 377, loss: 0.072055
epoch 377, 
 train loss: 0.072055, val loss: 0.191475 
 val auc: 0.976502,  test auc: 0.977604
epoch 378, loss: 0.071527
model updated at epoch 378 
epoch 378, 
 train loss: 0.071527, val loss: 0.189433 
 val auc: 0.976989,  test auc: 0.978167
epoch 379, loss: 0.071053
epoch 379, 
 train loss: 0.071053, val loss: 0.190046 
 val auc: 0.976502,  test auc: 0.977801
epoch 380, loss: 0.070851
epoch 380, 
 train loss: 0.070851, val loss: 0.189746 
 val auc: 0.976652,  test auc: 0.977951
epoch 381, loss: 0.070871
model updated at epoch 381 
epoch 381, 
 train loss: 0.070871, val loss: 0.189031 
 val auc: 0.977065,  test auc: 0.978224
epoch 382, loss: 0.070903
epoch 382, 
 train loss: 0.070903, val loss: 0.190480 
 val auc: 0.976577,  test auc: 0.977698
epoch 383, loss: 0.070686
model updated at epoch 383 
epoch 383, 
 train loss: 0.070686, val loss: 0.188977 
 val auc: 0.977102,  test auc: 0.978317
epoch 384, loss: 0.070354
epoch 384, 
 train loss: 0.070354, val loss: 0.190163 
 val auc: 0.976577,  test auc: 0.977707
epoch 385, loss: 0.070008
epoch 385, 
 train loss: 0.070008, val loss: 0.189193 
 val auc: 0.976914,  test auc: 0.978130
epoch 386, loss: 0.069817
epoch 386, 
 train loss: 0.069817, val loss: 0.189109 
 val auc: 0.976952,  test auc: 0.978102
epoch 387, loss: 0.069759
epoch 387, 
 train loss: 0.069759, val loss: 0.189611 
 val auc: 0.976689,  test auc: 0.977858
epoch 388, loss: 0.069693
model updated at epoch 388 
epoch 388, 
 train loss: 0.069693, val loss: 0.188672 
 val auc: 0.977177,  test auc: 0.978327
epoch 389, loss: 0.069528
epoch 389, 
 train loss: 0.069528, val loss: 0.189905 
 val auc: 0.976652,  test auc: 0.977829
epoch 390, loss: 0.069256
epoch 390, 
 train loss: 0.069256, val loss: 0.188884 
 val auc: 0.977102,  test auc: 0.978261
epoch 391, loss: 0.068996
epoch 391, 
 train loss: 0.068996, val loss: 0.189334 
 val auc: 0.976914,  test auc: 0.978111
epoch 392, loss: 0.068818
epoch 392, 
 train loss: 0.068818, val loss: 0.189026 
 val auc: 0.976877,  test auc: 0.978139
epoch 393, loss: 0.068712
model updated at epoch 393 
epoch 393, 
 train loss: 0.068712, val loss: 0.188536 
 val auc: 0.977177,  test auc: 0.978308
epoch 394, loss: 0.068625
epoch 394, 
 train loss: 0.068625, val loss: 0.189278 
 val auc: 0.976802,  test auc: 0.977961
epoch 395, loss: 0.068473
model updated at epoch 395 
epoch 395, 
 train loss: 0.068473, val loss: 0.188526 
 val auc: 0.977215,  test auc: 0.978421
epoch 396, loss: 0.068278
epoch 396, 
 train loss: 0.068278, val loss: 0.189514 
 val auc: 0.976839,  test auc: 0.978008
epoch 397, loss: 0.068056
epoch 397, 
 train loss: 0.068056, val loss: 0.188853 
 val auc: 0.977102,  test auc: 0.978252
epoch 398, loss: 0.067857
epoch 398, 
 train loss: 0.067857, val loss: 0.188991 
 val auc: 0.976914,  test auc: 0.978167
epoch 399, loss: 0.067706
epoch 399, 
 train loss: 0.067706, val loss: 0.188897 
 val auc: 0.976952,  test auc: 0.978167
epoch 400, loss: 0.067586
model updated at epoch 400 
epoch 400, 
 train loss: 0.067586, val loss: 0.188417 
 val auc: 0.977252,  test auc: 0.978439
epoch 401, loss: 0.067474
epoch 401, 
 train loss: 0.067474, val loss: 0.188993 
 val auc: 0.976989,  test auc: 0.978167
epoch 402, loss: 0.067333
model updated at epoch 402 
epoch 402, 
 train loss: 0.067333, val loss: 0.188317 
 val auc: 0.977271,  test auc: 0.978566
epoch 403, loss: 0.067173
epoch 403, 
 train loss: 0.067173, val loss: 0.189180 
 val auc: 0.976839,  test auc: 0.978186
epoch 404, loss: 0.066982
epoch 404, 
 train loss: 0.066982, val loss: 0.188515 
 val auc: 0.977140,  test auc: 0.978543
epoch 405, loss: 0.066789
epoch 405, 
 train loss: 0.066789, val loss: 0.188928 
 val auc: 0.976952,  test auc: 0.978261
epoch 406, loss: 0.066601
epoch 406, 
 train loss: 0.066601, val loss: 0.188325 
 val auc: 0.977215,  test auc: 0.978486
epoch 407, loss: 0.066437
model updated at epoch 407 
epoch 407, 
 train loss: 0.066437, val loss: 0.188293 
 val auc: 0.977215,  test auc: 0.978458
epoch 408, loss: 0.066288
epoch 408, 
 train loss: 0.066288, val loss: 0.188366 
 val auc: 0.977102,  test auc: 0.978421
epoch 409, loss: 0.066148
model updated at epoch 409 
epoch 409, 
 train loss: 0.066148, val loss: 0.188119 
 val auc: 0.977177,  test auc: 0.978599
epoch 410, loss: 0.066010
epoch 410, 
 train loss: 0.066010, val loss: 0.188489 
 val auc: 0.976989,  test auc: 0.978430
epoch 411, loss: 0.065870
model updated at epoch 411 
epoch 411, 
 train loss: 0.065870, val loss: 0.187987 
 val auc: 0.977102,  test auc: 0.978683
epoch 412, loss: 0.065721
epoch 412, 
 train loss: 0.065721, val loss: 0.188515 
 val auc: 0.977027,  test auc: 0.978449
epoch 413, loss: 0.065566
model updated at epoch 413 
epoch 413, 
 train loss: 0.065566, val loss: 0.187910 
 val auc: 0.977252,  test auc: 0.978758
epoch 414, loss: 0.065410
epoch 414, 
 train loss: 0.065410, val loss: 0.188270 
 val auc: 0.976989,  test auc: 0.978486
epoch 415, loss: 0.065251
model updated at epoch 415 
epoch 415, 
 train loss: 0.065251, val loss: 0.187661 
 val auc: 0.977252,  test auc: 0.978787
epoch 416, loss: 0.065093
epoch 416, 
 train loss: 0.065093, val loss: 0.188099 
 val auc: 0.977252,  test auc: 0.978655
epoch 417, loss: 0.064933
epoch 417, 
 train loss: 0.064933, val loss: 0.187675 
 val auc: 0.977215,  test auc: 0.978852
epoch 418, loss: 0.064772
epoch 418, 
 train loss: 0.064772, val loss: 0.187961 
 val auc: 0.977252,  test auc: 0.978749
epoch 419, loss: 0.064616
model updated at epoch 419 
epoch 419, 
 train loss: 0.064616, val loss: 0.187531 
 val auc: 0.977384,  test auc: 0.978951
epoch 420, loss: 0.064466
epoch 420, 
 train loss: 0.064466, val loss: 0.187618 
 val auc: 0.977346,  test auc: 0.978829
epoch 421, loss: 0.064315
model updated at epoch 421 
epoch 421, 
 train loss: 0.064315, val loss: 0.187259 
 val auc: 0.977402,  test auc: 0.978984
epoch 422, loss: 0.064172
epoch 422, 
 train loss: 0.064172, val loss: 0.187530 
 val auc: 0.977440,  test auc: 0.978890
epoch 423, loss: 0.064031
model updated at epoch 423 
epoch 423, 
 train loss: 0.064031, val loss: 0.187199 
 val auc: 0.977553,  test auc: 0.979106
epoch 424, loss: 0.063893
epoch 424, 
 train loss: 0.063893, val loss: 0.187562 
 val auc: 0.977477,  test auc: 0.978965
epoch 425, loss: 0.063762
model updated at epoch 425 
epoch 425, 
 train loss: 0.063762, val loss: 0.187018 
 val auc: 0.977665,  test auc: 0.979162
epoch 426, loss: 0.063633
epoch 426, 
 train loss: 0.063633, val loss: 0.187591 
 val auc: 0.977440,  test auc: 0.979002
epoch 427, loss: 0.063498
model updated at epoch 427 
epoch 427, 
 train loss: 0.063498, val loss: 0.186909 
 val auc: 0.977759,  test auc: 0.979298
epoch 428, loss: 0.063371
epoch 428, 
 train loss: 0.063371, val loss: 0.187515 
 val auc: 0.977609,  test auc: 0.979139
epoch 429, loss: 0.063323
model updated at epoch 429 
epoch 429, 
 train loss: 0.063323, val loss: 0.186564 
 val auc: 0.977703,  test auc: 0.979350
epoch 430, loss: 0.063482
epoch 430, 
 train loss: 0.063482, val loss: 0.188222 
 val auc: 0.977196,  test auc: 0.978970
epoch 431, loss: 0.064014
epoch 431, 
 train loss: 0.064014, val loss: 0.186809 
 val auc: 0.977909,  test auc: 0.979584
epoch 432, loss: 0.065682
epoch 432, 
 train loss: 0.065682, val loss: 0.191749 
 val auc: 0.976727,  test auc: 0.978505
epoch 433, loss: 0.067207
epoch 433, 
 train loss: 0.067207, val loss: 0.189463 
 val auc: 0.978191,  test auc: 0.979894
epoch 434, loss: 0.069631
epoch 434, 
 train loss: 0.069631, val loss: 0.196920 
 val auc: 0.976182,  test auc: 0.977843
epoch 435, loss: 0.065092
epoch 435, 
 train loss: 0.065092, val loss: 0.188708 
 val auc: 0.978191,  test auc: 0.979931
epoch 436, loss: 0.062247
epoch 436, 
 train loss: 0.062247, val loss: 0.188283 
 val auc: 0.977534,  test auc: 0.979364
epoch 437, loss: 0.063505
epoch 437, 
 train loss: 0.063505, val loss: 0.190502 
 val auc: 0.976877,  test auc: 0.978862
epoch 438, loss: 0.064758
epoch 438, 
 train loss: 0.064758, val loss: 0.188120 
 val auc: 0.978153,  test auc: 0.979960
epoch 439, loss: 0.063647
epoch 439, 
 train loss: 0.063647, val loss: 0.190982 
 val auc: 0.976802,  test auc: 0.978805
epoch 440, loss: 0.061713
epoch 440, 
 train loss: 0.061713, val loss: 0.187706 
 val auc: 0.977684,  test auc: 0.979556
epoch 441, loss: 0.062918
epoch 441, 
 train loss: 0.062918, val loss: 0.187401 
 val auc: 0.977834,  test auc: 0.979917
epoch 442, loss: 0.063851
epoch 442, 
 train loss: 0.063851, val loss: 0.191360 
 val auc: 0.976745,  test auc: 0.978735
epoch 443, loss: 0.061663
model updated at epoch 443 
epoch 443, 
 train loss: 0.061663, val loss: 0.186447 
 val auc: 0.977684,  test auc: 0.979711
epoch 444, loss: 0.061672
model updated at epoch 444 
epoch 444, 
 train loss: 0.061672, val loss: 0.186277 
 val auc: 0.977815,  test auc: 0.979819
epoch 445, loss: 0.062963
epoch 445, 
 train loss: 0.062963, val loss: 0.189929 
 val auc: 0.977309,  test auc: 0.979054
epoch 446, loss: 0.061567
model updated at epoch 446 
epoch 446, 
 train loss: 0.061567, val loss: 0.185989 
 val auc: 0.977909,  test auc: 0.979955
epoch 447, loss: 0.060878
epoch 447, 
 train loss: 0.060878, val loss: 0.186072 
 val auc: 0.977872,  test auc: 0.979763
epoch 448, loss: 0.061748
epoch 448, 
 train loss: 0.061748, val loss: 0.188713 
 val auc: 0.977402,  test auc: 0.979200
epoch 449, loss: 0.061215
epoch 449, 
 train loss: 0.061215, val loss: 0.186043 
 val auc: 0.977928,  test auc: 0.980016
epoch 450, loss: 0.060419
epoch 450, 
 train loss: 0.060419, val loss: 0.186319 
 val auc: 0.977834,  test auc: 0.979753
epoch 451, loss: 0.060782
epoch 451, 
 train loss: 0.060782, val loss: 0.187412 
 val auc: 0.977515,  test auc: 0.979519
epoch 452, loss: 0.060796
model updated at epoch 452 
epoch 452, 
 train loss: 0.060796, val loss: 0.185695 
 val auc: 0.978078,  test auc: 0.980082
epoch 453, loss: 0.060152
epoch 453, 
 train loss: 0.060152, val loss: 0.186335 
 val auc: 0.977947,  test auc: 0.979730
epoch 454, loss: 0.060046
epoch 454, 
 train loss: 0.060046, val loss: 0.186260 
 val auc: 0.977928,  test auc: 0.979753
epoch 455, loss: 0.060274
model updated at epoch 455 
epoch 455, 
 train loss: 0.060274, val loss: 0.185356 
 val auc: 0.978172,  test auc: 0.980218
epoch 456, loss: 0.059958
epoch 456, 
 train loss: 0.059958, val loss: 0.186335 
 val auc: 0.977947,  test auc: 0.979809
epoch 457, loss: 0.059561
epoch 457, 
 train loss: 0.059561, val loss: 0.185402 
 val auc: 0.978059,  test auc: 0.979964
epoch 458, loss: 0.059698
model updated at epoch 458 
epoch 458, 
 train loss: 0.059698, val loss: 0.184996 
 val auc: 0.978097,  test auc: 0.980124
epoch 459, loss: 0.059682
epoch 459, 
 train loss: 0.059682, val loss: 0.186254 
 val auc: 0.977965,  test auc: 0.979800
epoch 460, loss: 0.059248
epoch 460, 
 train loss: 0.059248, val loss: 0.185064 
 val auc: 0.978116,  test auc: 0.980072
epoch 461, loss: 0.059159
model updated at epoch 461 
epoch 461, 
 train loss: 0.059159, val loss: 0.184928 
 val auc: 0.978209,  test auc: 0.980133
epoch 462, loss: 0.059254
epoch 462, 
 train loss: 0.059254, val loss: 0.185866 
 val auc: 0.978078,  test auc: 0.979894
epoch 463, loss: 0.058978
model updated at epoch 463 
epoch 463, 
 train loss: 0.058978, val loss: 0.184643 
 val auc: 0.978247,  test auc: 0.980227
epoch 464, loss: 0.058727
epoch 464, 
 train loss: 0.058727, val loss: 0.184819 
 val auc: 0.978209,  test auc: 0.980138
epoch 465, loss: 0.058746
epoch 465, 
 train loss: 0.058746, val loss: 0.185369 
 val auc: 0.978097,  test auc: 0.979983
epoch 466, loss: 0.058656
model updated at epoch 466 
epoch 466, 
 train loss: 0.058656, val loss: 0.184617 
 val auc: 0.978378,  test auc: 0.980316
epoch 467, loss: 0.058405
epoch 467, 
 train loss: 0.058405, val loss: 0.185153 
 val auc: 0.978172,  test auc: 0.980068
epoch 468, loss: 0.058285
epoch 468, 
 train loss: 0.058285, val loss: 0.185194 
 val auc: 0.978209,  test auc: 0.980100
epoch 469, loss: 0.058266
epoch 469, 
 train loss: 0.058266, val loss: 0.184771 
 val auc: 0.978416,  test auc: 0.980354
epoch 470, loss: 0.058117
epoch 470, 
 train loss: 0.058117, val loss: 0.185420 
 val auc: 0.978153,  test auc: 0.980044
epoch 471, loss: 0.057917
epoch 471, 
 train loss: 0.057917, val loss: 0.184951 
 val auc: 0.978285,  test auc: 0.980227
epoch 472, loss: 0.057847
epoch 472, 
 train loss: 0.057847, val loss: 0.184761 
 val auc: 0.978397,  test auc: 0.980382
epoch 473, loss: 0.057781
epoch 473, 
 train loss: 0.057781, val loss: 0.185309 
 val auc: 0.978116,  test auc: 0.980082
epoch 474, loss: 0.057605
model updated at epoch 474 
epoch 474, 
 train loss: 0.057605, val loss: 0.184593 
 val auc: 0.978378,  test auc: 0.980344
epoch 475, loss: 0.057458
epoch 475, 
 train loss: 0.057458, val loss: 0.184610 
 val auc: 0.978322,  test auc: 0.980293
epoch 476, loss: 0.057388
epoch 476, 
 train loss: 0.057388, val loss: 0.184903 
 val auc: 0.978247,  test auc: 0.980185
epoch 477, loss: 0.057286
model updated at epoch 477 
epoch 477, 
 train loss: 0.057286, val loss: 0.184466 
 val auc: 0.978435,  test auc: 0.980452
epoch 478, loss: 0.057127
epoch 478, 
 train loss: 0.057127, val loss: 0.184816 
 val auc: 0.978247,  test auc: 0.980297
epoch 479, loss: 0.057008
epoch 479, 
 train loss: 0.057008, val loss: 0.184765 
 val auc: 0.978228,  test auc: 0.980283
epoch 480, loss: 0.056922
epoch 480, 
 train loss: 0.056922, val loss: 0.184501 
 val auc: 0.978416,  test auc: 0.980429
epoch 481, loss: 0.056811
epoch 481, 
 train loss: 0.056811, val loss: 0.184896 
 val auc: 0.978191,  test auc: 0.980232
epoch 482, loss: 0.056674
epoch 482, 
 train loss: 0.056674, val loss: 0.184651 
 val auc: 0.978285,  test auc: 0.980382
epoch 483, loss: 0.056557
epoch 483, 
 train loss: 0.056557, val loss: 0.184755 
 val auc: 0.978247,  test auc: 0.980358
epoch 484, loss: 0.056464
epoch 484, 
 train loss: 0.056464, val loss: 0.184993 
 val auc: 0.978285,  test auc: 0.980344
epoch 485, loss: 0.056352
epoch 485, 
 train loss: 0.056352, val loss: 0.184648 
 val auc: 0.978435,  test auc: 0.980513
epoch 486, loss: 0.056225
epoch 486, 
 train loss: 0.056225, val loss: 0.184832 
 val auc: 0.978247,  test auc: 0.980358
epoch 487, loss: 0.056127
epoch 487, 
 train loss: 0.056127, val loss: 0.184530 
 val auc: 0.978285,  test auc: 0.980410
epoch 488, loss: 0.056091
epoch 488, 
 train loss: 0.056091, val loss: 0.185286 
 val auc: 0.978191,  test auc: 0.980396
epoch 489, loss: 0.056076
epoch 489, 
 train loss: 0.056076, val loss: 0.184612 
 val auc: 0.978585,  test auc: 0.980687
epoch 490, loss: 0.055902
epoch 490, 
 train loss: 0.055902, val loss: 0.185280 
 val auc: 0.978285,  test auc: 0.980335
epoch 491, loss: 0.055684
epoch 491, 
 train loss: 0.055684, val loss: 0.184660 
 val auc: 0.978360,  test auc: 0.980462
epoch 492, loss: 0.055627
epoch 492, 
 train loss: 0.055627, val loss: 0.184549 
 val auc: 0.978360,  test auc: 0.980579
epoch 493, loss: 0.055591
epoch 493, 
 train loss: 0.055591, val loss: 0.185345 
 val auc: 0.978285,  test auc: 0.980429
epoch 494, loss: 0.055427
epoch 494, 
 train loss: 0.055427, val loss: 0.184593 
 val auc: 0.978472,  test auc: 0.980654
epoch 495, loss: 0.055252
epoch 495, 
 train loss: 0.055252, val loss: 0.184772 
 val auc: 0.978378,  test auc: 0.980546
epoch 496, loss: 0.055173
epoch 496, 
 train loss: 0.055173, val loss: 0.184947 
 val auc: 0.978341,  test auc: 0.980551
epoch 497, loss: 0.055112
epoch 497, 
 train loss: 0.055112, val loss: 0.184561 
 val auc: 0.978566,  test auc: 0.980762
epoch 498, loss: 0.054981
epoch 498, 
 train loss: 0.054981, val loss: 0.185094 
 val auc: 0.978378,  test auc: 0.980574
epoch 499, loss: 0.054826
epoch 499, 
 train loss: 0.054826, val loss: 0.184697 
 val auc: 0.978435,  test auc: 0.980729
epoch 500, loss: 0.054722
epoch 500, 
 train loss: 0.054722, val loss: 0.184680 
 val auc: 0.978435,  test auc: 0.980729
epoch 501, loss: 0.054655
epoch 501, 
 train loss: 0.054655, val loss: 0.185091 
 val auc: 0.978416,  test auc: 0.980593
epoch 502, loss: 0.054545
epoch 502, 
 train loss: 0.054545, val loss: 0.184606 
 val auc: 0.978435,  test auc: 0.980767
epoch 503, loss: 0.054411
epoch 503, 
 train loss: 0.054411, val loss: 0.184898 
 val auc: 0.978341,  test auc: 0.980640
epoch 504, loss: 0.054288
epoch 504, 
 train loss: 0.054288, val loss: 0.184750 
 val auc: 0.978360,  test auc: 0.980673
epoch 505, loss: 0.054208
epoch 505, 
 train loss: 0.054208, val loss: 0.184542 
 val auc: 0.978472,  test auc: 0.980785
epoch 506, loss: 0.054111
epoch 506, 
 train loss: 0.054111, val loss: 0.184899 
 val auc: 0.978378,  test auc: 0.980663
epoch 507, loss: 0.053993
epoch 507, 
 train loss: 0.053993, val loss: 0.184556 
 val auc: 0.978416,  test auc: 0.980818
epoch 508, loss: 0.053867
epoch 508, 
 train loss: 0.053867, val loss: 0.184784 
 val auc: 0.978453,  test auc: 0.980734
epoch 509, loss: 0.053761
epoch 509, 
 train loss: 0.053761, val loss: 0.184801 
 val auc: 0.978472,  test auc: 0.980767
epoch 510, loss: 0.053670
epoch 510, 
 train loss: 0.053670, val loss: 0.184627 
 val auc: 0.978510,  test auc: 0.980889
epoch 511, loss: 0.053569
epoch 511, 
 train loss: 0.053569, val loss: 0.184859 
 val auc: 0.978378,  test auc: 0.980743
epoch 512, loss: 0.053454
epoch 512, 
 train loss: 0.053454, val loss: 0.184589 
 val auc: 0.978435,  test auc: 0.980889
epoch 513, loss: 0.053339
epoch 513, 
 train loss: 0.053339, val loss: 0.184672 
 val auc: 0.978341,  test auc: 0.980776
epoch 514, loss: 0.053238
epoch 514, 
 train loss: 0.053238, val loss: 0.184685 
 val auc: 0.978416,  test auc: 0.980795
epoch 515, loss: 0.053144
epoch 515, 
 train loss: 0.053144, val loss: 0.184527 
 val auc: 0.978529,  test auc: 0.980903
epoch 516, loss: 0.053042
epoch 516, 
 train loss: 0.053042, val loss: 0.184831 
 val auc: 0.978529,  test auc: 0.980828
epoch 517, loss: 0.052927
epoch 517, 
 train loss: 0.052927, val loss: 0.184708 
 val auc: 0.978529,  test auc: 0.980926
epoch 518, loss: 0.052819
epoch 518, 
 train loss: 0.052819, val loss: 0.184838 
 val auc: 0.978604,  test auc: 0.980912
epoch 519, loss: 0.052720
epoch 519, 
 train loss: 0.052720, val loss: 0.184878 
 val auc: 0.978566,  test auc: 0.980940
epoch 520, loss: 0.052618
epoch 520, 
 train loss: 0.052618, val loss: 0.184859 
 val auc: 0.978472,  test auc: 0.981001
epoch 521, loss: 0.052517
epoch 521, 
 train loss: 0.052517, val loss: 0.185157 
 val auc: 0.978510,  test auc: 0.980983
epoch 522, loss: 0.052409
epoch 522, 
 train loss: 0.052409, val loss: 0.185077 
 val auc: 0.978491,  test auc: 0.981048
epoch 523, loss: 0.052296
epoch 523, 
 train loss: 0.052296, val loss: 0.185264 
 val auc: 0.978547,  test auc: 0.981001
epoch 524, loss: 0.052186
epoch 524, 
 train loss: 0.052186, val loss: 0.185257 
 val auc: 0.978604,  test auc: 0.980992
epoch 525, loss: 0.052084
epoch 525, 
 train loss: 0.052084, val loss: 0.185372 
 val auc: 0.978604,  test auc: 0.981011
epoch 526, loss: 0.051983
epoch 526, 
 train loss: 0.051983, val loss: 0.185594 
 val auc: 0.978604,  test auc: 0.980978
epoch 527, loss: 0.051880
epoch 527, 
 train loss: 0.051880, val loss: 0.185583 
 val auc: 0.978585,  test auc: 0.981006
epoch 528, loss: 0.051775
epoch 528, 
 train loss: 0.051775, val loss: 0.185868 
 val auc: 0.978585,  test auc: 0.980983
epoch 529, loss: 0.051670
epoch 529, 
 train loss: 0.051670, val loss: 0.185865 
 val auc: 0.978604,  test auc: 0.981025
epoch 530, loss: 0.051564
epoch 530, 
 train loss: 0.051564, val loss: 0.186006 
 val auc: 0.978622,  test auc: 0.981011
epoch 531, loss: 0.051460
epoch 531, 
 train loss: 0.051460, val loss: 0.186014 
 val auc: 0.978566,  test auc: 0.981011
epoch 532, loss: 0.051360
epoch 532, 
 train loss: 0.051360, val loss: 0.186021 
 val auc: 0.978566,  test auc: 0.981011
epoch 533, loss: 0.051260
epoch 533, 
 train loss: 0.051260, val loss: 0.186173 
 val auc: 0.978585,  test auc: 0.981015
epoch 534, loss: 0.051160
epoch 534, 
 train loss: 0.051160, val loss: 0.186201 
 val auc: 0.978622,  test auc: 0.981095
epoch 535, loss: 0.051058
epoch 535, 
 train loss: 0.051058, val loss: 0.186391 
 val auc: 0.978547,  test auc: 0.981039
epoch 536, loss: 0.050957
epoch 536, 
 train loss: 0.050957, val loss: 0.186305 
 val auc: 0.978604,  test auc: 0.981072
epoch 537, loss: 0.050855
epoch 537, 
 train loss: 0.050855, val loss: 0.186471 
 val auc: 0.978529,  test auc: 0.981011
epoch 538, loss: 0.050752
epoch 538, 
 train loss: 0.050752, val loss: 0.186439 
 val auc: 0.978510,  test auc: 0.981039
epoch 539, loss: 0.050650
epoch 539, 
 train loss: 0.050650, val loss: 0.186529 
 val auc: 0.978510,  test auc: 0.981067
epoch 540, loss: 0.050546
epoch 540, 
 train loss: 0.050546, val loss: 0.186482 
 val auc: 0.978491,  test auc: 0.981058
epoch 541, loss: 0.050447
epoch 541, 
 train loss: 0.050447, val loss: 0.186429 
 val auc: 0.978491,  test auc: 0.981090
epoch 542, loss: 0.050346
epoch 542, 
 train loss: 0.050346, val loss: 0.186471 
 val auc: 0.978529,  test auc: 0.981095
epoch 543, loss: 0.050248
epoch 543, 
 train loss: 0.050248, val loss: 0.186403 
 val auc: 0.978566,  test auc: 0.981142
epoch 544, loss: 0.050148
epoch 544, 
 train loss: 0.050148, val loss: 0.186427 
 val auc: 0.978604,  test auc: 0.981133
epoch 545, loss: 0.050050
epoch 545, 
 train loss: 0.050050, val loss: 0.186346 
 val auc: 0.978529,  test auc: 0.981180
epoch 546, loss: 0.049949
epoch 546, 
 train loss: 0.049949, val loss: 0.186533 
 val auc: 0.978585,  test auc: 0.981189
epoch 547, loss: 0.049850
epoch 547, 
 train loss: 0.049850, val loss: 0.186471 
 val auc: 0.978604,  test auc: 0.981212
epoch 548, loss: 0.049749
epoch 548, 
 train loss: 0.049749, val loss: 0.186374 
 val auc: 0.978585,  test auc: 0.981227
epoch 549, loss: 0.049653
epoch 549, 
 train loss: 0.049653, val loss: 0.186231 
 val auc: 0.978604,  test auc: 0.981245
epoch 550, loss: 0.049553
epoch 550, 
 train loss: 0.049553, val loss: 0.186230 
 val auc: 0.978641,  test auc: 0.981302
epoch 551, loss: 0.049457
epoch 551, 
 train loss: 0.049457, val loss: 0.186517 
 val auc: 0.978773,  test auc: 0.981349
epoch 552, loss: 0.049361
epoch 552, 
 train loss: 0.049361, val loss: 0.186555 
 val auc: 0.978679,  test auc: 0.981339
epoch 553, loss: 0.049268
epoch 553, 
 train loss: 0.049268, val loss: 0.186696 
 val auc: 0.978641,  test auc: 0.981330
epoch 554, loss: 0.049171
epoch 554, 
 train loss: 0.049171, val loss: 0.186422 
 val auc: 0.978716,  test auc: 0.981386
epoch 555, loss: 0.049072
epoch 555, 
 train loss: 0.049072, val loss: 0.186617 
 val auc: 0.978735,  test auc: 0.981386
epoch 556, loss: 0.048970
epoch 556, 
 train loss: 0.048970, val loss: 0.186496 
 val auc: 0.978679,  test auc: 0.981400
epoch 557, loss: 0.048868
epoch 557, 
 train loss: 0.048868, val loss: 0.186654 
 val auc: 0.978716,  test auc: 0.981372
epoch 558, loss: 0.048771
epoch 558, 
 train loss: 0.048771, val loss: 0.186568 
 val auc: 0.978679,  test auc: 0.981395
epoch 559, loss: 0.048673
epoch 559, 
 train loss: 0.048673, val loss: 0.186519 
 val auc: 0.978697,  test auc: 0.981400
epoch 560, loss: 0.048576
epoch 560, 
 train loss: 0.048576, val loss: 0.186509 
 val auc: 0.978660,  test auc: 0.981438
epoch 561, loss: 0.048480
epoch 561, 
 train loss: 0.048480, val loss: 0.186535 
 val auc: 0.978604,  test auc: 0.981480
epoch 562, loss: 0.048388
epoch 562, 
 train loss: 0.048388, val loss: 0.186814 
 val auc: 0.978697,  test auc: 0.981447
epoch 563, loss: 0.048299
epoch 563, 
 train loss: 0.048299, val loss: 0.186659 
 val auc: 0.978697,  test auc: 0.981471
epoch 564, loss: 0.048209
epoch 564, 
 train loss: 0.048209, val loss: 0.186799 
 val auc: 0.978773,  test auc: 0.981485
epoch 565, loss: 0.048129
epoch 565, 
 train loss: 0.048129, val loss: 0.186290 
 val auc: 0.978697,  test auc: 0.981546
epoch 566, loss: 0.048051
epoch 566, 
 train loss: 0.048051, val loss: 0.186862 
 val auc: 0.978754,  test auc: 0.981532
epoch 567, loss: 0.047968
epoch 567, 
 train loss: 0.047968, val loss: 0.186348 
 val auc: 0.978660,  test auc: 0.981616
epoch 568, loss: 0.047879
epoch 568, 
 train loss: 0.047879, val loss: 0.187091 
 val auc: 0.978791,  test auc: 0.981541
epoch 569, loss: 0.047778
epoch 569, 
 train loss: 0.047778, val loss: 0.186366 
 val auc: 0.978697,  test auc: 0.981696
epoch 570, loss: 0.047674
epoch 570, 
 train loss: 0.047674, val loss: 0.186923 
 val auc: 0.978810,  test auc: 0.981574
epoch 571, loss: 0.047565
epoch 571, 
 train loss: 0.047565, val loss: 0.186296 
 val auc: 0.978697,  test auc: 0.981621
epoch 572, loss: 0.047460
epoch 572, 
 train loss: 0.047460, val loss: 0.186830 
 val auc: 0.978773,  test auc: 0.981555
epoch 573, loss: 0.047356
epoch 573, 
 train loss: 0.047356, val loss: 0.186520 
 val auc: 0.978679,  test auc: 0.981583
epoch 574, loss: 0.047265
epoch 574, 
 train loss: 0.047265, val loss: 0.186996 
 val auc: 0.978791,  test auc: 0.981569
epoch 575, loss: 0.047177
epoch 575, 
 train loss: 0.047177, val loss: 0.186530 
 val auc: 0.978697,  test auc: 0.981630
epoch 576, loss: 0.047092
epoch 576, 
 train loss: 0.047092, val loss: 0.186858 
 val auc: 0.978735,  test auc: 0.981546
epoch 577, loss: 0.047007
epoch 577, 
 train loss: 0.047007, val loss: 0.186283 
 val auc: 0.978697,  test auc: 0.981616
epoch 578, loss: 0.046932
epoch 578, 
 train loss: 0.046932, val loss: 0.186882 
 val auc: 0.978773,  test auc: 0.981574
epoch 579, loss: 0.046854
epoch 579, 
 train loss: 0.046854, val loss: 0.186168 
 val auc: 0.978697,  test auc: 0.981686
epoch 580, loss: 0.046774
epoch 580, 
 train loss: 0.046774, val loss: 0.186835 
 val auc: 0.978866,  test auc: 0.981644
epoch 581, loss: 0.046689
epoch 581, 
 train loss: 0.046689, val loss: 0.186006 
 val auc: 0.978716,  test auc: 0.981729
epoch 582, loss: 0.046607
epoch 582, 
 train loss: 0.046607, val loss: 0.186826 
 val auc: 0.978754,  test auc: 0.981574
epoch 583, loss: 0.046517
epoch 583, 
 train loss: 0.046517, val loss: 0.186157 
 val auc: 0.978791,  test auc: 0.981771
epoch 584, loss: 0.046425
epoch 584, 
 train loss: 0.046425, val loss: 0.187079 
 val auc: 0.978716,  test auc: 0.981588
epoch 585, loss: 0.046323
epoch 585, 
 train loss: 0.046323, val loss: 0.186258 
 val auc: 0.978791,  test auc: 0.981799
epoch 586, loss: 0.046220
epoch 586, 
 train loss: 0.046220, val loss: 0.186931 
 val auc: 0.978716,  test auc: 0.981625
epoch 587, loss: 0.046111
epoch 587, 
 train loss: 0.046111, val loss: 0.186135 
 val auc: 0.978773,  test auc: 0.981822
epoch 588, loss: 0.046003
epoch 588, 
 train loss: 0.046003, val loss: 0.186646 
 val auc: 0.978735,  test auc: 0.981658
epoch 589, loss: 0.045899
epoch 589, 
 train loss: 0.045899, val loss: 0.186157 
 val auc: 0.978716,  test auc: 0.981799
epoch 590, loss: 0.045799
epoch 590, 
 train loss: 0.045799, val loss: 0.186634 
 val auc: 0.978754,  test auc: 0.981719
epoch 591, loss: 0.045702
epoch 591, 
 train loss: 0.045702, val loss: 0.186346 
 val auc: 0.978697,  test auc: 0.981766
epoch 592, loss: 0.045608
epoch 592, 
 train loss: 0.045608, val loss: 0.186585 
 val auc: 0.978754,  test auc: 0.981719
epoch 593, loss: 0.045516
epoch 593, 
 train loss: 0.045516, val loss: 0.186383 
 val auc: 0.978773,  test auc: 0.981780
epoch 594, loss: 0.045427
epoch 594, 
 train loss: 0.045427, val loss: 0.186589 
 val auc: 0.978679,  test auc: 0.981715
epoch 595, loss: 0.045338
epoch 595, 
 train loss: 0.045338, val loss: 0.186438 
 val auc: 0.978697,  test auc: 0.981771
epoch 596, loss: 0.045250
epoch 596, 
 train loss: 0.045250, val loss: 0.186542 
 val auc: 0.978697,  test auc: 0.981738
epoch 597, loss: 0.045160
epoch 597, 
 train loss: 0.045160, val loss: 0.186263 
 val auc: 0.978791,  test auc: 0.981813
epoch 598, loss: 0.045073
epoch 598, 
 train loss: 0.045073, val loss: 0.186302 
 val auc: 0.978791,  test auc: 0.981813
epoch 599, loss: 0.044985
epoch 599, 
 train loss: 0.044985, val loss: 0.186253 
 val auc: 0.978773,  test auc: 0.981813
epoch 600, loss: 0.044898
epoch 600, 
 train loss: 0.044898, val loss: 0.186446 
 val auc: 0.978735,  test auc: 0.981785
epoch 601, loss: 0.044811
epoch 601, 
 train loss: 0.044811, val loss: 0.186384 
 val auc: 0.978810,  test auc: 0.981799
epoch 602, loss: 0.044723
epoch 602, 
 train loss: 0.044723, val loss: 0.186462 
 val auc: 0.978641,  test auc: 0.981771
epoch 603, loss: 0.044639
epoch 603, 
 train loss: 0.044639, val loss: 0.186394 
 val auc: 0.978697,  test auc: 0.981799
epoch 604, loss: 0.044554
epoch 604, 
 train loss: 0.044554, val loss: 0.186459 
 val auc: 0.978697,  test auc: 0.981785
epoch 605, loss: 0.044467
epoch 605, 
 train loss: 0.044467, val loss: 0.186325 
 val auc: 0.978735,  test auc: 0.981837
epoch 606, loss: 0.044387
epoch 606, 
 train loss: 0.044387, val loss: 0.186516 
 val auc: 0.978697,  test auc: 0.981794
epoch 607, loss: 0.044305
epoch 607, 
 train loss: 0.044305, val loss: 0.186327 
 val auc: 0.978754,  test auc: 0.981898
epoch 608, loss: 0.044235
epoch 608, 
 train loss: 0.044235, val loss: 0.186645 
 val auc: 0.978716,  test auc: 0.981776
epoch 609, loss: 0.044177
epoch 609, 
 train loss: 0.044177, val loss: 0.186304 
 val auc: 0.978679,  test auc: 0.981921
epoch 610, loss: 0.044138
epoch 610, 
 train loss: 0.044138, val loss: 0.187061 
 val auc: 0.978622,  test auc: 0.981752
epoch 611, loss: 0.044118
epoch 611, 
 train loss: 0.044118, val loss: 0.186381 
 val auc: 0.978773,  test auc: 0.981996
epoch 612, loss: 0.044133
epoch 612, 
 train loss: 0.044133, val loss: 0.187483 
 val auc: 0.978754,  test auc: 0.981700
epoch 613, loss: 0.044178
epoch 613, 
 train loss: 0.044178, val loss: 0.186343 
 val auc: 0.978773,  test auc: 0.982132
epoch 614, loss: 0.044296
epoch 614, 
 train loss: 0.044296, val loss: 0.188064 
 val auc: 0.978697,  test auc: 0.981715
epoch 615, loss: 0.044433
epoch 615, 
 train loss: 0.044433, val loss: 0.186477 
 val auc: 0.978904,  test auc: 0.982165
epoch 616, loss: 0.045211
epoch 616, 
 train loss: 0.045211, val loss: 0.190115 
 val auc: 0.978397,  test auc: 0.981438
epoch 617, loss: 0.045849
epoch 617, 
 train loss: 0.045849, val loss: 0.188395 
 val auc: 0.979035,  test auc: 0.982160
epoch 618, loss: 0.046647
epoch 618, 
 train loss: 0.046647, val loss: 0.193025 
 val auc: 0.978078,  test auc: 0.981283
epoch 619, loss: 0.045938
epoch 619, 
 train loss: 0.045938, val loss: 0.188980 
 val auc: 0.979073,  test auc: 0.982259
epoch 620, loss: 0.044815
epoch 620, 
 train loss: 0.044815, val loss: 0.190376 
 val auc: 0.978435,  test auc: 0.981574
epoch 621, loss: 0.043452
epoch 621, 
 train loss: 0.043452, val loss: 0.186687 
 val auc: 0.978660,  test auc: 0.982066
epoch 622, loss: 0.043330
epoch 622, 
 train loss: 0.043330, val loss: 0.186385 
 val auc: 0.978697,  test auc: 0.982174
epoch 623, loss: 0.044139
epoch 623, 
 train loss: 0.044139, val loss: 0.188493 
 val auc: 0.978566,  test auc: 0.981776
epoch 624, loss: 0.044381
epoch 624, 
 train loss: 0.044381, val loss: 0.186566 
 val auc: 0.979035,  test auc: 0.982334
epoch 625, loss: 0.043795
epoch 625, 
 train loss: 0.043795, val loss: 0.188227 
 val auc: 0.978547,  test auc: 0.981752
epoch 626, loss: 0.042926
epoch 626, 
 train loss: 0.042926, val loss: 0.186279 
 val auc: 0.978773,  test auc: 0.982156
epoch 627, loss: 0.042930
epoch 627, 
 train loss: 0.042930, val loss: 0.186403 
 val auc: 0.978660,  test auc: 0.982165
epoch 628, loss: 0.043414
epoch 628, 
 train loss: 0.043414, val loss: 0.188401 
 val auc: 0.978529,  test auc: 0.981794
epoch 629, loss: 0.043393
epoch 629, 
 train loss: 0.043393, val loss: 0.186604 
 val auc: 0.978810,  test auc: 0.982179
epoch 630, loss: 0.042883
epoch 630, 
 train loss: 0.042883, val loss: 0.187896 
 val auc: 0.978585,  test auc: 0.981776
epoch 631, loss: 0.042454
epoch 631, 
 train loss: 0.042454, val loss: 0.186861 
 val auc: 0.978641,  test auc: 0.982029
epoch 632, loss: 0.042576
epoch 632, 
 train loss: 0.042576, val loss: 0.186603 
 val auc: 0.978679,  test auc: 0.982123
epoch 633, loss: 0.042819
epoch 633, 
 train loss: 0.042819, val loss: 0.188033 
 val auc: 0.978585,  test auc: 0.981747
epoch 634, loss: 0.042645
epoch 634, 
 train loss: 0.042645, val loss: 0.186712 
 val auc: 0.978660,  test auc: 0.982095
epoch 635, loss: 0.042240
epoch 635, 
 train loss: 0.042240, val loss: 0.187467 
 val auc: 0.978622,  test auc: 0.981912
epoch 636, loss: 0.042089
epoch 636, 
 train loss: 0.042089, val loss: 0.187271 
 val auc: 0.978697,  test auc: 0.982062
epoch 637, loss: 0.042219
epoch 637, 
 train loss: 0.042219, val loss: 0.186780 
 val auc: 0.978716,  test auc: 0.982156
epoch 638, loss: 0.042257
epoch 638, 
 train loss: 0.042257, val loss: 0.187807 
 val auc: 0.978697,  test auc: 0.981846
epoch 639, loss: 0.042000
epoch 639, 
 train loss: 0.042000, val loss: 0.186738 
 val auc: 0.978716,  test auc: 0.982179
epoch 640, loss: 0.041765
epoch 640, 
 train loss: 0.041765, val loss: 0.187146 
 val auc: 0.978735,  test auc: 0.982099
epoch 641, loss: 0.041762
epoch 641, 
 train loss: 0.041762, val loss: 0.187402 
 val auc: 0.978679,  test auc: 0.982034
epoch 642, loss: 0.041819
epoch 642, 
 train loss: 0.041819, val loss: 0.186720 
 val auc: 0.978773,  test auc: 0.982203
epoch 643, loss: 0.041714
epoch 643, 
 train loss: 0.041714, val loss: 0.187475 
 val auc: 0.978810,  test auc: 0.982034
epoch 644, loss: 0.041499
epoch 644, 
 train loss: 0.041499, val loss: 0.186842 
 val auc: 0.978660,  test auc: 0.982193
epoch 645, loss: 0.041390
epoch 645, 
 train loss: 0.041390, val loss: 0.187105 
 val auc: 0.978735,  test auc: 0.982203
epoch 646, loss: 0.041401
epoch 646, 
 train loss: 0.041401, val loss: 0.187676 
 val auc: 0.978754,  test auc: 0.982062
epoch 647, loss: 0.041382
epoch 647, 
 train loss: 0.041382, val loss: 0.187261 
 val auc: 0.978735,  test auc: 0.982221
epoch 648, loss: 0.041257
epoch 648, 
 train loss: 0.041257, val loss: 0.188047 
 val auc: 0.978735,  test auc: 0.982024
epoch 649, loss: 0.041101
epoch 649, 
 train loss: 0.041101, val loss: 0.187762 
 val auc: 0.978829,  test auc: 0.982207
epoch 650, loss: 0.041024
epoch 650, 
 train loss: 0.041024, val loss: 0.187815 
 val auc: 0.978773,  test auc: 0.982193
epoch 651, loss: 0.041009
epoch 651, 
 train loss: 0.041009, val loss: 0.188122 
 val auc: 0.978716,  test auc: 0.982015
epoch 652, loss: 0.040965
epoch 652, 
 train loss: 0.040965, val loss: 0.187556 
 val auc: 0.978679,  test auc: 0.982240
epoch 653, loss: 0.040866
epoch 653, 
 train loss: 0.040866, val loss: 0.188060 
 val auc: 0.978773,  test auc: 0.982038
epoch 654, loss: 0.040742
epoch 654, 
 train loss: 0.040742, val loss: 0.187776 
 val auc: 0.978735,  test auc: 0.982179
epoch 655, loss: 0.040655
epoch 655, 
 train loss: 0.040655, val loss: 0.187971 
 val auc: 0.978810,  test auc: 0.982203
epoch 656, loss: 0.040612
epoch 656, 
 train loss: 0.040612, val loss: 0.188343 
 val auc: 0.978810,  test auc: 0.982081
epoch 657, loss: 0.040566
epoch 657, 
 train loss: 0.040566, val loss: 0.188121 
 val auc: 0.978735,  test auc: 0.982240
epoch 658, loss: 0.040486
epoch 658, 
 train loss: 0.040486, val loss: 0.188625 
 val auc: 0.978735,  test auc: 0.982043
epoch 659, loss: 0.040386
epoch 659, 
 train loss: 0.040386, val loss: 0.188318 
 val auc: 0.978810,  test auc: 0.982193
epoch 660, loss: 0.040305
epoch 660, 
 train loss: 0.040305, val loss: 0.188385 
 val auc: 0.978866,  test auc: 0.982207
epoch 661, loss: 0.040250
epoch 661, 
 train loss: 0.040250, val loss: 0.188577 
 val auc: 0.978791,  test auc: 0.982132
epoch 662, loss: 0.040197
epoch 662, 
 train loss: 0.040197, val loss: 0.188286 
 val auc: 0.978773,  test auc: 0.982254
epoch 663, loss: 0.040120
epoch 663, 
 train loss: 0.040120, val loss: 0.188645 
 val auc: 0.978829,  test auc: 0.982160
epoch 664, loss: 0.040029
epoch 664, 
 train loss: 0.040029, val loss: 0.188381 
 val auc: 0.978829,  test auc: 0.982264
epoch 665, loss: 0.039952
epoch 665, 
 train loss: 0.039952, val loss: 0.188507 
 val auc: 0.978791,  test auc: 0.982221
epoch 666, loss: 0.039891
epoch 666, 
 train loss: 0.039891, val loss: 0.188709 
 val auc: 0.978829,  test auc: 0.982179
epoch 667, loss: 0.039832
epoch 667, 
 train loss: 0.039832, val loss: 0.188555 
 val auc: 0.978735,  test auc: 0.982273
epoch 668, loss: 0.039762
epoch 668, 
 train loss: 0.039762, val loss: 0.188885 
 val auc: 0.978716,  test auc: 0.982212
epoch 669, loss: 0.039683
epoch 669, 
 train loss: 0.039683, val loss: 0.188640 
 val auc: 0.978754,  test auc: 0.982292
epoch 670, loss: 0.039606
epoch 670, 
 train loss: 0.039606, val loss: 0.188723 
 val auc: 0.978735,  test auc: 0.982273
epoch 671, loss: 0.039539
epoch 671, 
 train loss: 0.039539, val loss: 0.188703 
 val auc: 0.978735,  test auc: 0.982273
epoch 672, loss: 0.039478
epoch 672, 
 train loss: 0.039478, val loss: 0.188587 
 val auc: 0.978810,  test auc: 0.982306
epoch 673, loss: 0.039411
epoch 673, 
 train loss: 0.039411, val loss: 0.188902 
 val auc: 0.978773,  test auc: 0.982268
epoch 674, loss: 0.039337
epoch 674, 
 train loss: 0.039337, val loss: 0.188821 
 val auc: 0.978866,  test auc: 0.982301
epoch 675, loss: 0.039263
epoch 675, 
 train loss: 0.039263, val loss: 0.189011 
 val auc: 0.978791,  test auc: 0.982235
epoch 676, loss: 0.039191
epoch 676, 
 train loss: 0.039191, val loss: 0.189028 
 val auc: 0.978773,  test auc: 0.982259
epoch 677, loss: 0.039125
epoch 677, 
 train loss: 0.039125, val loss: 0.188984 
 val auc: 0.978848,  test auc: 0.982306
epoch 678, loss: 0.039063
epoch 678, 
 train loss: 0.039063, val loss: 0.189148 
 val auc: 0.978773,  test auc: 0.982287
epoch 679, loss: 0.038996
epoch 679, 
 train loss: 0.038996, val loss: 0.189001 
 val auc: 0.978829,  test auc: 0.982339
epoch 680, loss: 0.038926
epoch 680, 
 train loss: 0.038926, val loss: 0.189274 
 val auc: 0.978866,  test auc: 0.982320
epoch 681, loss: 0.038852
epoch 681, 
 train loss: 0.038852, val loss: 0.189126 
 val auc: 0.978885,  test auc: 0.982325
epoch 682, loss: 0.038779
epoch 682, 
 train loss: 0.038779, val loss: 0.189167 
 val auc: 0.978923,  test auc: 0.982343
epoch 683, loss: 0.038712
epoch 683, 
 train loss: 0.038712, val loss: 0.189188 
 val auc: 0.978866,  test auc: 0.982339
epoch 684, loss: 0.038646
epoch 684, 
 train loss: 0.038646, val loss: 0.189123 
 val auc: 0.978885,  test auc: 0.982362
epoch 685, loss: 0.038580
epoch 685, 
 train loss: 0.038580, val loss: 0.189275 
 val auc: 0.978904,  test auc: 0.982367
epoch 686, loss: 0.038510
epoch 686, 
 train loss: 0.038510, val loss: 0.189141 
 val auc: 0.978904,  test auc: 0.982414
epoch 687, loss: 0.038440
epoch 687, 
 train loss: 0.038440, val loss: 0.189205 
 val auc: 0.978923,  test auc: 0.982390
epoch 688, loss: 0.038370
epoch 688, 
 train loss: 0.038370, val loss: 0.189177 
 val auc: 0.978885,  test auc: 0.982357
epoch 689, loss: 0.038302
epoch 689, 
 train loss: 0.038302, val loss: 0.189204 
 val auc: 0.978866,  test auc: 0.982353
epoch 690, loss: 0.038236
epoch 690, 
 train loss: 0.038236, val loss: 0.189277 
 val auc: 0.978866,  test auc: 0.982353
epoch 691, loss: 0.038169
epoch 691, 
 train loss: 0.038169, val loss: 0.189197 
 val auc: 0.978904,  test auc: 0.982404
epoch 692, loss: 0.038103
epoch 692, 
 train loss: 0.038103, val loss: 0.189349 
 val auc: 0.978904,  test auc: 0.982367
epoch 693, loss: 0.038036
epoch 693, 
 train loss: 0.038036, val loss: 0.189227 
 val auc: 0.978866,  test auc: 0.982381
epoch 694, loss: 0.037965
epoch 694, 
 train loss: 0.037965, val loss: 0.189277 
 val auc: 0.978866,  test auc: 0.982357
epoch 695, loss: 0.037896
epoch 695, 
 train loss: 0.037896, val loss: 0.189207 
 val auc: 0.978904,  test auc: 0.982386
epoch 696, loss: 0.037828
epoch 696, 
 train loss: 0.037828, val loss: 0.189229 
 val auc: 0.978885,  test auc: 0.982371
epoch 697, loss: 0.037762
epoch 697, 
 train loss: 0.037762, val loss: 0.189234 
 val auc: 0.978866,  test auc: 0.982353
epoch 698, loss: 0.037696
epoch 698, 
 train loss: 0.037696, val loss: 0.189190 
 val auc: 0.978923,  test auc: 0.982371
epoch 699, loss: 0.037629
epoch 699, 
 train loss: 0.037629, val loss: 0.189259 
 val auc: 0.978904,  test auc: 0.982339
epoch 700, loss: 0.037563
epoch 700, 
 train loss: 0.037563, val loss: 0.189177 
 val auc: 0.978848,  test auc: 0.982357
epoch 701, loss: 0.037495
epoch 701, 
 train loss: 0.037495, val loss: 0.189240 
 val auc: 0.978941,  test auc: 0.982386
epoch 702, loss: 0.037428
epoch 702, 
 train loss: 0.037428, val loss: 0.189207 
 val auc: 0.978960,  test auc: 0.982418
epoch 703, loss: 0.037363
epoch 703, 
 train loss: 0.037363, val loss: 0.189188 
 val auc: 0.978848,  test auc: 0.982376
epoch 704, loss: 0.037299
epoch 704, 
 train loss: 0.037299, val loss: 0.189298 
 val auc: 0.978960,  test auc: 0.982390
epoch 705, loss: 0.037239
epoch 705, 
 train loss: 0.037239, val loss: 0.189122 
 val auc: 0.979073,  test auc: 0.982447
epoch 706, loss: 0.037205
epoch 706, 
 train loss: 0.037205, val loss: 0.189559 
 val auc: 0.978904,  test auc: 0.982381
epoch 707, loss: 0.037268
epoch 707, 
 train loss: 0.037268, val loss: 0.188924 
 val auc: 0.979167,  test auc: 0.982508
epoch 708, loss: 0.037640
epoch 708, 
 train loss: 0.037640, val loss: 0.190846 
 val auc: 0.978848,  test auc: 0.982137
epoch 709, loss: 0.037984
epoch 709, 
 train loss: 0.037984, val loss: 0.189891 
 val auc: 0.979411,  test auc: 0.982583
epoch 710, loss: 0.037803
epoch 710, 
 train loss: 0.037803, val loss: 0.191425 
 val auc: 0.978810,  test auc: 0.982081
epoch 711, loss: 0.037199
epoch 711, 
 train loss: 0.037199, val loss: 0.189451 
 val auc: 0.979167,  test auc: 0.982493
epoch 712, loss: 0.036791
epoch 712, 
 train loss: 0.036791, val loss: 0.189538 
 val auc: 0.978829,  test auc: 0.982409
epoch 713, loss: 0.036911
epoch 713, 
 train loss: 0.036911, val loss: 0.189991 
 val auc: 0.978960,  test auc: 0.982371
epoch 714, loss: 0.037175
epoch 714, 
 train loss: 0.037175, val loss: 0.189366 
 val auc: 0.979336,  test auc: 0.982615
epoch 715, loss: 0.037109
epoch 715, 
 train loss: 0.037109, val loss: 0.190478 
 val auc: 0.978998,  test auc: 0.982240
epoch 716, loss: 0.036729
epoch 716, 
 train loss: 0.036729, val loss: 0.189046 
 val auc: 0.979167,  test auc: 0.982559
epoch 717, loss: 0.036464
epoch 717, 
 train loss: 0.036464, val loss: 0.189179 
 val auc: 0.979073,  test auc: 0.982428
epoch 718, loss: 0.036523
epoch 718, 
 train loss: 0.036523, val loss: 0.189656 
 val auc: 0.978941,  test auc: 0.982325
epoch 719, loss: 0.036662
epoch 719, 
 train loss: 0.036662, val loss: 0.189289 
 val auc: 0.979298,  test auc: 0.982597
epoch 720, loss: 0.036565
epoch 720, 
 train loss: 0.036565, val loss: 0.190253 
 val auc: 0.978941,  test auc: 0.982353
epoch 721, loss: 0.036302
epoch 721, 
 train loss: 0.036302, val loss: 0.189261 
 val auc: 0.979223,  test auc: 0.982526
epoch 722, loss: 0.036141
epoch 722, 
 train loss: 0.036141, val loss: 0.189272 
 val auc: 0.979129,  test auc: 0.982517
epoch 723, loss: 0.036179
epoch 723, 
 train loss: 0.036179, val loss: 0.189630 
 val auc: 0.978904,  test auc: 0.982362
epoch 724, loss: 0.036222
epoch 724, 
 train loss: 0.036222, val loss: 0.189176 
 val auc: 0.979279,  test auc: 0.982540
epoch 725, loss: 0.036100
epoch 725, 
 train loss: 0.036100, val loss: 0.189872 
 val auc: 0.978998,  test auc: 0.982381
epoch 726, loss: 0.035915
epoch 726, 
 train loss: 0.035915, val loss: 0.189353 
 val auc: 0.979261,  test auc: 0.982526
epoch 727, loss: 0.035828
epoch 727, 
 train loss: 0.035828, val loss: 0.189417 
 val auc: 0.979223,  test auc: 0.982550
epoch 728, loss: 0.035840
epoch 728, 
 train loss: 0.035840, val loss: 0.189813 
 val auc: 0.979017,  test auc: 0.982414
epoch 729, loss: 0.035821
epoch 729, 
 train loss: 0.035821, val loss: 0.189337 
 val auc: 0.979354,  test auc: 0.982583
epoch 730, loss: 0.035712
epoch 730, 
 train loss: 0.035712, val loss: 0.189752 
 val auc: 0.979035,  test auc: 0.982437
epoch 731, loss: 0.035578
epoch 731, 
 train loss: 0.035578, val loss: 0.189419 
 val auc: 0.979223,  test auc: 0.982545
epoch 732, loss: 0.035514
epoch 732, 
 train loss: 0.035514, val loss: 0.189583 
 val auc: 0.979317,  test auc: 0.982564
epoch 733, loss: 0.035499
epoch 733, 
 train loss: 0.035499, val loss: 0.190084 
 val auc: 0.979035,  test auc: 0.982456
epoch 734, loss: 0.035460
epoch 734, 
 train loss: 0.035460, val loss: 0.189786 
 val auc: 0.979261,  test auc: 0.982550
epoch 735, loss: 0.035363
epoch 735, 
 train loss: 0.035363, val loss: 0.190145 
 val auc: 0.979073,  test auc: 0.982428
epoch 736, loss: 0.035257
epoch 736, 
 train loss: 0.035257, val loss: 0.189885 
 val auc: 0.979242,  test auc: 0.982554
epoch 737, loss: 0.035197
epoch 737, 
 train loss: 0.035197, val loss: 0.189933 
 val auc: 0.979185,  test auc: 0.982564
epoch 738, loss: 0.035169
epoch 738, 
 train loss: 0.035169, val loss: 0.190253 
 val auc: 0.979148,  test auc: 0.982493
epoch 739, loss: 0.035120
epoch 739, 
 train loss: 0.035120, val loss: 0.190002 
 val auc: 0.979204,  test auc: 0.982583
epoch 740, loss: 0.035035
epoch 740, 
 train loss: 0.035035, val loss: 0.190327 
 val auc: 0.979185,  test auc: 0.982531
epoch 741, loss: 0.034946
epoch 741, 
 train loss: 0.034946, val loss: 0.190137 
 val auc: 0.979223,  test auc: 0.982564
epoch 742, loss: 0.034884
epoch 742, 
 train loss: 0.034884, val loss: 0.190142 
 val auc: 0.979167,  test auc: 0.982550
epoch 743, loss: 0.034844
epoch 743, 
 train loss: 0.034844, val loss: 0.190332 
 val auc: 0.979110,  test auc: 0.982517
epoch 744, loss: 0.034796
epoch 744, 
 train loss: 0.034796, val loss: 0.190132 
 val auc: 0.979110,  test auc: 0.982554
epoch 745, loss: 0.034727
epoch 745, 
 train loss: 0.034727, val loss: 0.190448 
 val auc: 0.979223,  test auc: 0.982578
epoch 746, loss: 0.034646
epoch 746, 
 train loss: 0.034646, val loss: 0.190222 
 val auc: 0.979261,  test auc: 0.982597
epoch 747, loss: 0.034578
epoch 747, 
 train loss: 0.034578, val loss: 0.190240 
 val auc: 0.979148,  test auc: 0.982564
epoch 748, loss: 0.034524
epoch 748, 
 train loss: 0.034524, val loss: 0.190305 
 val auc: 0.979148,  test auc: 0.982564
epoch 749, loss: 0.034477
epoch 749, 
 train loss: 0.034477, val loss: 0.190148 
 val auc: 0.979261,  test auc: 0.982625
epoch 750, loss: 0.034416
epoch 750, 
 train loss: 0.034416, val loss: 0.190391 
 val auc: 0.979223,  test auc: 0.982634
epoch 751, loss: 0.034347
epoch 751, 
 train loss: 0.034347, val loss: 0.190226 
 val auc: 0.979223,  test auc: 0.982606
epoch 752, loss: 0.034282
epoch 752, 
 train loss: 0.034282, val loss: 0.190493 
 val auc: 0.979261,  test auc: 0.982653
epoch 753, loss: 0.034219
epoch 753, 
 train loss: 0.034219, val loss: 0.190482 
 val auc: 0.979148,  test auc: 0.982639
epoch 754, loss: 0.034159
epoch 754, 
 train loss: 0.034159, val loss: 0.190489 
 val auc: 0.979261,  test auc: 0.982676
epoch 755, loss: 0.034102
epoch 755, 
 train loss: 0.034102, val loss: 0.190432 
 val auc: 0.979242,  test auc: 0.982686
epoch 756, loss: 0.034046
epoch 756, 
 train loss: 0.034046, val loss: 0.190239 
 val auc: 0.979298,  test auc: 0.982672
epoch 757, loss: 0.033989
epoch 757, 
 train loss: 0.033989, val loss: 0.190248 
 val auc: 0.979261,  test auc: 0.982700
epoch 758, loss: 0.033929
epoch 758, 
 train loss: 0.033929, val loss: 0.190169 
 val auc: 0.979242,  test auc: 0.982705
epoch 759, loss: 0.033868
epoch 759, 
 train loss: 0.033868, val loss: 0.190262 
 val auc: 0.979261,  test auc: 0.982747
epoch 760, loss: 0.033809
epoch 760, 
 train loss: 0.033809, val loss: 0.190207 
 val auc: 0.979185,  test auc: 0.982705
epoch 761, loss: 0.033754
epoch 761, 
 train loss: 0.033754, val loss: 0.190130 
 val auc: 0.979261,  test auc: 0.982737
epoch 762, loss: 0.033699
epoch 762, 
 train loss: 0.033699, val loss: 0.190244 
 val auc: 0.979185,  test auc: 0.982723
epoch 763, loss: 0.033645
epoch 763, 
 train loss: 0.033645, val loss: 0.190132 
 val auc: 0.979298,  test auc: 0.982794
epoch 764, loss: 0.033590
epoch 764, 
 train loss: 0.033590, val loss: 0.190349 
 val auc: 0.979261,  test auc: 0.982756
epoch 765, loss: 0.033533
epoch 765, 
 train loss: 0.033533, val loss: 0.190247 
 val auc: 0.979279,  test auc: 0.982794
epoch 766, loss: 0.033471
epoch 766, 
 train loss: 0.033471, val loss: 0.190381 
 val auc: 0.979261,  test auc: 0.982747
epoch 767, loss: 0.033410
epoch 767, 
 train loss: 0.033410, val loss: 0.190319 
 val auc: 0.979261,  test auc: 0.982794
epoch 768, loss: 0.033354
epoch 768, 
 train loss: 0.033354, val loss: 0.190274 
 val auc: 0.979279,  test auc: 0.982789
epoch 769, loss: 0.033301
epoch 769, 
 train loss: 0.033301, val loss: 0.190308 
 val auc: 0.979242,  test auc: 0.982766
epoch 770, loss: 0.033247
epoch 770, 
 train loss: 0.033247, val loss: 0.190262 
 val auc: 0.979223,  test auc: 0.982770
epoch 771, loss: 0.033189
epoch 771, 
 train loss: 0.033189, val loss: 0.190327 
 val auc: 0.979298,  test auc: 0.982803
epoch 772, loss: 0.033137
epoch 772, 
 train loss: 0.033137, val loss: 0.190062 
 val auc: 0.979336,  test auc: 0.982841
epoch 773, loss: 0.033098
epoch 773, 
 train loss: 0.033098, val loss: 0.190315 
 val auc: 0.979223,  test auc: 0.982780
epoch 774, loss: 0.033111
epoch 774, 
 train loss: 0.033111, val loss: 0.189964 
 val auc: 0.979467,  test auc: 0.982920
epoch 775, loss: 0.033303
epoch 775, 
 train loss: 0.033303, val loss: 0.191231 
 val auc: 0.979148,  test auc: 0.982747
epoch 776, loss: 0.033498
epoch 776, 
 train loss: 0.033498, val loss: 0.190776 
 val auc: 0.979448,  test auc: 0.982949
epoch 777, loss: 0.033364
epoch 777, 
 train loss: 0.033364, val loss: 0.191435 
 val auc: 0.979110,  test auc: 0.982667
epoch 778, loss: 0.033002
epoch 778, 
 train loss: 0.033002, val loss: 0.190242 
 val auc: 0.979505,  test auc: 0.982953
epoch 779, loss: 0.032763
epoch 779, 
 train loss: 0.032763, val loss: 0.190105 
 val auc: 0.979411,  test auc: 0.982925
epoch 780, loss: 0.032827
epoch 780, 
 train loss: 0.032827, val loss: 0.190252 
 val auc: 0.979373,  test auc: 0.982859
epoch 781, loss: 0.032966
epoch 781, 
 train loss: 0.032966, val loss: 0.190001 
 val auc: 0.979561,  test auc: 0.983028
epoch 782, loss: 0.032898
epoch 782, 
 train loss: 0.032898, val loss: 0.190618 
 val auc: 0.979279,  test auc: 0.982836
epoch 783, loss: 0.032662
epoch 783, 
 train loss: 0.032662, val loss: 0.190069 
 val auc: 0.979561,  test auc: 0.983038
epoch 784, loss: 0.032495
epoch 784, 
 train loss: 0.032495, val loss: 0.190245 
 val auc: 0.979373,  test auc: 0.982953
epoch 785, loss: 0.032519
epoch 785, 
 train loss: 0.032519, val loss: 0.190621 
 val auc: 0.979411,  test auc: 0.982925
epoch 786, loss: 0.032612
epoch 786, 
 train loss: 0.032612, val loss: 0.190505 
 val auc: 0.979598,  test auc: 0.983047
epoch 787, loss: 0.032651
epoch 787, 
 train loss: 0.032651, val loss: 0.191474 
 val auc: 0.979223,  test auc: 0.982859
epoch 788, loss: 0.032506
epoch 788, 
 train loss: 0.032506, val loss: 0.190801 
 val auc: 0.979486,  test auc: 0.983028
epoch 789, loss: 0.032282
epoch 789, 
 train loss: 0.032282, val loss: 0.190741 
 val auc: 0.979336,  test auc: 0.982902
epoch 790, loss: 0.032208
epoch 790, 
 train loss: 0.032208, val loss: 0.190476 
 val auc: 0.979467,  test auc: 0.982958
epoch 791, loss: 0.032268
epoch 791, 
 train loss: 0.032268, val loss: 0.190216 
 val auc: 0.979523,  test auc: 0.983056
epoch 792, loss: 0.032280
epoch 792, 
 train loss: 0.032280, val loss: 0.190437 
 val auc: 0.979448,  test auc: 0.982963
epoch 793, loss: 0.032167
epoch 793, 
 train loss: 0.032167, val loss: 0.190055 
 val auc: 0.979542,  test auc: 0.983103
epoch 794, loss: 0.032015
epoch 794, 
 train loss: 0.032015, val loss: 0.190237 
 val auc: 0.979467,  test auc: 0.983019
epoch 795, loss: 0.031956
epoch 795, 
 train loss: 0.031956, val loss: 0.190356 
 val auc: 0.979523,  test auc: 0.983038
epoch 796, loss: 0.031976
epoch 796, 
 train loss: 0.031976, val loss: 0.190406 
 val auc: 0.979523,  test auc: 0.983108
epoch 797, loss: 0.031950
epoch 797, 
 train loss: 0.031950, val loss: 0.190719 
 val auc: 0.979429,  test auc: 0.982981
epoch 798, loss: 0.031852
epoch 798, 
 train loss: 0.031852, val loss: 0.190425 
 val auc: 0.979523,  test auc: 0.983085
epoch 799, loss: 0.031748
epoch 799, 
 train loss: 0.031748, val loss: 0.190488 
 val auc: 0.979448,  test auc: 0.983005
epoch 800, loss: 0.031708
epoch 800, 
 train loss: 0.031708, val loss: 0.190633 
 val auc: 0.979523,  test auc: 0.982995
epoch 801, loss: 0.031697
epoch 801, 
 train loss: 0.031697, val loss: 0.190609 
 val auc: 0.979598,  test auc: 0.983099
epoch 802, loss: 0.031687
epoch 802, 
 train loss: 0.031687, val loss: 0.191043 
 val auc: 0.979467,  test auc: 0.982977
epoch 803, loss: 0.031611
epoch 803, 
 train loss: 0.031611, val loss: 0.190659 
 val auc: 0.979486,  test auc: 0.983033
epoch 804, loss: 0.031524
epoch 804, 
 train loss: 0.031524, val loss: 0.190765 
 val auc: 0.979598,  test auc: 0.983019
epoch 805, loss: 0.031458
epoch 805, 
 train loss: 0.031458, val loss: 0.190481 
 val auc: 0.979636,  test auc: 0.983038
epoch 806, loss: 0.031432
epoch 806, 
 train loss: 0.031432, val loss: 0.190244 
 val auc: 0.979598,  test auc: 0.983066
epoch 807, loss: 0.031401
epoch 807, 
 train loss: 0.031401, val loss: 0.190298 
 val auc: 0.979617,  test auc: 0.983056
epoch 808, loss: 0.031337
epoch 808, 
 train loss: 0.031337, val loss: 0.190012 
 val auc: 0.979617,  test auc: 0.983094
epoch 809, loss: 0.031266
epoch 809, 
 train loss: 0.031266, val loss: 0.190150 
 val auc: 0.979617,  test auc: 0.983127
epoch 810, loss: 0.031220
epoch 810, 
 train loss: 0.031220, val loss: 0.190278 
 val auc: 0.979617,  test auc: 0.983094
epoch 811, loss: 0.031188
epoch 811, 
 train loss: 0.031188, val loss: 0.190148 
 val auc: 0.979598,  test auc: 0.983085
epoch 812, loss: 0.031144
epoch 812, 
 train loss: 0.031144, val loss: 0.190315 
 val auc: 0.979636,  test auc: 0.983085
epoch 813, loss: 0.031080
epoch 813, 
 train loss: 0.031080, val loss: 0.190225 
 val auc: 0.979505,  test auc: 0.983047
epoch 814, loss: 0.031022
epoch 814, 
 train loss: 0.031022, val loss: 0.190351 
 val auc: 0.979448,  test auc: 0.983042
epoch 815, loss: 0.030980
epoch 815, 
 train loss: 0.030980, val loss: 0.190402 
 val auc: 0.979636,  test auc: 0.983113
epoch 816, loss: 0.030944
epoch 816, 
 train loss: 0.030944, val loss: 0.190265 
 val auc: 0.979542,  test auc: 0.983103
epoch 817, loss: 0.030890
epoch 817, 
 train loss: 0.030890, val loss: 0.190401 
 val auc: 0.979655,  test auc: 0.983141
epoch 818, loss: 0.030829
epoch 818, 
 train loss: 0.030829, val loss: 0.190346 
 val auc: 0.979542,  test auc: 0.983099
epoch 819, loss: 0.030783
epoch 819, 
 train loss: 0.030783, val loss: 0.190360 
 val auc: 0.979692,  test auc: 0.983117
epoch 820, loss: 0.030746
epoch 820, 
 train loss: 0.030746, val loss: 0.190581 
 val auc: 0.979486,  test auc: 0.983080
epoch 821, loss: 0.030702
epoch 821, 
 train loss: 0.030702, val loss: 0.190718 
 val auc: 0.979542,  test auc: 0.983085
epoch 822, loss: 0.030648
epoch 822, 
 train loss: 0.030648, val loss: 0.191130 
 val auc: 0.979561,  test auc: 0.983094
epoch 823, loss: 0.030594
epoch 823, 
 train loss: 0.030594, val loss: 0.191277 
 val auc: 0.979580,  test auc: 0.983099
epoch 824, loss: 0.030548
epoch 824, 
 train loss: 0.030548, val loss: 0.191303 
 val auc: 0.979486,  test auc: 0.983075
epoch 825, loss: 0.030508
epoch 825, 
 train loss: 0.030508, val loss: 0.191288 
 val auc: 0.979580,  test auc: 0.983122
epoch 826, loss: 0.030462
epoch 826, 
 train loss: 0.030462, val loss: 0.191122 
 val auc: 0.979542,  test auc: 0.983094
epoch 827, loss: 0.030411
epoch 827, 
 train loss: 0.030411, val loss: 0.191228 
 val auc: 0.979448,  test auc: 0.983089
epoch 828, loss: 0.030361
epoch 828, 
 train loss: 0.030361, val loss: 0.191187 
 val auc: 0.979598,  test auc: 0.983122
epoch 829, loss: 0.030320
epoch 829, 
 train loss: 0.030320, val loss: 0.191110 
 val auc: 0.979542,  test auc: 0.983075
epoch 830, loss: 0.030278
epoch 830, 
 train loss: 0.030278, val loss: 0.191278 
 val auc: 0.979580,  test auc: 0.983103
epoch 831, loss: 0.030231
epoch 831, 
 train loss: 0.030231, val loss: 0.191303 
 val auc: 0.979448,  test auc: 0.983071
epoch 832, loss: 0.030182
epoch 832, 
 train loss: 0.030182, val loss: 0.191303 
 val auc: 0.979580,  test auc: 0.983108
epoch 833, loss: 0.030137
epoch 833, 
 train loss: 0.030137, val loss: 0.191245 
 val auc: 0.979486,  test auc: 0.983080
epoch 834, loss: 0.030093
epoch 834, 
 train loss: 0.030093, val loss: 0.191333 
 val auc: 0.979542,  test auc: 0.983132
epoch 835, loss: 0.030048
epoch 835, 
 train loss: 0.030048, val loss: 0.191570 
 val auc: 0.979505,  test auc: 0.983094
epoch 836, loss: 0.030004
epoch 836, 
 train loss: 0.030004, val loss: 0.191570 
 val auc: 0.979505,  test auc: 0.983127
epoch 837, loss: 0.029958
epoch 837, 
 train loss: 0.029958, val loss: 0.191521 
 val auc: 0.979580,  test auc: 0.983141
epoch 838, loss: 0.029913
epoch 838, 
 train loss: 0.029913, val loss: 0.191510 
 val auc: 0.979486,  test auc: 0.983113
epoch 839, loss: 0.029869
epoch 839, 
 train loss: 0.029869, val loss: 0.191591 
 val auc: 0.979486,  test auc: 0.983103
epoch 840, loss: 0.029827
epoch 840, 
 train loss: 0.029827, val loss: 0.191658 
 val auc: 0.979523,  test auc: 0.983117
epoch 841, loss: 0.029790
epoch 841, 
 train loss: 0.029790, val loss: 0.191572 
 val auc: 0.979523,  test auc: 0.983122
epoch 842, loss: 0.029768
epoch 842, 
 train loss: 0.029768, val loss: 0.191967 
 val auc: 0.979486,  test auc: 0.983089
epoch 843, loss: 0.029794
epoch 843, 
 train loss: 0.029794, val loss: 0.191486 
 val auc: 0.979523,  test auc: 0.983160
epoch 844, loss: 0.029919
epoch 844, 
 train loss: 0.029919, val loss: 0.192542 
 val auc: 0.979467,  test auc: 0.983075
epoch 845, loss: 0.029923
epoch 845, 
 train loss: 0.029923, val loss: 0.191952 
 val auc: 0.979542,  test auc: 0.983188
epoch 846, loss: 0.029687
epoch 846, 
 train loss: 0.029687, val loss: 0.192281 
 val auc: 0.979392,  test auc: 0.983056
epoch 847, loss: 0.029525
epoch 847, 
 train loss: 0.029525, val loss: 0.191934 
 val auc: 0.979505,  test auc: 0.983155
epoch 848, loss: 0.029586
epoch 848, 
 train loss: 0.029586, val loss: 0.191780 
 val auc: 0.979467,  test auc: 0.983141
epoch 849, loss: 0.029648
epoch 849, 
 train loss: 0.029648, val loss: 0.192254 
 val auc: 0.979505,  test auc: 0.983127
epoch 850, loss: 0.029540
epoch 850, 
 train loss: 0.029540, val loss: 0.191692 
 val auc: 0.979486,  test auc: 0.983150
epoch 851, loss: 0.029371
epoch 851, 
 train loss: 0.029371, val loss: 0.191742 
 val auc: 0.979542,  test auc: 0.983150
epoch 852, loss: 0.029339
epoch 852, 
 train loss: 0.029339, val loss: 0.191756 
 val auc: 0.979561,  test auc: 0.983169
epoch 853, loss: 0.029392
epoch 853, 
 train loss: 0.029392, val loss: 0.191673 
 val auc: 0.979486,  test auc: 0.983178
epoch 854, loss: 0.029360
epoch 854, 
 train loss: 0.029360, val loss: 0.192180 
 val auc: 0.979542,  test auc: 0.983178
epoch 855, loss: 0.029229
epoch 855, 
 train loss: 0.029229, val loss: 0.191751 
 val auc: 0.979467,  test auc: 0.983160
epoch 856, loss: 0.029146
epoch 856, 
 train loss: 0.029146, val loss: 0.191846 
 val auc: 0.979486,  test auc: 0.983160
epoch 857, loss: 0.029154
epoch 857, 
 train loss: 0.029154, val loss: 0.192105 
 val auc: 0.979505,  test auc: 0.983197
epoch 858, loss: 0.029152
epoch 858, 
 train loss: 0.029152, val loss: 0.191813 
 val auc: 0.979467,  test auc: 0.983178
epoch 859, loss: 0.029071
epoch 859, 
 train loss: 0.029071, val loss: 0.191917 
 val auc: 0.979542,  test auc: 0.983207
epoch 860, loss: 0.028980
epoch 860, 
 train loss: 0.028980, val loss: 0.191682 
 val auc: 0.979429,  test auc: 0.983216
epoch 861, loss: 0.028946
epoch 861, 
 train loss: 0.028946, val loss: 0.191817 
 val auc: 0.979429,  test auc: 0.983207
epoch 862, loss: 0.028935
epoch 862, 
 train loss: 0.028935, val loss: 0.192057 
 val auc: 0.979486,  test auc: 0.983230
epoch 863, loss: 0.028890
epoch 863, 
 train loss: 0.028890, val loss: 0.191770 
 val auc: 0.979467,  test auc: 0.983221
epoch 864, loss: 0.028820
epoch 864, 
 train loss: 0.028820, val loss: 0.191907 
 val auc: 0.979336,  test auc: 0.983174
epoch 865, loss: 0.028770
epoch 865, 
 train loss: 0.028770, val loss: 0.192019 
 val auc: 0.979373,  test auc: 0.983207
epoch 866, loss: 0.028748
epoch 866, 
 train loss: 0.028748, val loss: 0.192013 
 val auc: 0.979392,  test auc: 0.983197
epoch 867, loss: 0.028719
epoch 867, 
 train loss: 0.028719, val loss: 0.192141 
 val auc: 0.979542,  test auc: 0.983258
epoch 868, loss: 0.028660
epoch 868, 
 train loss: 0.028660, val loss: 0.192100 
 val auc: 0.979467,  test auc: 0.983225
epoch 869, loss: 0.028605
epoch 869, 
 train loss: 0.028605, val loss: 0.192300 
 val auc: 0.979392,  test auc: 0.983207
epoch 870, loss: 0.028570
epoch 870, 
 train loss: 0.028570, val loss: 0.192340 
 val auc: 0.979486,  test auc: 0.983211
epoch 871, loss: 0.028540
epoch 871, 
 train loss: 0.028540, val loss: 0.192224 
 val auc: 0.979373,  test auc: 0.983188
epoch 872, loss: 0.028492
epoch 872, 
 train loss: 0.028492, val loss: 0.192431 
 val auc: 0.979429,  test auc: 0.983197
epoch 873, loss: 0.028442
epoch 873, 
 train loss: 0.028442, val loss: 0.192458 
 val auc: 0.979336,  test auc: 0.983202
epoch 874, loss: 0.028401
epoch 874, 
 train loss: 0.028401, val loss: 0.192552 
 val auc: 0.979392,  test auc: 0.983216
epoch 875, loss: 0.028363
epoch 875, 
 train loss: 0.028363, val loss: 0.192591 
 val auc: 0.979448,  test auc: 0.983202
epoch 876, loss: 0.028324
epoch 876, 
 train loss: 0.028324, val loss: 0.192583 
 val auc: 0.979411,  test auc: 0.983225
epoch 877, loss: 0.028279
epoch 877, 
 train loss: 0.028279, val loss: 0.192776 
 val auc: 0.979486,  test auc: 0.983258
epoch 878, loss: 0.028237
epoch 878, 
 train loss: 0.028237, val loss: 0.192713 
 val auc: 0.979505,  test auc: 0.983263
epoch 879, loss: 0.028200
epoch 879, 
 train loss: 0.028200, val loss: 0.192695 
 val auc: 0.979448,  test auc: 0.983239
epoch 880, loss: 0.028163
epoch 880, 
 train loss: 0.028163, val loss: 0.192922 
 val auc: 0.979505,  test auc: 0.983263
epoch 881, loss: 0.028124
epoch 881, 
 train loss: 0.028124, val loss: 0.192892 
 val auc: 0.979429,  test auc: 0.983244
epoch 882, loss: 0.028080
epoch 882, 
 train loss: 0.028080, val loss: 0.193008 
 val auc: 0.979505,  test auc: 0.983272
epoch 883, loss: 0.028038
epoch 883, 
 train loss: 0.028038, val loss: 0.192993 
 val auc: 0.979505,  test auc: 0.983268
epoch 884, loss: 0.027996
epoch 884, 
 train loss: 0.027996, val loss: 0.192866 
 val auc: 0.979486,  test auc: 0.983268
epoch 885, loss: 0.027959
epoch 885, 
 train loss: 0.027959, val loss: 0.192979 
 val auc: 0.979580,  test auc: 0.983282
epoch 886, loss: 0.027928
epoch 886, 
 train loss: 0.027928, val loss: 0.192784 
 val auc: 0.979336,  test auc: 0.983268
epoch 887, loss: 0.027920
epoch 887, 
 train loss: 0.027920, val loss: 0.193225 
 val auc: 0.979580,  test auc: 0.983282
epoch 888, loss: 0.027973
epoch 888, 
 train loss: 0.027973, val loss: 0.192715 
 val auc: 0.979505,  test auc: 0.983366
epoch 889, loss: 0.028139
epoch 889, 
 train loss: 0.028139, val loss: 0.194171 
 val auc: 0.979598,  test auc: 0.983315
epoch 890, loss: 0.028129
epoch 890, 
 train loss: 0.028129, val loss: 0.193368 
 val auc: 0.979523,  test auc: 0.983399
epoch 891, loss: 0.027822
epoch 891, 
 train loss: 0.027822, val loss: 0.193571 
 val auc: 0.979636,  test auc: 0.983310
epoch 892, loss: 0.027693
epoch 892, 
 train loss: 0.027693, val loss: 0.193210 
 val auc: 0.979542,  test auc: 0.983272
epoch 893, loss: 0.027827
epoch 893, 
 train loss: 0.027827, val loss: 0.192957 
 val auc: 0.979523,  test auc: 0.983408
epoch 894, loss: 0.027849
epoch 894, 
 train loss: 0.027849, val loss: 0.193578 
 val auc: 0.979636,  test auc: 0.983357
epoch 895, loss: 0.027660
epoch 895, 
 train loss: 0.027660, val loss: 0.193050 
 val auc: 0.979486,  test auc: 0.983418
epoch 896, loss: 0.027527
epoch 896, 
 train loss: 0.027527, val loss: 0.193104 
 val auc: 0.979467,  test auc: 0.983333
epoch 897, loss: 0.027584
epoch 897, 
 train loss: 0.027584, val loss: 0.193364 
 val auc: 0.979580,  test auc: 0.983329
epoch 898, loss: 0.027611
epoch 898, 
 train loss: 0.027611, val loss: 0.193075 
 val auc: 0.979523,  test auc: 0.983441
epoch 899, loss: 0.027487
epoch 899, 
 train loss: 0.027487, val loss: 0.193466 
 val auc: 0.979523,  test auc: 0.983277
epoch 900, loss: 0.027375
epoch 900, 
 train loss: 0.027375, val loss: 0.193207 
 val auc: 0.979561,  test auc: 0.983371
epoch 901, loss: 0.027395
epoch 901, 
 train loss: 0.027395, val loss: 0.193187 
 val auc: 0.979542,  test auc: 0.983408
epoch 902, loss: 0.027445
epoch 902, 
 train loss: 0.027445, val loss: 0.194136 
 val auc: 0.979542,  test auc: 0.983310
epoch 903, loss: 0.027361
epoch 903, 
 train loss: 0.027361, val loss: 0.193691 
 val auc: 0.979523,  test auc: 0.983408
epoch 904, loss: 0.027232
epoch 904, 
 train loss: 0.027232, val loss: 0.193737 
 val auc: 0.979542,  test auc: 0.983291
epoch 905, loss: 0.027214
epoch 905, 
 train loss: 0.027214, val loss: 0.193854 
 val auc: 0.979598,  test auc: 0.983254
epoch 906, loss: 0.027240
epoch 906, 
 train loss: 0.027240, val loss: 0.193734 
 val auc: 0.979598,  test auc: 0.983465
epoch 907, loss: 0.027186
epoch 907, 
 train loss: 0.027186, val loss: 0.194054 
 val auc: 0.979467,  test auc: 0.983254
epoch 908, loss: 0.027087
epoch 908, 
 train loss: 0.027087, val loss: 0.193711 
 val auc: 0.979561,  test auc: 0.983390
epoch 909, loss: 0.027050
epoch 909, 
 train loss: 0.027050, val loss: 0.193803 
 val auc: 0.979580,  test auc: 0.983404
epoch 910, loss: 0.027058
epoch 910, 
 train loss: 0.027058, val loss: 0.194280 
 val auc: 0.979636,  test auc: 0.983296
epoch 911, loss: 0.027019
epoch 911, 
 train loss: 0.027019, val loss: 0.194157 
 val auc: 0.979598,  test auc: 0.983437
epoch 912, loss: 0.026940
epoch 912, 
 train loss: 0.026940, val loss: 0.194347 
 val auc: 0.979636,  test auc: 0.983329
epoch 913, loss: 0.026896
epoch 913, 
 train loss: 0.026896, val loss: 0.194304 
 val auc: 0.979655,  test auc: 0.983352
epoch 914, loss: 0.026888
epoch 914, 
 train loss: 0.026888, val loss: 0.194334 
 val auc: 0.979598,  test auc: 0.983380
epoch 915, loss: 0.026859
epoch 915, 
 train loss: 0.026859, val loss: 0.194701 
 val auc: 0.979636,  test auc: 0.983286
epoch 916, loss: 0.026798
epoch 916, 
 train loss: 0.026798, val loss: 0.194398 
 val auc: 0.979580,  test auc: 0.983376
epoch 917, loss: 0.026749
epoch 917, 
 train loss: 0.026749, val loss: 0.194462 
 val auc: 0.979617,  test auc: 0.983347
epoch 918, loss: 0.026726
epoch 918, 
 train loss: 0.026726, val loss: 0.194727 
 val auc: 0.979730,  test auc: 0.983371
epoch 919, loss: 0.026701
epoch 919, 
 train loss: 0.026701, val loss: 0.194574 
 val auc: 0.979636,  test auc: 0.983446
epoch 920, loss: 0.026654
epoch 920, 
 train loss: 0.026654, val loss: 0.194534 
 val auc: 0.979711,  test auc: 0.983333
epoch 921, loss: 0.026604
epoch 921, 
 train loss: 0.026604, val loss: 0.194386 
 val auc: 0.979673,  test auc: 0.983404
epoch 922, loss: 0.026574
epoch 922, 
 train loss: 0.026574, val loss: 0.194425 
 val auc: 0.979673,  test auc: 0.983446
epoch 923, loss: 0.026549
epoch 923, 
 train loss: 0.026549, val loss: 0.194535 
 val auc: 0.979711,  test auc: 0.983343
epoch 924, loss: 0.026511
epoch 924, 
 train loss: 0.026511, val loss: 0.194443 
 val auc: 0.979692,  test auc: 0.983483
epoch 925, loss: 0.026463
epoch 925, 
 train loss: 0.026463, val loss: 0.194686 
 val auc: 0.979767,  test auc: 0.983437
epoch 926, loss: 0.026426
epoch 926, 
 train loss: 0.026426, val loss: 0.194783 
 val auc: 0.979767,  test auc: 0.983455
epoch 927, loss: 0.026397
epoch 927, 
 train loss: 0.026397, val loss: 0.194821 
 val auc: 0.979748,  test auc: 0.983479
epoch 928, loss: 0.026362
epoch 928, 
 train loss: 0.026362, val loss: 0.194995 
 val auc: 0.979692,  test auc: 0.983385
epoch 929, loss: 0.026320
epoch 929, 
 train loss: 0.026320, val loss: 0.194896 
 val auc: 0.979748,  test auc: 0.983446
epoch 930, loss: 0.026284
epoch 930, 
 train loss: 0.026284, val loss: 0.194892 
 val auc: 0.979824,  test auc: 0.983512
epoch 931, loss: 0.026251
epoch 931, 
 train loss: 0.026251, val loss: 0.195000 
 val auc: 0.979824,  test auc: 0.983512
epoch 932, loss: 0.026216
epoch 932, 
 train loss: 0.026216, val loss: 0.194964 
 val auc: 0.979748,  test auc: 0.983474
epoch 933, loss: 0.026181
epoch 933, 
 train loss: 0.026181, val loss: 0.195009 
 val auc: 0.979824,  test auc: 0.983483
epoch 934, loss: 0.026144
epoch 934, 
 train loss: 0.026144, val loss: 0.195076 
 val auc: 0.979730,  test auc: 0.983432
epoch 935, loss: 0.026109
epoch 935, 
 train loss: 0.026109, val loss: 0.195083 
 val auc: 0.979767,  test auc: 0.983455
epoch 936, loss: 0.026076
epoch 936, 
 train loss: 0.026076, val loss: 0.195193 
 val auc: 0.979711,  test auc: 0.983455
epoch 937, loss: 0.026043
epoch 937, 
 train loss: 0.026043, val loss: 0.195322 
 val auc: 0.979748,  test auc: 0.983479
epoch 938, loss: 0.026008
epoch 938, 
 train loss: 0.026008, val loss: 0.195375 
 val auc: 0.979805,  test auc: 0.983479
epoch 939, loss: 0.025972
epoch 939, 
 train loss: 0.025972, val loss: 0.195345 
 val auc: 0.979824,  test auc: 0.983483
epoch 940, loss: 0.025938
epoch 940, 
 train loss: 0.025938, val loss: 0.195458 
 val auc: 0.979748,  test auc: 0.983460
epoch 941, loss: 0.025905
epoch 941, 
 train loss: 0.025905, val loss: 0.195446 
 val auc: 0.979861,  test auc: 0.983502
epoch 942, loss: 0.025872
epoch 942, 
 train loss: 0.025872, val loss: 0.195261 
 val auc: 0.979786,  test auc: 0.983483
epoch 943, loss: 0.025837
epoch 943, 
 train loss: 0.025837, val loss: 0.195320 
 val auc: 0.979861,  test auc: 0.983516
epoch 944, loss: 0.025802
epoch 944, 
 train loss: 0.025802, val loss: 0.195332 
 val auc: 0.979824,  test auc: 0.983488
epoch 945, loss: 0.025768
epoch 945, 
 train loss: 0.025768, val loss: 0.195522 
 val auc: 0.979861,  test auc: 0.983498
epoch 946, loss: 0.025735
epoch 946, 
 train loss: 0.025735, val loss: 0.195608 
 val auc: 0.979861,  test auc: 0.983474
epoch 947, loss: 0.025702
epoch 947, 
 train loss: 0.025702, val loss: 0.195433 
 val auc: 0.979842,  test auc: 0.983483
epoch 948, loss: 0.025669
epoch 948, 
 train loss: 0.025669, val loss: 0.195468 
 val auc: 0.979842,  test auc: 0.983451
epoch 949, loss: 0.025639
epoch 949, 
 train loss: 0.025639, val loss: 0.195206 
 val auc: 0.979899,  test auc: 0.983502
epoch 950, loss: 0.025614
epoch 950, 
 train loss: 0.025614, val loss: 0.195427 
 val auc: 0.979936,  test auc: 0.983502
epoch 951, loss: 0.025604
epoch 951, 
 train loss: 0.025604, val loss: 0.195123 
 val auc: 0.979861,  test auc: 0.983549
epoch 952, loss: 0.025607
epoch 952, 
 train loss: 0.025607, val loss: 0.195625 
 val auc: 0.979917,  test auc: 0.983465
epoch 953, loss: 0.025560
epoch 953, 
 train loss: 0.025560, val loss: 0.195404 
 val auc: 0.979936,  test auc: 0.983568
epoch 954, loss: 0.025482
epoch 954, 
 train loss: 0.025482, val loss: 0.195587 
 val auc: 0.979936,  test auc: 0.983507
epoch 955, loss: 0.025448
epoch 955, 
 train loss: 0.025448, val loss: 0.195635 
 val auc: 0.979936,  test auc: 0.983498
epoch 956, loss: 0.025448
epoch 956, 
 train loss: 0.025448, val loss: 0.195471 
 val auc: 0.979936,  test auc: 0.983544
epoch 957, loss: 0.025419
epoch 957, 
 train loss: 0.025419, val loss: 0.195753 
 val auc: 0.979748,  test auc: 0.983390
epoch 958, loss: 0.025356
epoch 958, 
 train loss: 0.025356, val loss: 0.195789 
 val auc: 0.979861,  test auc: 0.983493
epoch 959, loss: 0.025313
epoch 959, 
 train loss: 0.025313, val loss: 0.195650 
 val auc: 0.979880,  test auc: 0.983469
epoch 960, loss: 0.025304
epoch 960, 
 train loss: 0.025304, val loss: 0.195692 
 val auc: 0.979955,  test auc: 0.983474
epoch 961, loss: 0.025282
epoch 961, 
 train loss: 0.025282, val loss: 0.195801 
 val auc: 0.979936,  test auc: 0.983544
epoch 962, loss: 0.025227
epoch 962, 
 train loss: 0.025227, val loss: 0.196035 
 val auc: 0.979899,  test auc: 0.983446
epoch 963, loss: 0.025185
epoch 963, 
 train loss: 0.025185, val loss: 0.196001 
 val auc: 0.979936,  test auc: 0.983455
epoch 964, loss: 0.025167
epoch 964, 
 train loss: 0.025167, val loss: 0.196063 
 val auc: 0.979899,  test auc: 0.983526
epoch 965, loss: 0.025145
epoch 965, 
 train loss: 0.025145, val loss: 0.196074 
 val auc: 0.979936,  test auc: 0.983437
epoch 966, loss: 0.025103
epoch 966, 
 train loss: 0.025103, val loss: 0.195824 
 val auc: 0.979974,  test auc: 0.983540
epoch 967, loss: 0.025059
epoch 967, 
 train loss: 0.025059, val loss: 0.196076 
 val auc: 0.979899,  test auc: 0.983474
epoch 968, loss: 0.025029
epoch 968, 
 train loss: 0.025029, val loss: 0.196168 
 val auc: 0.979936,  test auc: 0.983465
epoch 969, loss: 0.025006
epoch 969, 
 train loss: 0.025006, val loss: 0.196118 
 val auc: 0.979936,  test auc: 0.983540
epoch 970, loss: 0.024974
epoch 970, 
 train loss: 0.024974, val loss: 0.196209 
 val auc: 0.979974,  test auc: 0.983498
epoch 971, loss: 0.024935
epoch 971, 
 train loss: 0.024935, val loss: 0.196084 
 val auc: 0.980030,  test auc: 0.983573
epoch 972, loss: 0.024903
epoch 972, 
 train loss: 0.024903, val loss: 0.195989 
 val auc: 0.980068,  test auc: 0.983587
epoch 973, loss: 0.024877
epoch 973, 
 train loss: 0.024877, val loss: 0.196128 
 val auc: 0.980011,  test auc: 0.983568
epoch 974, loss: 0.024849
epoch 974, 
 train loss: 0.024849, val loss: 0.196219 
 val auc: 0.979955,  test auc: 0.983582
epoch 975, loss: 0.024814
epoch 975, 
 train loss: 0.024814, val loss: 0.196307 
 val auc: 0.979992,  test auc: 0.983568
epoch 976, loss: 0.024779
epoch 976, 
 train loss: 0.024779, val loss: 0.196460 
 val auc: 0.979992,  test auc: 0.983544
epoch 977, loss: 0.024751
epoch 977, 
 train loss: 0.024751, val loss: 0.196528 
 val auc: 0.979861,  test auc: 0.983540
epoch 978, loss: 0.024724
epoch 978, 
 train loss: 0.024724, val loss: 0.196505 
 val auc: 0.979936,  test auc: 0.983530
epoch 979, loss: 0.024690
epoch 979, 
 train loss: 0.024690, val loss: 0.196402 
 val auc: 0.979936,  test auc: 0.983540
epoch 980, loss: 0.024658
epoch 980, 
 train loss: 0.024658, val loss: 0.196456 
 val auc: 0.979861,  test auc: 0.983516
epoch 981, loss: 0.024627
epoch 981, 
 train loss: 0.024627, val loss: 0.196529 
 val auc: 0.979842,  test auc: 0.983502
epoch 982, loss: 0.024599
epoch 982, 
 train loss: 0.024599, val loss: 0.196667 
 val auc: 0.979899,  test auc: 0.983530
epoch 983, loss: 0.024574
epoch 983, 
 train loss: 0.024574, val loss: 0.196992 
 val auc: 0.979824,  test auc: 0.983465
epoch 984, loss: 0.024557
epoch 984, 
 train loss: 0.024557, val loss: 0.196706 
 val auc: 0.979748,  test auc: 0.983530
epoch 985, loss: 0.024552
epoch 985, 
 train loss: 0.024552, val loss: 0.197093 
 val auc: 0.979880,  test auc: 0.983465
epoch 986, loss: 0.024579
epoch 986, 
 train loss: 0.024579, val loss: 0.196523 
 val auc: 0.979955,  test auc: 0.983643
epoch 987, loss: 0.024634
epoch 987, 
 train loss: 0.024634, val loss: 0.197348 
 val auc: 0.979880,  test auc: 0.983455
epoch 988, loss: 0.024562
epoch 988, 
 train loss: 0.024562, val loss: 0.196933 
 val auc: 0.979899,  test auc: 0.983615
epoch 989, loss: 0.024404
epoch 989, 
 train loss: 0.024404, val loss: 0.197162 
 val auc: 0.979880,  test auc: 0.983474
epoch 990, loss: 0.024405
epoch 990, 
 train loss: 0.024405, val loss: 0.197062 
 val auc: 0.979861,  test auc: 0.983474
epoch 991, loss: 0.024463
epoch 991, 
 train loss: 0.024463, val loss: 0.196722 
 val auc: 0.979936,  test auc: 0.983676
epoch 992, loss: 0.024393
epoch 992, 
 train loss: 0.024393, val loss: 0.196958 
 val auc: 0.979692,  test auc: 0.983413
epoch 993, loss: 0.024282
epoch 993, 
 train loss: 0.024282, val loss: 0.196724 
 val auc: 0.979899,  test auc: 0.983582
epoch 994, loss: 0.024280
epoch 994, 
 train loss: 0.024280, val loss: 0.196538 
 val auc: 0.979974,  test auc: 0.983615
epoch 995, loss: 0.024303
epoch 995, 
 train loss: 0.024303, val loss: 0.196867 
 val auc: 0.979880,  test auc: 0.983512
epoch 996, loss: 0.024245
epoch 996, 
 train loss: 0.024245, val loss: 0.196674 
 val auc: 0.979974,  test auc: 0.983671
epoch 997, loss: 0.024166
epoch 997, 
 train loss: 0.024166, val loss: 0.196480 
 val auc: 0.980011,  test auc: 0.983615
epoch 998, loss: 0.024150
epoch 998, 
 train loss: 0.024150, val loss: 0.196544 
 val auc: 0.979880,  test auc: 0.983577
epoch 999, loss: 0.024153
epoch 999, 
 train loss: 0.024153, val loss: 0.196598 
 val auc: 0.979936,  test auc: 0.983671
AUC: 0.980452
