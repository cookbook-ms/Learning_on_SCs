epoch 0, loss: 0.733280
model updated at epoch 0 
epoch 0, 
 train loss: 0.733280, val loss: 0.729727 
 val auc: 0.534872,  test auc: 0.513476
epoch 1, loss: 0.721930
model updated at epoch 1 
epoch 1, 
 train loss: 0.721930, val loss: 0.719140 
 val auc: 0.575038,  test auc: 0.555077
epoch 2, loss: 0.712164
model updated at epoch 2 
epoch 2, 
 train loss: 0.712164, val loss: 0.710093 
 val auc: 0.570120,  test auc: 0.559215
epoch 3, loss: 0.703944
model updated at epoch 3 
epoch 3, 
 train loss: 0.703944, val loss: 0.702593 
 val auc: 0.571021,  test auc: 0.570064
epoch 4, loss: 0.697169
model updated at epoch 4 
epoch 4, 
 train loss: 0.697169, val loss: 0.696392 
 val auc: 0.573836,  test auc: 0.573611
epoch 5, loss: 0.691704
model updated at epoch 5 
epoch 5, 
 train loss: 0.691704, val loss: 0.691269 
 val auc: 0.580968,  test auc: 0.578885
epoch 6, loss: 0.687345
model updated at epoch 6 
epoch 6, 
 train loss: 0.687345, val loss: 0.687142 
 val auc: 0.587050,  test auc: 0.583990
epoch 7, loss: 0.683867
model updated at epoch 7 
epoch 7, 
 train loss: 0.683867, val loss: 0.683846 
 val auc: 0.593544,  test auc: 0.590625
epoch 8, loss: 0.681137
model updated at epoch 8 
epoch 8, 
 train loss: 0.681137, val loss: 0.681272 
 val auc: 0.600450,  test auc: 0.595880
epoch 9, loss: 0.679085
model updated at epoch 9 
epoch 9, 
 train loss: 0.679085, val loss: 0.679370 
 val auc: 0.609947,  test auc: 0.602477
epoch 10, loss: 0.677538
model updated at epoch 10 
epoch 10, 
 train loss: 0.677538, val loss: 0.677984 
 val auc: 0.616854,  test auc: 0.608202
epoch 11, loss: 0.676299
model updated at epoch 11 
epoch 11, 
 train loss: 0.676299, val loss: 0.676986 
 val auc: 0.621997,  test auc: 0.612885
epoch 12, loss: 0.675215
model updated at epoch 12 
epoch 12, 
 train loss: 0.675215, val loss: 0.676204 
 val auc: 0.623386,  test auc: 0.616507
epoch 13, loss: 0.674178
model updated at epoch 13 
epoch 13, 
 train loss: 0.674178, val loss: 0.675494 
 val auc: 0.623536,  test auc: 0.619416
epoch 14, loss: 0.673095
model updated at epoch 14 
epoch 14, 
 train loss: 0.673095, val loss: 0.674807 
 val auc: 0.625526,  test auc: 0.623677
epoch 15, loss: 0.671915
model updated at epoch 15 
epoch 15, 
 train loss: 0.671915, val loss: 0.674098 
 val auc: 0.627365,  test auc: 0.628360
epoch 16, loss: 0.670698
model updated at epoch 16 
epoch 16, 
 train loss: 0.670698, val loss: 0.673362 
 val auc: 0.629992,  test auc: 0.632648
epoch 17, loss: 0.669430
model updated at epoch 17 
epoch 17, 
 train loss: 0.669430, val loss: 0.672653 
 val auc: 0.630180,  test auc: 0.635858
epoch 18, loss: 0.668168
model updated at epoch 18 
epoch 18, 
 train loss: 0.668168, val loss: 0.671965 
 val auc: 0.630556,  test auc: 0.638054
epoch 19, loss: 0.666882
model updated at epoch 19 
epoch 19, 
 train loss: 0.666882, val loss: 0.671243 
 val auc: 0.630631,  test auc: 0.641901
epoch 20, loss: 0.665607
model updated at epoch 20 
epoch 20, 
 train loss: 0.665607, val loss: 0.670492 
 val auc: 0.632245,  test auc: 0.645458
epoch 21, loss: 0.664314
model updated at epoch 21 
epoch 21, 
 train loss: 0.664314, val loss: 0.669772 
 val auc: 0.632920,  test auc: 0.648696
epoch 22, loss: 0.663008
model updated at epoch 22 
epoch 22, 
 train loss: 0.663008, val loss: 0.669073 
 val auc: 0.633371,  test auc: 0.651717
epoch 23, loss: 0.661699
model updated at epoch 23 
epoch 23, 
 train loss: 0.661699, val loss: 0.668387 
 val auc: 0.635248,  test auc: 0.654673
epoch 24, loss: 0.660407
model updated at epoch 24 
epoch 24, 
 train loss: 0.660407, val loss: 0.667718 
 val auc: 0.636524,  test auc: 0.656700
epoch 25, loss: 0.659095
model updated at epoch 25 
epoch 25, 
 train loss: 0.659095, val loss: 0.667018 
 val auc: 0.639039,  test auc: 0.659244
epoch 26, loss: 0.657772
model updated at epoch 26 
epoch 26, 
 train loss: 0.657772, val loss: 0.666271 
 val auc: 0.641404,  test auc: 0.661486
epoch 27, loss: 0.656450
model updated at epoch 27 
epoch 27, 
 train loss: 0.656450, val loss: 0.665484 
 val auc: 0.643431,  test auc: 0.663908
epoch 28, loss: 0.655108
model updated at epoch 28 
epoch 28, 
 train loss: 0.655108, val loss: 0.664667 
 val auc: 0.646246,  test auc: 0.666273
epoch 29, loss: 0.653722
model updated at epoch 29 
epoch 29, 
 train loss: 0.653722, val loss: 0.663792 
 val auc: 0.648574,  test auc: 0.668769
epoch 30, loss: 0.652285
model updated at epoch 30 
epoch 30, 
 train loss: 0.652285, val loss: 0.662813 
 val auc: 0.650676,  test auc: 0.672044
epoch 31, loss: 0.650825
model updated at epoch 31 
epoch 31, 
 train loss: 0.650825, val loss: 0.661771 
 val auc: 0.653641,  test auc: 0.675319
epoch 32, loss: 0.649359
model updated at epoch 32 
epoch 32, 
 train loss: 0.649359, val loss: 0.660684 
 val auc: 0.655706,  test auc: 0.678012
epoch 33, loss: 0.647915
model updated at epoch 33 
epoch 33, 
 train loss: 0.647915, val loss: 0.659539 
 val auc: 0.657958,  test auc: 0.681081
epoch 34, loss: 0.646478
model updated at epoch 34 
epoch 34, 
 train loss: 0.646478, val loss: 0.658349 
 val auc: 0.660661,  test auc: 0.684375
epoch 35, loss: 0.645041
model updated at epoch 35 
epoch 35, 
 train loss: 0.645041, val loss: 0.657109 
 val auc: 0.664114,  test auc: 0.687416
epoch 36, loss: 0.643578
model updated at epoch 36 
epoch 36, 
 train loss: 0.643578, val loss: 0.655829 
 val auc: 0.666667,  test auc: 0.690184
epoch 37, loss: 0.642129
model updated at epoch 37 
epoch 37, 
 train loss: 0.642129, val loss: 0.654491 
 val auc: 0.670045,  test auc: 0.692943
epoch 38, loss: 0.640689
model updated at epoch 38 
epoch 38, 
 train loss: 0.640689, val loss: 0.653138 
 val auc: 0.672935,  test auc: 0.695458
epoch 39, loss: 0.639238
model updated at epoch 39 
epoch 39, 
 train loss: 0.639238, val loss: 0.651833 
 val auc: 0.675638,  test auc: 0.698001
epoch 40, loss: 0.637769
model updated at epoch 40 
epoch 40, 
 train loss: 0.637769, val loss: 0.650611 
 val auc: 0.678979,  test auc: 0.700638
epoch 41, loss: 0.636370
model updated at epoch 41 
epoch 41, 
 train loss: 0.636370, val loss: 0.649472 
 val auc: 0.680781,  test auc: 0.702675
epoch 42, loss: 0.634899
model updated at epoch 42 
epoch 42, 
 train loss: 0.634899, val loss: 0.648322 
 val auc: 0.682470,  test auc: 0.704720
epoch 43, loss: 0.633438
model updated at epoch 43 
epoch 43, 
 train loss: 0.633438, val loss: 0.647318 
 val auc: 0.683521,  test auc: 0.707048
epoch 44, loss: 0.631996
model updated at epoch 44 
epoch 44, 
 train loss: 0.631996, val loss: 0.646403 
 val auc: 0.685661,  test auc: 0.708915
epoch 45, loss: 0.630564
model updated at epoch 45 
epoch 45, 
 train loss: 0.630564, val loss: 0.645474 
 val auc: 0.686749,  test auc: 0.710933
epoch 46, loss: 0.629130
model updated at epoch 46 
epoch 46, 
 train loss: 0.629130, val loss: 0.644522 
 val auc: 0.689152,  test auc: 0.713514
epoch 47, loss: 0.627694
model updated at epoch 47 
epoch 47, 
 train loss: 0.627694, val loss: 0.643536 
 val auc: 0.692380,  test auc: 0.716601
epoch 48, loss: 0.626238
model updated at epoch 48 
epoch 48, 
 train loss: 0.626238, val loss: 0.642472 
 val auc: 0.693956,  test auc: 0.719182
epoch 49, loss: 0.624756
model updated at epoch 49 
epoch 49, 
 train loss: 0.624756, val loss: 0.641298 
 val auc: 0.696396,  test auc: 0.722035
epoch 50, loss: 0.623256
model updated at epoch 50 
epoch 50, 
 train loss: 0.623256, val loss: 0.640026 
 val auc: 0.699962,  test auc: 0.725282
epoch 51, loss: 0.621728
model updated at epoch 51 
epoch 51, 
 train loss: 0.621728, val loss: 0.638634 
 val auc: 0.702140,  test auc: 0.728012
epoch 52, loss: 0.620185
model updated at epoch 52 
epoch 52, 
 train loss: 0.620185, val loss: 0.637180 
 val auc: 0.704354,  test auc: 0.730631
epoch 53, loss: 0.618605
model updated at epoch 53 
epoch 53, 
 train loss: 0.618605, val loss: 0.635714 
 val auc: 0.706156,  test auc: 0.733033
epoch 54, loss: 0.617000
model updated at epoch 54 
epoch 54, 
 train loss: 0.617000, val loss: 0.634293 
 val auc: 0.708408,  test auc: 0.735276
epoch 55, loss: 0.615381
model updated at epoch 55 
epoch 55, 
 train loss: 0.615381, val loss: 0.632904 
 val auc: 0.710435,  test auc: 0.737575
epoch 56, loss: 0.613724
model updated at epoch 56 
epoch 56, 
 train loss: 0.613724, val loss: 0.631490 
 val auc: 0.712650,  test auc: 0.739640
epoch 57, loss: 0.612044
model updated at epoch 57 
epoch 57, 
 train loss: 0.612044, val loss: 0.630006 
 val auc: 0.716254,  test auc: 0.742117
epoch 58, loss: 0.610320
model updated at epoch 58 
epoch 58, 
 train loss: 0.610320, val loss: 0.628391 
 val auc: 0.719820,  test auc: 0.744867
epoch 59, loss: 0.608536
model updated at epoch 59 
epoch 59, 
 train loss: 0.608536, val loss: 0.626611 
 val auc: 0.722222,  test auc: 0.747626
epoch 60, loss: 0.606748
model updated at epoch 60 
epoch 60, 
 train loss: 0.606748, val loss: 0.624711 
 val auc: 0.724324,  test auc: 0.750507
epoch 61, loss: 0.604927
model updated at epoch 61 
epoch 61, 
 train loss: 0.604927, val loss: 0.622831 
 val auc: 0.727140,  test auc: 0.753106
epoch 62, loss: 0.603055
model updated at epoch 62 
epoch 62, 
 train loss: 0.603055, val loss: 0.621005 
 val auc: 0.729542,  test auc: 0.755180
epoch 63, loss: 0.601097
model updated at epoch 63 
epoch 63, 
 train loss: 0.601097, val loss: 0.619211 
 val auc: 0.732545,  test auc: 0.757170
epoch 64, loss: 0.599051
model updated at epoch 64 
epoch 64, 
 train loss: 0.599051, val loss: 0.617367 
 val auc: 0.735511,  test auc: 0.759732
epoch 65, loss: 0.596896
model updated at epoch 65 
epoch 65, 
 train loss: 0.596896, val loss: 0.615458 
 val auc: 0.738964,  test auc: 0.762416
epoch 66, loss: 0.594678
model updated at epoch 66 
epoch 66, 
 train loss: 0.594678, val loss: 0.613388 
 val auc: 0.742042,  test auc: 0.765297
epoch 67, loss: 0.592419
model updated at epoch 67 
epoch 67, 
 train loss: 0.592419, val loss: 0.611121 
 val auc: 0.745983,  test auc: 0.768572
epoch 68, loss: 0.590095
model updated at epoch 68 
epoch 68, 
 train loss: 0.590095, val loss: 0.608754 
 val auc: 0.750075,  test auc: 0.772382
epoch 69, loss: 0.587635
model updated at epoch 69 
epoch 69, 
 train loss: 0.587635, val loss: 0.606271 
 val auc: 0.754805,  test auc: 0.776276
epoch 70, loss: 0.585048
model updated at epoch 70 
epoch 70, 
 train loss: 0.585048, val loss: 0.603706 
 val auc: 0.759234,  test auc: 0.780161
epoch 71, loss: 0.582315
model updated at epoch 71 
epoch 71, 
 train loss: 0.582315, val loss: 0.601031 
 val auc: 0.764602,  test auc: 0.783887
epoch 72, loss: 0.579460
model updated at epoch 72 
epoch 72, 
 train loss: 0.579460, val loss: 0.598244 
 val auc: 0.769632,  test auc: 0.788119
epoch 73, loss: 0.576459
model updated at epoch 73 
epoch 73, 
 train loss: 0.576459, val loss: 0.595342 
 val auc: 0.773986,  test auc: 0.791676
epoch 74, loss: 0.573241
model updated at epoch 74 
epoch 74, 
 train loss: 0.573241, val loss: 0.592105 
 val auc: 0.778303,  test auc: 0.795327
epoch 75, loss: 0.569869
model updated at epoch 75 
epoch 75, 
 train loss: 0.569869, val loss: 0.588539 
 val auc: 0.783146,  test auc: 0.799334
epoch 76, loss: 0.566430
model updated at epoch 76 
epoch 76, 
 train loss: 0.566430, val loss: 0.585036 
 val auc: 0.787387,  test auc: 0.803050
epoch 77, loss: 0.562835
model updated at epoch 77 
epoch 77, 
 train loss: 0.562835, val loss: 0.581589 
 val auc: 0.792230,  test auc: 0.807038
epoch 78, loss: 0.559115
model updated at epoch 78 
epoch 78, 
 train loss: 0.559115, val loss: 0.578083 
 val auc: 0.797560,  test auc: 0.811149
epoch 79, loss: 0.555284
model updated at epoch 79 
epoch 79, 
 train loss: 0.555284, val loss: 0.574154 
 val auc: 0.803303,  test auc: 0.816047
epoch 80, loss: 0.551287
model updated at epoch 80 
epoch 80, 
 train loss: 0.551287, val loss: 0.569770 
 val auc: 0.810023,  test auc: 0.821265
epoch 81, loss: 0.547214
model updated at epoch 81 
epoch 81, 
 train loss: 0.547214, val loss: 0.565412 
 val auc: 0.815503,  test auc: 0.825901
epoch 82, loss: 0.542878
model updated at epoch 82 
epoch 82, 
 train loss: 0.542878, val loss: 0.561150 
 val auc: 0.819707,  test auc: 0.829833
epoch 83, loss: 0.538354
model updated at epoch 83 
epoch 83, 
 train loss: 0.538354, val loss: 0.556706 
 val auc: 0.824962,  test auc: 0.833718
epoch 84, loss: 0.533642
model updated at epoch 84 
epoch 84, 
 train loss: 0.533642, val loss: 0.551943 
 val auc: 0.828829,  test auc: 0.838063
epoch 85, loss: 0.528751
model updated at epoch 85 
epoch 85, 
 train loss: 0.528751, val loss: 0.546988 
 val auc: 0.832920,  test auc: 0.842145
epoch 86, loss: 0.523655
model updated at epoch 86 
epoch 86, 
 train loss: 0.523655, val loss: 0.541886 
 val auc: 0.837950,  test auc: 0.846959
epoch 87, loss: 0.518399
model updated at epoch 87 
epoch 87, 
 train loss: 0.518399, val loss: 0.536790 
 val auc: 0.842718,  test auc: 0.852111
epoch 88, loss: 0.512969
model updated at epoch 88 
epoch 88, 
 train loss: 0.512969, val loss: 0.531651 
 val auc: 0.846659,  test auc: 0.856522
epoch 89, loss: 0.507324
model updated at epoch 89 
epoch 89, 
 train loss: 0.507324, val loss: 0.526367 
 val auc: 0.850075,  test auc: 0.860586
epoch 90, loss: 0.501350
model updated at epoch 90 
epoch 90, 
 train loss: 0.501350, val loss: 0.520946 
 val auc: 0.854167,  test auc: 0.864987
epoch 91, loss: 0.495007
model updated at epoch 91 
epoch 91, 
 train loss: 0.495007, val loss: 0.515376 
 val auc: 0.856982,  test auc: 0.869163
epoch 92, loss: 0.488640
model updated at epoch 92 
epoch 92, 
 train loss: 0.488640, val loss: 0.509817 
 val auc: 0.860173,  test auc: 0.873864
epoch 93, loss: 0.481960
model updated at epoch 93 
epoch 93, 
 train loss: 0.481960, val loss: 0.504466 
 val auc: 0.863176,  test auc: 0.877881
epoch 94, loss: 0.474976
model updated at epoch 94 
epoch 94, 
 train loss: 0.474976, val loss: 0.498333 
 val auc: 0.866104,  test auc: 0.881804
epoch 95, loss: 0.467938
model updated at epoch 95 
epoch 95, 
 train loss: 0.467938, val loss: 0.491098 
 val auc: 0.870120,  test auc: 0.885792
epoch 96, loss: 0.460450
model updated at epoch 96 
epoch 96, 
 train loss: 0.460450, val loss: 0.484975 
 val auc: 0.873198,  test auc: 0.890165
epoch 97, loss: 0.452810
model updated at epoch 97 
epoch 97, 
 train loss: 0.452810, val loss: 0.477970 
 val auc: 0.877477,  test auc: 0.894529
epoch 98, loss: 0.445281
model updated at epoch 98 
epoch 98, 
 train loss: 0.445281, val loss: 0.470687 
 val auc: 0.882357,  test auc: 0.899043
epoch 99, loss: 0.437720
model updated at epoch 99 
epoch 99, 
 train loss: 0.437720, val loss: 0.464334 
 val auc: 0.885661,  test auc: 0.902168
epoch 100, loss: 0.430062
model updated at epoch 100 
epoch 100, 
 train loss: 0.430062, val loss: 0.457027 
 val auc: 0.890203,  test auc: 0.905330
epoch 101, loss: 0.422246
model updated at epoch 101 
epoch 101, 
 train loss: 0.422246, val loss: 0.450547 
 val auc: 0.894932,  test auc: 0.908437
epoch 102, loss: 0.414364
model updated at epoch 102 
epoch 102, 
 train loss: 0.414364, val loss: 0.443656 
 val auc: 0.899737,  test auc: 0.912115
epoch 103, loss: 0.406650
model updated at epoch 103 
epoch 103, 
 train loss: 0.406650, val loss: 0.436426 
 val auc: 0.905631,  test auc: 0.915813
epoch 104, loss: 0.398609
model updated at epoch 104 
epoch 104, 
 train loss: 0.398609, val loss: 0.429424 
 val auc: 0.908896,  test auc: 0.918928
epoch 105, loss: 0.390616
model updated at epoch 105 
epoch 105, 
 train loss: 0.390616, val loss: 0.421948 
 val auc: 0.912125,  test auc: 0.922016
epoch 106, loss: 0.382946
model updated at epoch 106 
epoch 106, 
 train loss: 0.382946, val loss: 0.414613 
 val auc: 0.915541,  test auc: 0.924681
epoch 107, loss: 0.375368
model updated at epoch 107 
epoch 107, 
 train loss: 0.375368, val loss: 0.408646 
 val auc: 0.917868,  test auc: 0.926774
epoch 108, loss: 0.367835
model updated at epoch 108 
epoch 108, 
 train loss: 0.367835, val loss: 0.402366 
 val auc: 0.920571,  test auc: 0.929167
epoch 109, loss: 0.360489
model updated at epoch 109 
epoch 109, 
 train loss: 0.360489, val loss: 0.396718 
 val auc: 0.922372,  test auc: 0.931062
epoch 110, loss: 0.353234
model updated at epoch 110 
epoch 110, 
 train loss: 0.353234, val loss: 0.390772 
 val auc: 0.924399,  test auc: 0.933061
epoch 111, loss: 0.346209
model updated at epoch 111 
epoch 111, 
 train loss: 0.346209, val loss: 0.383340 
 val auc: 0.928116,  test auc: 0.935942
epoch 112, loss: 0.339422
model updated at epoch 112 
epoch 112, 
 train loss: 0.339422, val loss: 0.377125 
 val auc: 0.930443,  test auc: 0.938148
epoch 113, loss: 0.332966
model updated at epoch 113 
epoch 113, 
 train loss: 0.332966, val loss: 0.370067 
 val auc: 0.933859,  test auc: 0.940982
epoch 114, loss: 0.326723
model updated at epoch 114 
epoch 114, 
 train loss: 0.326723, val loss: 0.365467 
 val auc: 0.934047,  test auc: 0.941714
epoch 115, loss: 0.320661
model updated at epoch 115 
epoch 115, 
 train loss: 0.320661, val loss: 0.359491 
 val auc: 0.937050,  test auc: 0.944257
epoch 116, loss: 0.314897
model updated at epoch 116 
epoch 116, 
 train loss: 0.314897, val loss: 0.355526 
 val auc: 0.936524,  test auc: 0.944388
epoch 117, loss: 0.309353
model updated at epoch 117 
epoch 117, 
 train loss: 0.309353, val loss: 0.349795 
 val auc: 0.938288,  test auc: 0.946105
epoch 118, loss: 0.303887
model updated at epoch 118 
epoch 118, 
 train loss: 0.303887, val loss: 0.345527 
 val auc: 0.939077,  test auc: 0.946762
epoch 119, loss: 0.298598
model updated at epoch 119 
epoch 119, 
 train loss: 0.298598, val loss: 0.340214 
 val auc: 0.940465,  test auc: 0.948029
epoch 120, loss: 0.293583
model updated at epoch 120 
epoch 120, 
 train loss: 0.293583, val loss: 0.335514 
 val auc: 0.941667,  test auc: 0.948846
epoch 121, loss: 0.288815
model updated at epoch 121 
epoch 121, 
 train loss: 0.288815, val loss: 0.331599 
 val auc: 0.942492,  test auc: 0.949512
epoch 122, loss: 0.284236
model updated at epoch 122 
epoch 122, 
 train loss: 0.284236, val loss: 0.327423 
 val auc: 0.943806,  test auc: 0.950394
epoch 123, loss: 0.279879
model updated at epoch 123 
epoch 123, 
 train loss: 0.279879, val loss: 0.324981 
 val auc: 0.944144,  test auc: 0.950502
epoch 124, loss: 0.275643
model updated at epoch 124 
epoch 124, 
 train loss: 0.275643, val loss: 0.320658 
 val auc: 0.945420,  test auc: 0.951839
epoch 125, loss: 0.271621
model updated at epoch 125 
epoch 125, 
 train loss: 0.271621, val loss: 0.318581 
 val auc: 0.944632,  test auc: 0.951342
epoch 126, loss: 0.267653
model updated at epoch 126 
epoch 126, 
 train loss: 0.267653, val loss: 0.313060 
 val auc: 0.947710,  test auc: 0.953585
epoch 127, loss: 0.264053
model updated at epoch 127 
epoch 127, 
 train loss: 0.264053, val loss: 0.311676 
 val auc: 0.945871,  test auc: 0.952609
epoch 128, loss: 0.260129
model updated at epoch 128 
epoch 128, 
 train loss: 0.260129, val loss: 0.306610 
 val auc: 0.949137,  test auc: 0.954795
epoch 129, loss: 0.256386
model updated at epoch 129 
epoch 129, 
 train loss: 0.256386, val loss: 0.304672 
 val auc: 0.948799,  test auc: 0.954861
epoch 130, loss: 0.252976
model updated at epoch 130 
epoch 130, 
 train loss: 0.252976, val loss: 0.301870 
 val auc: 0.949399,  test auc: 0.955321
epoch 131, loss: 0.249887
model updated at epoch 131 
epoch 131, 
 train loss: 0.249887, val loss: 0.297844 
 val auc: 0.951051,  test auc: 0.956494
epoch 132, loss: 0.247344
model updated at epoch 132 
epoch 132, 
 train loss: 0.247344, val loss: 0.297261 
 val auc: 0.949812,  test auc: 0.956100
epoch 133, loss: 0.244598
model updated at epoch 133 
epoch 133, 
 train loss: 0.244598, val loss: 0.291201 
 val auc: 0.952590,  test auc: 0.957995
epoch 134, loss: 0.241635
epoch 134, 
 train loss: 0.241635, val loss: 0.292061 
 val auc: 0.950601,  test auc: 0.956672
epoch 135, loss: 0.237750
model updated at epoch 135 
epoch 135, 
 train loss: 0.237750, val loss: 0.287281 
 val auc: 0.952252,  test auc: 0.958183
epoch 136, loss: 0.235975
model updated at epoch 136 
epoch 136, 
 train loss: 0.235975, val loss: 0.284193 
 val auc: 0.953491,  test auc: 0.959000
epoch 137, loss: 0.234119
epoch 137, 
 train loss: 0.234119, val loss: 0.285822 
 val auc: 0.951164,  test auc: 0.957883
epoch 138, loss: 0.229957
model updated at epoch 138 
epoch 138, 
 train loss: 0.229957, val loss: 0.279241 
 val auc: 0.953866,  test auc: 0.959825
epoch 139, loss: 0.228999
model updated at epoch 139 
epoch 139, 
 train loss: 0.228999, val loss: 0.275821 
 val auc: 0.955105,  test auc: 0.960586
epoch 140, loss: 0.227533
epoch 140, 
 train loss: 0.227533, val loss: 0.279060 
 val auc: 0.952665,  test auc: 0.959788
epoch 141, loss: 0.223051
model updated at epoch 141 
epoch 141, 
 train loss: 0.223051, val loss: 0.273396 
 val auc: 0.955405,  test auc: 0.961318
epoch 142, loss: 0.223745
model updated at epoch 142 
epoch 142, 
 train loss: 0.223745, val loss: 0.270798 
 val auc: 0.956682,  test auc: 0.961655
epoch 143, loss: 0.220486
epoch 143, 
 train loss: 0.220486, val loss: 0.272642 
 val auc: 0.954917,  test auc: 0.961242
epoch 144, loss: 0.218426
model updated at epoch 144 
epoch 144, 
 train loss: 0.218426, val loss: 0.270304 
 val auc: 0.955518,  test auc: 0.961665
epoch 145, loss: 0.217006
model updated at epoch 145 
epoch 145, 
 train loss: 0.217006, val loss: 0.264477 
 val auc: 0.957620,  test auc: 0.962669
epoch 146, loss: 0.213589
model updated at epoch 146 
epoch 146, 
 train loss: 0.213589, val loss: 0.262937 
 val auc: 0.958146,  test auc: 0.963110
epoch 147, loss: 0.213389
epoch 147, 
 train loss: 0.213389, val loss: 0.265466 
 val auc: 0.956832,  test auc: 0.962660
epoch 148, loss: 0.210168
model updated at epoch 148 
epoch 148, 
 train loss: 0.210168, val loss: 0.260908 
 val auc: 0.957733,  test auc: 0.963335
epoch 149, loss: 0.210313
model updated at epoch 149 
epoch 149, 
 train loss: 0.210313, val loss: 0.258761 
 val auc: 0.958296,  test auc: 0.963523
epoch 150, loss: 0.207605
epoch 150, 
 train loss: 0.207605, val loss: 0.260131 
 val auc: 0.957695,  test auc: 0.963523
epoch 151, loss: 0.206465
epoch 151, 
 train loss: 0.206465, val loss: 0.259575 
 val auc: 0.958108,  test auc: 0.963729
epoch 152, loss: 0.205028
model updated at epoch 152 
epoch 152, 
 train loss: 0.205028, val loss: 0.255418 
 val auc: 0.958634,  test auc: 0.964011
epoch 153, loss: 0.202953
model updated at epoch 153 
epoch 153, 
 train loss: 0.202953, val loss: 0.254897 
 val auc: 0.958934,  test auc: 0.964264
epoch 154, loss: 0.202366
epoch 154, 
 train loss: 0.202366, val loss: 0.257022 
 val auc: 0.958183,  test auc: 0.963964
epoch 155, loss: 0.200102
model updated at epoch 155 
epoch 155, 
 train loss: 0.200102, val loss: 0.253934 
 val auc: 0.959497,  test auc: 0.964508
epoch 156, loss: 0.199729
model updated at epoch 156 
epoch 156, 
 train loss: 0.199729, val loss: 0.251836 
 val auc: 0.959835,  test auc: 0.964902
epoch 157, loss: 0.197861
epoch 157, 
 train loss: 0.197861, val loss: 0.253048 
 val auc: 0.959347,  test auc: 0.964489
epoch 158, loss: 0.196600
epoch 158, 
 train loss: 0.196600, val loss: 0.251991 
 val auc: 0.959647,  test auc: 0.964762
epoch 159, loss: 0.195860
model updated at epoch 159 
epoch 159, 
 train loss: 0.195860, val loss: 0.248560 
 val auc: 0.960323,  test auc: 0.965231
epoch 160, loss: 0.193907
epoch 160, 
 train loss: 0.193907, val loss: 0.249237 
 val auc: 0.960435,  test auc: 0.965231
epoch 161, loss: 0.193168
epoch 161, 
 train loss: 0.193168, val loss: 0.249797 
 val auc: 0.960398,  test auc: 0.965259
epoch 162, loss: 0.191959
model updated at epoch 162 
epoch 162, 
 train loss: 0.191959, val loss: 0.246464 
 val auc: 0.961299,  test auc: 0.965869
epoch 163, loss: 0.190515
model updated at epoch 163 
epoch 163, 
 train loss: 0.190515, val loss: 0.246199 
 val auc: 0.961411,  test auc: 0.966047
epoch 164, loss: 0.189784
epoch 164, 
 train loss: 0.189784, val loss: 0.246782 
 val auc: 0.961374,  test auc: 0.966029
epoch 165, loss: 0.188547
model updated at epoch 165 
epoch 165, 
 train loss: 0.188547, val loss: 0.243808 
 val auc: 0.962312,  test auc: 0.966592
epoch 166, loss: 0.187359
model updated at epoch 166 
epoch 166, 
 train loss: 0.187359, val loss: 0.243502 
 val auc: 0.962350,  test auc: 0.966779
epoch 167, loss: 0.186589
epoch 167, 
 train loss: 0.186589, val loss: 0.244206 
 val auc: 0.962350,  test auc: 0.966685
epoch 168, loss: 0.185522
model updated at epoch 168 
epoch 168, 
 train loss: 0.185522, val loss: 0.241596 
 val auc: 0.962688,  test auc: 0.967070
epoch 169, loss: 0.184377
model updated at epoch 169 
epoch 169, 
 train loss: 0.184377, val loss: 0.241501 
 val auc: 0.963101,  test auc: 0.967399
epoch 170, loss: 0.183485
model updated at epoch 170 
epoch 170, 
 train loss: 0.183485, val loss: 0.241107 
 val auc: 0.963026,  test auc: 0.967333
epoch 171, loss: 0.182628
model updated at epoch 171 
epoch 171, 
 train loss: 0.182628, val loss: 0.239020 
 val auc: 0.963251,  test auc: 0.967530
epoch 172, loss: 0.181646
epoch 172, 
 train loss: 0.181646, val loss: 0.239807 
 val auc: 0.963438,  test auc: 0.967483
epoch 173, loss: 0.180602
model updated at epoch 173 
epoch 173, 
 train loss: 0.180602, val loss: 0.238129 
 val auc: 0.963851,  test auc: 0.967858
epoch 174, loss: 0.179693
model updated at epoch 174 
epoch 174, 
 train loss: 0.179693, val loss: 0.237445 
 val auc: 0.964189,  test auc: 0.968037
epoch 175, loss: 0.178887
epoch 175, 
 train loss: 0.178887, val loss: 0.237738 
 val auc: 0.964039,  test auc: 0.967962
epoch 176, loss: 0.178061
model updated at epoch 176 
epoch 176, 
 train loss: 0.178061, val loss: 0.235539 
 val auc: 0.964565,  test auc: 0.968403
epoch 177, loss: 0.177231
epoch 177, 
 train loss: 0.177231, val loss: 0.236575 
 val auc: 0.964489,  test auc: 0.968290
epoch 178, loss: 0.176328
model updated at epoch 178 
epoch 178, 
 train loss: 0.176328, val loss: 0.234117 
 val auc: 0.965053,  test auc: 0.968769
epoch 179, loss: 0.175460
epoch 179, 
 train loss: 0.175460, val loss: 0.235213 
 val auc: 0.964865,  test auc: 0.968609
epoch 180, loss: 0.174583
model updated at epoch 180 
epoch 180, 
 train loss: 0.174583, val loss: 0.233058 
 val auc: 0.965315,  test auc: 0.968863
epoch 181, loss: 0.173767
epoch 181, 
 train loss: 0.173767, val loss: 0.233953 
 val auc: 0.965053,  test auc: 0.968769
epoch 182, loss: 0.172996
model updated at epoch 182 
epoch 182, 
 train loss: 0.172996, val loss: 0.231635 
 val auc: 0.965541,  test auc: 0.969163
epoch 183, loss: 0.172410
epoch 183, 
 train loss: 0.172410, val loss: 0.233309 
 val auc: 0.965165,  test auc: 0.968919
epoch 184, loss: 0.171982
model updated at epoch 184 
epoch 184, 
 train loss: 0.171982, val loss: 0.230069 
 val auc: 0.966141,  test auc: 0.969566
epoch 185, loss: 0.172356
epoch 185, 
 train loss: 0.172356, val loss: 0.234683 
 val auc: 0.964715,  test auc: 0.968834
epoch 186, loss: 0.171735
model updated at epoch 186 
epoch 186, 
 train loss: 0.171735, val loss: 0.229165 
 val auc: 0.966554,  test auc: 0.969801
epoch 187, loss: 0.171480
epoch 187, 
 train loss: 0.171480, val loss: 0.234370 
 val auc: 0.964602,  test auc: 0.968919
epoch 188, loss: 0.168620
model updated at epoch 188 
epoch 188, 
 train loss: 0.168620, val loss: 0.227986 
 val auc: 0.966742,  test auc: 0.969932
epoch 189, loss: 0.167629
model updated at epoch 189 
epoch 189, 
 train loss: 0.167629, val loss: 0.227514 
 val auc: 0.966892,  test auc: 0.969970
epoch 190, loss: 0.168224
epoch 190, 
 train loss: 0.168224, val loss: 0.230751 
 val auc: 0.965878,  test auc: 0.969520
epoch 191, loss: 0.167361
model updated at epoch 191 
epoch 191, 
 train loss: 0.167361, val loss: 0.226285 
 val auc: 0.967492,  test auc: 0.970317
epoch 192, loss: 0.165917
epoch 192, 
 train loss: 0.165917, val loss: 0.228169 
 val auc: 0.966554,  test auc: 0.969792
epoch 193, loss: 0.164639
model updated at epoch 193 
epoch 193, 
 train loss: 0.164639, val loss: 0.226026 
 val auc: 0.967080,  test auc: 0.970195
epoch 194, loss: 0.164545
model updated at epoch 194 
epoch 194, 
 train loss: 0.164545, val loss: 0.224823 
 val auc: 0.967417,  test auc: 0.970458
epoch 195, loss: 0.164668
epoch 195, 
 train loss: 0.164668, val loss: 0.227982 
 val auc: 0.966179,  test auc: 0.969773
epoch 196, loss: 0.163129
model updated at epoch 196 
epoch 196, 
 train loss: 0.163129, val loss: 0.223981 
 val auc: 0.967718,  test auc: 0.970636
epoch 197, loss: 0.161924
epoch 197, 
 train loss: 0.161924, val loss: 0.224176 
 val auc: 0.967380,  test auc: 0.970430
epoch 198, loss: 0.161567
epoch 198, 
 train loss: 0.161567, val loss: 0.224734 
 val auc: 0.967005,  test auc: 0.970261
epoch 199, loss: 0.161354
model updated at epoch 199 
epoch 199, 
 train loss: 0.161354, val loss: 0.222878 
 val auc: 0.968168,  test auc: 0.970815
epoch 200, loss: 0.160784
epoch 200, 
 train loss: 0.160784, val loss: 0.225117 
 val auc: 0.966779,  test auc: 0.970242
epoch 201, loss: 0.159481
model updated at epoch 201 
epoch 201, 
 train loss: 0.159481, val loss: 0.222514 
 val auc: 0.968018,  test auc: 0.970843
epoch 202, loss: 0.158697
model updated at epoch 202 
epoch 202, 
 train loss: 0.158697, val loss: 0.222305 
 val auc: 0.967943,  test auc: 0.970786
epoch 203, loss: 0.158468
epoch 203, 
 train loss: 0.158468, val loss: 0.223283 
 val auc: 0.967267,  test auc: 0.970571
epoch 204, loss: 0.158035
model updated at epoch 204 
epoch 204, 
 train loss: 0.158035, val loss: 0.221092 
 val auc: 0.968281,  test auc: 0.971021
epoch 205, loss: 0.157362
epoch 205, 
 train loss: 0.157362, val loss: 0.222608 
 val auc: 0.967380,  test auc: 0.970683
epoch 206, loss: 0.156345
model updated at epoch 206 
epoch 206, 
 train loss: 0.156345, val loss: 0.220327 
 val auc: 0.968356,  test auc: 0.971115
epoch 207, loss: 0.155582
model updated at epoch 207 
epoch 207, 
 train loss: 0.155582, val loss: 0.220240 
 val auc: 0.968168,  test auc: 0.971068
epoch 208, loss: 0.155125
epoch 208, 
 train loss: 0.155125, val loss: 0.220476 
 val auc: 0.968018,  test auc: 0.970946
epoch 209, loss: 0.154746
model updated at epoch 209 
epoch 209, 
 train loss: 0.154746, val loss: 0.219083 
 val auc: 0.968619,  test auc: 0.971256
epoch 210, loss: 0.154327
epoch 210, 
 train loss: 0.154327, val loss: 0.220457 
 val auc: 0.967755,  test auc: 0.970927
epoch 211, loss: 0.153591
model updated at epoch 211 
epoch 211, 
 train loss: 0.153591, val loss: 0.218274 
 val auc: 0.968694,  test auc: 0.971406
epoch 212, loss: 0.152845
epoch 212, 
 train loss: 0.152845, val loss: 0.218851 
 val auc: 0.968131,  test auc: 0.971181
epoch 213, loss: 0.152119
model updated at epoch 213 
epoch 213, 
 train loss: 0.152119, val loss: 0.217401 
 val auc: 0.968619,  test auc: 0.971425
epoch 214, loss: 0.151545
model updated at epoch 214 
epoch 214, 
 train loss: 0.151545, val loss: 0.216843 
 val auc: 0.968844,  test auc: 0.971556
epoch 215, loss: 0.151074
model updated at epoch 215 
epoch 215, 
 train loss: 0.151074, val loss: 0.216662 
 val auc: 0.968806,  test auc: 0.971640
epoch 216, loss: 0.150640
model updated at epoch 216 
epoch 216, 
 train loss: 0.150640, val loss: 0.215178 
 val auc: 0.969257,  test auc: 0.971950
epoch 217, loss: 0.150255
epoch 217, 
 train loss: 0.150255, val loss: 0.216009 
 val auc: 0.968731,  test auc: 0.971819
epoch 218, loss: 0.149795
model updated at epoch 218 
epoch 218, 
 train loss: 0.149795, val loss: 0.214070 
 val auc: 0.969332,  test auc: 0.972119
epoch 219, loss: 0.149371
epoch 219, 
 train loss: 0.149371, val loss: 0.215401 
 val auc: 0.968844,  test auc: 0.971809
epoch 220, loss: 0.148717
model updated at epoch 220 
epoch 220, 
 train loss: 0.148717, val loss: 0.213353 
 val auc: 0.969632,  test auc: 0.972335
epoch 221, loss: 0.148094
epoch 221, 
 train loss: 0.148094, val loss: 0.214171 
 val auc: 0.969219,  test auc: 0.972091
epoch 222, loss: 0.147411
model updated at epoch 222 
epoch 222, 
 train loss: 0.147411, val loss: 0.212419 
 val auc: 0.969745,  test auc: 0.972447
epoch 223, loss: 0.146818
model updated at epoch 223 
epoch 223, 
 train loss: 0.146818, val loss: 0.212390 
 val auc: 0.969444,  test auc: 0.972325
epoch 224, loss: 0.146265
model updated at epoch 224 
epoch 224, 
 train loss: 0.146265, val loss: 0.211346 
 val auc: 0.969932,  test auc: 0.972645
epoch 225, loss: 0.145744
model updated at epoch 225 
epoch 225, 
 train loss: 0.145744, val loss: 0.210801 
 val auc: 0.969970,  test auc: 0.972701
epoch 226, loss: 0.145248
model updated at epoch 226 
epoch 226, 
 train loss: 0.145248, val loss: 0.210342 
 val auc: 0.969895,  test auc: 0.972673
epoch 227, loss: 0.144847
model updated at epoch 227 
epoch 227, 
 train loss: 0.144847, val loss: 0.209454 
 val auc: 0.970233,  test auc: 0.972823
epoch 228, loss: 0.145109
epoch 228, 
 train loss: 0.145109, val loss: 0.210880 
 val auc: 0.969707,  test auc: 0.972598
epoch 229, loss: 0.148083
epoch 229, 
 train loss: 0.148083, val loss: 0.210431 
 val auc: 0.971284,  test auc: 0.973292
epoch 230, loss: 0.157168
epoch 230, 
 train loss: 0.157168, val loss: 0.226076 
 val auc: 0.967417,  test auc: 0.970974
epoch 231, loss: 0.143143
model updated at epoch 231 
epoch 231, 
 train loss: 0.143143, val loss: 0.207591 
 val auc: 0.970758,  test auc: 0.973123
epoch 232, loss: 0.153981
epoch 232, 
 train loss: 0.153981, val loss: 0.213832 
 val auc: 0.972035,  test auc: 0.973498
epoch 233, loss: 0.157216
epoch 233, 
 train loss: 0.157216, val loss: 0.225353 
 val auc: 0.967680,  test auc: 0.971171
epoch 234, loss: 0.150398
epoch 234, 
 train loss: 0.150398, val loss: 0.216875 
 val auc: 0.968806,  test auc: 0.972053
epoch 235, loss: 0.157369
epoch 235, 
 train loss: 0.157369, val loss: 0.215474 
 val auc: 0.972673,  test auc: 0.973771
epoch 236, loss: 0.141577
model updated at epoch 236 
epoch 236, 
 train loss: 0.141577, val loss: 0.204720 
 val auc: 0.971547,  test auc: 0.973724
epoch 237, loss: 0.151388
epoch 237, 
 train loss: 0.151388, val loss: 0.217577 
 val auc: 0.968806,  test auc: 0.972035
epoch 238, loss: 0.142726
epoch 238, 
 train loss: 0.142726, val loss: 0.207043 
 val auc: 0.970646,  test auc: 0.973189
epoch 239, loss: 0.150230
epoch 239, 
 train loss: 0.150230, val loss: 0.209950 
 val auc: 0.972748,  test auc: 0.974108
epoch 240, loss: 0.140509
model updated at epoch 240 
epoch 240, 
 train loss: 0.140509, val loss: 0.202974 
 val auc: 0.972072,  test auc: 0.974080
epoch 241, loss: 0.146438
epoch 241, 
 train loss: 0.146438, val loss: 0.211366 
 val auc: 0.970233,  test auc: 0.972889
epoch 242, loss: 0.141543
epoch 242, 
 train loss: 0.141543, val loss: 0.205343 
 val auc: 0.970983,  test auc: 0.973489
epoch 243, loss: 0.143636
epoch 243, 
 train loss: 0.143636, val loss: 0.204313 
 val auc: 0.973086,  test auc: 0.974437
epoch 244, loss: 0.140283
model updated at epoch 244 
epoch 244, 
 train loss: 0.140283, val loss: 0.201997 
 val auc: 0.972410,  test auc: 0.974343
epoch 245, loss: 0.141439
epoch 245, 
 train loss: 0.141439, val loss: 0.205706 
 val auc: 0.970758,  test auc: 0.973452
epoch 246, loss: 0.140487
epoch 246, 
 train loss: 0.140487, val loss: 0.204753 
 val auc: 0.971096,  test auc: 0.973574
epoch 247, loss: 0.138940
model updated at epoch 247 
epoch 247, 
 train loss: 0.138940, val loss: 0.201179 
 val auc: 0.972485,  test auc: 0.974465
epoch 248, loss: 0.139497
epoch 248, 
 train loss: 0.139497, val loss: 0.201599 
 val auc: 0.972710,  test auc: 0.974634
epoch 249, loss: 0.137944
epoch 249, 
 train loss: 0.137944, val loss: 0.202332 
 val auc: 0.971134,  test auc: 0.974015
epoch 250, loss: 0.138728
epoch 250, 
 train loss: 0.138728, val loss: 0.203476 
 val auc: 0.971209,  test auc: 0.973930
epoch 251, loss: 0.136410
model updated at epoch 251 
epoch 251, 
 train loss: 0.136410, val loss: 0.199286 
 val auc: 0.972785,  test auc: 0.974887
epoch 252, loss: 0.137782
epoch 252, 
 train loss: 0.137782, val loss: 0.199925 
 val auc: 0.973086,  test auc: 0.975009
epoch 253, loss: 0.135634
epoch 253, 
 train loss: 0.135634, val loss: 0.199493 
 val auc: 0.971959,  test auc: 0.974493
epoch 254, loss: 0.136703
epoch 254, 
 train loss: 0.136703, val loss: 0.201232 
 val auc: 0.971697,  test auc: 0.974184
epoch 255, loss: 0.134618
model updated at epoch 255 
epoch 255, 
 train loss: 0.134618, val loss: 0.198151 
 val auc: 0.972785,  test auc: 0.974887
epoch 256, loss: 0.135802
epoch 256, 
 train loss: 0.135802, val loss: 0.198716 
 val auc: 0.973423,  test auc: 0.975225
epoch 257, loss: 0.133896
model updated at epoch 257 
epoch 257, 
 train loss: 0.133896, val loss: 0.197779 
 val auc: 0.972523,  test auc: 0.974775
epoch 258, loss: 0.134726
epoch 258, 
 train loss: 0.134726, val loss: 0.199033 
 val auc: 0.972260,  test auc: 0.974512
epoch 259, loss: 0.133095
model updated at epoch 259 
epoch 259, 
 train loss: 0.133095, val loss: 0.196346 
 val auc: 0.972973,  test auc: 0.975094
epoch 260, loss: 0.133850
model updated at epoch 260 
epoch 260, 
 train loss: 0.133850, val loss: 0.196127 
 val auc: 0.973461,  test auc: 0.975488
epoch 261, loss: 0.132382
model updated at epoch 261 
epoch 261, 
 train loss: 0.132382, val loss: 0.195318 
 val auc: 0.973086,  test auc: 0.975263
epoch 262, loss: 0.132888
epoch 262, 
 train loss: 0.132888, val loss: 0.196300 
 val auc: 0.972485,  test auc: 0.974831
epoch 263, loss: 0.131660
model updated at epoch 263 
epoch 263, 
 train loss: 0.131660, val loss: 0.194273 
 val auc: 0.973198,  test auc: 0.975375
epoch 264, loss: 0.132078
model updated at epoch 264 
epoch 264, 
 train loss: 0.132078, val loss: 0.194031 
 val auc: 0.973799,  test auc: 0.975807
epoch 265, loss: 0.130970
model updated at epoch 265 
epoch 265, 
 train loss: 0.130970, val loss: 0.193547 
 val auc: 0.973311,  test auc: 0.975460
epoch 266, loss: 0.131205
epoch 266, 
 train loss: 0.131205, val loss: 0.194201 
 val auc: 0.972748,  test auc: 0.975084
epoch 267, loss: 0.130283
model updated at epoch 267 
epoch 267, 
 train loss: 0.130283, val loss: 0.192732 
 val auc: 0.973386,  test auc: 0.975648
epoch 268, loss: 0.130436
model updated at epoch 268 
epoch 268, 
 train loss: 0.130436, val loss: 0.192451 
 val auc: 0.974062,  test auc: 0.976107
epoch 269, loss: 0.129613
model updated at epoch 269 
epoch 269, 
 train loss: 0.129613, val loss: 0.192189 
 val auc: 0.973423,  test auc: 0.975741
epoch 270, loss: 0.129641
epoch 270, 
 train loss: 0.129641, val loss: 0.192561 
 val auc: 0.972973,  test auc: 0.975507
epoch 271, loss: 0.128937
model updated at epoch 271 
epoch 271, 
 train loss: 0.128937, val loss: 0.191375 
 val auc: 0.973874,  test auc: 0.976042
epoch 272, loss: 0.128904
model updated at epoch 272 
epoch 272, 
 train loss: 0.128904, val loss: 0.191048 
 val auc: 0.974324,  test auc: 0.976333
epoch 273, loss: 0.128296
model updated at epoch 273 
epoch 273, 
 train loss: 0.128296, val loss: 0.190877 
 val auc: 0.973761,  test auc: 0.975995
epoch 274, loss: 0.128165
model updated at epoch 274 
epoch 274, 
 train loss: 0.128165, val loss: 0.190852 
 val auc: 0.973911,  test auc: 0.975892
epoch 275, loss: 0.127633
model updated at epoch 275 
epoch 275, 
 train loss: 0.127633, val loss: 0.189783 
 val auc: 0.974399,  test auc: 0.976380
epoch 276, loss: 0.127438
model updated at epoch 276 
epoch 276, 
 train loss: 0.127438, val loss: 0.189360 
 val auc: 0.974662,  test auc: 0.976595
epoch 277, loss: 0.126996
model updated at epoch 277 
epoch 277, 
 train loss: 0.126996, val loss: 0.189331 
 val auc: 0.974174,  test auc: 0.976304
epoch 278, loss: 0.126729
model updated at epoch 278 
epoch 278, 
 train loss: 0.126729, val loss: 0.189180 
 val auc: 0.974137,  test auc: 0.976286
epoch 279, loss: 0.126354
model updated at epoch 279 
epoch 279, 
 train loss: 0.126354, val loss: 0.188496 
 val auc: 0.974625,  test auc: 0.976830
epoch 280, loss: 0.126032
model updated at epoch 280 
epoch 280, 
 train loss: 0.126032, val loss: 0.188114 
 val auc: 0.974850,  test auc: 0.976980
epoch 281, loss: 0.125704
model updated at epoch 281 
epoch 281, 
 train loss: 0.125704, val loss: 0.187933 
 val auc: 0.974587,  test auc: 0.976717
epoch 282, loss: 0.125343
model updated at epoch 282 
epoch 282, 
 train loss: 0.125343, val loss: 0.187358 
 val auc: 0.974887,  test auc: 0.976877
epoch 283, loss: 0.125061
model updated at epoch 283 
epoch 283, 
 train loss: 0.125061, val loss: 0.186669 
 val auc: 0.975713,  test auc: 0.977327
epoch 284, loss: 0.124670
model updated at epoch 284 
epoch 284, 
 train loss: 0.124670, val loss: 0.186328 
 val auc: 0.975563,  test auc: 0.977280
epoch 285, loss: 0.124413
epoch 285, 
 train loss: 0.124413, val loss: 0.186339 
 val auc: 0.975300,  test auc: 0.977074
epoch 286, loss: 0.124013
model updated at epoch 286 
epoch 286, 
 train loss: 0.124013, val loss: 0.185909 
 val auc: 0.975638,  test auc: 0.977365
epoch 287, loss: 0.123768
model updated at epoch 287 
epoch 287, 
 train loss: 0.123768, val loss: 0.185572 
 val auc: 0.976089,  test auc: 0.977609
epoch 288, loss: 0.123388
model updated at epoch 288 
epoch 288, 
 train loss: 0.123388, val loss: 0.185384 
 val auc: 0.975788,  test auc: 0.977449
epoch 289, loss: 0.123128
model updated at epoch 289 
epoch 289, 
 train loss: 0.123128, val loss: 0.185245 
 val auc: 0.975863,  test auc: 0.977449
epoch 290, loss: 0.122769
model updated at epoch 290 
epoch 290, 
 train loss: 0.122769, val loss: 0.184769 
 val auc: 0.976126,  test auc: 0.977675
epoch 291, loss: 0.122498
model updated at epoch 291 
epoch 291, 
 train loss: 0.122498, val loss: 0.184436 
 val auc: 0.976276,  test auc: 0.977853
epoch 292, loss: 0.122172
model updated at epoch 292 
epoch 292, 
 train loss: 0.122172, val loss: 0.184215 
 val auc: 0.976051,  test auc: 0.977665
epoch 293, loss: 0.121879
model updated at epoch 293 
epoch 293, 
 train loss: 0.121879, val loss: 0.183925 
 val auc: 0.976201,  test auc: 0.977740
epoch 294, loss: 0.121575
model updated at epoch 294 
epoch 294, 
 train loss: 0.121575, val loss: 0.183521 
 val auc: 0.976464,  test auc: 0.977965
epoch 295, loss: 0.121262
model updated at epoch 295 
epoch 295, 
 train loss: 0.121262, val loss: 0.183288 
 val auc: 0.976314,  test auc: 0.977947
epoch 296, loss: 0.120974
model updated at epoch 296 
epoch 296, 
 train loss: 0.120974, val loss: 0.183192 
 val auc: 0.976351,  test auc: 0.977843
epoch 297, loss: 0.120655
model updated at epoch 297 
epoch 297, 
 train loss: 0.120655, val loss: 0.182870 
 val auc: 0.976426,  test auc: 0.977975
epoch 298, loss: 0.120378
model updated at epoch 298 
epoch 298, 
 train loss: 0.120378, val loss: 0.182511 
 val auc: 0.976689,  test auc: 0.978125
epoch 299, loss: 0.120067
model updated at epoch 299 
epoch 299, 
 train loss: 0.120067, val loss: 0.182225 
 val auc: 0.976652,  test auc: 0.978087
epoch 300, loss: 0.119782
model updated at epoch 300 
epoch 300, 
 train loss: 0.119782, val loss: 0.181947 
 val auc: 0.976652,  test auc: 0.978106
epoch 301, loss: 0.119477
model updated at epoch 301 
epoch 301, 
 train loss: 0.119477, val loss: 0.181558 
 val auc: 0.976877,  test auc: 0.978238
epoch 302, loss: 0.119192
model updated at epoch 302 
epoch 302, 
 train loss: 0.119192, val loss: 0.181248 
 val auc: 0.977140,  test auc: 0.978369
epoch 303, loss: 0.118901
model updated at epoch 303 
epoch 303, 
 train loss: 0.118901, val loss: 0.181016 
 val auc: 0.977027,  test auc: 0.978331
epoch 304, loss: 0.118608
model updated at epoch 304 
epoch 304, 
 train loss: 0.118608, val loss: 0.180737 
 val auc: 0.977065,  test auc: 0.978369
epoch 305, loss: 0.118325
model updated at epoch 305 
epoch 305, 
 train loss: 0.118325, val loss: 0.180453 
 val auc: 0.977252,  test auc: 0.978453
epoch 306, loss: 0.118035
model updated at epoch 306 
epoch 306, 
 train loss: 0.118035, val loss: 0.180248 
 val auc: 0.977140,  test auc: 0.978482
epoch 307, loss: 0.117756
model updated at epoch 307 
epoch 307, 
 train loss: 0.117756, val loss: 0.180090 
 val auc: 0.977140,  test auc: 0.978500
epoch 308, loss: 0.117466
model updated at epoch 308 
epoch 308, 
 train loss: 0.117466, val loss: 0.179846 
 val auc: 0.977215,  test auc: 0.978604
epoch 309, loss: 0.117184
model updated at epoch 309 
epoch 309, 
 train loss: 0.117184, val loss: 0.179583 
 val auc: 0.977327,  test auc: 0.978669
epoch 310, loss: 0.116898
model updated at epoch 310 
epoch 310, 
 train loss: 0.116898, val loss: 0.179361 
 val auc: 0.977327,  test auc: 0.978632
epoch 311, loss: 0.116619
model updated at epoch 311 
epoch 311, 
 train loss: 0.116619, val loss: 0.179136 
 val auc: 0.977327,  test auc: 0.978669
epoch 312, loss: 0.116343
model updated at epoch 312 
epoch 312, 
 train loss: 0.116343, val loss: 0.178913 
 val auc: 0.977515,  test auc: 0.978810
epoch 313, loss: 0.116061
model updated at epoch 313 
epoch 313, 
 train loss: 0.116061, val loss: 0.178712 
 val auc: 0.977477,  test auc: 0.978763
epoch 314, loss: 0.115781
model updated at epoch 314 
epoch 314, 
 train loss: 0.115781, val loss: 0.178455 
 val auc: 0.977496,  test auc: 0.978749
epoch 315, loss: 0.115502
model updated at epoch 315 
epoch 315, 
 train loss: 0.115502, val loss: 0.178194 
 val auc: 0.977590,  test auc: 0.978848
epoch 316, loss: 0.115224
model updated at epoch 316 
epoch 316, 
 train loss: 0.115224, val loss: 0.177956 
 val auc: 0.977628,  test auc: 0.978885
epoch 317, loss: 0.114947
model updated at epoch 317 
epoch 317, 
 train loss: 0.114947, val loss: 0.177744 
 val auc: 0.977665,  test auc: 0.978904
epoch 318, loss: 0.114664
model updated at epoch 318 
epoch 318, 
 train loss: 0.114664, val loss: 0.177535 
 val auc: 0.977778,  test auc: 0.978998
epoch 319, loss: 0.114390
model updated at epoch 319 
epoch 319, 
 train loss: 0.114390, val loss: 0.177403 
 val auc: 0.977815,  test auc: 0.979017
epoch 320, loss: 0.114110
model updated at epoch 320 
epoch 320, 
 train loss: 0.114110, val loss: 0.177293 
 val auc: 0.977778,  test auc: 0.979045
epoch 321, loss: 0.113843
model updated at epoch 321 
epoch 321, 
 train loss: 0.113843, val loss: 0.177136 
 val auc: 0.977890,  test auc: 0.979110
epoch 322, loss: 0.113570
model updated at epoch 322 
epoch 322, 
 train loss: 0.113570, val loss: 0.176875 
 val auc: 0.977928,  test auc: 0.979120
epoch 323, loss: 0.113289
model updated at epoch 323 
epoch 323, 
 train loss: 0.113289, val loss: 0.176540 
 val auc: 0.978003,  test auc: 0.979185
epoch 324, loss: 0.113032
model updated at epoch 324 
epoch 324, 
 train loss: 0.113032, val loss: 0.176283 
 val auc: 0.978116,  test auc: 0.979261
epoch 325, loss: 0.112755
model updated at epoch 325 
epoch 325, 
 train loss: 0.112755, val loss: 0.176115 
 val auc: 0.978078,  test auc: 0.979298
epoch 326, loss: 0.112493
model updated at epoch 326 
epoch 326, 
 train loss: 0.112493, val loss: 0.175967 
 val auc: 0.978116,  test auc: 0.979364
epoch 327, loss: 0.112233
model updated at epoch 327 
epoch 327, 
 train loss: 0.112233, val loss: 0.175713 
 val auc: 0.978266,  test auc: 0.979420
epoch 328, loss: 0.111961
model updated at epoch 328 
epoch 328, 
 train loss: 0.111961, val loss: 0.175417 
 val auc: 0.978341,  test auc: 0.979486
epoch 329, loss: 0.111685
model updated at epoch 329 
epoch 329, 
 train loss: 0.111685, val loss: 0.175112 
 val auc: 0.978453,  test auc: 0.979542
epoch 330, loss: 0.111424
model updated at epoch 330 
epoch 330, 
 train loss: 0.111424, val loss: 0.174835 
 val auc: 0.978641,  test auc: 0.979598
epoch 331, loss: 0.111152
model updated at epoch 331 
epoch 331, 
 train loss: 0.111152, val loss: 0.174607 
 val auc: 0.978754,  test auc: 0.979645
epoch 332, loss: 0.110885
model updated at epoch 332 
epoch 332, 
 train loss: 0.110885, val loss: 0.174375 
 val auc: 0.978791,  test auc: 0.979655
epoch 333, loss: 0.110625
model updated at epoch 333 
epoch 333, 
 train loss: 0.110625, val loss: 0.174107 
 val auc: 0.978754,  test auc: 0.979758
epoch 334, loss: 0.110361
model updated at epoch 334 
epoch 334, 
 train loss: 0.110361, val loss: 0.173831 
 val auc: 0.978829,  test auc: 0.979795
epoch 335, loss: 0.110104
model updated at epoch 335 
epoch 335, 
 train loss: 0.110104, val loss: 0.173590 
 val auc: 0.978904,  test auc: 0.979824
epoch 336, loss: 0.109849
model updated at epoch 336 
epoch 336, 
 train loss: 0.109849, val loss: 0.173393 
 val auc: 0.979017,  test auc: 0.979927
epoch 337, loss: 0.109588
model updated at epoch 337 
epoch 337, 
 train loss: 0.109588, val loss: 0.173156 
 val auc: 0.979054,  test auc: 0.979955
epoch 338, loss: 0.109329
model updated at epoch 338 
epoch 338, 
 train loss: 0.109329, val loss: 0.172979 
 val auc: 0.979054,  test auc: 0.979974
epoch 339, loss: 0.109076
model updated at epoch 339 
epoch 339, 
 train loss: 0.109076, val loss: 0.172750 
 val auc: 0.979242,  test auc: 0.980105
epoch 340, loss: 0.108821
model updated at epoch 340 
epoch 340, 
 train loss: 0.108821, val loss: 0.172539 
 val auc: 0.979317,  test auc: 0.980133
epoch 341, loss: 0.108561
model updated at epoch 341 
epoch 341, 
 train loss: 0.108561, val loss: 0.172326 
 val auc: 0.979467,  test auc: 0.980180
epoch 342, loss: 0.108309
model updated at epoch 342 
epoch 342, 
 train loss: 0.108309, val loss: 0.172153 
 val auc: 0.979692,  test auc: 0.980312
epoch 343, loss: 0.108056
model updated at epoch 343 
epoch 343, 
 train loss: 0.108056, val loss: 0.171940 
 val auc: 0.979767,  test auc: 0.980377
epoch 344, loss: 0.107797
model updated at epoch 344 
epoch 344, 
 train loss: 0.107797, val loss: 0.171674 
 val auc: 0.979992,  test auc: 0.980499
epoch 345, loss: 0.107545
model updated at epoch 345 
epoch 345, 
 train loss: 0.107545, val loss: 0.171475 
 val auc: 0.979992,  test auc: 0.980565
epoch 346, loss: 0.107291
model updated at epoch 346 
epoch 346, 
 train loss: 0.107291, val loss: 0.171259 
 val auc: 0.980030,  test auc: 0.980584
epoch 347, loss: 0.107039
model updated at epoch 347 
epoch 347, 
 train loss: 0.107039, val loss: 0.171042 
 val auc: 0.980180,  test auc: 0.980659
epoch 348, loss: 0.106788
model updated at epoch 348 
epoch 348, 
 train loss: 0.106788, val loss: 0.170810 
 val auc: 0.980218,  test auc: 0.980687
epoch 349, loss: 0.106533
model updated at epoch 349 
epoch 349, 
 train loss: 0.106533, val loss: 0.170594 
 val auc: 0.980293,  test auc: 0.980724
epoch 350, loss: 0.106281
model updated at epoch 350 
epoch 350, 
 train loss: 0.106281, val loss: 0.170427 
 val auc: 0.980405,  test auc: 0.980800
epoch 351, loss: 0.106030
model updated at epoch 351 
epoch 351, 
 train loss: 0.106030, val loss: 0.170267 
 val auc: 0.980443,  test auc: 0.980865
epoch 352, loss: 0.105778
model updated at epoch 352 
epoch 352, 
 train loss: 0.105778, val loss: 0.170065 
 val auc: 0.980593,  test auc: 0.980931
epoch 353, loss: 0.105529
model updated at epoch 353 
epoch 353, 
 train loss: 0.105529, val loss: 0.169804 
 val auc: 0.980668,  test auc: 0.980959
epoch 354, loss: 0.105278
model updated at epoch 354 
epoch 354, 
 train loss: 0.105278, val loss: 0.169572 
 val auc: 0.980781,  test auc: 0.981006
epoch 355, loss: 0.105028
model updated at epoch 355 
epoch 355, 
 train loss: 0.105028, val loss: 0.169393 
 val auc: 0.980856,  test auc: 0.981100
epoch 356, loss: 0.104775
model updated at epoch 356 
epoch 356, 
 train loss: 0.104775, val loss: 0.169153 
 val auc: 0.980893,  test auc: 0.981119
epoch 357, loss: 0.104525
model updated at epoch 357 
epoch 357, 
 train loss: 0.104525, val loss: 0.168882 
 val auc: 0.980931,  test auc: 0.981175
epoch 358, loss: 0.104277
model updated at epoch 358 
epoch 358, 
 train loss: 0.104277, val loss: 0.168642 
 val auc: 0.980968,  test auc: 0.981222
epoch 359, loss: 0.104027
model updated at epoch 359 
epoch 359, 
 train loss: 0.104027, val loss: 0.168425 
 val auc: 0.981006,  test auc: 0.981269
epoch 360, loss: 0.103777
model updated at epoch 360 
epoch 360, 
 train loss: 0.103777, val loss: 0.168196 
 val auc: 0.981006,  test auc: 0.981344
epoch 361, loss: 0.103525
model updated at epoch 361 
epoch 361, 
 train loss: 0.103525, val loss: 0.167947 
 val auc: 0.981044,  test auc: 0.981400
epoch 362, loss: 0.103278
model updated at epoch 362 
epoch 362, 
 train loss: 0.103278, val loss: 0.167826 
 val auc: 0.981081,  test auc: 0.981419
epoch 363, loss: 0.103031
model updated at epoch 363 
epoch 363, 
 train loss: 0.103031, val loss: 0.167712 
 val auc: 0.981119,  test auc: 0.981503
epoch 364, loss: 0.102780
model updated at epoch 364 
epoch 364, 
 train loss: 0.102780, val loss: 0.167453 
 val auc: 0.981194,  test auc: 0.981532
epoch 365, loss: 0.102530
model updated at epoch 365 
epoch 365, 
 train loss: 0.102530, val loss: 0.167126 
 val auc: 0.981306,  test auc: 0.981616
epoch 366, loss: 0.102283
model updated at epoch 366 
epoch 366, 
 train loss: 0.102283, val loss: 0.166890 
 val auc: 0.981344,  test auc: 0.981672
epoch 367, loss: 0.102032
model updated at epoch 367 
epoch 367, 
 train loss: 0.102032, val loss: 0.166626 
 val auc: 0.981419,  test auc: 0.981719
epoch 368, loss: 0.101783
model updated at epoch 368 
epoch 368, 
 train loss: 0.101783, val loss: 0.166322 
 val auc: 0.981419,  test auc: 0.981738
epoch 369, loss: 0.101536
model updated at epoch 369 
epoch 369, 
 train loss: 0.101536, val loss: 0.166037 
 val auc: 0.981532,  test auc: 0.981822
epoch 370, loss: 0.101288
model updated at epoch 370 
epoch 370, 
 train loss: 0.101288, val loss: 0.165725 
 val auc: 0.981569,  test auc: 0.981851
epoch 371, loss: 0.101039
model updated at epoch 371 
epoch 371, 
 train loss: 0.101039, val loss: 0.165442 
 val auc: 0.981682,  test auc: 0.981926
epoch 372, loss: 0.100789
model updated at epoch 372 
epoch 372, 
 train loss: 0.100789, val loss: 0.165219 
 val auc: 0.981719,  test auc: 0.982001
epoch 373, loss: 0.100536
model updated at epoch 373 
epoch 373, 
 train loss: 0.100536, val loss: 0.165057 
 val auc: 0.981757,  test auc: 0.982066
epoch 374, loss: 0.100293
model updated at epoch 374 
epoch 374, 
 train loss: 0.100293, val loss: 0.164872 
 val auc: 0.981869,  test auc: 0.982132
epoch 375, loss: 0.100039
model updated at epoch 375 
epoch 375, 
 train loss: 0.100039, val loss: 0.164589 
 val auc: 0.981944,  test auc: 0.982151
epoch 376, loss: 0.099794
model updated at epoch 376 
epoch 376, 
 train loss: 0.099794, val loss: 0.164277 
 val auc: 0.981982,  test auc: 0.982207
epoch 377, loss: 0.099549
model updated at epoch 377 
epoch 377, 
 train loss: 0.099549, val loss: 0.164044 
 val auc: 0.982020,  test auc: 0.982235
epoch 378, loss: 0.099298
model updated at epoch 378 
epoch 378, 
 train loss: 0.099298, val loss: 0.163803 
 val auc: 0.982095,  test auc: 0.982292
epoch 379, loss: 0.099042
model updated at epoch 379 
epoch 379, 
 train loss: 0.099042, val loss: 0.163612 
 val auc: 0.982245,  test auc: 0.982367
epoch 380, loss: 0.098791
model updated at epoch 380 
epoch 380, 
 train loss: 0.098791, val loss: 0.163475 
 val auc: 0.982320,  test auc: 0.982404
epoch 381, loss: 0.098550
model updated at epoch 381 
epoch 381, 
 train loss: 0.098550, val loss: 0.163297 
 val auc: 0.982320,  test auc: 0.982470
epoch 382, loss: 0.098296
model updated at epoch 382 
epoch 382, 
 train loss: 0.098296, val loss: 0.162996 
 val auc: 0.982357,  test auc: 0.982517
epoch 383, loss: 0.098042
model updated at epoch 383 
epoch 383, 
 train loss: 0.098042, val loss: 0.162704 
 val auc: 0.982395,  test auc: 0.982583
epoch 384, loss: 0.097794
model updated at epoch 384 
epoch 384, 
 train loss: 0.097794, val loss: 0.162440 
 val auc: 0.982395,  test auc: 0.982611
epoch 385, loss: 0.097545
model updated at epoch 385 
epoch 385, 
 train loss: 0.097545, val loss: 0.162157 
 val auc: 0.982545,  test auc: 0.982714
epoch 386, loss: 0.097293
model updated at epoch 386 
epoch 386, 
 train loss: 0.097293, val loss: 0.161896 
 val auc: 0.982545,  test auc: 0.982789
epoch 387, loss: 0.097039
model updated at epoch 387 
epoch 387, 
 train loss: 0.097039, val loss: 0.161695 
 val auc: 0.982583,  test auc: 0.982827
epoch 388, loss: 0.096784
model updated at epoch 388 
epoch 388, 
 train loss: 0.096784, val loss: 0.161494 
 val auc: 0.982658,  test auc: 0.982883
epoch 389, loss: 0.096529
model updated at epoch 389 
epoch 389, 
 train loss: 0.096529, val loss: 0.161246 
 val auc: 0.982620,  test auc: 0.982883
epoch 390, loss: 0.096288
model updated at epoch 390 
epoch 390, 
 train loss: 0.096288, val loss: 0.160937 
 val auc: 0.982770,  test auc: 0.982958
epoch 391, loss: 0.096028
model updated at epoch 391 
epoch 391, 
 train loss: 0.096028, val loss: 0.160631 
 val auc: 0.982958,  test auc: 0.983052
epoch 392, loss: 0.095764
model updated at epoch 392 
epoch 392, 
 train loss: 0.095764, val loss: 0.160385 
 val auc: 0.982995,  test auc: 0.983155
epoch 393, loss: 0.095513
model updated at epoch 393 
epoch 393, 
 train loss: 0.095513, val loss: 0.160127 
 val auc: 0.983071,  test auc: 0.983174
epoch 394, loss: 0.095259
model updated at epoch 394 
epoch 394, 
 train loss: 0.095259, val loss: 0.159798 
 val auc: 0.983146,  test auc: 0.983211
epoch 395, loss: 0.094999
model updated at epoch 395 
epoch 395, 
 train loss: 0.094999, val loss: 0.159521 
 val auc: 0.983183,  test auc: 0.983230
epoch 396, loss: 0.094734
model updated at epoch 396 
epoch 396, 
 train loss: 0.094734, val loss: 0.159228 
 val auc: 0.983221,  test auc: 0.983286
epoch 397, loss: 0.094476
model updated at epoch 397 
epoch 397, 
 train loss: 0.094476, val loss: 0.158866 
 val auc: 0.983371,  test auc: 0.983333
epoch 398, loss: 0.094216
model updated at epoch 398 
epoch 398, 
 train loss: 0.094216, val loss: 0.158596 
 val auc: 0.983446,  test auc: 0.983352
epoch 399, loss: 0.093951
model updated at epoch 399 
epoch 399, 
 train loss: 0.093951, val loss: 0.158339 
 val auc: 0.983483,  test auc: 0.983399
epoch 400, loss: 0.093685
model updated at epoch 400 
epoch 400, 
 train loss: 0.093685, val loss: 0.158054 
 val auc: 0.983483,  test auc: 0.983408
epoch 401, loss: 0.093419
model updated at epoch 401 
epoch 401, 
 train loss: 0.093419, val loss: 0.157809 
 val auc: 0.983483,  test auc: 0.983455
epoch 402, loss: 0.093145
model updated at epoch 402 
epoch 402, 
 train loss: 0.093145, val loss: 0.157434 
 val auc: 0.983559,  test auc: 0.983512
epoch 403, loss: 0.092877
model updated at epoch 403 
epoch 403, 
 train loss: 0.092877, val loss: 0.157132 
 val auc: 0.983596,  test auc: 0.983624
epoch 404, loss: 0.092605
model updated at epoch 404 
epoch 404, 
 train loss: 0.092605, val loss: 0.156757 
 val auc: 0.983596,  test auc: 0.983624
epoch 405, loss: 0.092331
model updated at epoch 405 
epoch 405, 
 train loss: 0.092331, val loss: 0.156360 
 val auc: 0.983709,  test auc: 0.983681
epoch 406, loss: 0.092057
model updated at epoch 406 
epoch 406, 
 train loss: 0.092057, val loss: 0.155994 
 val auc: 0.983746,  test auc: 0.983727
epoch 407, loss: 0.091785
model updated at epoch 407 
epoch 407, 
 train loss: 0.091785, val loss: 0.155602 
 val auc: 0.983784,  test auc: 0.983793
epoch 408, loss: 0.091509
model updated at epoch 408 
epoch 408, 
 train loss: 0.091509, val loss: 0.155200 
 val auc: 0.983821,  test auc: 0.983859
epoch 409, loss: 0.091240
model updated at epoch 409 
epoch 409, 
 train loss: 0.091240, val loss: 0.154834 
 val auc: 0.983859,  test auc: 0.983887
epoch 410, loss: 0.090963
model updated at epoch 410 
epoch 410, 
 train loss: 0.090963, val loss: 0.154602 
 val auc: 0.983971,  test auc: 0.983953
epoch 411, loss: 0.090684
model updated at epoch 411 
epoch 411, 
 train loss: 0.090684, val loss: 0.154398 
 val auc: 0.983934,  test auc: 0.983971
epoch 412, loss: 0.090393
model updated at epoch 412 
epoch 412, 
 train loss: 0.090393, val loss: 0.154028 
 val auc: 0.983971,  test auc: 0.983990
epoch 413, loss: 0.090096
model updated at epoch 413 
epoch 413, 
 train loss: 0.090096, val loss: 0.153630 
 val auc: 0.984084,  test auc: 0.984093
epoch 414, loss: 0.089799
model updated at epoch 414 
epoch 414, 
 train loss: 0.089799, val loss: 0.153254 
 val auc: 0.984122,  test auc: 0.984169
epoch 415, loss: 0.089503
model updated at epoch 415 
epoch 415, 
 train loss: 0.089503, val loss: 0.152923 
 val auc: 0.984159,  test auc: 0.984187
epoch 416, loss: 0.089203
model updated at epoch 416 
epoch 416, 
 train loss: 0.089203, val loss: 0.152492 
 val auc: 0.984234,  test auc: 0.984244
epoch 417, loss: 0.088907
model updated at epoch 417 
epoch 417, 
 train loss: 0.088907, val loss: 0.152070 
 val auc: 0.984272,  test auc: 0.984337
epoch 418, loss: 0.088616
model updated at epoch 418 
epoch 418, 
 train loss: 0.088616, val loss: 0.151639 
 val auc: 0.984459,  test auc: 0.984403
epoch 419, loss: 0.088319
model updated at epoch 419 
epoch 419, 
 train loss: 0.088319, val loss: 0.151306 
 val auc: 0.984572,  test auc: 0.984459
epoch 420, loss: 0.088026
model updated at epoch 420 
epoch 420, 
 train loss: 0.088026, val loss: 0.150907 
 val auc: 0.984535,  test auc: 0.984497
epoch 421, loss: 0.087731
model updated at epoch 421 
epoch 421, 
 train loss: 0.087731, val loss: 0.150531 
 val auc: 0.984572,  test auc: 0.984544
epoch 422, loss: 0.087433
model updated at epoch 422 
epoch 422, 
 train loss: 0.087433, val loss: 0.150162 
 val auc: 0.984685,  test auc: 0.984619
epoch 423, loss: 0.087137
model updated at epoch 423 
epoch 423, 
 train loss: 0.087137, val loss: 0.149713 
 val auc: 0.984760,  test auc: 0.984675
epoch 424, loss: 0.086848
model updated at epoch 424 
epoch 424, 
 train loss: 0.086848, val loss: 0.149284 
 val auc: 0.984835,  test auc: 0.984732
epoch 425, loss: 0.086553
model updated at epoch 425 
epoch 425, 
 train loss: 0.086553, val loss: 0.148819 
 val auc: 0.984797,  test auc: 0.984750
epoch 426, loss: 0.086262
model updated at epoch 426 
epoch 426, 
 train loss: 0.086262, val loss: 0.148608 
 val auc: 0.984872,  test auc: 0.984779
epoch 427, loss: 0.085975
model updated at epoch 427 
epoch 427, 
 train loss: 0.085975, val loss: 0.148393 
 val auc: 0.984910,  test auc: 0.984825
epoch 428, loss: 0.085685
model updated at epoch 428 
epoch 428, 
 train loss: 0.085685, val loss: 0.148046 
 val auc: 0.984947,  test auc: 0.984844
epoch 429, loss: 0.085407
model updated at epoch 429 
epoch 429, 
 train loss: 0.085407, val loss: 0.147729 
 val auc: 0.984985,  test auc: 0.984872
epoch 430, loss: 0.085115
model updated at epoch 430 
epoch 430, 
 train loss: 0.085115, val loss: 0.147337 
 val auc: 0.985285,  test auc: 0.984947
epoch 431, loss: 0.084834
model updated at epoch 431 
epoch 431, 
 train loss: 0.084834, val loss: 0.146977 
 val auc: 0.985360,  test auc: 0.985023
epoch 432, loss: 0.084551
model updated at epoch 432 
epoch 432, 
 train loss: 0.084551, val loss: 0.146568 
 val auc: 0.985511,  test auc: 0.985098
epoch 433, loss: 0.084272
model updated at epoch 433 
epoch 433, 
 train loss: 0.084272, val loss: 0.146313 
 val auc: 0.985548,  test auc: 0.985163
epoch 434, loss: 0.083991
model updated at epoch 434 
epoch 434, 
 train loss: 0.083991, val loss: 0.146199 
 val auc: 0.985623,  test auc: 0.985210
epoch 435, loss: 0.083715
model updated at epoch 435 
epoch 435, 
 train loss: 0.083715, val loss: 0.145953 
 val auc: 0.985661,  test auc: 0.985210
epoch 436, loss: 0.083438
model updated at epoch 436 
epoch 436, 
 train loss: 0.083438, val loss: 0.145466 
 val auc: 0.985698,  test auc: 0.985267
epoch 437, loss: 0.083165
model updated at epoch 437 
epoch 437, 
 train loss: 0.083165, val loss: 0.144972 
 val auc: 0.985698,  test auc: 0.985220
epoch 438, loss: 0.082885
model updated at epoch 438 
epoch 438, 
 train loss: 0.082885, val loss: 0.144725 
 val auc: 0.985961,  test auc: 0.985407
epoch 439, loss: 0.082616
model updated at epoch 439 
epoch 439, 
 train loss: 0.082616, val loss: 0.144495 
 val auc: 0.985848,  test auc: 0.985267
epoch 440, loss: 0.082351
model updated at epoch 440 
epoch 440, 
 train loss: 0.082351, val loss: 0.144155 
 val auc: 0.986074,  test auc: 0.985482
epoch 441, loss: 0.082085
model updated at epoch 441 
epoch 441, 
 train loss: 0.082085, val loss: 0.143531 
 val auc: 0.985886,  test auc: 0.985370
epoch 442, loss: 0.081822
model updated at epoch 442 
epoch 442, 
 train loss: 0.081822, val loss: 0.143163 
 val auc: 0.986261,  test auc: 0.985567
epoch 443, loss: 0.081557
model updated at epoch 443 
epoch 443, 
 train loss: 0.081557, val loss: 0.142830 
 val auc: 0.985961,  test auc: 0.985417
epoch 444, loss: 0.081296
model updated at epoch 444 
epoch 444, 
 train loss: 0.081296, val loss: 0.142683 
 val auc: 0.986299,  test auc: 0.985679
epoch 445, loss: 0.081031
model updated at epoch 445 
epoch 445, 
 train loss: 0.081031, val loss: 0.142214 
 val auc: 0.985998,  test auc: 0.985482
epoch 446, loss: 0.080769
model updated at epoch 446 
epoch 446, 
 train loss: 0.080769, val loss: 0.141854 
 val auc: 0.986336,  test auc: 0.985783
epoch 447, loss: 0.080503
model updated at epoch 447 
epoch 447, 
 train loss: 0.080503, val loss: 0.141417 
 val auc: 0.986149,  test auc: 0.985586
epoch 448, loss: 0.080239
model updated at epoch 448 
epoch 448, 
 train loss: 0.080239, val loss: 0.141135 
 val auc: 0.986374,  test auc: 0.985773
epoch 449, loss: 0.079974
model updated at epoch 449 
epoch 449, 
 train loss: 0.079974, val loss: 0.140738 
 val auc: 0.986261,  test auc: 0.985755
epoch 450, loss: 0.079712
model updated at epoch 450 
epoch 450, 
 train loss: 0.079712, val loss: 0.140505 
 val auc: 0.986374,  test auc: 0.985839
epoch 451, loss: 0.079454
model updated at epoch 451 
epoch 451, 
 train loss: 0.079454, val loss: 0.140282 
 val auc: 0.986299,  test auc: 0.985820
epoch 452, loss: 0.079207
model updated at epoch 452 
epoch 452, 
 train loss: 0.079207, val loss: 0.139969 
 val auc: 0.986224,  test auc: 0.985839
epoch 453, loss: 0.078973
model updated at epoch 453 
epoch 453, 
 train loss: 0.078973, val loss: 0.139542 
 val auc: 0.986374,  test auc: 0.985914
epoch 454, loss: 0.078752
model updated at epoch 454 
epoch 454, 
 train loss: 0.078752, val loss: 0.139032 
 val auc: 0.986186,  test auc: 0.985867
epoch 455, loss: 0.078525
model updated at epoch 455 
epoch 455, 
 train loss: 0.078525, val loss: 0.138763 
 val auc: 0.986486,  test auc: 0.986111
epoch 456, loss: 0.078301
model updated at epoch 456 
epoch 456, 
 train loss: 0.078301, val loss: 0.138430 
 val auc: 0.986261,  test auc: 0.985970
epoch 457, loss: 0.078085
model updated at epoch 457 
epoch 457, 
 train loss: 0.078085, val loss: 0.138193 
 val auc: 0.986674,  test auc: 0.986205
epoch 458, loss: 0.077857
model updated at epoch 458 
epoch 458, 
 train loss: 0.077857, val loss: 0.137722 
 val auc: 0.986449,  test auc: 0.986111
epoch 459, loss: 0.077595
model updated at epoch 459 
epoch 459, 
 train loss: 0.077595, val loss: 0.137553 
 val auc: 0.986674,  test auc: 0.986289
epoch 460, loss: 0.077335
model updated at epoch 460 
epoch 460, 
 train loss: 0.077335, val loss: 0.137249 
 val auc: 0.986486,  test auc: 0.986224
epoch 461, loss: 0.077077
model updated at epoch 461 
epoch 461, 
 train loss: 0.077077, val loss: 0.136991 
 val auc: 0.986712,  test auc: 0.986393
epoch 462, loss: 0.076825
model updated at epoch 462 
epoch 462, 
 train loss: 0.076825, val loss: 0.136681 
 val auc: 0.986562,  test auc: 0.986430
epoch 463, loss: 0.076584
model updated at epoch 463 
epoch 463, 
 train loss: 0.076584, val loss: 0.136307 
 val auc: 0.986637,  test auc: 0.986590
epoch 464, loss: 0.076352
model updated at epoch 464 
epoch 464, 
 train loss: 0.076352, val loss: 0.135893 
 val auc: 0.986787,  test auc: 0.986693
epoch 465, loss: 0.076131
model updated at epoch 465 
epoch 465, 
 train loss: 0.076131, val loss: 0.135467 
 val auc: 0.986674,  test auc: 0.986702
epoch 466, loss: 0.075915
model updated at epoch 466 
epoch 466, 
 train loss: 0.075915, val loss: 0.135182 
 val auc: 0.986862,  test auc: 0.986899
epoch 467, loss: 0.075708
model updated at epoch 467 
epoch 467, 
 train loss: 0.075708, val loss: 0.134868 
 val auc: 0.986712,  test auc: 0.986881
epoch 468, loss: 0.075502
model updated at epoch 468 
epoch 468, 
 train loss: 0.075502, val loss: 0.134459 
 val auc: 0.987125,  test auc: 0.987181
epoch 469, loss: 0.075289
model updated at epoch 469 
epoch 469, 
 train loss: 0.075289, val loss: 0.134069 
 val auc: 0.986862,  test auc: 0.987003
epoch 470, loss: 0.075068
model updated at epoch 470 
epoch 470, 
 train loss: 0.075068, val loss: 0.133792 
 val auc: 0.987162,  test auc: 0.987218
epoch 471, loss: 0.074844
model updated at epoch 471 
epoch 471, 
 train loss: 0.074844, val loss: 0.133422 
 val auc: 0.987012,  test auc: 0.987125
epoch 472, loss: 0.074616
model updated at epoch 472 
epoch 472, 
 train loss: 0.074616, val loss: 0.133129 
 val auc: 0.987200,  test auc: 0.987312
epoch 473, loss: 0.074394
model updated at epoch 473 
epoch 473, 
 train loss: 0.074394, val loss: 0.132927 
 val auc: 0.987125,  test auc: 0.987256
epoch 474, loss: 0.074174
model updated at epoch 474 
epoch 474, 
 train loss: 0.074174, val loss: 0.132620 
 val auc: 0.987200,  test auc: 0.987359
epoch 475, loss: 0.073963
model updated at epoch 475 
epoch 475, 
 train loss: 0.073963, val loss: 0.132204 
 val auc: 0.987200,  test auc: 0.987387
epoch 476, loss: 0.073758
model updated at epoch 476 
epoch 476, 
 train loss: 0.073758, val loss: 0.131842 
 val auc: 0.987275,  test auc: 0.987378
epoch 477, loss: 0.073559
model updated at epoch 477 
epoch 477, 
 train loss: 0.073559, val loss: 0.131619 
 val auc: 0.987200,  test auc: 0.987416
epoch 478, loss: 0.073368
model updated at epoch 478 
epoch 478, 
 train loss: 0.073368, val loss: 0.131402 
 val auc: 0.987237,  test auc: 0.987406
epoch 479, loss: 0.073180
model updated at epoch 479 
epoch 479, 
 train loss: 0.073180, val loss: 0.131096 
 val auc: 0.987387,  test auc: 0.987500
epoch 480, loss: 0.072994
model updated at epoch 480 
epoch 480, 
 train loss: 0.072994, val loss: 0.130922 
 val auc: 0.987275,  test auc: 0.987481
epoch 481, loss: 0.072810
model updated at epoch 481 
epoch 481, 
 train loss: 0.072810, val loss: 0.130680 
 val auc: 0.987462,  test auc: 0.987641
epoch 482, loss: 0.072629
model updated at epoch 482 
epoch 482, 
 train loss: 0.072629, val loss: 0.130489 
 val auc: 0.987237,  test auc: 0.987500
epoch 483, loss: 0.072447
model updated at epoch 483 
epoch 483, 
 train loss: 0.072447, val loss: 0.130147 
 val auc: 0.987462,  test auc: 0.987706
epoch 484, loss: 0.072260
model updated at epoch 484 
epoch 484, 
 train loss: 0.072260, val loss: 0.130034 
 val auc: 0.987387,  test auc: 0.987556
epoch 485, loss: 0.072073
model updated at epoch 485 
epoch 485, 
 train loss: 0.072073, val loss: 0.129737 
 val auc: 0.987575,  test auc: 0.987725
epoch 486, loss: 0.071878
model updated at epoch 486 
epoch 486, 
 train loss: 0.071878, val loss: 0.129673 
 val auc: 0.987350,  test auc: 0.987556
epoch 487, loss: 0.071660
model updated at epoch 487 
epoch 487, 
 train loss: 0.071660, val loss: 0.129163 
 val auc: 0.987613,  test auc: 0.987735
epoch 488, loss: 0.071443
model updated at epoch 488 
epoch 488, 
 train loss: 0.071443, val loss: 0.128871 
 val auc: 0.987462,  test auc: 0.987669
epoch 489, loss: 0.071225
model updated at epoch 489 
epoch 489, 
 train loss: 0.071225, val loss: 0.128456 
 val auc: 0.987688,  test auc: 0.987828
epoch 490, loss: 0.071014
model updated at epoch 490 
epoch 490, 
 train loss: 0.071014, val loss: 0.128287 
 val auc: 0.987613,  test auc: 0.987885
epoch 491, loss: 0.070797
model updated at epoch 491 
epoch 491, 
 train loss: 0.070797, val loss: 0.128000 
 val auc: 0.987725,  test auc: 0.987941
epoch 492, loss: 0.070589
model updated at epoch 492 
epoch 492, 
 train loss: 0.070589, val loss: 0.127878 
 val auc: 0.987688,  test auc: 0.987969
epoch 493, loss: 0.070385
model updated at epoch 493 
epoch 493, 
 train loss: 0.070385, val loss: 0.127661 
 val auc: 0.987688,  test auc: 0.987969
epoch 494, loss: 0.070187
model updated at epoch 494 
epoch 494, 
 train loss: 0.070187, val loss: 0.127481 
 val auc: 0.987763,  test auc: 0.988035
epoch 495, loss: 0.069993
model updated at epoch 495 
epoch 495, 
 train loss: 0.069993, val loss: 0.127225 
 val auc: 0.987875,  test auc: 0.988091
epoch 496, loss: 0.069805
model updated at epoch 496 
epoch 496, 
 train loss: 0.069805, val loss: 0.126978 
 val auc: 0.987913,  test auc: 0.988157
epoch 497, loss: 0.069618
model updated at epoch 497 
epoch 497, 
 train loss: 0.069618, val loss: 0.126763 
 val auc: 0.987875,  test auc: 0.988091
epoch 498, loss: 0.069433
model updated at epoch 498 
epoch 498, 
 train loss: 0.069433, val loss: 0.126499 
 val auc: 0.987988,  test auc: 0.988129
epoch 499, loss: 0.069252
model updated at epoch 499 
epoch 499, 
 train loss: 0.069252, val loss: 0.126369 
 val auc: 0.987875,  test auc: 0.988223
epoch 500, loss: 0.069087
model updated at epoch 500 
epoch 500, 
 train loss: 0.069087, val loss: 0.126123 
 val auc: 0.987913,  test auc: 0.988138
epoch 501, loss: 0.068968
epoch 501, 
 train loss: 0.068968, val loss: 0.126125 
 val auc: 0.987913,  test auc: 0.988110
epoch 502, loss: 0.069005
model updated at epoch 502 
epoch 502, 
 train loss: 0.069005, val loss: 0.125946 
 val auc: 0.988101,  test auc: 0.988251
epoch 503, loss: 0.069527
epoch 503, 
 train loss: 0.069527, val loss: 0.127026 
 val auc: 0.987500,  test auc: 0.987678
epoch 504, loss: 0.070962
epoch 504, 
 train loss: 0.070962, val loss: 0.127904 
 val auc: 0.988213,  test auc: 0.988241
epoch 505, loss: 0.074349
epoch 505, 
 train loss: 0.074349, val loss: 0.133295 
 val auc: 0.987387,  test auc: 0.987397
epoch 506, loss: 0.072360
epoch 506, 
 train loss: 0.072360, val loss: 0.129290 
 val auc: 0.988514,  test auc: 0.988373
epoch 507, loss: 0.068742
model updated at epoch 507 
epoch 507, 
 train loss: 0.068742, val loss: 0.125808 
 val auc: 0.987763,  test auc: 0.987997
epoch 508, loss: 0.068447
model updated at epoch 508 
epoch 508, 
 train loss: 0.068447, val loss: 0.125507 
 val auc: 0.987838,  test auc: 0.988091
epoch 509, loss: 0.070613
epoch 509, 
 train loss: 0.070613, val loss: 0.127598 
 val auc: 0.988514,  test auc: 0.988457
epoch 510, loss: 0.069813
epoch 510, 
 train loss: 0.069813, val loss: 0.127948 
 val auc: 0.987688,  test auc: 0.987791
epoch 511, loss: 0.067303
model updated at epoch 511 
epoch 511, 
 train loss: 0.067303, val loss: 0.124265 
 val auc: 0.988363,  test auc: 0.988448
epoch 512, loss: 0.069184
epoch 512, 
 train loss: 0.069184, val loss: 0.125874 
 val auc: 0.988589,  test auc: 0.988467
epoch 513, loss: 0.069671
epoch 513, 
 train loss: 0.069671, val loss: 0.127699 
 val auc: 0.987763,  test auc: 0.987706
epoch 514, loss: 0.066879
model updated at epoch 514 
epoch 514, 
 train loss: 0.066879, val loss: 0.124147 
 val auc: 0.988288,  test auc: 0.988363
epoch 515, loss: 0.068216
epoch 515, 
 train loss: 0.068216, val loss: 0.125359 
 val auc: 0.988626,  test auc: 0.988476
epoch 516, loss: 0.068864
epoch 516, 
 train loss: 0.068864, val loss: 0.126860 
 val auc: 0.987838,  test auc: 0.987847
epoch 517, loss: 0.066341
model updated at epoch 517 
epoch 517, 
 train loss: 0.066341, val loss: 0.122969 
 val auc: 0.988401,  test auc: 0.988373
epoch 518, loss: 0.067626
epoch 518, 
 train loss: 0.067626, val loss: 0.124318 
 val auc: 0.988851,  test auc: 0.988420
epoch 519, loss: 0.067926
epoch 519, 
 train loss: 0.067926, val loss: 0.125957 
 val auc: 0.987950,  test auc: 0.987735
epoch 520, loss: 0.065778
model updated at epoch 520 
epoch 520, 
 train loss: 0.065778, val loss: 0.122820 
 val auc: 0.988589,  test auc: 0.988392
epoch 521, loss: 0.067178
epoch 521, 
 train loss: 0.067178, val loss: 0.123874 
 val auc: 0.988814,  test auc: 0.988429
epoch 522, loss: 0.067008
epoch 522, 
 train loss: 0.067008, val loss: 0.124832 
 val auc: 0.987988,  test auc: 0.987941
epoch 523, loss: 0.065280
model updated at epoch 523 
epoch 523, 
 train loss: 0.065280, val loss: 0.122578 
 val auc: 0.988401,  test auc: 0.988307
epoch 524, loss: 0.066679
epoch 524, 
 train loss: 0.066679, val loss: 0.124069 
 val auc: 0.988814,  test auc: 0.988457
epoch 525, loss: 0.066024
epoch 525, 
 train loss: 0.066024, val loss: 0.124634 
 val auc: 0.988101,  test auc: 0.987969
epoch 526, loss: 0.064870
epoch 526, 
 train loss: 0.064870, val loss: 0.122897 
 val auc: 0.988288,  test auc: 0.988279
epoch 527, loss: 0.066070
epoch 527, 
 train loss: 0.066070, val loss: 0.123483 
 val auc: 0.988814,  test auc: 0.988504
epoch 528, loss: 0.065240
epoch 528, 
 train loss: 0.065240, val loss: 0.123552 
 val auc: 0.988138,  test auc: 0.988101
epoch 529, loss: 0.064456
model updated at epoch 529 
epoch 529, 
 train loss: 0.064456, val loss: 0.122217 
 val auc: 0.988401,  test auc: 0.988345
epoch 530, loss: 0.065364
epoch 530, 
 train loss: 0.065364, val loss: 0.122676 
 val auc: 0.989002,  test auc: 0.988514
epoch 531, loss: 0.064447
epoch 531, 
 train loss: 0.064447, val loss: 0.122897 
 val auc: 0.988213,  test auc: 0.988176
epoch 532, loss: 0.064100
epoch 532, 
 train loss: 0.064100, val loss: 0.122910 
 val auc: 0.988326,  test auc: 0.988298
epoch 533, loss: 0.064630
epoch 533, 
 train loss: 0.064630, val loss: 0.123025 
 val auc: 0.988851,  test auc: 0.988589
epoch 534, loss: 0.063728
epoch 534, 
 train loss: 0.063728, val loss: 0.122502 
 val auc: 0.988401,  test auc: 0.988392
epoch 535, loss: 0.063774
epoch 535, 
 train loss: 0.063774, val loss: 0.122521 
 val auc: 0.988363,  test auc: 0.988316
epoch 536, loss: 0.063850
model updated at epoch 536 
epoch 536, 
 train loss: 0.063850, val loss: 0.121919 
 val auc: 0.989114,  test auc: 0.988626
epoch 537, loss: 0.063157
model updated at epoch 537 
epoch 537, 
 train loss: 0.063157, val loss: 0.121647 
 val auc: 0.988551,  test auc: 0.988532
epoch 538, loss: 0.063369
epoch 538, 
 train loss: 0.063369, val loss: 0.122217 
 val auc: 0.988288,  test auc: 0.988354
epoch 539, loss: 0.063126
model updated at epoch 539 
epoch 539, 
 train loss: 0.063126, val loss: 0.121057 
 val auc: 0.988776,  test auc: 0.988664
epoch 540, loss: 0.062729
model updated at epoch 540 
epoch 540, 
 train loss: 0.062729, val loss: 0.120841 
 val auc: 0.988514,  test auc: 0.988617
epoch 541, loss: 0.062899
epoch 541, 
 train loss: 0.062899, val loss: 0.121703 
 val auc: 0.988401,  test auc: 0.988438
epoch 542, loss: 0.062502
model updated at epoch 542 
epoch 542, 
 train loss: 0.062502, val loss: 0.120759 
 val auc: 0.988776,  test auc: 0.988673
epoch 543, loss: 0.062345
model updated at epoch 543 
epoch 543, 
 train loss: 0.062345, val loss: 0.120629 
 val auc: 0.988814,  test auc: 0.988692
epoch 544, loss: 0.062383
epoch 544, 
 train loss: 0.062383, val loss: 0.121250 
 val auc: 0.988514,  test auc: 0.988514
epoch 545, loss: 0.062013
model updated at epoch 545 
epoch 545, 
 train loss: 0.062013, val loss: 0.120301 
 val auc: 0.988701,  test auc: 0.988664
epoch 546, loss: 0.061937
model updated at epoch 546 
epoch 546, 
 train loss: 0.061937, val loss: 0.120066 
 val auc: 0.988814,  test auc: 0.988739
epoch 547, loss: 0.061865
epoch 547, 
 train loss: 0.061865, val loss: 0.120448 
 val auc: 0.988626,  test auc: 0.988598
epoch 548, loss: 0.061564
model updated at epoch 548 
epoch 548, 
 train loss: 0.061564, val loss: 0.119702 
 val auc: 0.988701,  test auc: 0.988701
epoch 549, loss: 0.061532
model updated at epoch 549 
epoch 549, 
 train loss: 0.061532, val loss: 0.119506 
 val auc: 0.988851,  test auc: 0.988795
epoch 550, loss: 0.061386
epoch 550, 
 train loss: 0.061386, val loss: 0.119818 
 val auc: 0.988664,  test auc: 0.988711
epoch 551, loss: 0.061146
model updated at epoch 551 
epoch 551, 
 train loss: 0.061146, val loss: 0.119314 
 val auc: 0.988814,  test auc: 0.988833
epoch 552, loss: 0.061125
model updated at epoch 552 
epoch 552, 
 train loss: 0.061125, val loss: 0.119122 
 val auc: 0.988889,  test auc: 0.988870
epoch 553, loss: 0.060988
epoch 553, 
 train loss: 0.060988, val loss: 0.119580 
 val auc: 0.988701,  test auc: 0.988748
epoch 554, loss: 0.060735
model updated at epoch 554 
epoch 554, 
 train loss: 0.060735, val loss: 0.119085 
 val auc: 0.988851,  test auc: 0.988842
epoch 555, loss: 0.060686
model updated at epoch 555 
epoch 555, 
 train loss: 0.060686, val loss: 0.118790 
 val auc: 0.988926,  test auc: 0.988870
epoch 556, loss: 0.060530
epoch 556, 
 train loss: 0.060530, val loss: 0.119020 
 val auc: 0.988739,  test auc: 0.988804
epoch 557, loss: 0.060335
model updated at epoch 557 
epoch 557, 
 train loss: 0.060335, val loss: 0.118776 
 val auc: 0.988814,  test auc: 0.988851
epoch 558, loss: 0.060274
model updated at epoch 558 
epoch 558, 
 train loss: 0.060274, val loss: 0.118502 
 val auc: 0.988964,  test auc: 0.988908
epoch 559, loss: 0.060105
epoch 559, 
 train loss: 0.060105, val loss: 0.118564 
 val auc: 0.988851,  test auc: 0.988889
epoch 560, loss: 0.059943
model updated at epoch 560 
epoch 560, 
 train loss: 0.059943, val loss: 0.118236 
 val auc: 0.988964,  test auc: 0.988926
epoch 561, loss: 0.059862
model updated at epoch 561 
epoch 561, 
 train loss: 0.059862, val loss: 0.117901 
 val auc: 0.989077,  test auc: 0.988945
epoch 562, loss: 0.059695
epoch 562, 
 train loss: 0.059695, val loss: 0.118064 
 val auc: 0.989077,  test auc: 0.988908
epoch 563, loss: 0.059550
model updated at epoch 563 
epoch 563, 
 train loss: 0.059550, val loss: 0.117882 
 val auc: 0.989039,  test auc: 0.988917
epoch 564, loss: 0.059459
model updated at epoch 564 
epoch 564, 
 train loss: 0.059459, val loss: 0.117573 
 val auc: 0.989114,  test auc: 0.988983
epoch 565, loss: 0.059304
epoch 565, 
 train loss: 0.059304, val loss: 0.117753 
 val auc: 0.989189,  test auc: 0.988992
epoch 566, loss: 0.059164
epoch 566, 
 train loss: 0.059164, val loss: 0.117598 
 val auc: 0.989152,  test auc: 0.989011
epoch 567, loss: 0.059063
model updated at epoch 567 
epoch 567, 
 train loss: 0.059063, val loss: 0.117389 
 val auc: 0.989189,  test auc: 0.989048
epoch 568, loss: 0.058919
epoch 568, 
 train loss: 0.058919, val loss: 0.117480 
 val auc: 0.989264,  test auc: 0.989058
epoch 569, loss: 0.058784
model updated at epoch 569 
epoch 569, 
 train loss: 0.058784, val loss: 0.117263 
 val auc: 0.989227,  test auc: 0.989086
epoch 570, loss: 0.058675
model updated at epoch 570 
epoch 570, 
 train loss: 0.058675, val loss: 0.117007 
 val auc: 0.989227,  test auc: 0.989114
epoch 571, loss: 0.058537
epoch 571, 
 train loss: 0.058537, val loss: 0.117101 
 val auc: 0.989227,  test auc: 0.989086
epoch 572, loss: 0.058408
epoch 572, 
 train loss: 0.058408, val loss: 0.117041 
 val auc: 0.989189,  test auc: 0.989077
epoch 573, loss: 0.058295
model updated at epoch 573 
epoch 573, 
 train loss: 0.058295, val loss: 0.116922 
 val auc: 0.989302,  test auc: 0.989123
epoch 574, loss: 0.058164
epoch 574, 
 train loss: 0.058164, val loss: 0.116929 
 val auc: 0.989227,  test auc: 0.989067
epoch 575, loss: 0.058040
model updated at epoch 575 
epoch 575, 
 train loss: 0.058040, val loss: 0.116680 
 val auc: 0.989264,  test auc: 0.989086
epoch 576, loss: 0.057926
model updated at epoch 576 
epoch 576, 
 train loss: 0.057926, val loss: 0.116486 
 val auc: 0.989264,  test auc: 0.989114
epoch 577, loss: 0.057801
epoch 577, 
 train loss: 0.057801, val loss: 0.116599 
 val auc: 0.989264,  test auc: 0.989105
epoch 578, loss: 0.057677
model updated at epoch 578 
epoch 578, 
 train loss: 0.057677, val loss: 0.116470 
 val auc: 0.989264,  test auc: 0.989114
epoch 579, loss: 0.057564
model updated at epoch 579 
epoch 579, 
 train loss: 0.057564, val loss: 0.116271 
 val auc: 0.989339,  test auc: 0.989217
epoch 580, loss: 0.057445
epoch 580, 
 train loss: 0.057445, val loss: 0.116372 
 val auc: 0.989302,  test auc: 0.989189
epoch 581, loss: 0.057321
model updated at epoch 581 
epoch 581, 
 train loss: 0.057321, val loss: 0.116176 
 val auc: 0.989414,  test auc: 0.989245
epoch 582, loss: 0.057205
model updated at epoch 582 
epoch 582, 
 train loss: 0.057205, val loss: 0.116017 
 val auc: 0.989414,  test auc: 0.989236
epoch 583, loss: 0.057092
model updated at epoch 583 
epoch 583, 
 train loss: 0.057092, val loss: 0.115917 
 val auc: 0.989452,  test auc: 0.989236
epoch 584, loss: 0.056973
model updated at epoch 584 
epoch 584, 
 train loss: 0.056973, val loss: 0.115738 
 val auc: 0.989489,  test auc: 0.989255
epoch 585, loss: 0.056855
epoch 585, 
 train loss: 0.056855, val loss: 0.115808 
 val auc: 0.989489,  test auc: 0.989245
epoch 586, loss: 0.056742
epoch 586, 
 train loss: 0.056742, val loss: 0.115845 
 val auc: 0.989414,  test auc: 0.989227
epoch 587, loss: 0.056631
model updated at epoch 587 
epoch 587, 
 train loss: 0.056631, val loss: 0.115734 
 val auc: 0.989489,  test auc: 0.989274
epoch 588, loss: 0.056516
model updated at epoch 588 
epoch 588, 
 train loss: 0.056516, val loss: 0.115667 
 val auc: 0.989414,  test auc: 0.989236
epoch 589, loss: 0.056405
model updated at epoch 589 
epoch 589, 
 train loss: 0.056405, val loss: 0.115515 
 val auc: 0.989414,  test auc: 0.989269
epoch 590, loss: 0.056292
model updated at epoch 590 
epoch 590, 
 train loss: 0.056292, val loss: 0.115404 
 val auc: 0.989452,  test auc: 0.989292
epoch 591, loss: 0.056183
epoch 591, 
 train loss: 0.056183, val loss: 0.115435 
 val auc: 0.989414,  test auc: 0.989245
epoch 592, loss: 0.056068
model updated at epoch 592 
epoch 592, 
 train loss: 0.056068, val loss: 0.115280 
 val auc: 0.989489,  test auc: 0.989302
epoch 593, loss: 0.055955
model updated at epoch 593 
epoch 593, 
 train loss: 0.055955, val loss: 0.115255 
 val auc: 0.989527,  test auc: 0.989321
epoch 594, loss: 0.055838
model updated at epoch 594 
epoch 594, 
 train loss: 0.055838, val loss: 0.115138 
 val auc: 0.989489,  test auc: 0.989311
epoch 595, loss: 0.055727
model updated at epoch 595 
epoch 595, 
 train loss: 0.055727, val loss: 0.115125 
 val auc: 0.989489,  test auc: 0.989292
epoch 596, loss: 0.055616
epoch 596, 
 train loss: 0.055616, val loss: 0.115134 
 val auc: 0.989414,  test auc: 0.989274
epoch 597, loss: 0.055497
model updated at epoch 597 
epoch 597, 
 train loss: 0.055497, val loss: 0.114949 
 val auc: 0.989527,  test auc: 0.989330
epoch 598, loss: 0.055377
model updated at epoch 598 
epoch 598, 
 train loss: 0.055377, val loss: 0.114897 
 val auc: 0.989489,  test auc: 0.989321
epoch 599, loss: 0.055251
model updated at epoch 599 
epoch 599, 
 train loss: 0.055251, val loss: 0.114820 
 val auc: 0.989489,  test auc: 0.989321
epoch 600, loss: 0.055124
model updated at epoch 600 
epoch 600, 
 train loss: 0.055124, val loss: 0.114727 
 val auc: 0.989602,  test auc: 0.989396
epoch 601, loss: 0.055001
epoch 601, 
 train loss: 0.055001, val loss: 0.114874 
 val auc: 0.989489,  test auc: 0.989367
epoch 602, loss: 0.054878
epoch 602, 
 train loss: 0.054878, val loss: 0.114779 
 val auc: 0.989489,  test auc: 0.989349
epoch 603, loss: 0.054759
model updated at epoch 603 
epoch 603, 
 train loss: 0.054759, val loss: 0.114643 
 val auc: 0.989565,  test auc: 0.989367
epoch 604, loss: 0.054646
model updated at epoch 604 
epoch 604, 
 train loss: 0.054646, val loss: 0.114472 
 val auc: 0.989565,  test auc: 0.989405
epoch 605, loss: 0.054537
model updated at epoch 605 
epoch 605, 
 train loss: 0.054537, val loss: 0.114345 
 val auc: 0.989602,  test auc: 0.989424
epoch 606, loss: 0.054428
model updated at epoch 606 
epoch 606, 
 train loss: 0.054428, val loss: 0.114305 
 val auc: 0.989640,  test auc: 0.989461
epoch 607, loss: 0.054319
model updated at epoch 607 
epoch 607, 
 train loss: 0.054319, val loss: 0.114266 
 val auc: 0.989640,  test auc: 0.989461
epoch 608, loss: 0.054210
model updated at epoch 608 
epoch 608, 
 train loss: 0.054210, val loss: 0.114221 
 val auc: 0.989640,  test auc: 0.989443
epoch 609, loss: 0.054104
model updated at epoch 609 
epoch 609, 
 train loss: 0.054104, val loss: 0.114212 
 val auc: 0.989565,  test auc: 0.989443
epoch 610, loss: 0.053997
model updated at epoch 610 
epoch 610, 
 train loss: 0.053997, val loss: 0.114134 
 val auc: 0.989602,  test auc: 0.989480
epoch 611, loss: 0.053892
epoch 611, 
 train loss: 0.053892, val loss: 0.114198 
 val auc: 0.989565,  test auc: 0.989471
epoch 612, loss: 0.053786
epoch 612, 
 train loss: 0.053786, val loss: 0.114183 
 val auc: 0.989565,  test auc: 0.989461
epoch 613, loss: 0.053678
model updated at epoch 613 
epoch 613, 
 train loss: 0.053678, val loss: 0.114018 
 val auc: 0.989602,  test auc: 0.989452
epoch 614, loss: 0.053574
model updated at epoch 614 
epoch 614, 
 train loss: 0.053574, val loss: 0.113804 
 val auc: 0.989715,  test auc: 0.989489
epoch 615, loss: 0.053469
model updated at epoch 615 
epoch 615, 
 train loss: 0.053469, val loss: 0.113727 
 val auc: 0.989677,  test auc: 0.989508
epoch 616, loss: 0.053364
epoch 616, 
 train loss: 0.053364, val loss: 0.113857 
 val auc: 0.989640,  test auc: 0.989480
epoch 617, loss: 0.053260
epoch 617, 
 train loss: 0.053260, val loss: 0.113871 
 val auc: 0.989640,  test auc: 0.989480
epoch 618, loss: 0.053158
epoch 618, 
 train loss: 0.053158, val loss: 0.113804 
 val auc: 0.989677,  test auc: 0.989499
epoch 619, loss: 0.053054
model updated at epoch 619 
epoch 619, 
 train loss: 0.053054, val loss: 0.113663 
 val auc: 0.989677,  test auc: 0.989489
epoch 620, loss: 0.052953
model updated at epoch 620 
epoch 620, 
 train loss: 0.052953, val loss: 0.113539 
 val auc: 0.989715,  test auc: 0.989499
epoch 621, loss: 0.052850
model updated at epoch 621 
epoch 621, 
 train loss: 0.052850, val loss: 0.113496 
 val auc: 0.989715,  test auc: 0.989527
epoch 622, loss: 0.052745
epoch 622, 
 train loss: 0.052745, val loss: 0.113565 
 val auc: 0.989677,  test auc: 0.989527
epoch 623, loss: 0.052647
epoch 623, 
 train loss: 0.052647, val loss: 0.113542 
 val auc: 0.989715,  test auc: 0.989565
epoch 624, loss: 0.052543
epoch 624, 
 train loss: 0.052543, val loss: 0.113625 
 val auc: 0.989677,  test auc: 0.989555
epoch 625, loss: 0.052443
epoch 625, 
 train loss: 0.052443, val loss: 0.113500 
 val auc: 0.989677,  test auc: 0.989508
epoch 626, loss: 0.052340
model updated at epoch 626 
epoch 626, 
 train loss: 0.052340, val loss: 0.113322 
 val auc: 0.989715,  test auc: 0.989527
epoch 627, loss: 0.052244
model updated at epoch 627 
epoch 627, 
 train loss: 0.052244, val loss: 0.113224 
 val auc: 0.989752,  test auc: 0.989583
epoch 628, loss: 0.052142
model updated at epoch 628 
epoch 628, 
 train loss: 0.052142, val loss: 0.113211 
 val auc: 0.989752,  test auc: 0.989546
epoch 629, loss: 0.052042
epoch 629, 
 train loss: 0.052042, val loss: 0.113360 
 val auc: 0.989752,  test auc: 0.989536
epoch 630, loss: 0.051942
epoch 630, 
 train loss: 0.051942, val loss: 0.113224 
 val auc: 0.989790,  test auc: 0.989574
epoch 631, loss: 0.051841
model updated at epoch 631 
epoch 631, 
 train loss: 0.051841, val loss: 0.112950 
 val auc: 0.989790,  test auc: 0.989583
epoch 632, loss: 0.051743
epoch 632, 
 train loss: 0.051743, val loss: 0.112995 
 val auc: 0.989790,  test auc: 0.989593
epoch 633, loss: 0.051643
epoch 633, 
 train loss: 0.051643, val loss: 0.113090 
 val auc: 0.989752,  test auc: 0.989588
epoch 634, loss: 0.051545
epoch 634, 
 train loss: 0.051545, val loss: 0.112961 
 val auc: 0.989790,  test auc: 0.989621
epoch 635, loss: 0.051447
model updated at epoch 635 
epoch 635, 
 train loss: 0.051447, val loss: 0.112850 
 val auc: 0.989827,  test auc: 0.989640
epoch 636, loss: 0.051350
model updated at epoch 636 
epoch 636, 
 train loss: 0.051350, val loss: 0.112764 
 val auc: 0.989865,  test auc: 0.989640
epoch 637, loss: 0.051253
epoch 637, 
 train loss: 0.051253, val loss: 0.112909 
 val auc: 0.989865,  test auc: 0.989696
epoch 638, loss: 0.051157
epoch 638, 
 train loss: 0.051157, val loss: 0.112826 
 val auc: 0.989827,  test auc: 0.989705
epoch 639, loss: 0.051059
model updated at epoch 639 
epoch 639, 
 train loss: 0.051059, val loss: 0.112723 
 val auc: 0.989827,  test auc: 0.989687
epoch 640, loss: 0.050965
model updated at epoch 640 
epoch 640, 
 train loss: 0.050965, val loss: 0.112491 
 val auc: 0.989902,  test auc: 0.989705
epoch 641, loss: 0.050868
model updated at epoch 641 
epoch 641, 
 train loss: 0.050868, val loss: 0.112489 
 val auc: 0.989902,  test auc: 0.989696
epoch 642, loss: 0.050773
epoch 642, 
 train loss: 0.050773, val loss: 0.112625 
 val auc: 0.989865,  test auc: 0.989677
epoch 643, loss: 0.050677
model updated at epoch 643 
epoch 643, 
 train loss: 0.050677, val loss: 0.112440 
 val auc: 0.989790,  test auc: 0.989677
epoch 644, loss: 0.050582
model updated at epoch 644 
epoch 644, 
 train loss: 0.050582, val loss: 0.112357 
 val auc: 0.989790,  test auc: 0.989668
epoch 645, loss: 0.050488
epoch 645, 
 train loss: 0.050488, val loss: 0.112373 
 val auc: 0.989865,  test auc: 0.989696
epoch 646, loss: 0.050397
model updated at epoch 646 
epoch 646, 
 train loss: 0.050397, val loss: 0.112352 
 val auc: 0.989827,  test auc: 0.989705
epoch 647, loss: 0.050300
model updated at epoch 647 
epoch 647, 
 train loss: 0.050300, val loss: 0.112236 
 val auc: 0.989865,  test auc: 0.989733
epoch 648, loss: 0.050207
model updated at epoch 648 
epoch 648, 
 train loss: 0.050207, val loss: 0.112171 
 val auc: 0.989865,  test auc: 0.989715
epoch 649, loss: 0.050114
model updated at epoch 649 
epoch 649, 
 train loss: 0.050114, val loss: 0.112137 
 val auc: 0.989902,  test auc: 0.989743
epoch 650, loss: 0.050020
model updated at epoch 650 
epoch 650, 
 train loss: 0.050020, val loss: 0.111984 
 val auc: 0.989977,  test auc: 0.989762
epoch 651, loss: 0.049928
epoch 651, 
 train loss: 0.049928, val loss: 0.112007 
 val auc: 0.989865,  test auc: 0.989752
epoch 652, loss: 0.049835
epoch 652, 
 train loss: 0.049835, val loss: 0.112144 
 val auc: 0.989865,  test auc: 0.989752
epoch 653, loss: 0.049741
epoch 653, 
 train loss: 0.049741, val loss: 0.112109 
 val auc: 0.989865,  test auc: 0.989771
epoch 654, loss: 0.049649
model updated at epoch 654 
epoch 654, 
 train loss: 0.049649, val loss: 0.111860 
 val auc: 0.989902,  test auc: 0.989809
epoch 655, loss: 0.049554
model updated at epoch 655 
epoch 655, 
 train loss: 0.049554, val loss: 0.111803 
 val auc: 0.989940,  test auc: 0.989827
epoch 656, loss: 0.049466
model updated at epoch 656 
epoch 656, 
 train loss: 0.049466, val loss: 0.111764 
 val auc: 0.990053,  test auc: 0.989846
epoch 657, loss: 0.049374
epoch 657, 
 train loss: 0.049374, val loss: 0.111874 
 val auc: 0.989977,  test auc: 0.989837
epoch 658, loss: 0.049285
model updated at epoch 658 
epoch 658, 
 train loss: 0.049285, val loss: 0.111741 
 val auc: 0.989902,  test auc: 0.989837
epoch 659, loss: 0.049198
model updated at epoch 659 
epoch 659, 
 train loss: 0.049198, val loss: 0.111719 
 val auc: 0.989940,  test auc: 0.989865
epoch 660, loss: 0.049107
epoch 660, 
 train loss: 0.049107, val loss: 0.111835 
 val auc: 0.990015,  test auc: 0.989855
epoch 661, loss: 0.049019
epoch 661, 
 train loss: 0.049019, val loss: 0.111745 
 val auc: 0.990015,  test auc: 0.989874
epoch 662, loss: 0.048927
model updated at epoch 662 
epoch 662, 
 train loss: 0.048927, val loss: 0.111685 
 val auc: 0.990015,  test auc: 0.989893
epoch 663, loss: 0.048841
model updated at epoch 663 
epoch 663, 
 train loss: 0.048841, val loss: 0.111673 
 val auc: 0.989977,  test auc: 0.989902
epoch 664, loss: 0.048752
model updated at epoch 664 
epoch 664, 
 train loss: 0.048752, val loss: 0.111489 
 val auc: 0.990015,  test auc: 0.989940
epoch 665, loss: 0.048664
model updated at epoch 665 
epoch 665, 
 train loss: 0.048664, val loss: 0.111488 
 val auc: 0.989977,  test auc: 0.989893
epoch 666, loss: 0.048579
epoch 666, 
 train loss: 0.048579, val loss: 0.111542 
 val auc: 0.990015,  test auc: 0.989865
epoch 667, loss: 0.048488
epoch 667, 
 train loss: 0.048488, val loss: 0.111496 
 val auc: 0.990015,  test auc: 0.989912
epoch 668, loss: 0.048402
model updated at epoch 668 
epoch 668, 
 train loss: 0.048402, val loss: 0.111355 
 val auc: 0.990015,  test auc: 0.989931
epoch 669, loss: 0.048314
model updated at epoch 669 
epoch 669, 
 train loss: 0.048314, val loss: 0.111346 
 val auc: 0.990053,  test auc: 0.989959
epoch 670, loss: 0.048229
epoch 670, 
 train loss: 0.048229, val loss: 0.111518 
 val auc: 0.990015,  test auc: 0.989921
epoch 671, loss: 0.048141
epoch 671, 
 train loss: 0.048141, val loss: 0.111472 
 val auc: 0.990090,  test auc: 0.989959
epoch 672, loss: 0.048054
epoch 672, 
 train loss: 0.048054, val loss: 0.111490 
 val auc: 0.990053,  test auc: 0.989963
epoch 673, loss: 0.047970
epoch 673, 
 train loss: 0.047970, val loss: 0.111531 
 val auc: 0.990053,  test auc: 0.989968
epoch 674, loss: 0.047884
epoch 674, 
 train loss: 0.047884, val loss: 0.111349 
 val auc: 0.990128,  test auc: 0.989977
epoch 675, loss: 0.047799
epoch 675, 
 train loss: 0.047799, val loss: 0.111368 
 val auc: 0.990165,  test auc: 0.989968
epoch 676, loss: 0.047716
model updated at epoch 676 
epoch 676, 
 train loss: 0.047716, val loss: 0.111253 
 val auc: 0.990165,  test auc: 0.989996
epoch 677, loss: 0.047630
model updated at epoch 677 
epoch 677, 
 train loss: 0.047630, val loss: 0.111222 
 val auc: 0.990128,  test auc: 0.989996
epoch 678, loss: 0.047545
epoch 678, 
 train loss: 0.047545, val loss: 0.111322 
 val auc: 0.990165,  test auc: 0.990006
epoch 679, loss: 0.047461
epoch 679, 
 train loss: 0.047461, val loss: 0.111268 
 val auc: 0.990165,  test auc: 0.990034
epoch 680, loss: 0.047377
epoch 680, 
 train loss: 0.047377, val loss: 0.111239 
 val auc: 0.990165,  test auc: 0.990053
epoch 681, loss: 0.047292
epoch 681, 
 train loss: 0.047292, val loss: 0.111238 
 val auc: 0.990128,  test auc: 0.990053
epoch 682, loss: 0.047211
model updated at epoch 682 
epoch 682, 
 train loss: 0.047211, val loss: 0.111209 
 val auc: 0.990165,  test auc: 0.990043
epoch 683, loss: 0.047126
model updated at epoch 683 
epoch 683, 
 train loss: 0.047126, val loss: 0.111158 
 val auc: 0.990128,  test auc: 0.990034
epoch 684, loss: 0.047043
model updated at epoch 684 
epoch 684, 
 train loss: 0.047043, val loss: 0.111021 
 val auc: 0.990203,  test auc: 0.990043
epoch 685, loss: 0.046958
epoch 685, 
 train loss: 0.046958, val loss: 0.111182 
 val auc: 0.990128,  test auc: 0.990071
epoch 686, loss: 0.046876
epoch 686, 
 train loss: 0.046876, val loss: 0.111356 
 val auc: 0.990128,  test auc: 0.990081
epoch 687, loss: 0.046795
epoch 687, 
 train loss: 0.046795, val loss: 0.111220 
 val auc: 0.990109,  test auc: 0.990067
epoch 688, loss: 0.046712
epoch 688, 
 train loss: 0.046712, val loss: 0.111072 
 val auc: 0.990053,  test auc: 0.990034
epoch 689, loss: 0.046632
model updated at epoch 689 
epoch 689, 
 train loss: 0.046632, val loss: 0.110860 
 val auc: 0.990165,  test auc: 0.990071
epoch 690, loss: 0.046547
epoch 690, 
 train loss: 0.046547, val loss: 0.111045 
 val auc: 0.990165,  test auc: 0.990090
epoch 691, loss: 0.046470
epoch 691, 
 train loss: 0.046470, val loss: 0.111380 
 val auc: 0.990128,  test auc: 0.990128
epoch 692, loss: 0.046386
epoch 692, 
 train loss: 0.046386, val loss: 0.111095 
 val auc: 0.990090,  test auc: 0.990090
epoch 693, loss: 0.046304
model updated at epoch 693 
epoch 693, 
 train loss: 0.046304, val loss: 0.110844 
 val auc: 0.990090,  test auc: 0.990099
epoch 694, loss: 0.046227
model updated at epoch 694 
epoch 694, 
 train loss: 0.046227, val loss: 0.110817 
 val auc: 0.990165,  test auc: 0.990109
epoch 695, loss: 0.046145
epoch 695, 
 train loss: 0.046145, val loss: 0.110935 
 val auc: 0.990128,  test auc: 0.990090
epoch 696, loss: 0.046067
epoch 696, 
 train loss: 0.046067, val loss: 0.111176 
 val auc: 0.990090,  test auc: 0.990099
epoch 697, loss: 0.045985
epoch 697, 
 train loss: 0.045985, val loss: 0.110994 
 val auc: 0.990090,  test auc: 0.990099
epoch 698, loss: 0.045904
model updated at epoch 698 
epoch 698, 
 train loss: 0.045904, val loss: 0.110815 
 val auc: 0.990128,  test auc: 0.990118
epoch 699, loss: 0.045822
model updated at epoch 699 
epoch 699, 
 train loss: 0.045822, val loss: 0.110814 
 val auc: 0.990165,  test auc: 0.990156
epoch 700, loss: 0.045747
epoch 700, 
 train loss: 0.045747, val loss: 0.110978 
 val auc: 0.990165,  test auc: 0.990165
epoch 701, loss: 0.045665
epoch 701, 
 train loss: 0.045665, val loss: 0.110952 
 val auc: 0.990128,  test auc: 0.990128
epoch 702, loss: 0.045588
epoch 702, 
 train loss: 0.045588, val loss: 0.110899 
 val auc: 0.990128,  test auc: 0.990137
epoch 703, loss: 0.045508
epoch 703, 
 train loss: 0.045508, val loss: 0.110892 
 val auc: 0.990128,  test auc: 0.990146
epoch 704, loss: 0.045431
epoch 704, 
 train loss: 0.045431, val loss: 0.110925 
 val auc: 0.990203,  test auc: 0.990193
epoch 705, loss: 0.045351
model updated at epoch 705 
epoch 705, 
 train loss: 0.045351, val loss: 0.110715 
 val auc: 0.990203,  test auc: 0.990193
epoch 706, loss: 0.045274
epoch 706, 
 train loss: 0.045274, val loss: 0.110753 
 val auc: 0.990165,  test auc: 0.990156
epoch 707, loss: 0.045193
epoch 707, 
 train loss: 0.045193, val loss: 0.110789 
 val auc: 0.990165,  test auc: 0.990156
epoch 708, loss: 0.045116
epoch 708, 
 train loss: 0.045116, val loss: 0.110818 
 val auc: 0.990240,  test auc: 0.990221
epoch 709, loss: 0.045039
epoch 709, 
 train loss: 0.045039, val loss: 0.110755 
 val auc: 0.990165,  test auc: 0.990193
epoch 710, loss: 0.044962
epoch 710, 
 train loss: 0.044962, val loss: 0.110798 
 val auc: 0.990203,  test auc: 0.990184
epoch 711, loss: 0.044883
epoch 711, 
 train loss: 0.044883, val loss: 0.110872 
 val auc: 0.990203,  test auc: 0.990203
epoch 712, loss: 0.044807
epoch 712, 
 train loss: 0.044807, val loss: 0.110786 
 val auc: 0.990203,  test auc: 0.990193
epoch 713, loss: 0.044727
epoch 713, 
 train loss: 0.044727, val loss: 0.110740 
 val auc: 0.990203,  test auc: 0.990231
epoch 714, loss: 0.044652
epoch 714, 
 train loss: 0.044652, val loss: 0.110786 
 val auc: 0.990203,  test auc: 0.990231
epoch 715, loss: 0.044574
model updated at epoch 715 
epoch 715, 
 train loss: 0.044574, val loss: 0.110611 
 val auc: 0.990203,  test auc: 0.990231
epoch 716, loss: 0.044492
model updated at epoch 716 
epoch 716, 
 train loss: 0.044492, val loss: 0.110604 
 val auc: 0.990203,  test auc: 0.990231
epoch 717, loss: 0.044413
epoch 717, 
 train loss: 0.044413, val loss: 0.110720 
 val auc: 0.990203,  test auc: 0.990221
epoch 718, loss: 0.044324
model updated at epoch 718 
epoch 718, 
 train loss: 0.044324, val loss: 0.110603 
 val auc: 0.990240,  test auc: 0.990259
epoch 719, loss: 0.044229
epoch 719, 
 train loss: 0.044229, val loss: 0.110669 
 val auc: 0.990240,  test auc: 0.990250
epoch 720, loss: 0.044128
epoch 720, 
 train loss: 0.044128, val loss: 0.110817 
 val auc: 0.990203,  test auc: 0.990203
epoch 721, loss: 0.044028
model updated at epoch 721 
epoch 721, 
 train loss: 0.044028, val loss: 0.110596 
 val auc: 0.990240,  test auc: 0.990278
epoch 722, loss: 0.043937
model updated at epoch 722 
epoch 722, 
 train loss: 0.043937, val loss: 0.110564 
 val auc: 0.990240,  test auc: 0.990287
epoch 723, loss: 0.043849
epoch 723, 
 train loss: 0.043849, val loss: 0.110628 
 val auc: 0.990278,  test auc: 0.990343
epoch 724, loss: 0.043766
epoch 724, 
 train loss: 0.043766, val loss: 0.110722 
 val auc: 0.990240,  test auc: 0.990390
epoch 725, loss: 0.043686
model updated at epoch 725 
epoch 725, 
 train loss: 0.043686, val loss: 0.110552 
 val auc: 0.990240,  test auc: 0.990456
epoch 726, loss: 0.043615
model updated at epoch 726 
epoch 726, 
 train loss: 0.043615, val loss: 0.110450 
 val auc: 0.990278,  test auc: 0.990503
epoch 727, loss: 0.043543
epoch 727, 
 train loss: 0.043543, val loss: 0.110625 
 val auc: 0.990165,  test auc: 0.990494
epoch 728, loss: 0.043474
epoch 728, 
 train loss: 0.043474, val loss: 0.110743 
 val auc: 0.990203,  test auc: 0.990512
epoch 729, loss: 0.043399
epoch 729, 
 train loss: 0.043399, val loss: 0.110759 
 val auc: 0.990165,  test auc: 0.990503
epoch 730, loss: 0.043324
epoch 730, 
 train loss: 0.043324, val loss: 0.110698 
 val auc: 0.990165,  test auc: 0.990494
epoch 731, loss: 0.043251
epoch 731, 
 train loss: 0.043251, val loss: 0.110650 
 val auc: 0.990203,  test auc: 0.990522
epoch 732, loss: 0.043175
epoch 732, 
 train loss: 0.043175, val loss: 0.110541 
 val auc: 0.990240,  test auc: 0.990484
epoch 733, loss: 0.043106
epoch 733, 
 train loss: 0.043106, val loss: 0.110465 
 val auc: 0.990240,  test auc: 0.990475
epoch 734, loss: 0.043025
epoch 734, 
 train loss: 0.043025, val loss: 0.110451 
 val auc: 0.990240,  test auc: 0.990447
epoch 735, loss: 0.042954
model updated at epoch 735 
epoch 735, 
 train loss: 0.042954, val loss: 0.110444 
 val auc: 0.990240,  test auc: 0.990447
epoch 736, loss: 0.042882
model updated at epoch 736 
epoch 736, 
 train loss: 0.042882, val loss: 0.110385 
 val auc: 0.990315,  test auc: 0.990484
epoch 737, loss: 0.042805
model updated at epoch 737 
epoch 737, 
 train loss: 0.042805, val loss: 0.110299 
 val auc: 0.990203,  test auc: 0.990428
epoch 738, loss: 0.042733
epoch 738, 
 train loss: 0.042733, val loss: 0.110471 
 val auc: 0.990203,  test auc: 0.990428
epoch 739, loss: 0.042662
epoch 739, 
 train loss: 0.042662, val loss: 0.110607 
 val auc: 0.990203,  test auc: 0.990465
epoch 740, loss: 0.042587
epoch 740, 
 train loss: 0.042587, val loss: 0.110420 
 val auc: 0.990203,  test auc: 0.990465
epoch 741, loss: 0.042517
model updated at epoch 741 
epoch 741, 
 train loss: 0.042517, val loss: 0.110057 
 val auc: 0.990240,  test auc: 0.990465
epoch 742, loss: 0.042443
epoch 742, 
 train loss: 0.042443, val loss: 0.110095 
 val auc: 0.990315,  test auc: 0.990475
epoch 743, loss: 0.042373
epoch 743, 
 train loss: 0.042373, val loss: 0.110280 
 val auc: 0.990353,  test auc: 0.990522
epoch 744, loss: 0.042304
epoch 744, 
 train loss: 0.042304, val loss: 0.110323 
 val auc: 0.990503,  test auc: 0.990559
epoch 745, loss: 0.042233
epoch 745, 
 train loss: 0.042233, val loss: 0.110314 
 val auc: 0.990503,  test auc: 0.990597
epoch 746, loss: 0.042163
epoch 746, 
 train loss: 0.042163, val loss: 0.110214 
 val auc: 0.990503,  test auc: 0.990597
epoch 747, loss: 0.042095
epoch 747, 
 train loss: 0.042095, val loss: 0.110182 
 val auc: 0.990465,  test auc: 0.990606
epoch 748, loss: 0.042025
epoch 748, 
 train loss: 0.042025, val loss: 0.110253 
 val auc: 0.990465,  test auc: 0.990616
epoch 749, loss: 0.041956
epoch 749, 
 train loss: 0.041956, val loss: 0.110441 
 val auc: 0.990503,  test auc: 0.990634
epoch 750, loss: 0.041887
epoch 750, 
 train loss: 0.041887, val loss: 0.110584 
 val auc: 0.990465,  test auc: 0.990616
epoch 751, loss: 0.041819
epoch 751, 
 train loss: 0.041819, val loss: 0.110292 
 val auc: 0.990465,  test auc: 0.990634
epoch 752, loss: 0.041750
epoch 752, 
 train loss: 0.041750, val loss: 0.110129 
 val auc: 0.990465,  test auc: 0.990634
epoch 753, loss: 0.041684
epoch 753, 
 train loss: 0.041684, val loss: 0.110095 
 val auc: 0.990541,  test auc: 0.990672
epoch 754, loss: 0.041613
model updated at epoch 754 
epoch 754, 
 train loss: 0.041613, val loss: 0.110003 
 val auc: 0.990503,  test auc: 0.990644
epoch 755, loss: 0.041549
epoch 755, 
 train loss: 0.041549, val loss: 0.110201 
 val auc: 0.990503,  test auc: 0.990644
epoch 756, loss: 0.041484
epoch 756, 
 train loss: 0.041484, val loss: 0.110171 
 val auc: 0.990541,  test auc: 0.990634
epoch 757, loss: 0.041414
model updated at epoch 757 
epoch 757, 
 train loss: 0.041414, val loss: 0.109966 
 val auc: 0.990465,  test auc: 0.990644
epoch 758, loss: 0.041348
model updated at epoch 758 
epoch 758, 
 train loss: 0.041348, val loss: 0.109801 
 val auc: 0.990503,  test auc: 0.990663
epoch 759, loss: 0.041282
epoch 759, 
 train loss: 0.041282, val loss: 0.109885 
 val auc: 0.990503,  test auc: 0.990700
epoch 760, loss: 0.041215
epoch 760, 
 train loss: 0.041215, val loss: 0.110030 
 val auc: 0.990503,  test auc: 0.990672
epoch 761, loss: 0.041148
epoch 761, 
 train loss: 0.041148, val loss: 0.110172 
 val auc: 0.990578,  test auc: 0.990681
epoch 762, loss: 0.041082
epoch 762, 
 train loss: 0.041082, val loss: 0.110303 
 val auc: 0.990541,  test auc: 0.990653
epoch 763, loss: 0.041016
epoch 763, 
 train loss: 0.041016, val loss: 0.110098 
 val auc: 0.990503,  test auc: 0.990663
epoch 764, loss: 0.040956
model updated at epoch 764 
epoch 764, 
 train loss: 0.040956, val loss: 0.109696 
 val auc: 0.990616,  test auc: 0.990691
epoch 765, loss: 0.040890
epoch 765, 
 train loss: 0.040890, val loss: 0.109867 
 val auc: 0.990653,  test auc: 0.990728
epoch 766, loss: 0.040820
epoch 766, 
 train loss: 0.040820, val loss: 0.110294 
 val auc: 0.990541,  test auc: 0.990663
epoch 767, loss: 0.040761
epoch 767, 
 train loss: 0.040761, val loss: 0.110476 
 val auc: 0.990541,  test auc: 0.990709
epoch 768, loss: 0.040690
epoch 768, 
 train loss: 0.040690, val loss: 0.110123 
 val auc: 0.990616,  test auc: 0.990719
epoch 769, loss: 0.040629
epoch 769, 
 train loss: 0.040629, val loss: 0.109798 
 val auc: 0.990728,  test auc: 0.990756
epoch 770, loss: 0.040563
epoch 770, 
 train loss: 0.040563, val loss: 0.109802 
 val auc: 0.990653,  test auc: 0.990747
epoch 771, loss: 0.040500
epoch 771, 
 train loss: 0.040500, val loss: 0.110116 
 val auc: 0.990691,  test auc: 0.990766
epoch 772, loss: 0.040435
epoch 772, 
 train loss: 0.040435, val loss: 0.110261 
 val auc: 0.990691,  test auc: 0.990747
epoch 773, loss: 0.040371
epoch 773, 
 train loss: 0.040371, val loss: 0.110013 
 val auc: 0.990728,  test auc: 0.990756
epoch 774, loss: 0.040305
epoch 774, 
 train loss: 0.040305, val loss: 0.109861 
 val auc: 0.990691,  test auc: 0.990785
epoch 775, loss: 0.040242
epoch 775, 
 train loss: 0.040242, val loss: 0.109946 
 val auc: 0.990653,  test auc: 0.990775
epoch 776, loss: 0.040177
epoch 776, 
 train loss: 0.040177, val loss: 0.109940 
 val auc: 0.990803,  test auc: 0.990813
epoch 777, loss: 0.040117
epoch 777, 
 train loss: 0.040117, val loss: 0.109981 
 val auc: 0.990803,  test auc: 0.990841
epoch 778, loss: 0.040050
epoch 778, 
 train loss: 0.040050, val loss: 0.109988 
 val auc: 0.990803,  test auc: 0.990860
epoch 779, loss: 0.039987
epoch 779, 
 train loss: 0.039987, val loss: 0.110038 
 val auc: 0.990841,  test auc: 0.990831
epoch 780, loss: 0.039927
epoch 780, 
 train loss: 0.039927, val loss: 0.110018 
 val auc: 0.990803,  test auc: 0.990841
epoch 781, loss: 0.039865
epoch 781, 
 train loss: 0.039865, val loss: 0.109849 
 val auc: 0.990878,  test auc: 0.990888
epoch 782, loss: 0.039802
epoch 782, 
 train loss: 0.039802, val loss: 0.110062 
 val auc: 0.990878,  test auc: 0.990897
epoch 783, loss: 0.039735
epoch 783, 
 train loss: 0.039735, val loss: 0.110058 
 val auc: 0.990841,  test auc: 0.990878
epoch 784, loss: 0.039676
epoch 784, 
 train loss: 0.039676, val loss: 0.110018 
 val auc: 0.990878,  test auc: 0.990916
epoch 785, loss: 0.039611
epoch 785, 
 train loss: 0.039611, val loss: 0.109933 
 val auc: 0.990916,  test auc: 0.990907
epoch 786, loss: 0.039549
epoch 786, 
 train loss: 0.039549, val loss: 0.109961 
 val auc: 0.990953,  test auc: 0.990916
epoch 787, loss: 0.039488
epoch 787, 
 train loss: 0.039488, val loss: 0.110056 
 val auc: 0.990916,  test auc: 0.990935
epoch 788, loss: 0.039428
epoch 788, 
 train loss: 0.039428, val loss: 0.109901 
 val auc: 0.991029,  test auc: 0.990935
epoch 789, loss: 0.039369
epoch 789, 
 train loss: 0.039369, val loss: 0.110024 
 val auc: 0.990953,  test auc: 0.990925
epoch 790, loss: 0.039309
epoch 790, 
 train loss: 0.039309, val loss: 0.109748 
 val auc: 0.990991,  test auc: 0.990916
epoch 791, loss: 0.039244
epoch 791, 
 train loss: 0.039244, val loss: 0.109993 
 val auc: 0.990991,  test auc: 0.990935
epoch 792, loss: 0.039181
epoch 792, 
 train loss: 0.039181, val loss: 0.110091 
 val auc: 0.990991,  test auc: 0.990925
epoch 793, loss: 0.039124
epoch 793, 
 train loss: 0.039124, val loss: 0.110053 
 val auc: 0.991029,  test auc: 0.990944
epoch 794, loss: 0.039066
epoch 794, 
 train loss: 0.039066, val loss: 0.110049 
 val auc: 0.990991,  test auc: 0.990982
epoch 795, loss: 0.039004
epoch 795, 
 train loss: 0.039004, val loss: 0.109704 
 val auc: 0.991029,  test auc: 0.990972
epoch 796, loss: 0.038939
epoch 796, 
 train loss: 0.038939, val loss: 0.109832 
 val auc: 0.990991,  test auc: 0.990982
epoch 797, loss: 0.038880
epoch 797, 
 train loss: 0.038880, val loss: 0.109978 
 val auc: 0.990991,  test auc: 0.990982
epoch 798, loss: 0.038825
epoch 798, 
 train loss: 0.038825, val loss: 0.109764 
 val auc: 0.991066,  test auc: 0.991000
epoch 799, loss: 0.038765
epoch 799, 
 train loss: 0.038765, val loss: 0.109861 
 val auc: 0.990991,  test auc: 0.991019
epoch 800, loss: 0.038704
model updated at epoch 800 
epoch 800, 
 train loss: 0.038704, val loss: 0.109650 
 val auc: 0.991066,  test auc: 0.991019
epoch 801, loss: 0.038644
model updated at epoch 801 
epoch 801, 
 train loss: 0.038644, val loss: 0.109578 
 val auc: 0.991066,  test auc: 0.991066
epoch 802, loss: 0.038586
model updated at epoch 802 
epoch 802, 
 train loss: 0.038586, val loss: 0.109374 
 val auc: 0.991104,  test auc: 0.991075
epoch 803, loss: 0.038525
epoch 803, 
 train loss: 0.038525, val loss: 0.109660 
 val auc: 0.991066,  test auc: 0.991057
epoch 804, loss: 0.038468
epoch 804, 
 train loss: 0.038468, val loss: 0.110185 
 val auc: 0.991066,  test auc: 0.991066
epoch 805, loss: 0.038408
epoch 805, 
 train loss: 0.038408, val loss: 0.110020 
 val auc: 0.991066,  test auc: 0.991047
epoch 806, loss: 0.038348
epoch 806, 
 train loss: 0.038348, val loss: 0.109847 
 val auc: 0.991141,  test auc: 0.991085
epoch 807, loss: 0.038287
epoch 807, 
 train loss: 0.038287, val loss: 0.109568 
 val auc: 0.991141,  test auc: 0.991075
epoch 808, loss: 0.038232
epoch 808, 
 train loss: 0.038232, val loss: 0.109639 
 val auc: 0.991141,  test auc: 0.991085
epoch 809, loss: 0.038178
epoch 809, 
 train loss: 0.038178, val loss: 0.109905 
 val auc: 0.991141,  test auc: 0.991075
epoch 810, loss: 0.038125
epoch 810, 
 train loss: 0.038125, val loss: 0.109611 
 val auc: 0.991291,  test auc: 0.991132
epoch 811, loss: 0.038070
epoch 811, 
 train loss: 0.038070, val loss: 0.109885 
 val auc: 0.991141,  test auc: 0.991104
epoch 812, loss: 0.038005
epoch 812, 
 train loss: 0.038005, val loss: 0.109846 
 val auc: 0.991254,  test auc: 0.991113
epoch 813, loss: 0.037944
epoch 813, 
 train loss: 0.037944, val loss: 0.109891 
 val auc: 0.991254,  test auc: 0.991141
epoch 814, loss: 0.037892
epoch 814, 
 train loss: 0.037892, val loss: 0.109693 
 val auc: 0.991179,  test auc: 0.991151
epoch 815, loss: 0.037838
epoch 815, 
 train loss: 0.037838, val loss: 0.109528 
 val auc: 0.991254,  test auc: 0.991113
epoch 816, loss: 0.037776
epoch 816, 
 train loss: 0.037776, val loss: 0.109830 
 val auc: 0.991179,  test auc: 0.991113
epoch 817, loss: 0.037715
epoch 817, 
 train loss: 0.037715, val loss: 0.109553 
 val auc: 0.991254,  test auc: 0.991160
epoch 818, loss: 0.037657
model updated at epoch 818 
epoch 818, 
 train loss: 0.037657, val loss: 0.109244 
 val auc: 0.991329,  test auc: 0.991197
epoch 819, loss: 0.037605
model updated at epoch 819 
epoch 819, 
 train loss: 0.037605, val loss: 0.109231 
 val auc: 0.991404,  test auc: 0.991197
epoch 820, loss: 0.037548
epoch 820, 
 train loss: 0.037548, val loss: 0.109340 
 val auc: 0.991291,  test auc: 0.991179
epoch 821, loss: 0.037492
epoch 821, 
 train loss: 0.037492, val loss: 0.109656 
 val auc: 0.991254,  test auc: 0.991207
epoch 822, loss: 0.037439
epoch 822, 
 train loss: 0.037439, val loss: 0.109728 
 val auc: 0.991291,  test auc: 0.991151
epoch 823, loss: 0.037382
epoch 823, 
 train loss: 0.037382, val loss: 0.109387 
 val auc: 0.991291,  test auc: 0.991197
epoch 824, loss: 0.037323
epoch 824, 
 train loss: 0.037323, val loss: 0.109251 
 val auc: 0.991329,  test auc: 0.991207
epoch 825, loss: 0.037273
epoch 825, 
 train loss: 0.037273, val loss: 0.109371 
 val auc: 0.991329,  test auc: 0.991179
epoch 826, loss: 0.037217
epoch 826, 
 train loss: 0.037217, val loss: 0.109318 
 val auc: 0.991291,  test auc: 0.991207
epoch 827, loss: 0.037158
epoch 827, 
 train loss: 0.037158, val loss: 0.109448 
 val auc: 0.991366,  test auc: 0.991254
epoch 828, loss: 0.037107
epoch 828, 
 train loss: 0.037107, val loss: 0.109801 
 val auc: 0.991366,  test auc: 0.991216
epoch 829, loss: 0.037053
epoch 829, 
 train loss: 0.037053, val loss: 0.109536 
 val auc: 0.991329,  test auc: 0.991254
epoch 830, loss: 0.036995
epoch 830, 
 train loss: 0.036995, val loss: 0.109398 
 val auc: 0.991291,  test auc: 0.991226
epoch 831, loss: 0.036947
epoch 831, 
 train loss: 0.036947, val loss: 0.109495 
 val auc: 0.991329,  test auc: 0.991235
epoch 832, loss: 0.036890
epoch 832, 
 train loss: 0.036890, val loss: 0.109278 
 val auc: 0.991366,  test auc: 0.991282
epoch 833, loss: 0.036836
epoch 833, 
 train loss: 0.036836, val loss: 0.109577 
 val auc: 0.991329,  test auc: 0.991282
epoch 834, loss: 0.036783
epoch 834, 
 train loss: 0.036783, val loss: 0.109496 
 val auc: 0.991404,  test auc: 0.991254
epoch 835, loss: 0.036730
epoch 835, 
 train loss: 0.036730, val loss: 0.109594 
 val auc: 0.991329,  test auc: 0.991291
epoch 836, loss: 0.036674
epoch 836, 
 train loss: 0.036674, val loss: 0.109371 
 val auc: 0.991366,  test auc: 0.991319
epoch 837, loss: 0.036615
epoch 837, 
 train loss: 0.036615, val loss: 0.109343 
 val auc: 0.991479,  test auc: 0.991348
epoch 838, loss: 0.036562
epoch 838, 
 train loss: 0.036562, val loss: 0.109245 
 val auc: 0.991441,  test auc: 0.991376
epoch 839, loss: 0.036509
epoch 839, 
 train loss: 0.036509, val loss: 0.109295 
 val auc: 0.991479,  test auc: 0.991348
epoch 840, loss: 0.036457
epoch 840, 
 train loss: 0.036457, val loss: 0.109523 
 val auc: 0.991366,  test auc: 0.991348
epoch 841, loss: 0.036413
epoch 841, 
 train loss: 0.036413, val loss: 0.109314 
 val auc: 0.991479,  test auc: 0.991338
epoch 842, loss: 0.036364
epoch 842, 
 train loss: 0.036364, val loss: 0.109521 
 val auc: 0.991366,  test auc: 0.991338
epoch 843, loss: 0.036300
epoch 843, 
 train loss: 0.036300, val loss: 0.109414 
 val auc: 0.991441,  test auc: 0.991385
epoch 844, loss: 0.036244
epoch 844, 
 train loss: 0.036244, val loss: 0.109602 
 val auc: 0.991441,  test auc: 0.991385
epoch 845, loss: 0.036191
epoch 845, 
 train loss: 0.036191, val loss: 0.109410 
 val auc: 0.991329,  test auc: 0.991376
epoch 846, loss: 0.036141
epoch 846, 
 train loss: 0.036141, val loss: 0.109285 
 val auc: 0.991441,  test auc: 0.991385
epoch 847, loss: 0.036096
epoch 847, 
 train loss: 0.036096, val loss: 0.109518 
 val auc: 0.991404,  test auc: 0.991385
epoch 848, loss: 0.036051
epoch 848, 
 train loss: 0.036051, val loss: 0.109241 
 val auc: 0.991441,  test auc: 0.991395
epoch 849, loss: 0.036003
epoch 849, 
 train loss: 0.036003, val loss: 0.109378 
 val auc: 0.991404,  test auc: 0.991366
epoch 850, loss: 0.035938
epoch 850, 
 train loss: 0.035938, val loss: 0.109274 
 val auc: 0.991404,  test auc: 0.991376
epoch 851, loss: 0.035880
epoch 851, 
 train loss: 0.035880, val loss: 0.109385 
 val auc: 0.991404,  test auc: 0.991385
epoch 852, loss: 0.035838
epoch 852, 
 train loss: 0.035838, val loss: 0.109449 
 val auc: 0.991404,  test auc: 0.991385
epoch 853, loss: 0.035799
model updated at epoch 853 
epoch 853, 
 train loss: 0.035799, val loss: 0.109046 
 val auc: 0.991441,  test auc: 0.991395
epoch 854, loss: 0.035742
epoch 854, 
 train loss: 0.035742, val loss: 0.109069 
 val auc: 0.991441,  test auc: 0.991385
epoch 855, loss: 0.035678
model updated at epoch 855 
epoch 855, 
 train loss: 0.035678, val loss: 0.108802 
 val auc: 0.991554,  test auc: 0.991470
epoch 856, loss: 0.035621
epoch 856, 
 train loss: 0.035621, val loss: 0.108983 
 val auc: 0.991554,  test auc: 0.991470
epoch 857, loss: 0.035581
epoch 857, 
 train loss: 0.035581, val loss: 0.109184 
 val auc: 0.991517,  test auc: 0.991432
epoch 858, loss: 0.035539
epoch 858, 
 train loss: 0.035539, val loss: 0.108977 
 val auc: 0.991629,  test auc: 0.991498
epoch 859, loss: 0.035490
epoch 859, 
 train loss: 0.035490, val loss: 0.109251 
 val auc: 0.991554,  test auc: 0.991441
epoch 860, loss: 0.035434
model updated at epoch 860 
epoch 860, 
 train loss: 0.035434, val loss: 0.108775 
 val auc: 0.991592,  test auc: 0.991507
epoch 861, loss: 0.035376
epoch 861, 
 train loss: 0.035376, val loss: 0.109014 
 val auc: 0.991629,  test auc: 0.991498
epoch 862, loss: 0.035323
epoch 862, 
 train loss: 0.035323, val loss: 0.109217 
 val auc: 0.991629,  test auc: 0.991526
epoch 863, loss: 0.035278
epoch 863, 
 train loss: 0.035278, val loss: 0.109142 
 val auc: 0.991667,  test auc: 0.991554
epoch 864, loss: 0.035228
epoch 864, 
 train loss: 0.035228, val loss: 0.109234 
 val auc: 0.991592,  test auc: 0.991517
epoch 865, loss: 0.035181
epoch 865, 
 train loss: 0.035181, val loss: 0.108858 
 val auc: 0.991629,  test auc: 0.991535
epoch 866, loss: 0.035129
epoch 866, 
 train loss: 0.035129, val loss: 0.108951 
 val auc: 0.991629,  test auc: 0.991535
epoch 867, loss: 0.035078
epoch 867, 
 train loss: 0.035078, val loss: 0.109083 
 val auc: 0.991704,  test auc: 0.991545
epoch 868, loss: 0.035030
epoch 868, 
 train loss: 0.035030, val loss: 0.108782 
 val auc: 0.991667,  test auc: 0.991554
epoch 869, loss: 0.034990
epoch 869, 
 train loss: 0.034990, val loss: 0.108910 
 val auc: 0.991629,  test auc: 0.991535
epoch 870, loss: 0.034958
epoch 870, 
 train loss: 0.034958, val loss: 0.108986 
 val auc: 0.991629,  test auc: 0.991535
epoch 871, loss: 0.034923
epoch 871, 
 train loss: 0.034923, val loss: 0.109298 
 val auc: 0.991592,  test auc: 0.991517
epoch 872, loss: 0.034864
epoch 872, 
 train loss: 0.034864, val loss: 0.108903 
 val auc: 0.991629,  test auc: 0.991535
epoch 873, loss: 0.034798
epoch 873, 
 train loss: 0.034798, val loss: 0.109019 
 val auc: 0.991592,  test auc: 0.991498
epoch 874, loss: 0.034740
model updated at epoch 874 
epoch 874, 
 train loss: 0.034740, val loss: 0.108769 
 val auc: 0.991592,  test auc: 0.991526
epoch 875, loss: 0.034696
epoch 875, 
 train loss: 0.034696, val loss: 0.108894 
 val auc: 0.991592,  test auc: 0.991535
epoch 876, loss: 0.034655
epoch 876, 
 train loss: 0.034655, val loss: 0.108936 
 val auc: 0.991592,  test auc: 0.991535
epoch 877, loss: 0.034616
model updated at epoch 877 
epoch 877, 
 train loss: 0.034616, val loss: 0.108353 
 val auc: 0.991592,  test auc: 0.991554
epoch 878, loss: 0.034563
epoch 878, 
 train loss: 0.034563, val loss: 0.108637 
 val auc: 0.991667,  test auc: 0.991592
epoch 879, loss: 0.034505
epoch 879, 
 train loss: 0.034505, val loss: 0.108624 
 val auc: 0.991704,  test auc: 0.991582
epoch 880, loss: 0.034448
epoch 880, 
 train loss: 0.034448, val loss: 0.108684 
 val auc: 0.991667,  test auc: 0.991610
epoch 881, loss: 0.034399
epoch 881, 
 train loss: 0.034399, val loss: 0.108531 
 val auc: 0.991704,  test auc: 0.991610
epoch 882, loss: 0.034355
epoch 882, 
 train loss: 0.034355, val loss: 0.108466 
 val auc: 0.991629,  test auc: 0.991582
epoch 883, loss: 0.034308
epoch 883, 
 train loss: 0.034308, val loss: 0.108674 
 val auc: 0.991629,  test auc: 0.991601
epoch 884, loss: 0.034263
epoch 884, 
 train loss: 0.034263, val loss: 0.108705 
 val auc: 0.991629,  test auc: 0.991582
epoch 885, loss: 0.034212
epoch 885, 
 train loss: 0.034212, val loss: 0.108919 
 val auc: 0.991629,  test auc: 0.991592
epoch 886, loss: 0.034161
epoch 886, 
 train loss: 0.034161, val loss: 0.108526 
 val auc: 0.991629,  test auc: 0.991592
epoch 887, loss: 0.034108
epoch 887, 
 train loss: 0.034108, val loss: 0.108680 
 val auc: 0.991629,  test auc: 0.991610
epoch 888, loss: 0.034057
epoch 888, 
 train loss: 0.034057, val loss: 0.108869 
 val auc: 0.991592,  test auc: 0.991592
epoch 889, loss: 0.033999
epoch 889, 
 train loss: 0.033999, val loss: 0.108733 
 val auc: 0.991629,  test auc: 0.991620
epoch 890, loss: 0.033939
epoch 890, 
 train loss: 0.033939, val loss: 0.108534 
 val auc: 0.991667,  test auc: 0.991601
epoch 891, loss: 0.033870
epoch 891, 
 train loss: 0.033870, val loss: 0.108522 
 val auc: 0.991667,  test auc: 0.991610
epoch 892, loss: 0.033794
epoch 892, 
 train loss: 0.033794, val loss: 0.108617 
 val auc: 0.991704,  test auc: 0.991629
epoch 893, loss: 0.033716
epoch 893, 
 train loss: 0.033716, val loss: 0.108552 
 val auc: 0.991704,  test auc: 0.991657
epoch 894, loss: 0.033658
epoch 894, 
 train loss: 0.033658, val loss: 0.108539 
 val auc: 0.991704,  test auc: 0.991667
epoch 895, loss: 0.033613
epoch 895, 
 train loss: 0.033613, val loss: 0.108474 
 val auc: 0.991817,  test auc: 0.991685
epoch 896, loss: 0.033573
epoch 896, 
 train loss: 0.033573, val loss: 0.108682 
 val auc: 0.991704,  test auc: 0.991648
epoch 897, loss: 0.033525
model updated at epoch 897 
epoch 897, 
 train loss: 0.033525, val loss: 0.108292 
 val auc: 0.991779,  test auc: 0.991667
epoch 898, loss: 0.033474
epoch 898, 
 train loss: 0.033474, val loss: 0.108464 
 val auc: 0.991742,  test auc: 0.991629
epoch 899, loss: 0.033421
model updated at epoch 899 
epoch 899, 
 train loss: 0.033421, val loss: 0.108192 
 val auc: 0.991779,  test auc: 0.991685
epoch 900, loss: 0.033368
epoch 900, 
 train loss: 0.033368, val loss: 0.108544 
 val auc: 0.991704,  test auc: 0.991667
epoch 901, loss: 0.033322
epoch 901, 
 train loss: 0.033322, val loss: 0.108766 
 val auc: 0.991667,  test auc: 0.991667
epoch 902, loss: 0.033280
epoch 902, 
 train loss: 0.033280, val loss: 0.108419 
 val auc: 0.991742,  test auc: 0.991695
epoch 903, loss: 0.033237
epoch 903, 
 train loss: 0.033237, val loss: 0.108538 
 val auc: 0.991742,  test auc: 0.991657
epoch 904, loss: 0.033198
epoch 904, 
 train loss: 0.033198, val loss: 0.108448 
 val auc: 0.991742,  test auc: 0.991620
epoch 905, loss: 0.033168
epoch 905, 
 train loss: 0.033168, val loss: 0.108686 
 val auc: 0.991704,  test auc: 0.991685
epoch 906, loss: 0.033117
epoch 906, 
 train loss: 0.033117, val loss: 0.108407 
 val auc: 0.991854,  test auc: 0.991667
epoch 907, loss: 0.033054
epoch 907, 
 train loss: 0.033054, val loss: 0.108365 
 val auc: 0.991779,  test auc: 0.991714
epoch 908, loss: 0.032987
model updated at epoch 908 
epoch 908, 
 train loss: 0.032987, val loss: 0.108155 
 val auc: 0.991817,  test auc: 0.991732
epoch 909, loss: 0.032923
epoch 909, 
 train loss: 0.032923, val loss: 0.108437 
 val auc: 0.991854,  test auc: 0.991723
epoch 910, loss: 0.032858
epoch 910, 
 train loss: 0.032858, val loss: 0.108499 
 val auc: 0.991704,  test auc: 0.991732
epoch 911, loss: 0.032809
model updated at epoch 911 
epoch 911, 
 train loss: 0.032809, val loss: 0.108001 
 val auc: 0.991854,  test auc: 0.991789
epoch 912, loss: 0.032771
epoch 912, 
 train loss: 0.032771, val loss: 0.108567 
 val auc: 0.991704,  test auc: 0.991761
epoch 913, loss: 0.032727
epoch 913, 
 train loss: 0.032727, val loss: 0.108421 
 val auc: 0.991929,  test auc: 0.991742
epoch 914, loss: 0.032676
epoch 914, 
 train loss: 0.032676, val loss: 0.108769 
 val auc: 0.991742,  test auc: 0.991761
epoch 915, loss: 0.032602
epoch 915, 
 train loss: 0.032602, val loss: 0.108208 
 val auc: 0.991892,  test auc: 0.991779
epoch 916, loss: 0.032539
epoch 916, 
 train loss: 0.032539, val loss: 0.108336 
 val auc: 0.991892,  test auc: 0.991761
epoch 917, loss: 0.032491
epoch 917, 
 train loss: 0.032491, val loss: 0.108328 
 val auc: 0.991854,  test auc: 0.991770
epoch 918, loss: 0.032458
epoch 918, 
 train loss: 0.032458, val loss: 0.108300 
 val auc: 0.991892,  test auc: 0.991789
epoch 919, loss: 0.032425
epoch 919, 
 train loss: 0.032425, val loss: 0.108387 
 val auc: 0.991817,  test auc: 0.991770
epoch 920, loss: 0.032384
model updated at epoch 920 
epoch 920, 
 train loss: 0.032384, val loss: 0.107805 
 val auc: 0.991929,  test auc: 0.991845
epoch 921, loss: 0.032338
epoch 921, 
 train loss: 0.032338, val loss: 0.108248 
 val auc: 0.991817,  test auc: 0.991798
epoch 922, loss: 0.032286
epoch 922, 
 train loss: 0.032286, val loss: 0.108456 
 val auc: 0.991817,  test auc: 0.991770
epoch 923, loss: 0.032236
epoch 923, 
 train loss: 0.032236, val loss: 0.108363 
 val auc: 0.991817,  test auc: 0.991807
epoch 924, loss: 0.032195
epoch 924, 
 train loss: 0.032195, val loss: 0.108209 
 val auc: 0.991929,  test auc: 0.991817
epoch 925, loss: 0.032152
epoch 925, 
 train loss: 0.032152, val loss: 0.108326 
 val auc: 0.991892,  test auc: 0.991798
epoch 926, loss: 0.032118
epoch 926, 
 train loss: 0.032118, val loss: 0.108799 
 val auc: 0.991854,  test auc: 0.991761
epoch 927, loss: 0.032071
epoch 927, 
 train loss: 0.032071, val loss: 0.108439 
 val auc: 0.991892,  test auc: 0.991798
epoch 928, loss: 0.032024
epoch 928, 
 train loss: 0.032024, val loss: 0.108309 
 val auc: 0.991929,  test auc: 0.991845
epoch 929, loss: 0.031978
epoch 929, 
 train loss: 0.031978, val loss: 0.108374 
 val auc: 0.991929,  test auc: 0.991836
epoch 930, loss: 0.031938
epoch 930, 
 train loss: 0.031938, val loss: 0.108455 
 val auc: 0.991929,  test auc: 0.991807
epoch 931, loss: 0.031902
epoch 931, 
 train loss: 0.031902, val loss: 0.108437 
 val auc: 0.991854,  test auc: 0.991817
epoch 932, loss: 0.031869
epoch 932, 
 train loss: 0.031869, val loss: 0.108068 
 val auc: 0.991929,  test auc: 0.991826
epoch 933, loss: 0.031840
epoch 933, 
 train loss: 0.031840, val loss: 0.108456 
 val auc: 0.991929,  test auc: 0.991854
epoch 934, loss: 0.031790
epoch 934, 
 train loss: 0.031790, val loss: 0.108679 
 val auc: 0.991854,  test auc: 0.991845
epoch 935, loss: 0.031739
epoch 935, 
 train loss: 0.031739, val loss: 0.109062 
 val auc: 0.991854,  test auc: 0.991854
epoch 936, loss: 0.031688
epoch 936, 
 train loss: 0.031688, val loss: 0.108512 
 val auc: 0.991892,  test auc: 0.991854
epoch 937, loss: 0.031648
epoch 937, 
 train loss: 0.031648, val loss: 0.108284 
 val auc: 0.991892,  test auc: 0.991883
epoch 938, loss: 0.031616
epoch 938, 
 train loss: 0.031616, val loss: 0.108610 
 val auc: 0.991854,  test auc: 0.991845
epoch 939, loss: 0.031584
epoch 939, 
 train loss: 0.031584, val loss: 0.108514 
 val auc: 0.991929,  test auc: 0.991864
epoch 940, loss: 0.031541
epoch 940, 
 train loss: 0.031541, val loss: 0.108664 
 val auc: 0.991892,  test auc: 0.991864
epoch 941, loss: 0.031492
epoch 941, 
 train loss: 0.031492, val loss: 0.108581 
 val auc: 0.991892,  test auc: 0.991836
epoch 942, loss: 0.031444
epoch 942, 
 train loss: 0.031444, val loss: 0.108773 
 val auc: 0.991929,  test auc: 0.991901
epoch 943, loss: 0.031407
epoch 943, 
 train loss: 0.031407, val loss: 0.108785 
 val auc: 0.991929,  test auc: 0.991873
epoch 944, loss: 0.031374
epoch 944, 
 train loss: 0.031374, val loss: 0.108517 
 val auc: 0.991967,  test auc: 0.991911
epoch 945, loss: 0.031348
epoch 945, 
 train loss: 0.031348, val loss: 0.108796 
 val auc: 0.991892,  test auc: 0.991873
epoch 946, loss: 0.031316
epoch 946, 
 train loss: 0.031316, val loss: 0.108748 
 val auc: 0.992005,  test auc: 0.991892
epoch 947, loss: 0.031283
epoch 947, 
 train loss: 0.031283, val loss: 0.109278 
 val auc: 0.991892,  test auc: 0.991901
epoch 948, loss: 0.031248
epoch 948, 
 train loss: 0.031248, val loss: 0.108727 
 val auc: 0.992005,  test auc: 0.991873
epoch 949, loss: 0.031208
epoch 949, 
 train loss: 0.031208, val loss: 0.108941 
 val auc: 0.991892,  test auc: 0.991864
epoch 950, loss: 0.031151
epoch 950, 
 train loss: 0.031151, val loss: 0.108615 
 val auc: 0.991967,  test auc: 0.991864
epoch 951, loss: 0.031099
epoch 951, 
 train loss: 0.031099, val loss: 0.108878 
 val auc: 0.991929,  test auc: 0.991892
epoch 952, loss: 0.031058
epoch 952, 
 train loss: 0.031058, val loss: 0.108791 
 val auc: 0.991929,  test auc: 0.991920
epoch 953, loss: 0.031029
epoch 953, 
 train loss: 0.031029, val loss: 0.108735 
 val auc: 0.991929,  test auc: 0.991911
epoch 954, loss: 0.030997
epoch 954, 
 train loss: 0.030997, val loss: 0.109070 
 val auc: 0.991892,  test auc: 0.991920
epoch 955, loss: 0.030955
epoch 955, 
 train loss: 0.030955, val loss: 0.108695 
 val auc: 0.992005,  test auc: 0.991901
epoch 956, loss: 0.030908
epoch 956, 
 train loss: 0.030908, val loss: 0.108564 
 val auc: 0.991929,  test auc: 0.991911
epoch 957, loss: 0.030858
epoch 957, 
 train loss: 0.030858, val loss: 0.108466 
 val auc: 0.991929,  test auc: 0.991920
epoch 958, loss: 0.030828
epoch 958, 
 train loss: 0.030828, val loss: 0.108819 
 val auc: 0.991929,  test auc: 0.991873
epoch 959, loss: 0.030799
epoch 959, 
 train loss: 0.030799, val loss: 0.109157 
 val auc: 0.991892,  test auc: 0.991883
epoch 960, loss: 0.030755
epoch 960, 
 train loss: 0.030755, val loss: 0.108973 
 val auc: 0.991967,  test auc: 0.991892
epoch 961, loss: 0.030713
epoch 961, 
 train loss: 0.030713, val loss: 0.109116 
 val auc: 0.991892,  test auc: 0.991892
epoch 962, loss: 0.030675
epoch 962, 
 train loss: 0.030675, val loss: 0.108975 
 val auc: 0.991967,  test auc: 0.991883
epoch 963, loss: 0.030630
epoch 963, 
 train loss: 0.030630, val loss: 0.108990 
 val auc: 0.991929,  test auc: 0.991920
epoch 964, loss: 0.030594
epoch 964, 
 train loss: 0.030594, val loss: 0.109054 
 val auc: 0.991892,  test auc: 0.991901
epoch 965, loss: 0.030570
epoch 965, 
 train loss: 0.030570, val loss: 0.109122 
 val auc: 0.992005,  test auc: 0.991911
epoch 966, loss: 0.030561
epoch 966, 
 train loss: 0.030561, val loss: 0.109603 
 val auc: 0.991929,  test auc: 0.991929
epoch 967, loss: 0.030558
epoch 967, 
 train loss: 0.030558, val loss: 0.109301 
 val auc: 0.991967,  test auc: 0.991836
epoch 968, loss: 0.030534
epoch 968, 
 train loss: 0.030534, val loss: 0.109778 
 val auc: 0.991967,  test auc: 0.991911
epoch 969, loss: 0.030470
epoch 969, 
 train loss: 0.030470, val loss: 0.108931 
 val auc: 0.991892,  test auc: 0.991807
epoch 970, loss: 0.030390
epoch 970, 
 train loss: 0.030390, val loss: 0.109331 
 val auc: 0.991929,  test auc: 0.991883
epoch 971, loss: 0.030345
epoch 971, 
 train loss: 0.030345, val loss: 0.109192 
 val auc: 0.991967,  test auc: 0.991929
epoch 972, loss: 0.030341
epoch 972, 
 train loss: 0.030341, val loss: 0.108775 
 val auc: 0.992042,  test auc: 0.991929
epoch 973, loss: 0.030327
epoch 973, 
 train loss: 0.030327, val loss: 0.109733 
 val auc: 0.992005,  test auc: 0.991958
epoch 974, loss: 0.030280
epoch 974, 
 train loss: 0.030280, val loss: 0.109367 
 val auc: 0.992005,  test auc: 0.991929
epoch 975, loss: 0.030212
epoch 975, 
 train loss: 0.030212, val loss: 0.109514 
 val auc: 0.991967,  test auc: 0.991929
epoch 976, loss: 0.030157
epoch 976, 
 train loss: 0.030157, val loss: 0.108880 
 val auc: 0.991967,  test auc: 0.991901
epoch 977, loss: 0.030125
epoch 977, 
 train loss: 0.030125, val loss: 0.108749 
 val auc: 0.991967,  test auc: 0.991873
epoch 978, loss: 0.030096
epoch 978, 
 train loss: 0.030096, val loss: 0.109138 
 val auc: 0.991967,  test auc: 0.991939
epoch 979, loss: 0.030072
epoch 979, 
 train loss: 0.030072, val loss: 0.109258 
 val auc: 0.991929,  test auc: 0.991929
epoch 980, loss: 0.030030
epoch 980, 
 train loss: 0.030030, val loss: 0.109751 
 val auc: 0.992005,  test auc: 0.991967
epoch 981, loss: 0.029979
epoch 981, 
 train loss: 0.029979, val loss: 0.109268 
 val auc: 0.992042,  test auc: 0.991939
epoch 982, loss: 0.029929
epoch 982, 
 train loss: 0.029929, val loss: 0.109355 
 val auc: 0.992042,  test auc: 0.991948
epoch 983, loss: 0.029897
epoch 983, 
 train loss: 0.029897, val loss: 0.109669 
 val auc: 0.991967,  test auc: 0.991920
epoch 984, loss: 0.029864
epoch 984, 
 train loss: 0.029864, val loss: 0.109492 
 val auc: 0.991929,  test auc: 0.991897
epoch 985, loss: 0.029835
epoch 985, 
 train loss: 0.029835, val loss: 0.109661 
 val auc: 0.991948,  test auc: 0.991944
epoch 986, loss: 0.029811
epoch 986, 
 train loss: 0.029811, val loss: 0.109602 
 val auc: 0.991967,  test auc: 0.991892
epoch 987, loss: 0.029780
epoch 987, 
 train loss: 0.029780, val loss: 0.110127 
 val auc: 0.991967,  test auc: 0.991948
epoch 988, loss: 0.029732
epoch 988, 
 train loss: 0.029732, val loss: 0.109753 
 val auc: 0.991967,  test auc: 0.991911
epoch 989, loss: 0.029685
epoch 989, 
 train loss: 0.029685, val loss: 0.109895 
 val auc: 0.991929,  test auc: 0.991920
epoch 990, loss: 0.029645
epoch 990, 
 train loss: 0.029645, val loss: 0.109643 
 val auc: 0.991967,  test auc: 0.991892
epoch 991, loss: 0.029610
epoch 991, 
 train loss: 0.029610, val loss: 0.109395 
 val auc: 0.991967,  test auc: 0.991883
epoch 992, loss: 0.029577
epoch 992, 
 train loss: 0.029577, val loss: 0.109743 
 val auc: 0.991967,  test auc: 0.991939
epoch 993, loss: 0.029540
epoch 993, 
 train loss: 0.029540, val loss: 0.109651 
 val auc: 0.991967,  test auc: 0.991901
epoch 994, loss: 0.029503
epoch 994, 
 train loss: 0.029503, val loss: 0.109730 
 val auc: 0.991967,  test auc: 0.991929
epoch 995, loss: 0.029465
epoch 995, 
 train loss: 0.029465, val loss: 0.109746 
 val auc: 0.991967,  test auc: 0.991892
epoch 996, loss: 0.029428
epoch 996, 
 train loss: 0.029428, val loss: 0.109840 
 val auc: 0.991929,  test auc: 0.991920
epoch 997, loss: 0.029390
epoch 997, 
 train loss: 0.029390, val loss: 0.109901 
 val auc: 0.991967,  test auc: 0.991939
epoch 998, loss: 0.029361
epoch 998, 
 train loss: 0.029361, val loss: 0.109954 
 val auc: 0.991967,  test auc: 0.991901
epoch 999, loss: 0.029335
epoch 999, 
 train loss: 0.029335, val loss: 0.110133 
 val auc: 0.991929,  test auc: 0.991920
AUC: 0.991845
